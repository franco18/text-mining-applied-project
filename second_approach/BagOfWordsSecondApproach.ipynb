{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from Word2VecUtility import Word2VecUtility\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/juanespe/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/juanespe/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(['stopwords','wordnet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_txt = glob.glob(\"../data/papers-txt/*.txt\")\n",
    "clean_train_words = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juanespe/projects/master_on_data_science/fundamentos_en_ciencias_de_los_datos/text-mining-applied-project/second_approach/Word2VecUtility.py:28: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 28 of the file /Users/juanespe/projects/master_on_data_science/fundamentos_en_ciencias_de_los_datos/text-mining-applied-project/second_approach/Word2VecUtility.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  review_text = BeautifulSoup(review).get_text()\n"
     ]
    }
   ],
   "source": [
    "for file in files_txt:\n",
    "    #Leer Informacion\n",
    "    input_file = open(file,\"r\",encoding='utf-8')\n",
    "    texto = input_file.read()\n",
    "    clean_train_words.append(\" \".join(Word2VecUtility.review_to_wordlist(texto)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_features = vectorizer.fit_transform(clean_train_words)\n",
    "\n",
    "# Numpy arrays are easy to work with, so convert the result to an\n",
    "# array\n",
    "mat = np.asarray(train_data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 9676)\t1\n",
      "  (0, 13351)\t1\n",
      "  (0, 5733)\t1\n",
      "  (0, 3522)\t1\n",
      "  (0, 13124)\t1\n",
      "  (0, 54)\t1\n",
      "  (0, 1691)\t1\n",
      "  (0, 6598)\t1\n",
      "  (0, 3717)\t1\n",
      "  (0, 6330)\t1\n",
      "  (0, 4537)\t1\n",
      "  (0, 2102)\t1\n",
      "  (0, 1356)\t1\n",
      "  (0, 1710)\t2\n",
      "  (0, 1147)\t2\n",
      "  (0, 5814)\t1\n",
      "  (0, 9898)\t2\n",
      "  (0, 5805)\t2\n",
      "  (0, 7027)\t1\n",
      "  (0, 3241)\t1\n",
      "  (0, 1146)\t1\n",
      "  (0, 3991)\t1\n",
      "  (0, 5543)\t1\n",
      "  (0, 14174)\t3\n",
      "  (0, 1694)\t1\n",
      "  :\t:\n",
      "  (979, 1465)\t2\n",
      "  (979, 2368)\t13\n",
      "  (979, 4259)\t1\n",
      "  (979, 8104)\t3\n",
      "  (979, 8272)\t3\n",
      "  (979, 11357)\t1\n",
      "  (979, 4186)\t3\n",
      "  (979, 4586)\t11\n",
      "  (979, 10464)\t2\n",
      "  (979, 7573)\t27\n",
      "  (979, 5450)\t7\n",
      "  (979, 5914)\t1\n",
      "  (979, 9373)\t9\n",
      "  (979, 541)\t5\n",
      "  (979, 14090)\t22\n",
      "  (979, 11837)\t4\n",
      "  (979, 5646)\t1\n",
      "  (979, 4321)\t1\n",
      "  (979, 11304)\t25\n",
      "  (979, 12742)\t40\n",
      "  (979, 4568)\t8\n",
      "  (979, 802)\t1\n",
      "  (979, 46)\t1\n",
      "  (979, 12357)\t4\n",
      "  (979, 6317)\t2\n"
     ]
    }
   ],
   "source": [
    "print(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14318"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
