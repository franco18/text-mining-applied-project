{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob # libreria para extraer la rurta de los archivos\n",
    "import re # libreria para manejos de expresiones regulares\n",
    "import collections #### para poder contar los hash\n",
    "import pandas as pd # libreria para manejo de bases datos\n",
    "import numpy as np # libreria para manejo de vectores y arreglos\n",
    "from nltk.corpus import stopwords, wordnet # importa las stop words y las palabras del ingles\n",
    "from nltk.stem.porter import PorterStemmer # metodo para stemming\n",
    "from nltk.stem.lancaster import LancasterStemmer # metodo para stemming\n",
    "from nltk.stem import WordNetLemmatizer # metodo para lematizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-a3905452798f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mtexto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[^A-Za-z0-9]+'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtexto\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# solo permanecen los elementos alfanumericos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtexto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Realiza la tokenizacion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynsets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# deja solo las palabras asociadas al ingles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mstemmer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# instancia una forma de stemming\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m#stemmer2 = LancasterStemmer() # instancia una forma de stemming\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-80-a3905452798f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mtexto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[^A-Za-z0-9]+'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtexto\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# solo permanecen los elementos alfanumericos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtexto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Realiza la tokenizacion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynsets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# deja solo las palabras asociadas al ingles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mstemmer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# instancia una forma de stemming\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m#stemmer2 = LancasterStemmer() # instancia una forma de stemming\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36msynsets\u001b[0;34m(self, lemma, pos, lang, check_exceptions)\u001b[0m\n\u001b[1;32m   1585\u001b[0m             return [\n\u001b[1;32m   1586\u001b[0m                 \u001b[0mget_synset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1587\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1588\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_morphy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_exceptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1589\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mform\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1586\u001b[0m                 \u001b[0mget_synset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1587\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1588\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_morphy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_exceptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1589\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mform\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1590\u001b[0m             ]\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36m_morphy\u001b[0;34m(self, form, pos, check_exceptions)\u001b[0m\n\u001b[1;32m   1913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1914\u001b[0m         \u001b[0;31m# 2. Return all that are in the database (and check the original too)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1915\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_forms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mform\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Read Files\n",
    "files_txt = glob.glob(\"/opt/datasets/mcda-pi1-20191/papers-txt/*.txt\")\n",
    "\n",
    "# instanciar la clase para lematizar\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "# llamamos al diccionario de stop words en ingles\n",
    "sw = stopwords.words(\"english\")\n",
    "\n",
    "# Recorre los archivos para generar el bag of words\n",
    "bag_of_words = {} # creacion de la estructura de datos (diccionario) para almacenar el bag of words\n",
    "for file in files_txt:\n",
    "    input_file = open(file,\"r\",encoding='utf-8') # abre los archivos\n",
    "    texto = input_file.read() # carga el contenido del archivo\n",
    "    texto = re.sub('[^A-Za-z0-9]+',' ',texto) # solo permanecen los elementos alfanumericos\n",
    "    tokens = texto.split() # Realiza la tokenizacion\n",
    "    tokens = [x for x in total if wordnet.synsets(x)] # deja solo las palabras asociadas al ingles\n",
    "    stemmer = PorterStemmer() # instancia una forma de stemming\n",
    "    #stemmer2 = LancasterStemmer() # instancia una forma de stemming\n",
    "    # aplica lematizacion, stemming, elimina de stop words y aplica reglas logicas para reducir la cantidad de tokens\n",
    "    tokens = [wordnet_lemmatizer.lemmatize(stemmer.stem(w.lower()), pos=\"v\") for w in tokens if (len(w)>1) and w.isalpha() and w not in sw] # Longitud mayor a 1\n",
    "    # realiza el conteo de la frecuencia de cada palabra\n",
    "    counter=collections.Counter(tokens)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # para un diccionario almacenamos el key que es el nombre del documento y el value que es un diccionario con las key como palabras y los value como la frecuencia de la palabra\n",
    "    bag_of_words[file] = dict(counter)\n",
    "    \n",
    "    #helper = {}\n",
    "    #i = 0\n",
    "    #for key, value in bag_of_words.items():\n",
    "    #    for word in value.keys():\n",
    "    #        if word in helper:\n",
    "    #            helper[word] += 1\n",
    "    #        else:\n",
    "    #            helper[word] = 1\n",
    "\n",
    "    num_words = sum(bag_of_words[file].values())\n",
    "\n",
    "   # for documento, words in bag_of_words.items():\n",
    "    for key, value in words.items():\n",
    "        dic = {}\n",
    "        #print(value)\n",
    "        dic['freq'] = value\n",
    "        dic['freqR'] = value / num_words\n",
    "        dic['tf'] = 1 + np.log(value)\n",
    "        dic['idf'] = np.log(len(bag_of_words) / helper[key])\n",
    "        bag_of_words[documento][key] = dic\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esta funcion ordena el bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('abnorm', 1),\n",
       " ('abstract', 1),\n",
       " ('accompani', 1),\n",
       " ('accord', 1),\n",
       " ('account', 5),\n",
       " ('accuraci', 1),\n",
       " ('acm', 21),\n",
       " ('activ', 2),\n",
       " ('activandrew', 1),\n",
       " ('add', 1),\n",
       " ('addit', 2),\n",
       " ('address', 1),\n",
       " ('adjust', 7),\n",
       " ('adjustp', 1),\n",
       " ('adpoint', 1),\n",
       " ('advanc', 1),\n",
       " ('adversari', 1),\n",
       " ('advertis', 5),\n",
       " ('affect', 2),\n",
       " ('age', 1),\n",
       " ('agre', 2),\n",
       " ('ai', 1),\n",
       " ('aim', 1),\n",
       " ('ak', 3),\n",
       " ('akoglu', 4),\n",
       " ('alex', 1),\n",
       " ('algorithm', 24),\n",
       " ('alic', 12),\n",
       " ('all', 2),\n",
       " ('allow', 7),\n",
       " ('almost', 1),\n",
       " ('also', 6),\n",
       " ('altern', 2),\n",
       " ('alway', 1),\n",
       " ('amount', 1),\n",
       " ('an', 1),\n",
       " ('analofor', 1),\n",
       " ('analog', 1),\n",
       " ('analysi', 1),\n",
       " ('andrew', 1),\n",
       " ('annual', 2),\n",
       " ('anomal', 5),\n",
       " ('anomali', 7),\n",
       " ('anonym', 2),\n",
       " ('anoth', 1),\n",
       " ('answer', 3),\n",
       " ('app', 8),\n",
       " ('appear', 1),\n",
       " ('appli', 3),\n",
       " ('applic', 1),\n",
       " ('approach', 22),\n",
       " ('approxim', 1),\n",
       " ('arbitrarili', 1),\n",
       " ('arg', 7),\n",
       " ('argument', 1),\n",
       " ('around', 4),\n",
       " ('arriv', 1),\n",
       " ('arxiv', 2),\n",
       " ('as', 3),\n",
       " ('asid', 1),\n",
       " ('assign', 5),\n",
       " ('associ', 7),\n",
       " ('assum', 3),\n",
       " ('at', 1),\n",
       " ('attack', 1),\n",
       " ('attribut', 1),\n",
       " ('auction', 1),\n",
       " ('avail', 4),\n",
       " ('averag', 20),\n",
       " ('averpm', 1),\n",
       " ('background', 1),\n",
       " ('banerje', 1),\n",
       " ('base', 21),\n",
       " ('bay', 1),\n",
       " ('bayesian', 27),\n",
       " ('be', 1),\n",
       " ('becaus', 1),\n",
       " ('behav', 1),\n",
       " ('behavior', 28),\n",
       " ('belief', 11),\n",
       " ('believ', 2),\n",
       " ('belong', 2),\n",
       " ('benefit', 1),\n",
       " ('best', 1),\n",
       " ('beutel', 7),\n",
       " ('bhooi', 2),\n",
       " ('bic', 1),\n",
       " ('bimod', 1),\n",
       " ('bind', 1),\n",
       " ('bird', 8),\n",
       " ('birdnest', 21),\n",
       " ('block', 4),\n",
       " ('bob', 14),\n",
       " ('bodi', 1),\n",
       " ('bold', 1),\n",
       " ('bonu', 1),\n",
       " ('book', 1),\n",
       " ('boost', 1),\n",
       " ('bot', 1),\n",
       " ('both', 1),\n",
       " ('brook', 1),\n",
       " ('bryan', 1),\n",
       " ('bucket', 10),\n",
       " ('burst', 1),\n",
       " ('bursti', 2),\n",
       " ('busi', 2),\n",
       " ('by', 1),\n",
       " ('calcul', 1),\n",
       " ('cannot', 1),\n",
       " ('captur', 9),\n",
       " ('card', 1),\n",
       " ('cardi', 1),\n",
       " ('carlo', 1),\n",
       " ('carnegi', 1),\n",
       " ('carol', 11),\n",
       " ('carri', 1),\n",
       " ('case', 3),\n",
       " ('casella', 1),\n",
       " ('cash', 1),\n",
       " ('catch', 2),\n",
       " ('categori', 1),\n",
       " ('certain', 2),\n",
       " ('certainti', 2),\n",
       " ('chain', 1),\n",
       " ('chandi', 1),\n",
       " ('chang', 2),\n",
       " ('character', 1),\n",
       " ('characteri', 1),\n",
       " ('characterist', 1),\n",
       " ('chau', 1),\n",
       " ('cheng', 1),\n",
       " ('choi', 2),\n",
       " ('choos', 1),\n",
       " ('choose', 2),\n",
       " ('christo', 1),\n",
       " ('clear', 4),\n",
       " ('clearli', 1),\n",
       " ('climb', 1),\n",
       " ('close', 3),\n",
       " ('cluster', 29),\n",
       " ('cmu', 2),\n",
       " ('cobafi', 1),\n",
       " ('code', 11),\n",
       " ('coeffici', 1),\n",
       " ('collabor', 3),\n",
       " ('collect', 1),\n",
       " ('combin', 10),\n",
       " ('come', 2),\n",
       " ('commerc', 2),\n",
       " ('commerci', 1),\n",
       " ('common', 6),\n",
       " ('commonli', 2),\n",
       " ('commun', 3),\n",
       " ('compar', 2),\n",
       " ('competit', 1),\n",
       " ('competitor', 1),\n",
       " ('complet', 1),\n",
       " ('compon', 2),\n",
       " ('comput', 30),\n",
       " ('concentr', 1),\n",
       " ('conceptu', 1),\n",
       " ('conclud', 2),\n",
       " ('conclus', 1),\n",
       " ('condit', 1),\n",
       " ('conduct', 1),\n",
       " ('confer', 16),\n",
       " ('confid', 3),\n",
       " ('conform', 2),\n",
       " ('conjug', 1),\n",
       " ('connect', 1),\n",
       " ('consid', 2),\n",
       " ('consist', 8),\n",
       " ('construct', 1),\n",
       " ('contain', 6),\n",
       " ('content', 1),\n",
       " ('context', 1),\n",
       " ('contribut', 2),\n",
       " ('conver', 1),\n",
       " ('converg', 5),\n",
       " ('copycatch', 1),\n",
       " ('core', 1),\n",
       " ('correctli', 1),\n",
       " ('correspond', 2),\n",
       " ('costa', 1),\n",
       " ('could', 4),\n",
       " ('count', 2),\n",
       " ('coupl', 1),\n",
       " ('crawl', 1),\n",
       " ('criterion', 1),\n",
       " ('crucial', 1),\n",
       " ('cs', 1),\n",
       " ('cui', 2),\n",
       " ('current', 1),\n",
       " ('custom', 7),\n",
       " ('data', 38),\n",
       " ('databas', 1),\n",
       " ('dataset', 11),\n",
       " ('decept', 2),\n",
       " ('decid', 1),\n",
       " ('decis', 2),\n",
       " ('decomposit', 2),\n",
       " ('defam', 2),\n",
       " ('default', 1),\n",
       " ('defin', 6),\n",
       " ('demonstratt', 1),\n",
       " ('denot', 5),\n",
       " ('dens', 2),\n",
       " ('describ', 3),\n",
       " ('desir', 1),\n",
       " ('detail', 1),\n",
       " ('detect', 41),\n",
       " ('determin', 5),\n",
       " ('dev', 1),\n",
       " ('develop', 2),\n",
       " ('deviat', 11),\n",
       " ('di', 1),\n",
       " ('differ', 18),\n",
       " ('difficult', 1),\n",
       " ('difhi', 1),\n",
       " ('dimension', 2),\n",
       " ('directli', 1),\n",
       " ('dirichlet', 25),\n",
       " ('discov', 1),\n",
       " ('discoveri', 9),\n",
       " ('discret', 3),\n",
       " ('discuss', 1),\n",
       " ('disha', 1),\n",
       " ('dishonest', 1),\n",
       " ('display', 1),\n",
       " ('distribu', 1),\n",
       " ('distribulikelihood', 1),\n",
       " ('distribut', 101),\n",
       " ('diswithin', 1),\n",
       " ('divers', 1),\n",
       " ('dollar', 1),\n",
       " ('domain', 2),\n",
       " ('domin', 1),\n",
       " ('dominattribut', 1),\n",
       " ('download', 4),\n",
       " ('draw', 11),\n",
       " ('due', 2),\n",
       " ('dynam', 2),\n",
       " ('each', 3),\n",
       " ('easi', 1),\n",
       " ('easili', 1),\n",
       " ('edg', 2),\n",
       " ('edgecentr', 1),\n",
       " ('edu', 2),\n",
       " ('effect', 8),\n",
       " ('effici', 2),\n",
       " ('efinit', 2),\n",
       " ('eigen', 1),\n",
       " ('eigenspok', 1),\n",
       " ('either', 2),\n",
       " ('end', 5),\n",
       " ('endow', 1),\n",
       " ('enough', 1),\n",
       " ('ensur', 2),\n",
       " ('entertain', 1),\n",
       " ('entir', 3),\n",
       " ('entri', 3),\n",
       " ('ep', 3),\n",
       " ('equal', 3),\n",
       " ('equival', 2),\n",
       " ('error', 1),\n",
       " ('especi', 1),\n",
       " ('esti', 1),\n",
       " ('estim', 20),\n",
       " ('etc', 1),\n",
       " ('eter', 1),\n",
       " ('evalu', 6),\n",
       " ('even', 5),\n",
       " ('event', 1),\n",
       " ('ever', 1),\n",
       " ('everi', 1),\n",
       " ('evid', 1),\n",
       " ('evolut', 1),\n",
       " ('ex', 1),\n",
       " ('exactli', 1),\n",
       " ('examin', 1),\n",
       " ('exampl', 6),\n",
       " ('exhibit', 1),\n",
       " ('exist', 1),\n",
       " ('expect', 15),\n",
       " ('experi', 4),\n",
       " ('expert', 2),\n",
       " ('explain', 4),\n",
       " ('explicit', 1),\n",
       " ('exponenti', 1),\n",
       " ('express', 1),\n",
       " ('extens', 1),\n",
       " ('extrem', 5),\n",
       " ('fact', 1),\n",
       " ('factor', 2),\n",
       " ('fairli', 2),\n",
       " ('fake', 7),\n",
       " ('faloutso', 12),\n",
       " ('far', 1),\n",
       " ('fast', 3),\n",
       " ('fbox', 1),\n",
       " ('featur', 2),\n",
       " ('feng', 1),\n",
       " ('ferenc', 1),\n",
       " ('ferraz', 1),\n",
       " ('field', 1),\n",
       " ('fig', 1),\n",
       " ('figur', 22),\n",
       " ('filter', 3),\n",
       " ('final', 2),\n",
       " ('find', 14),\n",
       " ('finer', 1),\n",
       " ('first', 7),\n",
       " ('fit', 5),\n",
       " ('five', 1),\n",
       " ('fix', 4),\n",
       " ('flag', 8),\n",
       " ('flexibl', 3),\n",
       " ('flipkart', 13),\n",
       " ('focu', 6),\n",
       " ('focus', 3),\n",
       " ('follow', 1),\n",
       " ('footprint', 1),\n",
       " ('for', 5),\n",
       " ('form', 3),\n",
       " ('formul', 3),\n",
       " ('formula', 1),\n",
       " ('fraction', 1),\n",
       " ('fraud', 20),\n",
       " ('fraudul', 9),\n",
       " ('free', 1),\n",
       " ('frequenc', 2),\n",
       " ('frequentist', 1),\n",
       " ('from', 2),\n",
       " ('full', 1),\n",
       " ('function', 2),\n",
       " ('fx', 14),\n",
       " ('gallagh', 1),\n",
       " ('gamma', 1),\n",
       " ('gaussian', 1),\n",
       " ('gb', 1),\n",
       " ('genc', 1),\n",
       " ('gener', 18),\n",
       " ('generat', 1),\n",
       " ('get', 1),\n",
       " ('ghz', 1),\n",
       " ('gift', 1),\n",
       " ('give', 36),\n",
       " ('global', 6),\n",
       " ('goal', 2),\n",
       " ('good', 1),\n",
       " ('gousli', 1),\n",
       " ('graph', 11),\n",
       " ('graphbas', 1),\n",
       " ('graphic', 3),\n",
       " ('great', 1),\n",
       " ('greater', 1),\n",
       " ('greedi', 1),\n",
       " ('group', 6),\n",
       " ('grow', 1),\n",
       " ('growth', 1),\n",
       " ('gu', 3),\n",
       " ('gunnemann', 1),\n",
       " ('guruswami', 1),\n",
       " ('han', 1),\n",
       " ('hancock', 1),\n",
       " ('hand', 1),\n",
       " ('help', 1),\n",
       " ('henc', 5),\n",
       " ('here', 2),\n",
       " ('high', 5),\n",
       " ('highest', 2),\n",
       " ('highli', 5),\n",
       " ('hill', 1),\n",
       " ('histogram', 1),\n",
       " ('hockey', 1),\n",
       " ('honest', 1),\n",
       " ('hooi', 3),\n",
       " ('hour', 1),\n",
       " ('howev', 6),\n",
       " ('howsurpris', 1),\n",
       " ('hu', 1),\n",
       " ('human', 1),\n",
       " ('hyperparamet', 3),\n",
       " ('hypothesi', 2),\n",
       " ('icdm', 3),\n",
       " ('icwsm', 1),\n",
       " ('idea', 1),\n",
       " ('ident', 1),\n",
       " ('identifi', 4),\n",
       " ('ieee', 6),\n",
       " ('ij', 10),\n",
       " ('il', 5),\n",
       " ('ilarli', 1),\n",
       " ('illumin', 1),\n",
       " ('illustr', 2),\n",
       " ('imagin', 2),\n",
       " ('imiz', 1),\n",
       " ('implement', 1),\n",
       " ('import', 1),\n",
       " ('in', 37),\n",
       " ('includ', 2),\n",
       " ('increas', 3),\n",
       " ('inde', 1),\n",
       " ('index', 4),\n",
       " ('indic', 1),\n",
       " ('individu', 2),\n",
       " ('infer', 5),\n",
       " ('influenc', 2),\n",
       " ('inform', 11),\n",
       " ('ing', 3),\n",
       " ('input', 1),\n",
       " ('inspect', 2),\n",
       " ('instead', 4),\n",
       " ('integ', 1),\n",
       " ('intel', 1),\n",
       " ('inter', 2),\n",
       " ('intern', 16),\n",
       " ('interpret', 7),\n",
       " ('introduct', 1),\n",
       " ('intuit', 9),\n",
       " ('investig', 3),\n",
       " ('involv', 2),\n",
       " ('ion', 1),\n",
       " ('it', 3),\n",
       " ('iter', 6),\n",
       " ('iti', 1),\n",
       " ('jiang', 2),\n",
       " ('jindal', 3),\n",
       " ('jointli', 1),\n",
       " ('jr', 1),\n",
       " ('jth', 5),\n",
       " ('juci', 1),\n",
       " ('justment', 1),\n",
       " ('key', 1),\n",
       " ('kl', 10),\n",
       " ('klooster', 1),\n",
       " ('know', 6),\n",
       " ('knowledg', 11),\n",
       " ('koren', 2),\n",
       " ('kth', 1),\n",
       " ('kumar', 2),\n",
       " ('label', 4),\n",
       " ('languag', 1),\n",
       " ('larg', 9),\n",
       " ('larger', 3),\n",
       " ('largest', 1),\n",
       " ('larli', 2),\n",
       " ('last', 1),\n",
       " ('lauw', 1),\n",
       " ('lead', 1),\n",
       " ('learn', 4),\n",
       " ('least', 1),\n",
       " ('lehmann', 1),\n",
       " ('leman', 1),\n",
       " ('length', 1),\n",
       " ('less', 5),\n",
       " ('let', 5),\n",
       " ('level', 2),\n",
       " ('li', 1),\n",
       " ('lie', 1),\n",
       " ('life', 2),\n",
       " ('like', 6),\n",
       " ('likelihood', 18),\n",
       " ('likelihoodbas', 1),\n",
       " ('lim', 2),\n",
       " ('lin', 1),\n",
       " ('line', 5),\n",
       " ('linear', 3),\n",
       " ('linearli', 1),\n",
       " ('linguist', 4),\n",
       " ('link', 1),\n",
       " ('littl', 1),\n",
       " ('liu', 5),\n",
       " ('locat', 1),\n",
       " ('lockstep', 1),\n",
       " ('log', 10),\n",
       " ('logarithm', 2),\n",
       " ('loglikelihood', 1),\n",
       " ('long', 3),\n",
       " ('longterm', 1),\n",
       " ('loop', 1),\n",
       " ('loss', 1),\n",
       " ('low', 1),\n",
       " ('lower', 1),\n",
       " ('machado', 1),\n",
       " ('machin', 2),\n",
       " ('machiraju', 1),\n",
       " ('macw', 1),\n",
       " ('maintain', 2),\n",
       " ('make', 4),\n",
       " ('makhija', 2),\n",
       " ('manag', 2),\n",
       " ('mani', 3),\n",
       " ('manipul', 2),\n",
       " ('manner', 4),\n",
       " ('mar', 1),\n",
       " ('margin', 4),\n",
       " ('mark', 1),\n",
       " ('markov', 2),\n",
       " ('mass', 2),\n",
       " ('match', 1),\n",
       " ('mate', 1),\n",
       " ('matrix', 4),\n",
       " ('max', 9),\n",
       " ('maxi', 1),\n",
       " ('maxim', 4),\n",
       " ('maximum', 2),\n",
       " ('maxk', 1),\n",
       " ('may', 3),\n",
       " ('mean', 5),\n",
       " ('measur', 11),\n",
       " ('media', 3),\n",
       " ('meet', 3),\n",
       " ('mellon', 1),\n",
       " ('ment', 1),\n",
       " ('merchant', 1),\n",
       " ('method', 11),\n",
       " ('metric', 13),\n",
       " ('middl', 1),\n",
       " ('million', 1),\n",
       " ('mine', 14),\n",
       " ('minim', 1),\n",
       " ('minimum', 1),\n",
       " ('minka', 1),\n",
       " ('minut', 1),\n",
       " ('mixtur', 8),\n",
       " ('mk', 1),\n",
       " ('mnih', 1),\n",
       " ('model', 36),\n",
       " ('mohit', 1),\n",
       " ('mont', 1),\n",
       " ('moreov', 3),\n",
       " ('mostli', 1),\n",
       " ('motiv', 5),\n",
       " ('mu', 1),\n",
       " ('much', 11),\n",
       " ('multi', 2),\n",
       " ('multifacet', 1),\n",
       " ('multimod', 1),\n",
       " ('multinomi', 15),\n",
       " ('multipl', 2),\n",
       " ('multivari', 2),\n",
       " ('mum', 1),\n",
       " ('murray', 1),\n",
       " ('must', 1),\n",
       " ('name', 2),\n",
       " ('narrow', 2),\n",
       " ('natur', 1),\n",
       " ('nchen', 1),\n",
       " ('near', 1),\n",
       " ('nearident', 1),\n",
       " ('need', 4),\n",
       " ('neg', 5),\n",
       " ('neighborhood', 2),\n",
       " ('neil', 1),\n",
       " ('neither', 1),\n",
       " ('nest', 15),\n",
       " ('netprob', 1),\n",
       " ('network', 6),\n",
       " ('new', 5),\n",
       " ('next', 1),\n",
       " ('nformal', 1),\n",
       " ('nguyen', 1),\n",
       " ('ni', 15),\n",
       " ('nil', 2),\n",
       " ('nnemann', 3),\n",
       " ('no', 5),\n",
       " ('node', 2),\n",
       " ('non', 2),\n",
       " ('nonneg', 1),\n",
       " ('nonsuspici', 1),\n",
       " ('normal', 20),\n",
       " ('notat', 2),\n",
       " ('note', 6),\n",
       " ('now', 1),\n",
       " ('number', 14),\n",
       " ('nx', 5),\n",
       " ('nxi', 4),\n",
       " ('nxil', 2),\n",
       " ('observ', 5),\n",
       " ('occur', 1),\n",
       " ('occurr', 1),\n",
       " ('offer', 2),\n",
       " ('often', 2),\n",
       " ('one', 7),\n",
       " ('onlin', 9),\n",
       " ('open', 1),\n",
       " ('opin', 1),\n",
       " ('opinion', 4),\n",
       " ('order', 2),\n",
       " ('os', 1),\n",
       " ('other', 2),\n",
       " ('ott', 1),\n",
       " ('our', 5),\n",
       " ('outer', 1),\n",
       " ('outlier', 1),\n",
       " ('output', 1),\n",
       " ('overal', 4),\n",
       " ('owner', 1),\n",
       " ('page', 22),\n",
       " ('pakdd', 1),\n",
       " ('palow', 1),\n",
       " ('pandit', 1),\n",
       " ('paper', 6),\n",
       " ('param', 1),\n",
       " ('paramet', 9),\n",
       " ('parametr', 1),\n",
       " ('part', 2),\n",
       " ('particular', 1),\n",
       " ('patprecis', 1),\n",
       " ('pattern', 14),\n",
       " ('pect', 1),\n",
       " ('per', 2),\n",
       " ('percept', 1),\n",
       " ('perfect', 1),\n",
       " ('perform', 2),\n",
       " ('period', 1),\n",
       " ('person', 1),\n",
       " ('perspect', 2),\n",
       " ('pervas', 1),\n",
       " ('pi', 21),\n",
       " ('pk', 1),\n",
       " ('platform', 3),\n",
       " ('play', 1),\n",
       " ('plot', 2),\n",
       " ('pm', 2),\n",
       " ('pni', 1),\n",
       " ('point', 8),\n",
       " ('polar', 1),\n",
       " ('popul', 4),\n",
       " ('popular', 2),\n",
       " ('portion', 1),\n",
       " ('posit', 3),\n",
       " ('possibl', 3),\n",
       " ('post', 1),\n",
       " ('posterior', 37),\n",
       " ('potter', 1),\n",
       " ('practic', 6),\n",
       " ('prakash', 1),\n",
       " ('precis', 5),\n",
       " ('preprint', 1),\n",
       " ('preprocess', 1),\n",
       " ('present', 3),\n",
       " ('previou', 1),\n",
       " ('principl', 9),\n",
       " ('prior', 6),\n",
       " ('pro', 1),\n",
       " ('probabilist', 2),\n",
       " ('probabl', 8),\n",
       " ('problem', 8),\n",
       " ('procedur', 2),\n",
       " ('proceed', 15),\n",
       " ('process', 4),\n",
       " ('produc', 1),\n",
       " ('product', 18),\n",
       " ('promis', 1),\n",
       " ('propag', 1),\n",
       " ('properti', 2),\n",
       " ('proport', 1),\n",
       " ('propos', 9),\n",
       " ('provid', 4),\n",
       " ('purchas', 3),\n",
       " ('pure', 1),\n",
       " ('python', 1),\n",
       " ('qi', 10),\n",
       " ('quantit', 1),\n",
       " ('quantiti', 2),\n",
       " ('question', 2),\n",
       " ('rais', 1),\n",
       " ('ram', 1),\n",
       " ('ramaswami', 1),\n",
       " ('random', 5),\n",
       " ('rank', 3),\n",
       " ('rapid', 1),\n",
       " ('rapidli', 1),\n",
       " ('rastogi', 1),\n",
       " ('rate', 133),\n",
       " ('ratk', 1),\n",
       " ('raw', 1),\n",
       " ('real', 11),\n",
       " ('reason', 1),\n",
       " ('recal', 4),\n",
       " ('receiv', 1),\n",
       " ('recommend', 1),\n",
       " ('record', 1),\n",
       " ('refer', 7),\n",
       " ('regard', 2),\n",
       " ('regular', 1),\n",
       " ('rel', 1),\n",
       " ('relat', 1),\n",
       " ('remov', 1),\n",
       " ('repeat', 2),\n",
       " ('repeatedli', 1),\n",
       " ('repres', 5),\n",
       " ('reproduc', 1),\n",
       " ('research', 1),\n",
       " ('resolut', 1),\n",
       " ('resp', 6),\n",
       " ('respect', 6),\n",
       " ('rest', 1),\n",
       " ('restrict', 1),\n",
       " ('result', 4),\n",
       " ('return', 1),\n",
       " ('review', 44),\n",
       " ('rewher', 1),\n",
       " ('right', 1),\n",
       " ('ring', 3),\n",
       " ('roblem', 1),\n",
       " ('robust', 1),\n",
       " ('role', 1),\n",
       " ('rsc', 1),\n",
       " ('rule', 1),\n",
       " ('run', 3),\n",
       " ('sake', 1),\n",
       " ('salakhutdinov', 1),\n",
       " ('sampl', 4),\n",
       " ('sarrafzadeh', 1),\n",
       " ('say', 2),\n",
       " ('scalabl', 6),\n",
       " ('scale', 1),\n",
       " ('scienc', 1),\n",
       " ('score', 7),\n",
       " ('sdm', 2),\n",
       " ('search', 1),\n",
       " ('second', 1),\n",
       " ('section', 2),\n",
       " ('see', 3),\n",
       " ('select', 2),\n",
       " ('self', 1),\n",
       " ('sell', 1),\n",
       " ('seller', 4),\n",
       " ('sens', 1),\n",
       " ('sensibl', 1),\n",
       " ('seri', 4),\n",
       " ('servic', 2),\n",
       " ('seshadri', 1),\n",
       " ('set', 9),\n",
       " ('sever', 1),\n",
       " ('shah', 3),\n",
       " ('she', 1),\n",
       " ('shift', 1),\n",
       " ('shim', 1),\n",
       " ('short', 3),\n",
       " ('shorter', 2),\n",
       " ('show', 13),\n",
       " ('siam', 2),\n",
       " ('sigkdd', 5),\n",
       " ('sigmod', 1),\n",
       " ('sign', 4),\n",
       " ('signific', 1),\n",
       " ('significantli', 2),\n",
       " ('simi', 1),\n",
       " ('similar', 7),\n",
       " ('similarli', 8),\n",
       " ('simizi', 1),\n",
       " ('simpli', 3),\n",
       " ('simul', 2),\n",
       " ('sinc', 4),\n",
       " ('singl', 5),\n",
       " ('singleton', 1),\n",
       " ('singular', 1),\n",
       " ('site', 1),\n",
       " ('skew', 2),\n",
       " ('slightli', 2),\n",
       " ('small', 7),\n",
       " ('smola', 1),\n",
       " ('so', 1),\n",
       " ('social', 4),\n",
       " ('softwar', 1),\n",
       " ('solut', 1),\n",
       " ('solv', 1),\n",
       " ('sound', 2),\n",
       " ('sourc', 1),\n",
       " ('spam', 6),\n",
       " ('spammer', 4),\n",
       " ('spammi', 1),\n",
       " ('span', 1),\n",
       " ('specif', 1),\n",
       " ('spectral', 1),\n",
       " ('spot', 5),\n",
       " ('spread', 1),\n",
       " ('springer', 3),\n",
       " ('squar', 2),\n",
       " ('sridharan', 1),\n",
       " ('standard', 2),\n",
       " ('star', 14),\n",
       " ('start', 1),\n",
       " ('std', 1),\n",
       " ('step', 4),\n",
       " ('stephan', 1),\n",
       " ('stick', 1),\n",
       " ('stoni', 1),\n",
       " ('stop', 1),\n",
       " ('store', 3),\n",
       " ('strang', 1),\n",
       " ('stretch', 1),\n",
       " ('strongli', 2),\n",
       " ('structur', 1),\n",
       " ('studi', 2),\n",
       " ('stylometri', 1),\n",
       " ('subgraph', 1),\n",
       " ('subspac', 1),\n",
       " ('substanti', 1),\n",
       " ('subtract', 1),\n",
       " ('success', 5),\n",
       " ('suggest', 1),\n",
       " ('suitabl', 1),\n",
       " ('sult', 1),\n",
       " ('sum', 2),\n",
       " ('summar', 3),\n",
       " ('surpris', 20),\n",
       " ('suspici', 55),\n",
       " ('svd', 1),\n",
       " ('swm', 4),\n",
       " ('sx', 7),\n",
       " ('syntact', 1),\n",
       " ('system', 4),\n",
       " ('tabl', 6),\n",
       " ('take', 7),\n",
       " ('tan', 1),\n",
       " ('tar', 2),\n",
       " ('technisch', 1),\n",
       " ('technologiesvolum', 1),\n",
       " ('tempor', 32),\n",
       " ('tenth', 1),\n",
       " ('term', 6),\n",
       " ('tern', 1),\n",
       " ('test', 6),\n",
       " ('text', 9),\n",
       " ('the', 22),\n",
       " ('then', 2),\n",
       " ('theoret', 3),\n",
       " ('theori', 1),\n",
       " ('there', 1),\n",
       " ('therefor', 1),\n",
       " ('these', 3),\n",
       " ('they', 1),\n",
       " ('thi', 7),\n",
       " ('think', 1),\n",
       " ('three', 1),\n",
       " ('thu', 7),\n",
       " ('time', 27),\n",
       " ('timestamp', 7),\n",
       " ('tion', 2),\n",
       " ('titl', 1),\n",
       " ('to', 6),\n",
       " ('top', 7),\n",
       " ('total', 3),\n",
       " ('toward', 1),\n",
       " ('tradeoff', 2),\n",
       " ('traina', 2),\n",
       " ('treat', 1),\n",
       " ('tribut', 1),\n",
       " ('trivial', 1),\n",
       " ('true', 13),\n",
       " ('trust', 1),\n",
       " ('two', 5),\n",
       " ('type', 5),\n",
       " ('typic', 2),\n",
       " ('uncertain', 1),\n",
       " ('uncertainti', 2),\n",
       " ('underli', 1),\n",
       " ('understand', 2),\n",
       " ('unexpect', 1),\n",
       " ('uniqu', 1),\n",
       " ('unit', 2),\n",
       " ('univers', 2),\n",
       " ('universita', 1),\n",
       " ('unsupervis', 1),\n",
       " ('unusu', 6),\n",
       " ('updat', 2),\n",
       " ('urpris', 1),\n",
       " ('us', 9),\n",
       " ('use', 30),\n",
       " ('user', 152),\n",
       " ('usersar', 1),\n",
       " ('vahdatpour', 1),\n",
       " ('valu', 9),\n",
       " ('variabl', 3),\n",
       " ('variat', 1),\n",
       " ('varieti', 1),\n",
       " ('variou', 2),\n",
       " ('vector', 9),\n",
       " ('veri', 1),\n",
       " ('verifi', 1),\n",
       " ('via', 3),\n",
       " ('vldb', 1),\n",
       " ('volum', 3),\n",
       " ('volv', 1),\n",
       " ('vs', 2),\n",
       " ('wang', 3),\n",
       " ('way', 6),\n",
       " ('we', 20),\n",
       " ('wearabl', 1),\n",
       " ('web', 4),\n",
       " ('week', 1),\n",
       " ('well', 2),\n",
       " ('what', 1),\n",
       " ('whether', 1),\n",
       " ('whi', 1),\n",
       " ('which', 1),\n",
       " ('while', 1),\n",
       " ('whose', 1),\n",
       " ('wide', 6),\n",
       " ('wish', 1),\n",
       " ('within', 2),\n",
       " ('without', 2),\n",
       " ('work', 7),\n",
       " ('world', 7),\n",
       " ('would', 5),\n",
       " ('write', 2),\n",
       " ('www', 2),\n",
       " ('xi', 14),\n",
       " ('xie', 2),\n",
       " ('xij', 10),\n",
       " ('xpect', 1),\n",
       " ('xu', 1),\n",
       " ('yamaguchi', 1),\n",
       " ('yang', 2),\n",
       " ('ye', 1),\n",
       " ('yu', 2),\n",
       " ('zi', 28),\n",
       " ('zinew', 1)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words[files_txt[0]]\n",
    "#sort\n",
    "import operator\n",
    "sorted_x = sorted(bag_of_words[files_txt[0]].items(), key=lambda kv: kv[0])\n",
    "sorted_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdTest[['aisss']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aisss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>/opt/datasets/mcda-pi1-20191/papers-txt/1506.06055.txt</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    aisss\n",
       "/opt/datasets/mcda-pi1-20191/papers-txt/1506.06...    1.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdTest[['aisss']].dropna(axis = 'rows')#.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construccion de un DF con informacion de frecuencia de palabras por documento\n",
    "keys, values = [], [] # creacion de listas vacias\n",
    "for key, value in bag_of_words.items():\n",
    "    keys.append(key) # adjunta cada palabra a una lista vacia\n",
    "    values.append(value) # adjunta cada valor a una lista vacia\n",
    "    \n",
    "pdTest = pd.DataFrame(data=values, index=keys) # Genera el dataframe con los documentos, las palabras y las frecuencias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "if not wordnet.synsets. ('http'):\n",
    "    print('Not an English Word')\n",
    "else:\n",
    "    print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'http' in sison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9346"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa',\n",
       " 'aaa',\n",
       " 'aachen',\n",
       " 'aalborg',\n",
       " 'aalto',\n",
       " 'aaron',\n",
       " 'aas',\n",
       " 'ab',\n",
       " 'aba',\n",
       " 'abandon',\n",
       " 'abas',\n",
       " 'abb',\n",
       " 'abbey',\n",
       " 'abc',\n",
       " 'abduct',\n",
       " 'abel',\n",
       " 'abm',\n",
       " 'abolish',\n",
       " 'abor',\n",
       " 'abort',\n",
       " 'abound',\n",
       " 'about',\n",
       " 'abraham',\n",
       " 'abroad',\n",
       " 'abrupt',\n",
       " 'abruzzi',\n",
       " 'abscissa',\n",
       " 'absent',\n",
       " 'absorb',\n",
       " 'abstract',\n",
       " 'absurd',\n",
       " 'abut',\n",
       " 'ac',\n",
       " 'academia',\n",
       " 'academician',\n",
       " 'acapulco',\n",
       " 'acc',\n",
       " 'accent',\n",
       " 'accept',\n",
       " 'acceptor',\n",
       " 'access',\n",
       " 'accident',\n",
       " 'acclaim',\n",
       " 'accomplish',\n",
       " 'accord',\n",
       " 'account',\n",
       " 'accustom',\n",
       " 'ace',\n",
       " 'achillea',\n",
       " 'acid',\n",
       " 'acquaint',\n",
       " 'acronym',\n",
       " 'across',\n",
       " 'act',\n",
       " 'actin',\n",
       " 'action',\n",
       " 'activist',\n",
       " 'actor',\n",
       " 'actual',\n",
       " 'acyl',\n",
       " 'ad',\n",
       " 'ada',\n",
       " 'adam',\n",
       " 'adapt',\n",
       " 'adar',\n",
       " 'add',\n",
       " 'addend',\n",
       " 'addendum',\n",
       " 'adder',\n",
       " 'addict',\n",
       " 'address',\n",
       " 'ade',\n",
       " 'aden',\n",
       " 'adit',\n",
       " 'aditya',\n",
       " 'adjacent',\n",
       " 'adjoin',\n",
       " 'adjunct',\n",
       " 'adjust',\n",
       " 'admit',\n",
       " 'ado',\n",
       " 'adopt',\n",
       " 'adorn',\n",
       " 'adp',\n",
       " 'adrian',\n",
       " 'adult',\n",
       " 'adulthood',\n",
       " 'advect',\n",
       " 'advent',\n",
       " 'advert',\n",
       " 'advisor',\n",
       " 'adz',\n",
       " 'aegean',\n",
       " 'aeolian',\n",
       " 'aerial',\n",
       " 'aerofoil',\n",
       " 'aeronaut',\n",
       " 'aesop',\n",
       " 'afar',\n",
       " 'affair',\n",
       " 'affect',\n",
       " 'affection',\n",
       " 'affirm',\n",
       " 'affix',\n",
       " 'afflict',\n",
       " 'afford',\n",
       " 'afield',\n",
       " 'afl',\n",
       " 'aforesaid',\n",
       " 'afoul',\n",
       " 'afp',\n",
       " 'afraid',\n",
       " 'afresh',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'afrl',\n",
       " 'afro',\n",
       " 'aft',\n",
       " 'after',\n",
       " 'aftermath',\n",
       " 'afternoon',\n",
       " 'aftershock',\n",
       " 'afterward',\n",
       " 'ag',\n",
       " 'aga',\n",
       " 'again',\n",
       " 'age',\n",
       " 'agenda',\n",
       " 'agent',\n",
       " 'aggress',\n",
       " 'agha',\n",
       " 'ago',\n",
       " 'agon',\n",
       " 'agonist',\n",
       " 'agreement',\n",
       " 'ahead',\n",
       " 'ai',\n",
       " 'aid',\n",
       " 'aiken',\n",
       " 'ail',\n",
       " 'aim',\n",
       " 'ain',\n",
       " 'air',\n",
       " 'aircraft',\n",
       " 'airflow',\n",
       " 'airfoil',\n",
       " 'airport',\n",
       " 'airway',\n",
       " 'aiss',\n",
       " 'aisss',\n",
       " 'aix',\n",
       " 'ajax',\n",
       " 'ak',\n",
       " 'akin',\n",
       " 'akka',\n",
       " 'aku',\n",
       " 'al',\n",
       " 'ala',\n",
       " 'alabama',\n",
       " 'alamo',\n",
       " 'alarm',\n",
       " 'alarmist',\n",
       " 'alaska',\n",
       " 'alb',\n",
       " 'albanian',\n",
       " 'albedo',\n",
       " 'albert',\n",
       " 'alberta',\n",
       " 'alberti',\n",
       " 'alcohol',\n",
       " 'ale',\n",
       " 'alert',\n",
       " 'alexandria',\n",
       " 'alfalfa',\n",
       " 'alga',\n",
       " 'algebra',\n",
       " 'algebraist',\n",
       " 'algerian',\n",
       " 'algol',\n",
       " 'algorithm',\n",
       " 'ali',\n",
       " 'alias',\n",
       " 'alien',\n",
       " 'align',\n",
       " 'all',\n",
       " 'allen',\n",
       " 'aller',\n",
       " 'allergen',\n",
       " 'allest',\n",
       " 'alley',\n",
       " 'allot',\n",
       " 'allow',\n",
       " 'alloy',\n",
       " 'almost',\n",
       " 'aloha',\n",
       " 'along',\n",
       " 'alonso',\n",
       " 'alp',\n",
       " 'alpha',\n",
       " 'alphabet',\n",
       " 'als',\n",
       " 'also',\n",
       " 'alt',\n",
       " 'alter',\n",
       " 'alto',\n",
       " 'altruism',\n",
       " 'altruist',\n",
       " 'alum',\n",
       " 'alumina',\n",
       " 'aluminum',\n",
       " 'alumni',\n",
       " 'amalgam',\n",
       " 'amass',\n",
       " 'amateur',\n",
       " 'amateurish',\n",
       " 'amazon',\n",
       " 'amber',\n",
       " 'ambient',\n",
       " 'ambo',\n",
       " 'ambush',\n",
       " 'amd',\n",
       " 'amelia',\n",
       " 'amen',\n",
       " 'amend',\n",
       " 'america',\n",
       " 'american',\n",
       " 'amia',\n",
       " 'amigo',\n",
       " 'amino',\n",
       " 'amir',\n",
       " 'amman',\n",
       " 'amnesia',\n",
       " 'amoeba',\n",
       " 'amon',\n",
       " 'amor',\n",
       " 'amort',\n",
       " 'amount',\n",
       " 'amour',\n",
       " 'amp',\n",
       " 'amss',\n",
       " 'amsterdam',\n",
       " 'an',\n",
       " 'ana',\n",
       " 'anaheim',\n",
       " 'anal',\n",
       " 'analog',\n",
       " 'analyst',\n",
       " 'anaphora',\n",
       " 'anathema',\n",
       " 'ancestor',\n",
       " 'anchor',\n",
       " 'ancient',\n",
       " 'andersen',\n",
       " 'anderson',\n",
       " 'andrew',\n",
       " 'android',\n",
       " 'ane',\n",
       " 'anew',\n",
       " 'ang',\n",
       " 'angel',\n",
       " 'anger',\n",
       " 'angstrom',\n",
       " 'angular',\n",
       " 'ani',\n",
       " 'anil',\n",
       " 'anima',\n",
       " 'ankara',\n",
       " 'anna',\n",
       " 'anne',\n",
       " 'anneal',\n",
       " 'annex',\n",
       " 'annoy',\n",
       " 'annual',\n",
       " 'annul',\n",
       " 'annuli',\n",
       " 'ano',\n",
       " 'anon',\n",
       " 'anonym',\n",
       " 'anova',\n",
       " 'anselm',\n",
       " 'answer',\n",
       " 'ant',\n",
       " 'antagonist',\n",
       " 'antalya',\n",
       " 'ante',\n",
       " 'antenna',\n",
       " 'anterior',\n",
       " 'anthrax',\n",
       " 'anthropologist',\n",
       " 'anti',\n",
       " 'antigen',\n",
       " 'antiparallel',\n",
       " 'antler',\n",
       " 'antonym',\n",
       " 'antwerp',\n",
       " 'anu',\n",
       " 'anura',\n",
       " 'anuran',\n",
       " 'anxious',\n",
       " 'anyhow',\n",
       " 'anyway',\n",
       " 'aortic',\n",
       " 'apar',\n",
       " 'apart',\n",
       " 'apc',\n",
       " 'ape',\n",
       " 'apex',\n",
       " 'aplysia',\n",
       " 'appeal',\n",
       " 'appear',\n",
       " 'append',\n",
       " 'appendix',\n",
       " 'applaud',\n",
       " 'applet',\n",
       " 'application',\n",
       " 'applique',\n",
       " 'appoint',\n",
       " 'apportion',\n",
       " 'apprenticeship',\n",
       " 'approach',\n",
       " 'apr',\n",
       " 'april',\n",
       " 'apt',\n",
       " 'aquila',\n",
       " 'ar',\n",
       " 'ara',\n",
       " 'arab',\n",
       " 'arabian',\n",
       " 'arak',\n",
       " 'aram',\n",
       " 'arb',\n",
       " 'arbor',\n",
       " 'arboretum',\n",
       " 'arc',\n",
       " 'arcadia',\n",
       " 'arch',\n",
       " 'archaic',\n",
       " 'archer',\n",
       " 'archipelago',\n",
       " 'architect',\n",
       " 'arcsin',\n",
       " 'arctan',\n",
       " 'arctic',\n",
       " 'area',\n",
       " 'areal',\n",
       " 'arena',\n",
       " 'arendt',\n",
       " 'argentina',\n",
       " 'argo',\n",
       " 'arguer',\n",
       " 'argument',\n",
       " 'aria',\n",
       " 'arise',\n",
       " 'aristotelian',\n",
       " 'arizona',\n",
       " 'ark',\n",
       " 'arlington',\n",
       " 'arm',\n",
       " 'armadillo',\n",
       " 'armenia',\n",
       " 'armenian',\n",
       " 'armin',\n",
       " 'armpit',\n",
       " 'armstrong',\n",
       " 'arno',\n",
       " 'arnold',\n",
       " 'around',\n",
       " 'arp',\n",
       " 'array',\n",
       " 'arrest',\n",
       " 'arrhythmia',\n",
       " 'arrow',\n",
       " 'arrowhead',\n",
       " 'arroyo',\n",
       " 'art',\n",
       " 'artal',\n",
       " 'artefact',\n",
       " 'arthur',\n",
       " 'artifact',\n",
       " 'artificial',\n",
       " 'artist',\n",
       " 'artwork',\n",
       " 'aruba',\n",
       " 'aryan',\n",
       " 'as',\n",
       " 'asat',\n",
       " 'ascend',\n",
       " 'ascent',\n",
       " 'ascertain',\n",
       " 'asch',\n",
       " 'asci',\n",
       " 'ascii',\n",
       " 'ash',\n",
       " 'ashkenazi',\n",
       " 'ashton',\n",
       " 'asia',\n",
       " 'asian',\n",
       " 'asimov',\n",
       " 'ask',\n",
       " 'asl',\n",
       " 'asleep',\n",
       " 'asp',\n",
       " 'aspect',\n",
       " 'asper',\n",
       " 'asphalt',\n",
       " 'aspirin',\n",
       " 'ass',\n",
       " 'assail',\n",
       " 'assault',\n",
       " 'assay',\n",
       " 'assent',\n",
       " 'assert',\n",
       " 'assess',\n",
       " 'assessor',\n",
       " 'asset',\n",
       " 'assign',\n",
       " 'assist',\n",
       " 'assort',\n",
       " 'assur',\n",
       " 'assyrian',\n",
       " 'asterisk',\n",
       " 'asteroid',\n",
       " 'astonish',\n",
       " 'astound',\n",
       " 'astray',\n",
       " 'astronaut',\n",
       " 'asuncion',\n",
       " 'asur',\n",
       " 'at',\n",
       " 'athena',\n",
       " 'atheneum',\n",
       " 'athirst',\n",
       " 'atlanta',\n",
       " 'atm',\n",
       " 'atom',\n",
       " 'aton',\n",
       " 'atop',\n",
       " 'atp',\n",
       " 'attach',\n",
       " 'attack',\n",
       " 'attain',\n",
       " 'attempt',\n",
       " 'attend',\n",
       " 'attest',\n",
       " 'attic',\n",
       " 'attila',\n",
       " 'attorney',\n",
       " 'attract',\n",
       " 'attractor',\n",
       " 'au',\n",
       " 'auc',\n",
       " 'auckland',\n",
       " 'auction',\n",
       " 'audio',\n",
       " 'audit',\n",
       " 'auditor',\n",
       " 'aug',\n",
       " 'auger',\n",
       " 'augment',\n",
       " 'augur',\n",
       " 'august',\n",
       " 'auk',\n",
       " 'aum',\n",
       " 'aurora',\n",
       " 'austen',\n",
       " 'austin',\n",
       " 'austral',\n",
       " 'australasian',\n",
       " 'australia',\n",
       " 'australian',\n",
       " 'austria',\n",
       " 'austrian',\n",
       " 'austronesian',\n",
       " 'author',\n",
       " 'authorship',\n",
       " 'autism',\n",
       " 'auto',\n",
       " 'autofocus',\n",
       " 'automat',\n",
       " 'automata',\n",
       " 'automaton',\n",
       " 'autopilot',\n",
       " 'av',\n",
       " 'avail',\n",
       " 'avatar',\n",
       " 'aver',\n",
       " 'avert',\n",
       " 'avian',\n",
       " 'avid',\n",
       " 'avignon',\n",
       " 'avogadro',\n",
       " 'avoid',\n",
       " 'avss',\n",
       " 'await',\n",
       " 'awake',\n",
       " 'awaken',\n",
       " 'award',\n",
       " 'away',\n",
       " 'awe',\n",
       " 'awkward',\n",
       " 'awn',\n",
       " 'ax',\n",
       " 'axe',\n",
       " 'axial',\n",
       " 'axiom',\n",
       " 'axon',\n",
       " 'ayr',\n",
       " 'az',\n",
       " 'azimuth',\n",
       " 'aztec',\n",
       " 'ba',\n",
       " 'baa',\n",
       " 'baba',\n",
       " 'babe',\n",
       " 'babel',\n",
       " 'baboon',\n",
       " 'babu',\n",
       " 'babylon',\n",
       " 'babylonian',\n",
       " 'bach',\n",
       " 'bachelor',\n",
       " 'back',\n",
       " 'backbench',\n",
       " 'backdoor',\n",
       " 'backer',\n",
       " 'background',\n",
       " 'backlog',\n",
       " 'backpack',\n",
       " 'backseat',\n",
       " 'backtrack',\n",
       " 'backup',\n",
       " 'backward',\n",
       " 'bacon',\n",
       " 'bacteria',\n",
       " 'bacterium',\n",
       " 'bad',\n",
       " 'bader',\n",
       " 'bag',\n",
       " 'bahai',\n",
       " 'bai',\n",
       " 'baic',\n",
       " 'bail',\n",
       " 'bailey',\n",
       " 'bake',\n",
       " 'baker',\n",
       " 'balance',\n",
       " 'bald',\n",
       " 'balder',\n",
       " 'baldwin',\n",
       " 'balkan',\n",
       " 'ball',\n",
       " 'balloon',\n",
       " 'ballot',\n",
       " 'ballpark',\n",
       " 'balthasar',\n",
       " 'bam',\n",
       " 'bamboo',\n",
       " 'ban',\n",
       " 'banana',\n",
       " 'band',\n",
       " 'bandit',\n",
       " 'bandwagon',\n",
       " 'bandwidth',\n",
       " 'bane',\n",
       " 'banff',\n",
       " 'bang',\n",
       " 'bangkok',\n",
       " 'bangladesh',\n",
       " 'bangladeshi',\n",
       " 'banish',\n",
       " 'bank',\n",
       " 'banker',\n",
       " 'bankrupt',\n",
       " 'banner',\n",
       " 'baptist',\n",
       " 'bar',\n",
       " 'barb',\n",
       " 'barbarossa',\n",
       " 'barbel',\n",
       " 'barber',\n",
       " 'barbu',\n",
       " 'barcelona',\n",
       " 'bard',\n",
       " 'bare',\n",
       " 'bargain',\n",
       " 'bari',\n",
       " 'bark',\n",
       " 'barker',\n",
       " 'barman',\n",
       " 'barn',\n",
       " 'barnum',\n",
       " 'baron',\n",
       " 'barranquilla',\n",
       " 'barren',\n",
       " 'barrier',\n",
       " 'bart',\n",
       " 'barter',\n",
       " 'barth',\n",
       " 'bartholdi',\n",
       " 'bartlett',\n",
       " 'baruch',\n",
       " 'baryon',\n",
       " 'baryshnikov',\n",
       " 'basal',\n",
       " 'base',\n",
       " 'basel',\n",
       " 'basenji',\n",
       " 'basest',\n",
       " 'bash',\n",
       " 'basic',\n",
       " 'basil',\n",
       " 'basilar',\n",
       " 'basin',\n",
       " 'basket',\n",
       " 'bass',\n",
       " 'basser',\n",
       " 'bassi',\n",
       " 'bast',\n",
       " 'bastard',\n",
       " 'bat',\n",
       " 'batch',\n",
       " 'bate',\n",
       " 'bath',\n",
       " 'bathroom',\n",
       " 'baton',\n",
       " 'battlefield',\n",
       " 'baud',\n",
       " 'baum',\n",
       " 'bay',\n",
       " 'bayer',\n",
       " 'bayesian',\n",
       " 'bazaar',\n",
       " 'bb',\n",
       " 'bc',\n",
       " 'bce',\n",
       " 'bd',\n",
       " 'be',\n",
       " 'beach',\n",
       " 'beacon',\n",
       " 'bead',\n",
       " 'beam',\n",
       " 'bean',\n",
       " 'bear',\n",
       " 'beard',\n",
       " 'bearer',\n",
       " 'beat',\n",
       " 'beaver',\n",
       " 'beck',\n",
       " 'becket',\n",
       " 'bed',\n",
       " 'beda',\n",
       " 'bedrock',\n",
       " 'bee',\n",
       " 'beef',\n",
       " 'beep',\n",
       " 'beer',\n",
       " 'beet',\n",
       " 'befit',\n",
       " 'beforehand',\n",
       " 'befriend',\n",
       " 'beg',\n",
       " 'beget',\n",
       " 'begin',\n",
       " 'begum',\n",
       " 'behalf',\n",
       " 'behave',\n",
       " 'behavior',\n",
       " 'behaviour',\n",
       " 'behead',\n",
       " 'behind',\n",
       " 'behold',\n",
       " 'beirut',\n",
       " 'bel',\n",
       " 'belfast',\n",
       " 'belgian',\n",
       " 'belgium',\n",
       " 'belief',\n",
       " 'bell',\n",
       " 'bellini',\n",
       " 'bellman',\n",
       " 'bellow',\n",
       " 'belmont',\n",
       " 'belong',\n",
       " 'below',\n",
       " 'belt',\n",
       " 'ben',\n",
       " 'bench',\n",
       " 'benchmark',\n",
       " 'bend',\n",
       " 'bender',\n",
       " 'beneath',\n",
       " 'benefit',\n",
       " 'benelux',\n",
       " 'bengal',\n",
       " 'bengali',\n",
       " 'benghazi',\n",
       " 'benign',\n",
       " 'benin',\n",
       " 'benjamin',\n",
       " 'bennet',\n",
       " 'bennett',\n",
       " 'benni',\n",
       " 'bentham',\n",
       " 'benton',\n",
       " 'benzenoid',\n",
       " 'beograd',\n",
       " 'berg',\n",
       " 'bergen',\n",
       " 'bergman',\n",
       " 'bergson',\n",
       " 'berit',\n",
       " 'berk',\n",
       " 'berkeley',\n",
       " 'berlin',\n",
       " 'berm',\n",
       " 'bern',\n",
       " 'bernard',\n",
       " 'bernhardt',\n",
       " 'bernoulli',\n",
       " 'bernstein',\n",
       " 'berth',\n",
       " 'bessel',\n",
       " 'best',\n",
       " 'bet',\n",
       " 'beta',\n",
       " 'beth',\n",
       " 'bethel',\n",
       " 'bethlehem',\n",
       " 'better',\n",
       " 'between',\n",
       " 'beyond',\n",
       " 'bh',\n",
       " 'bi',\n",
       " 'bias',\n",
       " 'bib',\n",
       " 'bicolor',\n",
       " 'bicolour',\n",
       " 'biconvex',\n",
       " 'bid',\n",
       " 'bidder',\n",
       " 'biennial',\n",
       " 'bier',\n",
       " 'big',\n",
       " 'bigger',\n",
       " 'biggest',\n",
       " 'bigram',\n",
       " 'bilinear',\n",
       " 'bill',\n",
       " 'billboard',\n",
       " 'billiard',\n",
       " 'billion',\n",
       " 'bin',\n",
       " 'bind',\n",
       " 'binder',\n",
       " 'bine',\n",
       " 'binghamton',\n",
       " 'bingo',\n",
       " 'binocular',\n",
       " 'biochemist',\n",
       " 'biologist',\n",
       " 'bipartisan',\n",
       " 'biped',\n",
       " 'bipolar',\n",
       " 'birch',\n",
       " 'bird',\n",
       " 'birdnest',\n",
       " 'birken',\n",
       " 'birmingham',\n",
       " 'biro',\n",
       " 'birth',\n",
       " 'birthday',\n",
       " 'birthmark',\n",
       " 'bisect',\n",
       " 'bishop',\n",
       " 'bismark',\n",
       " 'bistro',\n",
       " 'bitch',\n",
       " 'bite',\n",
       " 'bitmap',\n",
       " 'bitter',\n",
       " 'bitumen',\n",
       " 'biz',\n",
       " 'bk',\n",
       " 'black',\n",
       " 'blackboard',\n",
       " 'blackburn',\n",
       " 'blacklist',\n",
       " 'blackmail',\n",
       " 'blackout',\n",
       " 'bladder',\n",
       " 'blade',\n",
       " 'blain',\n",
       " 'blair',\n",
       " 'blake',\n",
       " 'blame',\n",
       " 'blanc',\n",
       " 'blanch',\n",
       " 'bland',\n",
       " 'blank',\n",
       " 'blanket',\n",
       " 'blaser',\n",
       " 'blast',\n",
       " 'blaster',\n",
       " 'blat',\n",
       " 'blaze',\n",
       " 'bleach',\n",
       " 'bleak',\n",
       " 'bleed',\n",
       " 'blend',\n",
       " 'blender',\n",
       " 'bless',\n",
       " 'blind',\n",
       " 'blindfold',\n",
       " 'bling',\n",
       " 'blink',\n",
       " 'blinker',\n",
       " 'blip',\n",
       " 'bliss',\n",
       " 'blitzstein',\n",
       " 'blizzard',\n",
       " 'bloat',\n",
       " 'blob',\n",
       " 'bloch',\n",
       " 'block',\n",
       " 'blocker',\n",
       " 'bloemfontein',\n",
       " 'blog',\n",
       " 'blogger',\n",
       " 'blood',\n",
       " 'bloom',\n",
       " 'bloomer',\n",
       " 'bloomfield',\n",
       " 'bloomington',\n",
       " 'blossom',\n",
       " 'blot',\n",
       " 'blotto',\n",
       " 'blow',\n",
       " 'blower',\n",
       " 'blowfish',\n",
       " 'blowjob',\n",
       " 'blowup',\n",
       " 'blue',\n",
       " 'blueprint',\n",
       " 'bluff',\n",
       " 'blunder',\n",
       " 'blunt',\n",
       " 'blur',\n",
       " 'blush',\n",
       " 'bm',\n",
       " 'bmi',\n",
       " 'bmr',\n",
       " 'board',\n",
       " 'boarder',\n",
       " 'boat',\n",
       " 'bob',\n",
       " 'bobcat',\n",
       " 'bock',\n",
       " 'bod',\n",
       " 'boehm',\n",
       " 'bog',\n",
       " 'bogart',\n",
       " 'bohemia',\n",
       " 'bohr',\n",
       " 'boil',\n",
       " 'boiler',\n",
       " 'bold',\n",
       " 'bolder',\n",
       " 'boll',\n",
       " 'bologna',\n",
       " 'bolt',\n",
       " 'boltzmann',\n",
       " 'bolzano',\n",
       " 'bomb',\n",
       " 'bombay',\n",
       " 'bomber',\n",
       " 'bond',\n",
       " 'bone',\n",
       " 'bong',\n",
       " 'bongo',\n",
       " 'bonito',\n",
       " 'bonk',\n",
       " 'bonn',\n",
       " 'bonus',\n",
       " 'book',\n",
       " 'booker',\n",
       " 'booklet',\n",
       " 'bookmark',\n",
       " 'bookshelf',\n",
       " 'boolean',\n",
       " 'boom',\n",
       " 'boon',\n",
       " 'boor',\n",
       " 'boost',\n",
       " 'booster',\n",
       " 'boot',\n",
       " 'booth',\n",
       " 'bootstrap',\n",
       " 'bop',\n",
       " 'bordeaux',\n",
       " 'border',\n",
       " 'bore',\n",
       " 'boredom',\n",
       " 'borodin',\n",
       " 'borough',\n",
       " 'borrow',\n",
       " 'bosch',\n",
       " 'bose',\n",
       " 'boson',\n",
       " 'boss',\n",
       " 'boston',\n",
       " 'bot',\n",
       " 'both',\n",
       " 'bother',\n",
       " 'bottleneck',\n",
       " 'bottom',\n",
       " 'bottomless',\n",
       " 'bottommost',\n",
       " 'boulder',\n",
       " 'boulez',\n",
       " 'bouncer',\n",
       " 'bound',\n",
       " 'bounder',\n",
       " 'bouquet',\n",
       " 'bourdon',\n",
       " 'bourn',\n",
       " 'boustrophedon',\n",
       " 'bout',\n",
       " 'bow',\n",
       " 'bowditch',\n",
       " 'bowel',\n",
       " 'bower',\n",
       " 'bowl',\n",
       " 'bowler',\n",
       " 'bowman',\n",
       " 'box',\n",
       " 'boxer',\n",
       " 'boy',\n",
       " 'bpi',\n",
       " 'bpm',\n",
       " 'br',\n",
       " 'bra',\n",
       " 'brace',\n",
       " 'bracket',\n",
       " 'brad',\n",
       " 'bradford',\n",
       " 'bradley',\n",
       " 'braess',\n",
       " 'bragg',\n",
       " 'bragi',\n",
       " 'brahma',\n",
       " 'braid',\n",
       " 'brain',\n",
       " 'brainstem',\n",
       " 'brainstorm',\n",
       " 'brainwash',\n",
       " 'brake',\n",
       " 'branch',\n",
       " 'brand',\n",
       " 'brandenburg',\n",
       " 'brandt',\n",
       " 'brasil',\n",
       " 'brass',\n",
       " 'brassard',\n",
       " 'brat',\n",
       " 'bratislava',\n",
       " 'braun',\n",
       " 'braunschweig',\n",
       " 'brave',\n",
       " 'bray',\n",
       " 'brazil',\n",
       " 'brazilian',\n",
       " 'breach',\n",
       " 'breadth',\n",
       " 'break',\n",
       " 'breakdown',\n",
       " 'breaker',\n",
       " 'breakfast',\n",
       " 'breakthrough',\n",
       " 'breakup',\n",
       " 'breast',\n",
       " 'breath',\n",
       " 'breather',\n",
       " 'brecht',\n",
       " 'breech',\n",
       " 'breed',\n",
       " 'bremen',\n",
       " 'bren',\n",
       " 'brent',\n",
       " 'brescia',\n",
       " 'brest',\n",
       " 'breton',\n",
       " 'breuer',\n",
       " 'breve',\n",
       " 'brew',\n",
       " 'brewer',\n",
       " 'brick',\n",
       " 'bride',\n",
       " 'bridget',\n",
       " 'brie',\n",
       " 'brief',\n",
       " ...]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sison = [x for x in total if wordnet.synsets(x)]\n",
    "sison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = sorted(pdTest.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73541"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "helper = {}\n",
    "i = 0\n",
    "for key, value in bag_of_words.items():\n",
    "    for word in value.keys():\n",
    "        if word in helper:\n",
    "            helper[word] += 1\n",
    "        else:\n",
    "            helper[word] = 1\n",
    "\n",
    "num_words = sum(bag_of_words[files_txt[0]].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'birdnest': 1,\n",
       " 'bayesian': 123,\n",
       " 'infer': 262,\n",
       " 'rate': 442,\n",
       " 'fraud': 9,\n",
       " 'detect': 361,\n",
       " 'arxiv': 915,\n",
       " 'cs': 717,\n",
       " 'ai': 372,\n",
       " 'mar': 189,\n",
       " 'bryan': 12,\n",
       " 'hooi': 1,\n",
       " 'neil': 26,\n",
       " 'shah': 46,\n",
       " 'alex': 35,\n",
       " 'beutel': 1,\n",
       " 'stephan': 27,\n",
       " 'gu': 78,\n",
       " 'nnemann': 3,\n",
       " 'leman': 3,\n",
       " 'akoglu': 2,\n",
       " 'mohit': 3,\n",
       " 'kumar': 76,\n",
       " 'disha': 1,\n",
       " 'makhija': 1,\n",
       " 'christo': 29,\n",
       " 'faloutso': 15,\n",
       " 'abstract': 923,\n",
       " 'product': 532,\n",
       " 'comput': 953,\n",
       " 'suspici': 11,\n",
       " 'score': 138,\n",
       " 'user': 336,\n",
       " 'review': 464,\n",
       " 'pervas': 26,\n",
       " 'problem': 879,\n",
       " 'onlin': 305,\n",
       " 'commerc': 39,\n",
       " 'fraudul': 2,\n",
       " 'seller': 20,\n",
       " 'write': 688,\n",
       " 'purchas': 35,\n",
       " 'fake': 18,\n",
       " 'manipul': 169,\n",
       " 'percept': 54,\n",
       " 'servic': 143,\n",
       " 'often': 527,\n",
       " 'base': 899,\n",
       " 'sever': 723,\n",
       " 'sign': 213,\n",
       " 'includ': 796,\n",
       " 'occur': 526,\n",
       " 'short': 397,\n",
       " 'burst': 23,\n",
       " 'time': 901,\n",
       " 'account': 398,\n",
       " 'skew': 63,\n",
       " 'distribut': 690,\n",
       " 'howev': 877,\n",
       " 'may': 869,\n",
       " 'true': 612,\n",
       " 'give': 957,\n",
       " 'dataset': 217,\n",
       " 'henc': 703,\n",
       " 'paper': 911,\n",
       " 'propos': 654,\n",
       " 'approach': 797,\n",
       " 'combin': 761,\n",
       " 'principl': 422,\n",
       " 'manner': 294,\n",
       " 'allow': 770,\n",
       " 'success': 486,\n",
       " 'even': 823,\n",
       " 'one': 974,\n",
       " 'present': 875,\n",
       " 'to': 885,\n",
       " 'formul': 424,\n",
       " 'data': 652,\n",
       " 'bird': 20,\n",
       " 'model': 766,\n",
       " 'flexibl': 153,\n",
       " 'behavior': 410,\n",
       " 'likelihood': 170,\n",
       " 'metric': 298,\n",
       " 'normal': 532,\n",
       " 'expect': 603,\n",
       " 'surpris': 153,\n",
       " 'total': 694,\n",
       " 'nest': 100,\n",
       " 'we': 945,\n",
       " 'linear': 743,\n",
       " 'algorithm': 828,\n",
       " 'perform': 739,\n",
       " 'use': 976,\n",
       " 'experi': 438,\n",
       " 'real': 615,\n",
       " 'show': 956,\n",
       " 'spot': 34,\n",
       " 'larg': 791,\n",
       " 'world': 359,\n",
       " 'graph': 553,\n",
       " 'flipkart': 1,\n",
       " 'platform': 112,\n",
       " 'flag': 53,\n",
       " 'investig': 470,\n",
       " 'identifi': 537,\n",
       " 'domain': 393,\n",
       " 'expert': 92,\n",
       " 'current': 594,\n",
       " 'number': 945,\n",
       " 'tempor': 143,\n",
       " 'these': 736,\n",
       " 'focu': 493,\n",
       " 'catch': 38,\n",
       " 'receiv': 454,\n",
       " 'posit': 775,\n",
       " 'neg': 484,\n",
       " 'motiv': 442,\n",
       " 'bursti': 10,\n",
       " 'natur': 756,\n",
       " 'store': 286,\n",
       " 'wish': 184,\n",
       " 'rapidli': 93,\n",
       " 'increas': 730,\n",
       " 'popular': 267,\n",
       " 'defam': 1,\n",
       " 'competitor': 20,\n",
       " 'an': 878,\n",
       " 'altern': 544,\n",
       " 'find': 887,\n",
       " 'differ': 929,\n",
       " 'term': 832,\n",
       " 'deviat': 268,\n",
       " 'practic': 593,\n",
       " 'in': 978,\n",
       " 'aim': 417,\n",
       " 'way': 819,\n",
       " 'construct': 749,\n",
       " 'measur': 652,\n",
       " 'much': 646,\n",
       " 'rest': 440,\n",
       " 'the': 980,\n",
       " 'also': 961,\n",
       " 'provid': 861,\n",
       " 'solut': 657,\n",
       " 'conceptu': 133,\n",
       " 'difficult': 408,\n",
       " 'good': 517,\n",
       " 'tradeoff': 107,\n",
       " 'extrem': 323,\n",
       " 'vs': 249,\n",
       " 'larger': 612,\n",
       " 'be': 380,\n",
       " 'averag': 522,\n",
       " 'method': 804,\n",
       " 'us': 759,\n",
       " 'quantit': 147,\n",
       " 'answer': 346,\n",
       " 'question': 542,\n",
       " 'name': 619,\n",
       " 'estim': 529,\n",
       " 'belief': 98,\n",
       " 'characterist': 328,\n",
       " 'captur': 355,\n",
       " 'uncertainti': 141,\n",
       " 'determin': 732,\n",
       " 'our': 728,\n",
       " 'contribut': 552,\n",
       " 'theoret': 609,\n",
       " 'sound': 98,\n",
       " 'defin': 916,\n",
       " 'mixtur': 101,\n",
       " 'type': 693,\n",
       " 'thi': 969,\n",
       " 'anomal': 20,\n",
       " 'scalabl': 122,\n",
       " 'effect': 633,\n",
       " 'learn': 398,\n",
       " 'evalu': 545,\n",
       " 'introduct': 849,\n",
       " 'play': 369,\n",
       " 'import': 717,\n",
       " 'role': 422,\n",
       " 'inform': 831,\n",
       " 'custom': 108,\n",
       " 'decis': 348,\n",
       " 'lead': 701,\n",
       " 'busi': 113,\n",
       " 'order': 900,\n",
       " 'rais': 156,\n",
       " 'crucial': 311,\n",
       " 'commerci': 73,\n",
       " 'remov': 503,\n",
       " 'maintain': 300,\n",
       " 'trust': 83,\n",
       " 'accuraci': 285,\n",
       " 'variou': 518,\n",
       " 'input': 631,\n",
       " 'text': 219,\n",
       " 'timestamp': 20,\n",
       " 'etc': 336,\n",
       " 'avail': 598,\n",
       " 'system': 812,\n",
       " 'work': 907,\n",
       " 'commonli': 190,\n",
       " 'featur': 420,\n",
       " 'roblem': 37,\n",
       " 'nformal': 2,\n",
       " 'set': 958,\n",
       " 'star': 95,\n",
       " 'carnegi': 35,\n",
       " 'mellon': 34,\n",
       " 'univers': 896,\n",
       " 'universita': 68,\n",
       " 'mu': 61,\n",
       " 'nchen': 17,\n",
       " 'stoni': 9,\n",
       " 'brook': 35,\n",
       " 'technisch': 29,\n",
       " 'common': 573,\n",
       " 'pattern': 387,\n",
       " 'observ': 795,\n",
       " 'top': 396,\n",
       " 'involv': 552,\n",
       " 'bucket': 25,\n",
       " 'logarithm': 223,\n",
       " 'shorter': 116,\n",
       " 'figur': 708,\n",
       " 'high': 619,\n",
       " 'precis': 591,\n",
       " 'inspect': 116,\n",
       " 'strongli': 235,\n",
       " 'consist': 743,\n",
       " 'two': 965,\n",
       " 'group': 490,\n",
       " 'highli': 307,\n",
       " 'middl': 177,\n",
       " 'right': 629,\n",
       " 'exist': 872,\n",
       " 'anomali': 35,\n",
       " 'focus': 323,\n",
       " 'pure': 282,\n",
       " 'node': 419,\n",
       " 'edg': 425,\n",
       " 'label': 367,\n",
       " 'spectral': 160,\n",
       " 'eigen': 17,\n",
       " 'decomposit': 278,\n",
       " 'singular': 151,\n",
       " 'valu': 881,\n",
       " 'svd': 41,\n",
       " 'similar': 847,\n",
       " 'iter': 479,\n",
       " 'honest': 21,\n",
       " 'dishonest': 5,\n",
       " 'markov': 193,\n",
       " 'random': 630,\n",
       " 'field': 441,\n",
       " 'propag': 192,\n",
       " 'dens': 164,\n",
       " 'subgraph': 165,\n",
       " 'spammer': 4,\n",
       " 'graphbas': 7,\n",
       " 'self': 288,\n",
       " 'neighborhood': 155,\n",
       " 'divers': 146,\n",
       " 'make': 876,\n",
       " 'key': 540,\n",
       " 'there': 735,\n",
       " 'multivari': 99,\n",
       " 'seri': 427,\n",
       " 'patprecis': 1,\n",
       " 'tern': 3,\n",
       " 'inter': 117,\n",
       " 'arriv': 224,\n",
       " 'event': 325,\n",
       " 'social': 203,\n",
       " 'media': 114,\n",
       " 'coupl': 203,\n",
       " 'address': 506,\n",
       " 'reproduc': 108,\n",
       " 'code': 472,\n",
       " 'open': 544,\n",
       " 'sourc': 409,\n",
       " 'www': 361,\n",
       " 'spam': 22,\n",
       " 'singleton': 113,\n",
       " 'period': 219,\n",
       " 'unusu': 34,\n",
       " 'activandrew': 1,\n",
       " 'cmu': 31,\n",
       " 'edu': 451,\n",
       " 'bhooi': 1,\n",
       " 'tar': 8,\n",
       " 'iti': 36,\n",
       " 'goal': 483,\n",
       " 'gener': 960,\n",
       " 'background': 230,\n",
       " 'relat': 831,\n",
       " 'content': 250,\n",
       " 'signific': 440,\n",
       " 'portion': 119,\n",
       " 'opin': 2,\n",
       " 'regard': 404,\n",
       " 'offer': 227,\n",
       " 'ion': 24,\n",
       " 'come': 486,\n",
       " 'count': 377,\n",
       " 'suitabl': 349,\n",
       " 'long': 546,\n",
       " 'studi': 814,\n",
       " 'mani': 834,\n",
       " 'while': 480,\n",
       " 'wide': 405,\n",
       " 'bodi': 155,\n",
       " 'illumin': 38,\n",
       " 'site': 99,\n",
       " 'research': 775,\n",
       " 'understand': 506,\n",
       " 'without': 825,\n",
       " 'easili': 590,\n",
       " 'therefor': 779,\n",
       " 'especi': 304,\n",
       " 'particular': 790,\n",
       " 'characteri': 1,\n",
       " 'recommend': 114,\n",
       " 'commun': 579,\n",
       " 'frequentist': 7,\n",
       " 'demonstratt': 1,\n",
       " 'alway': 647,\n",
       " 'ing': 62,\n",
       " 'great': 162,\n",
       " 'addit': 823,\n",
       " 'take': 880,\n",
       " 'other': 489,\n",
       " 'bimod': 9,\n",
       " 'mean': 865,\n",
       " 'treat': 308,\n",
       " 'argument': 552,\n",
       " 'by': 769,\n",
       " 'develop': 630,\n",
       " 'significantli': 366,\n",
       " 'perspect': 298,\n",
       " 'result': 967,\n",
       " 'explicit': 311,\n",
       " 'prior': 300,\n",
       " 'uniqu': 579,\n",
       " 'posterior': 66,\n",
       " 'easi': 563,\n",
       " 'extens': 623,\n",
       " 'exampl': 888,\n",
       " 'start': 697,\n",
       " 'illustr': 550,\n",
       " 'help': 514,\n",
       " 'consid': 934,\n",
       " 'alic': 42,\n",
       " 'bob': 45,\n",
       " 'carol': 6,\n",
       " 'whose': 627,\n",
       " 'for': 957,\n",
       " 'exhibit': 234,\n",
       " 'hockey': 1,\n",
       " 'stick': 66,\n",
       " 'close': 710,\n",
       " 'which': 59,\n",
       " 'like': 763,\n",
       " 'intuit': 400,\n",
       " 'toward': 436,\n",
       " 'know': 880,\n",
       " 'confid': 119,\n",
       " 'appli': 886,\n",
       " 'it': 953,\n",
       " 'first': 958,\n",
       " 'repres': 787,\n",
       " 'default': 116,\n",
       " 'form': 855,\n",
       " 'final': 830,\n",
       " 'believ': 244,\n",
       " 'need': 876,\n",
       " 'refer': 941,\n",
       " 'express': 634,\n",
       " 'probabl': 613,\n",
       " 'point': 829,\n",
       " 'certain': 588,\n",
       " 'case': 944,\n",
       " 'mark': 256,\n",
       " 'narrow': 75,\n",
       " 'less': 685,\n",
       " 'spread': 140,\n",
       " 'histogram': 81,\n",
       " 'test': 515,\n",
       " 'what': 251,\n",
       " 'instead': 688,\n",
       " 'standard': 674,\n",
       " 'hypothesi': 322,\n",
       " 'quantiti': 291,\n",
       " 'whi': 73,\n",
       " 'low': 487,\n",
       " 'associ': 620,\n",
       " 'see': 921,\n",
       " 'whether': 611,\n",
       " 'sinc': 915,\n",
       " 'popul': 151,\n",
       " 'littl': 276,\n",
       " 'lie': 378,\n",
       " 'she': 41,\n",
       " 'simpli': 532,\n",
       " 'slightli': 403,\n",
       " 'appear': 635,\n",
       " 'non': 831,\n",
       " 'would': 765,\n",
       " 'converg': 399,\n",
       " 'typic': 460,\n",
       " 'say': 683,\n",
       " 'due': 737,\n",
       " 'person': 211,\n",
       " 'variat': 319,\n",
       " 'greater': 398,\n",
       " 'certainti': 36,\n",
       " 'enough': 536,\n",
       " 'small': 740,\n",
       " 'difhi': 1,\n",
       " 'ferenc': 5,\n",
       " 'could': 687,\n",
       " 'produc': 526,\n",
       " 'arbitrarili': 289,\n",
       " 'decid': 350,\n",
       " 'correctli': 238,\n",
       " 'conclud': 613,\n",
       " 'volv': 1,\n",
       " 'step': 760,\n",
       " 'process': 802,\n",
       " 'draw': 363,\n",
       " 'second': 869,\n",
       " 'esti': 2,\n",
       " 'equal': 809,\n",
       " 'mate': 10,\n",
       " 'uncertain': 56,\n",
       " 'cannot': 689,\n",
       " 'fairli': 102,\n",
       " 'entir': 391,\n",
       " 'belong': 417,\n",
       " 'cluster': 247,\n",
       " 'singl': 724,\n",
       " 'tabl': 530,\n",
       " 'summar': 403,\n",
       " 'notat': 624,\n",
       " 'each': 600,\n",
       " 'vector': 601,\n",
       " 'let': 841,\n",
       " 'index': 581,\n",
       " 'bold': 88,\n",
       " 'zi': 152,\n",
       " 'multinomi': 25,\n",
       " 'paramet': 676,\n",
       " 'interpret': 434,\n",
       " 'kth': 86,\n",
       " 'entri': 370,\n",
       " 'no': 399,\n",
       " 'within': 644,\n",
       " 'reason': 692,\n",
       " 'ni': 218,\n",
       " 'behav': 185,\n",
       " 'exactli': 607,\n",
       " 'thu': 864,\n",
       " 'level': 570,\n",
       " 'per': 466,\n",
       " 'xij': 48,\n",
       " 'jth': 62,\n",
       " 'dirichlet': 38,\n",
       " 'ij': 197,\n",
       " 'individu': 393,\n",
       " 'max': 579,\n",
       " 'highest': 213,\n",
       " 'denot': 818,\n",
       " 'pi': 320,\n",
       " 'xi': 508,\n",
       " 'resp': 148,\n",
       " 'length': 593,\n",
       " 'nonneg': 165,\n",
       " 'sum': 610,\n",
       " 'matrix': 498,\n",
       " 'contain': 816,\n",
       " 'nil': 14,\n",
       " 'similarli': 656,\n",
       " 'compon': 560,\n",
       " 'qi': 178,\n",
       " 'fx': 40,\n",
       " 'global': 401,\n",
       " 'describ': 795,\n",
       " 'variabl': 666,\n",
       " 'discret': 547,\n",
       " 'preprocess': 103,\n",
       " 'previou': 721,\n",
       " 'last': 657,\n",
       " 'accord': 638,\n",
       " 'integ': 521,\n",
       " 'part': 792,\n",
       " 'log': 518,\n",
       " 'correspond': 875,\n",
       " 'graphic': 166,\n",
       " 'choose': 584,\n",
       " 'sensibl': 34,\n",
       " 'analog': 385,\n",
       " 'raw': 81,\n",
       " 'possibl': 867,\n",
       " 'either': 720,\n",
       " 'rapid': 73,\n",
       " 'concentr': 214,\n",
       " 'regular': 359,\n",
       " 'everi': 768,\n",
       " 'hour': 103,\n",
       " 'both': 383,\n",
       " 'suggest': 502,\n",
       " 'bot': 9,\n",
       " 'spammi': 1,\n",
       " 'moreov': 601,\n",
       " 'ring': 576,\n",
       " 'assum': 838,\n",
       " 'restrict': 616,\n",
       " 'parametr': 140,\n",
       " 'gaussian': 262,\n",
       " 'from': 684,\n",
       " 'fit': 282,\n",
       " 'fig': 404,\n",
       " 'greedi': 135,\n",
       " 'hill': 86,\n",
       " 'climb': 15,\n",
       " 'maxim': 543,\n",
       " 'overal': 361,\n",
       " 'function': 889,\n",
       " 'adjust': 189,\n",
       " 'assign': 473,\n",
       " 'arg': 161,\n",
       " 'line': 617,\n",
       " 'solv': 616,\n",
       " 'effici': 648,\n",
       " 'next': 773,\n",
       " 'here': 627,\n",
       " 'fix': 746,\n",
       " 'respect': 877,\n",
       " 'note': 902,\n",
       " 'affect': 367,\n",
       " 'equival': 685,\n",
       " 'margin': 193,\n",
       " 'ak': 173,\n",
       " 'nxil': 1,\n",
       " 'kl': 78,\n",
       " 'gamma': 45,\n",
       " 'choos': 655,\n",
       " 'sampl': 453,\n",
       " 'explain': 446,\n",
       " 'nxi': 5,\n",
       " 'at': 584,\n",
       " 'hyperparamet': 22,\n",
       " 'complet': 813,\n",
       " 'clear': 522,\n",
       " 'conjug': 93,\n",
       " 'properti': 794,\n",
       " 'distribulikelihood': 1,\n",
       " 'tion': 96,\n",
       " 'nx': 36,\n",
       " 'simizi': 1,\n",
       " 'maxi': 83,\n",
       " 'larli': 3,\n",
       " 'mum': 4,\n",
       " 'updat': 382,\n",
       " 'select': 609,\n",
       " 'criterion': 193,\n",
       " 'bic': 12,\n",
       " 'as': 888,\n",
       " 'adpoint': 1,\n",
       " 'maximum': 661,\n",
       " 'justment': 1,\n",
       " 'specif': 717,\n",
       " 'repeat': 420,\n",
       " 'conver': 3,\n",
       " 'becaus': 296,\n",
       " 'genc': 4,\n",
       " 'bind': 753,\n",
       " 'must': 677,\n",
       " 'section': 910,\n",
       " 'recal': 559,\n",
       " 'idea': 585,\n",
       " 'averpm': 1,\n",
       " 'il': 132,\n",
       " 'age': 66,\n",
       " 'new': 895,\n",
       " 'ensur': 466,\n",
       " 'influenc': 224,\n",
       " 'param': 21,\n",
       " 'eter': 8,\n",
       " 'finer': 53,\n",
       " 'resolut': 170,\n",
       " 'chang': 694,\n",
       " 'neither': 282,\n",
       " 'domin': 290,\n",
       " 'imiz': 1,\n",
       " 'formula': 353,\n",
       " 'directli': 567,\n",
       " 'underli': 379,\n",
       " 'pni': 8,\n",
       " 'coeffici': 353,\n",
       " 'pm': 127,\n",
       " 'procedur': 504,\n",
       " 'output': 545,\n",
       " 'adjustp': 1,\n",
       " 'proport': 288,\n",
       " 'end': 674,\n",
       " 'zinew': 1,\n",
       " 'maxk': 13,\n",
       " 'think': 315,\n",
       " 'sens': 584,\n",
       " 'usersar': 1,\n",
       " 'lower': 677,\n",
       " 'compar': 731,\n",
       " 'now': 604,\n",
       " 'return': 468,\n",
       " 'bay': 74,\n",
       " 'best': 579,\n",
       " 'knowledg': 512,\n",
       " 'efinit': 10,\n",
       " 'xpect': 2,\n",
       " 'urpris': 1,\n",
       " 'sx': 49,\n",
       " 'ep': 75,\n",
       " 'discuss': 763,\n",
       " 'ratk': 1,\n",
       " 'rewher': 1,\n",
       " 'generat': 4,\n",
       " 'sult': 6,\n",
       " 'simi': 4,\n",
       " 'add': 470,\n",
       " 'howsurpris': 1,\n",
       " 'distribu': 4,\n",
       " 'ever': 128,\n",
       " 'di': 285,\n",
       " 'largest': 379,\n",
       " 'dominattribut': 1,\n",
       " 'std': 34,\n",
       " 'dev': 23,\n",
       " 'analofor': 1,\n",
       " 'sake': 192,\n",
       " 'imagin': 86,\n",
       " 'mass': 145,\n",
       " 'gousli': 3,\n",
       " 'then': 800,\n",
       " 'perfect': 231,\n",
       " 'jointli': 115,\n",
       " 'calcul': 466,\n",
       " 'minimum': 517,\n",
       " 'squar': 392,\n",
       " 'error': 537,\n",
       " 'minim': 607,\n",
       " 'least': 769,\n",
       " 'loss': 489,\n",
       " 'desir': 505,\n",
       " 'condit': 784,\n",
       " 'substanti': 191,\n",
       " 'multipl': 684,\n",
       " 'subtract': 116,\n",
       " 'boost': 86,\n",
       " 'anoth': 761,\n",
       " 'shift': 240,\n",
       " 'amount': 442,\n",
       " 'competit': 135,\n",
       " 'plot': 274,\n",
       " 'diswithin': 1,\n",
       " 'tribut': 16,\n",
       " 'frequenc': 231,\n",
       " 'get': 647,\n",
       " 'ilarli': 3,\n",
       " 'full': 519,\n",
       " 'pk': 202,\n",
       " 'examin': 253,\n",
       " 'ex': 116,\n",
       " 'pect': 1,\n",
       " 'polar': 62,\n",
       " 'well': 885,\n",
       " 'repeatedli': 134,\n",
       " 'mostli': 178,\n",
       " 'rel': 528,\n",
       " 'fraction': 290,\n",
       " 'conduct': 210,\n",
       " 'follow': 963,\n",
       " 'swm': 1,\n",
       " 'scale': 479,\n",
       " 'softwar': 279,\n",
       " 'app': 37,\n",
       " 'collect': 519,\n",
       " 'crawl': 14,\n",
       " 'entertain': 18,\n",
       " 'categori': 202,\n",
       " 'anonym': 194,\n",
       " 'life': 113,\n",
       " 'implement': 579,\n",
       " 'python': 35,\n",
       " 'ment': 36,\n",
       " 'carri': 348,\n",
       " 'ghz': 68,\n",
       " 'intel': 143,\n",
       " 'core': 267,\n",
       " 'macw': 1,\n",
       " 'evid': 267,\n",
       " 'book': 153,\n",
       " 'pro': 40,\n",
       " 'gb': 87,\n",
       " 'ram': 97,\n",
       " 'run': 571,\n",
       " 'os': 39,\n",
       " 'post': 188,\n",
       " 'block': 370,\n",
       " 'download': 68,\n",
       " 'andrew': 93,\n",
       " 'span': 240,\n",
       " 'week': 41,\n",
       " 'five': 228,\n",
       " 'near': 247,\n",
       " 'ident': 554,\n",
       " 'titl': 55,\n",
       " 'varieti': 251,\n",
       " 'detail': 716,\n",
       " 'advertis': 34,\n",
       " 'benefit': 261,\n",
       " 'owner': 31,\n",
       " 'via': 650,\n",
       " 'clearli': 499,\n",
       " 'nearident': 1,\n",
       " 'trivial': 459,\n",
       " 'dollar': 22,\n",
       " 'all': 588,\n",
       " 'merchant': 8,\n",
       " 'sell': 46,\n",
       " 'so': 453,\n",
       " 'hand': 700,\n",
       " 'bonu': 5,\n",
       " 'asid': 49,\n",
       " 'almost': 441,\n",
       " 'fact': 829,\n",
       " 'context': 534,\n",
       " 'accompani': 36,\n",
       " 'promis': 176,\n",
       " 'free': 454,\n",
       " 'cash': 7,\n",
       " 'gift': 12,\n",
       " 'card': 43,\n",
       " 'unit': 483,\n",
       " 'loglikelihood': 12,\n",
       " 'exponenti': 400,\n",
       " 'conform': 50,\n",
       " 'simul': 407,\n",
       " 'fast': 394,\n",
       " 'around': 379,\n",
       " 'minut': 79,\n",
       " 'growth': 143,\n",
       " 'outer': 109,\n",
       " 'loop': 263,\n",
       " 'mk': 104,\n",
       " 'grow': 340,\n",
       " 'linearli': 199,\n",
       " 'three': 777,\n",
       " 'verifi': 454,\n",
       " 'inde': 557,\n",
       " 'they': 440,\n",
       " 'match': 435,\n",
       " 'longterm': 9,\n",
       " 'display': 162,\n",
       " 'agre': 188,\n",
       " 'nonsuspici': 1,\n",
       " 'indic': 669,\n",
       " 'rank': 307,\n",
       " 'million': 105,\n",
       " 'locat': 377,\n",
       " 'far': 488,\n",
       " 'conclus': 639,\n",
       " 'likelihoodbas': 1,\n",
       " 'chandi': 4,\n",
       " 'opinion': 73,\n",
       " 'network': 523,\n",
       " 'icwsm': 5,\n",
       " 'murray': 36,\n",
       " 'smola': 20,\n",
       " 'cobafi': 1,\n",
       " 'collabor': 119,\n",
       " 'filter': 218,\n",
       " 'proceed': 715,\n",
       " 'intern': 705,\n",
       " 'confer': 596,\n",
       " 'web': 189,\n",
       " 'page': 519,\n",
       " 'acm': 572,\n",
       " 'xu': 153,\n",
       " 'guruswami': 19,\n",
       " 'palow': 1,\n",
       " 'copycatch': 1,\n",
       " 'stop': 254,\n",
       " 'attack': 102,\n",
       " 'lockstep': 4,\n",
       " 'cheng': 75,\n",
       " 'tan': 77,\n",
       " 'potter': 6,\n",
       " 'klooster': 1,\n",
       " 'character': 450,\n",
       " 'sdm': 14,\n",
       " 'siam': 384,\n",
       " 'feng': 47,\n",
       " 'banerje': 26,\n",
       " 'choi': 32,\n",
       " 'syntact': 71,\n",
       " 'stylometri': 1,\n",
       " 'decept': 15,\n",
       " 'annual': 325,\n",
       " 'meet': 300,\n",
       " 'linguist': 46,\n",
       " 'volum': 413,\n",
       " 'ferraz': 2,\n",
       " 'costa': 17,\n",
       " 'yamaguchi': 3,\n",
       " 'juci': 1,\n",
       " 'machado': 2,\n",
       " 'traina': 1,\n",
       " 'jr': 86,\n",
       " 'rsc': 3,\n",
       " 'mine': 157,\n",
       " 'activ': 339,\n",
       " 'sigkdd': 47,\n",
       " 'discoveri': 161,\n",
       " 'dynam': 420,\n",
       " 'robust': 313,\n",
       " 'probabilist': 256,\n",
       " 'evolut': 172,\n",
       " 'hu': 125,\n",
       " 'liu': 212,\n",
       " 'tenth': 22,\n",
       " 'jiang': 76,\n",
       " 'cui': 28,\n",
       " 'yang': 161,\n",
       " 'multimod': 24,\n",
       " 'icdm': 22,\n",
       " 'ieee': 656,\n",
       " 'strang': 31,\n",
       " 'connect': 632,\n",
       " 'advanc': 506,\n",
       " 'springer': 604,\n",
       " 'jindal': 7,\n",
       " 'analysi': 787,\n",
       " 'search': 453,\n",
       " 'lim': 202,\n",
       " 'unexpect': 42,\n",
       " 'rule': 460,\n",
       " 'manag': 287,\n",
       " 'koren': 11,\n",
       " 'factor': 597,\n",
       " 'multifacet': 5,\n",
       " 'lehmann': 11,\n",
       " 'casella': 7,\n",
       " 'theori': 800,\n",
       " 'scienc': 813,\n",
       " 'li': 370,\n",
       " 'han': 126,\n",
       " 'approxim': 622,\n",
       " 'subspac': 162,\n",
       " 'multi': 384,\n",
       " 'dimension': 443,\n",
       " 'veri': 84,\n",
       " 'vldb': 24,\n",
       " 'endow': 67,\n",
       " 'nguyen': 64,\n",
       " 'lauw': 1,\n",
       " 'minka': 5,\n",
       " 'ott': 10,\n",
       " 'cardi': 3,\n",
       " 'hancock': 6,\n",
       " 'stretch': 36,\n",
       " 'human': 227,\n",
       " 'languag': 347,\n",
       " 'technologiesvolum': 1,\n",
       " 'pandit': 4,\n",
       " 'chau': 4,\n",
       " 'wang': 293,\n",
       " 'netprob': 1,\n",
       " 'auction': 41,\n",
       " 'prakash': 8,\n",
       " 'seshadri': 5,\n",
       " 'sridharan': 11,\n",
       " 'machiraju': 3,\n",
       " 'eigenspok': 1,\n",
       " 'structur': 783,\n",
       " 'pakdd': 6,\n",
       " 'ramaswami': 9,\n",
       " 'rastogi': 5,\n",
       " 'shim': 5,\n",
       " 'outlier': 64,\n",
       " 'sigmod': 42,\n",
       " 'record': 261,\n",
       " 'salakhutdinov': 22,\n",
       " 'mnih': 5,\n",
       " 'chain': 260,\n",
       " 'mont': 90,\n",
       " 'carlo': 121,\n",
       " 'machin': 425,\n",
       " 'gallagh': 8,\n",
       " 'link': 333,\n",
       " 'fbox': 1,\n",
       " 'adversari': 88,\n",
       " 'gunnemann': 1,\n",
       " 'edgecentr': 1,\n",
       " 'attribut': 189,\n",
       " 'preprint': 221,\n",
       " 'vahdatpour': 1,\n",
       " 'sarrafzadeh': 1,\n",
       " 'unsupervis': 52,\n",
       " 'abnorm': 25,\n",
       " 'occurr': 181,\n",
       " 'applic': 855,\n",
       " 'wearabl': 11,\n",
       " 'xie': 55,\n",
       " 'yu': 175,\n",
       " 'lin': 145,\n",
       " 'ye': 168,\n",
       " 'discov': 206,\n",
       " 'footprint': 23,\n",
       " 'databas': 177,\n",
       " 'transact': 431,\n",
       " 'on': 865,\n",
       " 'imag': 349,\n",
       " 'vol': 468,\n",
       " 'decemb': 117,\n",
       " 'salient': 29,\n",
       " 'object': 568,\n",
       " 'benchmark': 163,\n",
       " 'cv': 74,\n",
       " 'feb': 169,\n",
       " 'ali': 46,\n",
       " 'borji': 2,\n",
       " 'ming': 37,\n",
       " 'huaizu': 2,\n",
       " 'jia': 38,\n",
       " 'qualit': 89,\n",
       " 'state': 818,\n",
       " 'art': 227,\n",
       " 'fixat': 6,\n",
       " 'predict': 302,\n",
       " 'baselin': 99,\n",
       " 'challeng': 393,\n",
       " 'purpos': 490,\n",
       " 'segment': 220,\n",
       " 'obtain': 876,\n",
       " 'progress': 235,\n",
       " 'year': 315,\n",
       " 'contend': 11,\n",
       " 'outperform': 193,\n",
       " 'ago': 45,\n",
       " 'design': 620,\n",
       " 'better': 605,\n",
       " 'area': 435,\n",
       " 'turn': 558,\n",
       " 'definit': 788,\n",
       " 'appropri': 435,\n",
       " 'treatment': 132,\n",
       " 'distinguish': 362,\n",
       " 'analyz': 492,\n",
       " 'center': 383,\n",
       " 'bia': 133,\n",
       " 'scene': 52,\n",
       " 'complex': 755,\n",
       " 'along': 487,\n",
       " 'hard': 443,\n",
       " 'hint': 60,\n",
       " 'salienc': 15,\n",
       " 'tackl': 118,\n",
       " 'futur': 492,\n",
       " 'direct': 727,\n",
       " 'visual': 228,\n",
       " 'attent': 303,\n",
       " 'region': 311,\n",
       " 'interest': 758,\n",
       " 'eye': 41,\n",
       " 'movement': 87,\n",
       " 'ntroduct': 172,\n",
       " 'isual': 1,\n",
       " 'astonish': 9,\n",
       " 'capabl': 221,\n",
       " 'stimuli': 15,\n",
       " 'disciplin': 62,\n",
       " 'cognit': 71,\n",
       " 'psycholog': 57,\n",
       " 'neurosci': 29,\n",
       " 'vision': 124,\n",
       " 'integr': 394,\n",
       " 'guid': 189,\n",
       " 'earli': 216,\n",
       " 'koch': 16,\n",
       " 'ullman': 35,\n",
       " 'itti': 3,\n",
       " 'et': 656,\n",
       " 'al': 645,\n",
       " 'hundr': 85,\n",
       " 'manuscript': 134,\n",
       " 'januari': 142,\n",
       " ...}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-fca9ac65d1d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mhelper\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mnum_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbag_of_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfiles_txt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'dict'"
     ]
    }
   ],
   "source": [
    "helper = {}\n",
    "i = 0\n",
    "for key, value in bag_of_words.items():\n",
    "    for word in value.keys():\n",
    "        if word in helper:\n",
    "            helper[word] += 1\n",
    "        else:\n",
    "            helper[word] = 1\n",
    "\n",
    "num_words = sum(bag_of_words[files_txt[0]].values())\n",
    "            \n",
    "\n",
    "#freq 0\n",
    "#Term frequency 1\n",
    "#tf 2\n",
    "#Inverse Document Frequency 3\n",
    "num_words = sum(bag_of_words[files_txt[0]].values())\n",
    "\n",
    "for documento, words in bag_of_words.items():\n",
    "    num_words = sum(bag_of_words[documento].values())\n",
    "    for key, value in words.items():\n",
    "        dic = {}\n",
    "        print(key, value)\n",
    "        dic['freq'] = value\n",
    "        dic['freqR'] = value / num_words\n",
    "        dic['tf'] = 1 + np.log(value)\n",
    "        dic['idf'] = np.log(len(bag_of_words) / helper[key])\n",
    "        bag_of_words[documento][key] = dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query\n",
    "def transformar_informacion (texto):\n",
    "    texto = re.sub('[^A-Za-z0-9]+',' ',texto) # Caracteres especiales\n",
    "    texto = texto.replace('','i')\n",
    "    tokens = texto.split()\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmer2 = LancasterStemmer()\n",
    "    tokens = [wordnet_lemmatizer.lemmatize(stemmer.stem(w.lower()), pos=\"v\") for w in tokens if (len(w)>1) and w.isalpha() and w not in sw] # Longitud mayor a 1\n",
    "    return tokens\n",
    "\n",
    "texto = \"User friendly user\"\n",
    "query = transformar_informacion(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user', 'friendli', 'user']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "980"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Contar documentos\n",
    "len(bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El documento '/1511.06030.txt' tiene 923 palabras unicas despues del proceso de limpieza\n",
      "El total de palabras contenido en el texto es de 3747\n"
     ]
    }
   ],
   "source": [
    "#Contar numero de palabras por documento despues de limpieza\n",
    "x_doc = [] # documentos\n",
    "y_doc = [] # num palabras unicas por doc\n",
    "total_palabras_doc = [] # total palabras\n",
    "for documento, words in bag_of_words.items():\n",
    "    x_doc.append(documento)\n",
    "    y_doc.append(len(words))\n",
    "    numero_palabras = 0\n",
    "    for word, values in words.items():\n",
    "        numero_palabras += values['freq']\n",
    "    total_palabras_doc.append(numero_palabras)\n",
    "\n",
    "#Imprimir Solo un documento\n",
    "print(\"El documento '{}' tiene {} palabras unicas despues del proceso de limpieza\".format(x_doc[0][-15:], y_doc[0]))\n",
    "print(\"El total de palabras contenido en el texto es de {}\".format(total_palabras_doc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(0, 'characterist'),\n",
       "             (1, 'activandrew'),\n",
       "             (2, 'frequentist'),\n",
       "             (3, 'demonstratt'),\n",
       "             (4, 'arbitrarili'),\n",
       "             (5, 'distribulikelihood'),\n",
       "             (6, 'dominattribut'),\n",
       "             (7, 'loglikelihood'),\n",
       "             (8, 'likelihoodbas'),\n",
       "             (9, 'technologiesvolum'),\n",
       "             (10, 'salakhutdinov'),\n",
       "             (11, 'sarrafzadeh'),\n",
       "             (12, 'distinguish'),\n",
       "             (13, 'multidisciplinari'),\n",
       "             (14, 'neighborhood'),\n",
       "             (15, 'surprisingli'),\n",
       "             (16, 'necessarili'),\n",
       "             (17, 'learningbas'),\n",
       "             (18, 'frequencytun'),\n",
       "             (19, 'complementari'),\n",
       "             (20, 'multiresolut'),\n",
       "             (21, 'heynderickx'),\n",
       "             (22, 'scandinavian'),\n",
       "             (23, 'reconstruct'),\n",
       "             (24, 'nonlinearli'),\n",
       "             (25, 'superpixelwis'),\n",
       "             (26, 'hallonquist'),\n",
       "             (27, 'russakovski'),\n",
       "             (28, 'determinist'),\n",
       "             (29, 'overdetermin'),\n",
       "             (30, 'ptychograhi'),\n",
       "             (31, 'increasingli'),\n",
       "             (32, 'monochromat'),\n",
       "             (33, 'componentwis'),\n",
       "             (34, 'probabilist'),\n",
       "             (35, 'interfermet'),\n",
       "             (36, 'intensityonli'),\n",
       "             (37, 'combinatori'),\n",
       "             (38, 'counterpart'),\n",
       "             (39, 'backproject'),\n",
       "             (40, 'wellconnect'),\n",
       "             (41, 'optimizationless'),\n",
       "             (42, 'poliannikov'),\n",
       "             (43, 'deceivingli'),\n",
       "             (44, 'necessarili'),\n",
       "             (45, 'groundbreak'),\n",
       "             (46, 'significantli'),\n",
       "             (47, 'devastatingli'),\n",
       "             (48, 'surprisingli'),\n",
       "             (49, 'straightaway'),\n",
       "             (50, 'circulararc'),\n",
       "             (51, 'supermarket'),\n",
       "             (52, 'bentleyottmann'),\n",
       "             (53, 'rectangular'),\n",
       "             (54, 'greinerhormann'),\n",
       "             (55, 'preliminari'),\n",
       "             (56, 'unnecessari'),\n",
       "             (57, 'constructsequencelist'),\n",
       "             (58, 'relationship'),\n",
       "             (59, 'trigonometr'),\n",
       "             (60, 'buildnewlinkedlist'),\n",
       "             (61, 'traverselinkedlist'),\n",
       "             (62, 'particularli'),\n",
       "             (63, 'selfintersect'),\n",
       "             (64, 'multiprocessor'),\n",
       "             (65, 'eigenwillig'),\n",
       "             (66, 'massachusett'),\n",
       "             (67, 'computeraid'),\n",
       "             (68, 'architectur'),\n",
       "             (69, 'meguerdichian'),\n",
       "             (70, 'geoinformatica'),\n",
       "             (71, 'nevertheless'),\n",
       "             (72, 'springfield'),\n",
       "             (73, 'infinitesim'),\n",
       "             (74, 'interestingli'),\n",
       "             (75, 'distributor'),\n",
       "             (76, 'monopsonist'),\n",
       "             (77, 'straightforward'),\n",
       "             (78, 'relationship'),\n",
       "             (79, 'nonetheless'),\n",
       "             (80, 'surprisingli'),\n",
       "             (81, 'swierzbinski'),\n",
       "             (82, 'schedulingsurvey'),\n",
       "             (83, 'sonnenschein'),\n",
       "             (84, 'arunachalam'),\n",
       "             (85, 'determinist'),\n",
       "             (86, 'veeraraghavan'),\n",
       "             (87, 'lopsidepend'),\n",
       "             (88, 'preliminari'),\n",
       "             (89, 'interestingli'),\n",
       "             (90, 'importantli'),\n",
       "             (91, 'straighforward'),\n",
       "             (92, 'lexicograph'),\n",
       "             (93, 'psaromiligko'),\n",
       "             (94, 'combinatorica'),\n",
       "             (95, 'complementari'),\n",
       "             (96, 'interestingli'),\n",
       "             (97, 'hcurrentnodei'),\n",
       "             (98, 'currentposit'),\n",
       "             (99, 'neighbourhood'),\n",
       "             (100, 'prevtruckrout'),\n",
       "             (101, 'nexttruckrout'),\n",
       "             (102, 'andisdronenod'),\n",
       "             (103, 'characteris'),\n",
       "             (104, 'haquangminh'),\n",
       "             (105, 'gambardella'),\n",
       "             (106, 'fastcompani'),\n",
       "             (107, 'cuthbertson'),\n",
       "             (108, 'marketwatch'),\n",
       "             (109, 'supplychainquarterli'),\n",
       "             (110, 'savelsbergh'),\n",
       "             (111, 'combinatori'),\n",
       "             (112, 'characterist'),\n",
       "             (113, 'counterpart'),\n",
       "             (114, 'antisymmetri'),\n",
       "             (115, 'adjacentclosur'),\n",
       "             (116, 'autoconcurr'),\n",
       "             (117, 'particularli'),\n",
       "             (118, 'contraposit'),\n",
       "             (119, 'stcstructur'),\n",
       "             (120, 'ieeecomputersocieti'),\n",
       "             (121, 'informatica'),\n",
       "             (122, 'cryptoanalyz'),\n",
       "             (123, 'determinist'),\n",
       "             (124, 'cryptologist'),\n",
       "             (125, 'iberoamericana'),\n",
       "             (126, 'mathematisch'),\n",
       "             (127, 'zeitschrift'),\n",
       "             (128, 'cryptosystem'),\n",
       "             (129, 'picocontain'),\n",
       "             (130, 'previouslyobserv'),\n",
       "             (131, 'redundancybas'),\n",
       "             (132, 'temporallyredund'),\n",
       "             (133, 'necessarili'),\n",
       "             (134, 'importantli'),\n",
       "             (135, 'multilinguist'),\n",
       "             (136, 'algorithmica'),\n",
       "             (137, 'roychoudhuri'),\n",
       "             (138, 'redistributionari'),\n",
       "             (139, 'arbitrarili'),\n",
       "             (140, 'vandenbergh'),\n",
       "             (141, 'wileyintersci'),\n",
       "             (142, 'nondifferenti'),\n",
       "             (143, 'haimltonian'),\n",
       "             (144, 'nonsingular'),\n",
       "             (145, 'equilibrium'),\n",
       "             (146, 'frequencydivis'),\n",
       "             (147, 'redistribut'),\n",
       "             (148, 'architectur'),\n",
       "             (149, 'sparsitybas'),\n",
       "             (150, 'sparsitypromot'),\n",
       "             (151, 'singleoutput'),\n",
       "             (152, 'straightforwardli'),\n",
       "             (153, 'bernoulligaussian'),\n",
       "             (154, 'straightforward'),\n",
       "             (155, 'messagepass'),\n",
       "             (156, 'iterativesolut'),\n",
       "             (157, 'counterpart'),\n",
       "             (158, 'intersymbol'),\n",
       "             (159, 'autoregress'),\n",
       "             (160, 'multichannel'),\n",
       "             (161, 'thitimajshima'),\n",
       "             (162, 'reggiannini'),\n",
       "             (163, 'zusammenhang'),\n",
       "             (164, 'harmonischen'),\n",
       "             (165, 'koeffizienten'),\n",
       "             (166, 'massachusett'),\n",
       "             (167, 'finitedelay'),\n",
       "             (168, 'multidimension'),\n",
       "             (169, 'sensorestim'),\n",
       "             (170, 'temporarili'),\n",
       "             (171, 'logdetermin'),\n",
       "             (172, 'weierstrass'),\n",
       "             (173, 'distinguish'),\n",
       "             (174, 'multitermin'),\n",
       "             (175, 'blocklength'),\n",
       "             (176, 'informatsii'),\n",
       "             (177, 'statistician'),\n",
       "             (178, 'semidefinitequadrat'),\n",
       "             (179, 'polynomialtim'),\n",
       "             (180, 'multiconfer'),\n",
       "             (181, 'naghshtabrizi'),\n",
       "             (182, 'mutuallydepend'),\n",
       "             (183, 'distinguish'),\n",
       "             (184, 'importantli'),\n",
       "             (185, 'structurallytyp'),\n",
       "             (186, 'mathematicallyequival'),\n",
       "             (187, 'incorrectli'),\n",
       "             (188, 'mathematicallyori'),\n",
       "             (189, 'unnecessari'),\n",
       "             (190, 'predetermin'),\n",
       "             (191, 'probabilist'),\n",
       "             (192, 'getrandombit'),\n",
       "             (193, 'unsurprisingli'),\n",
       "             (194, 'microsecond'),\n",
       "             (195, 'preprocessor'),\n",
       "             (196, 'pseudorandom'),\n",
       "             (197, 'probabilist'),\n",
       "             (198, 'arbitrarili'),\n",
       "             (199, 'subpolynomi'),\n",
       "             (200, 'semialgebra'),\n",
       "             (201, 'southeastern'),\n",
       "             (202, 'zarankiewicz'),\n",
       "             (203, 'internationaux'),\n",
       "             (204, 'combinatoir'),\n",
       "             (205, 'radziszowski'),\n",
       "             (206, 'machineverifi'),\n",
       "             (207, 'nonstandard'),\n",
       "             (208, 'nonetheless'),\n",
       "             (209, 'characteris'),\n",
       "             (210, 'distinguish'),\n",
       "             (211, 'relationship'),\n",
       "             (212, 'accordingli'),\n",
       "             (213, 'axtangentbas'),\n",
       "             (214, 'axtangentvertex'),\n",
       "             (215, 'axparallelcon'),\n",
       "             (216, 'meaningless'),\n",
       "             (217, 'lemoutsidenotoncon'),\n",
       "             (218, 'lemaxisislin'),\n",
       "             (219, 'contradictori'),\n",
       "             (220, 'lemslopedlineinverticalplan'),\n",
       "             (221, 'malamenthogarth'),\n",
       "             (222, 'govindarejulu'),\n",
       "             (223, 'entscheidungsproblem'),\n",
       "             (224, 'complementari'),\n",
       "             (225, 'preliminari'),\n",
       "             (226, 'determinist'),\n",
       "             (227, 'contraposit'),\n",
       "             (228, 'surprisingli'),\n",
       "             (229, 'intutionist'),\n",
       "             (230, 'significantli'),\n",
       "             (231, 'nonisomorph'),\n",
       "             (232, 'nevertheless'),\n",
       "             (233, 'jagiellonian'),\n",
       "             (234, 'eksperimentom'),\n",
       "             (235, 'matematicko'),\n",
       "             (236, 'informatiqu'),\n",
       "             (237, 'redistribut'),\n",
       "             (238, 'characterist'),\n",
       "             (239, 'segmentationbas'),\n",
       "             (240, 'interconnect'),\n",
       "             (241, 'accordingli'),\n",
       "             (242, 'architectur'),\n",
       "             (243, 'supplementari'),\n",
       "             (244, 'ieeecomputersocieti'),\n",
       "             (245, 'particularli'),\n",
       "             (246, 'necessarili'),\n",
       "             (247, 'marchingband'),\n",
       "             (248, 'distinguish'),\n",
       "             (249, 'feichtenhof'),\n",
       "             (250, 'interfeatur'),\n",
       "             (251, 'vijayanarasimhan'),\n",
       "             (252, 'galleguillo'),\n",
       "             (253, 'fingerprint'),\n",
       "             (254, 'samplespecif'),\n",
       "             (255, 'codebookfre'),\n",
       "             (256, 'highdimension'),\n",
       "             (257, 'particularli'),\n",
       "             (258, 'kullbackleibl'),\n",
       "             (259, 'accordingli'),\n",
       "             (260, 'eigenvector'),\n",
       "             (261, 'distinguish'),\n",
       "             (262, 'significantli'),\n",
       "             (263, 'probabilist'),\n",
       "             (264, 'discriminativess'),\n",
       "             (265, 'mikolajczyk'),\n",
       "             (266, 'salakhutdinov'),\n",
       "             (267, 'mallikarjuna'),\n",
       "             (268, 'straightforward'),\n",
       "             (269, 'necessarili'),\n",
       "             (270, 'radosavljev'),\n",
       "             (271, 'krishnaswami'),\n",
       "             (272, 'massachusett'),\n",
       "             (273, 'wileyintersci'),\n",
       "             (274, 'blocklength'),\n",
       "             (275, 'commodityspecif'),\n",
       "             (276, 'proposalrefus'),\n",
       "             (277, 'surprisingli'),\n",
       "             (278, 'terminaltermin'),\n",
       "             (279, 'particularli'),\n",
       "             (280, 'voluntarili'),\n",
       "             (281, 'necessarili'),\n",
       "             (282, 'characterist'),\n",
       "             (283, 'complementari'),\n",
       "             (284, 'papadimitri'),\n",
       "             (285, 'polylogarithm'),\n",
       "             (286, 'necessarili'),\n",
       "             (287, 'cryptograph'),\n",
       "             (288, 'accordingli'),\n",
       "             (289, 'arbitrarili'),\n",
       "             (290, 'metaalgorithm'),\n",
       "             (291, 'noninteract'),\n",
       "             (292, 'kasiviswanathan'),\n",
       "             (293, 'raskhodnikova'),\n",
       "             (294, 'indianapoli'),\n",
       "             (295, 'roughgarden'),\n",
       "             (296, 'massachusett'),\n",
       "             (297, 'microprocessor'),\n",
       "             (298, 'nonetheless'),\n",
       "             (299, 'preliminari'),\n",
       "             (300, 'preliminarili'),\n",
       "             (301, 'integervalu'),\n",
       "             (302, 'complexvalu'),\n",
       "             (303, 'increasingli'),\n",
       "             (304, 'unsatisfactori'),\n",
       "             (305, 'particularli'),\n",
       "             (306, 'knowledgeenhanc'),\n",
       "             (307, 'componentwis'),\n",
       "             (308, 'satisfactori'),\n",
       "             (309, 'uncertainti'),\n",
       "             (310, 'determinist'),\n",
       "             (311, 'emamineyestanak'),\n",
       "             (312, 'subdictionari'),\n",
       "             (313, 'slajmerjeva'),\n",
       "             (314, 'bibliograph'),\n",
       "             (315, 'biomolecular'),\n",
       "             (316, 'preliminari'),\n",
       "             (317, 'supplementari'),\n",
       "             (318, 'incorrectli'),\n",
       "             (319, 'biochemistri'),\n",
       "             (320, 'necessarili'),\n",
       "             (321, 'particularli'),\n",
       "             (322, 'straightforward'),\n",
       "             (323, 'reimplement'),\n",
       "             (324, 'nomenclatur'),\n",
       "             (325, 'underexpress'),\n",
       "             (326, 'overexpress'),\n",
       "             (327, 'gastrointest'),\n",
       "             (328, 'aphinyanaphong'),\n",
       "             (329, 'svmabstract'),\n",
       "             (330, 'probabilist'),\n",
       "             (331, 'preliminari'),\n",
       "             (332, 'counterexampl'),\n",
       "             (333, 'redistribut'),\n",
       "             (334, 'anticlockwis'),\n",
       "             (335, 'psaromiligko'),\n",
       "             (336, 'unnecessari'),\n",
       "             (337, 'logemannloveland'),\n",
       "             (338, 'combinatori'),\n",
       "             (339, 'combinatorica'),\n",
       "             (340, 'papadimitri'),\n",
       "             (341, 'increasingli'),\n",
       "             (342, 'characterist'),\n",
       "             (343, 'metamorphos'),\n",
       "             (344, 'superpreferenti'),\n",
       "             (345, 'kabakcioglu'),\n",
       "             (346, 'dorogovtsev'),\n",
       "             (347, 'particularli'),\n",
       "             (348, 'preliminari'),\n",
       "             (349, 'accordingli'),\n",
       "             (350, 'anshelevich'),\n",
       "             (351, 'algorithmica'),\n",
       "             (352, 'papadimitri'),\n",
       "             (353, 'photographi'),\n",
       "             (354, 'neighborhood'),\n",
       "             (355, 'multiprocessor'),\n",
       "             (356, 'salakhutdinov'),\n",
       "             (357, 'evolutionari'),\n",
       "             (358, 'relationship'),\n",
       "             (359, 'determinist'),\n",
       "             (360, 'linearlyparametr'),\n",
       "             (361, 'polylogarithm'),\n",
       "             (362, 'parameterdepend'),\n",
       "             (363, 'suchsinterv'),\n",
       "             (364, 'counterfactu'),\n",
       "             (365, 'nonstationari'),\n",
       "             (366, 'confidenceset'),\n",
       "             (367, 'krishnamachari'),\n",
       "             (368, 'nonstochast'),\n",
       "             (369, 'classicalquantum'),\n",
       "             (370, 'holevoschumach'),\n",
       "             (371, 'interestingli'),\n",
       "             (372, 'blocklength'),\n",
       "             (373, 'eigenproject'),\n",
       "             (374, 'selfadjoint'),\n",
       "             (375, 'commutanttof'),\n",
       "             (376, 'everytfinit'),\n",
       "             (377, 'characterist'),\n",
       "             (378, 'eigenvector'),\n",
       "             (379, 'counterexampl'),\n",
       "             (380, 'finitedimension'),\n",
       "             (381, 'generalitat'),\n",
       "             (382, 'universitat'),\n",
       "             (383, 'mathematisch'),\n",
       "             (384, 'vandenbergh'),\n",
       "             (385, 'encyclopedia'),\n",
       "             (386, 'multilinear'),\n",
       "             (387, 'wahrscheinlichkeitsth'),\n",
       "             (388, 'entanglementbreak'),\n",
       "             (389, 'increasingli'),\n",
       "             (390, 'wajdidhifli'),\n",
       "             (391, 'proteinencod'),\n",
       "             (392, 'featurevector'),\n",
       "             (393, 'necessarili'),\n",
       "             (394, 'electrostat'),\n",
       "             (395, 'uncertainti'),\n",
       "             (396, 'phosphoglycerid'),\n",
       "             (397, 'lysophospholipid'),\n",
       "             (398, 'immunoglobulin'),\n",
       "             (399, 'histocompat'),\n",
       "             (400, 'carbohydraterecognit'),\n",
       "             (401, 'significantli'),\n",
       "             (402, 'unsurprisingli'),\n",
       "             (403, 'alignmentanalyz'),\n",
       "             (404, 'alignmentbas'),\n",
       "             (405, 'vishwanathan'),\n",
       "             (406, 'relationship'),\n",
       "             (407, 'environment'),\n",
       "             (408, 'christensen'),\n",
       "             (409, 'pennsylvania'),\n",
       "             (410, 'massachusett'),\n",
       "             (411, 'prerequisit'),\n",
       "             (412, 'particularli'),\n",
       "             (413, 'probabilist'),\n",
       "             (414, 'combinatori'),\n",
       "             (415, 'encyclopaedia'),\n",
       "             (416, 'billingsley'),\n",
       "             (417, 'unidimension'),\n",
       "             (418, 'microeconom'),\n",
       "             (419, 'uncertainti'),\n",
       "             (420, 'equicontinu'),\n",
       "             (421, 'surprisingli'),\n",
       "             (422, 'semicontinu'),\n",
       "             (423, 'submartingal'),\n",
       "             (424, 'redistribut'),\n",
       "             (425, 'intuitionist'),\n",
       "             (426, 'distinguish'),\n",
       "             (427, 'explanatori'),\n",
       "             (428, 'nonconstruct'),\n",
       "             (429, 'grothendiek'),\n",
       "             (430, 'interpretaion'),\n",
       "             (431, 'bijectiveti'),\n",
       "             (432, 'straightforward'),\n",
       "             (433, 'explanatori'),\n",
       "             (434, 'semiconductor'),\n",
       "             (435, 'universidad'),\n",
       "             (436, 'particularli'),\n",
       "             (437, 'telecomunicaco'),\n",
       "             (438, 'comportamento'),\n",
       "             (439, 'computacion'),\n",
       "             (440, 'informatica'),\n",
       "             (441, 'refinamento'),\n",
       "             (442, 'desenvolvimento'),\n",
       "             (443, 'mascaramento'),\n",
       "             (444, 'counterpart'),\n",
       "             (445, 'nevertheless'),\n",
       "             (446, 'interestingli'),\n",
       "             (447, 'interconnect'),\n",
       "             (448, 'introductori'),\n",
       "             (449, 'ndgarecogniz'),\n",
       "             (450, 'relationship'),\n",
       "             (451, 'supplementari'),\n",
       "             (452, 'necessarili'),\n",
       "             (453, 'mathematisch'),\n",
       "             (454, 'sharpconcentr'),\n",
       "             (455, 'straightforward'),\n",
       "             (456, 'nevertheless'),\n",
       "             (457, 'distinguish'),\n",
       "             (458, 'predecessor'),\n",
       "             (459, 'necessarili'),\n",
       "             (460, 'increasingli'),\n",
       "             (461, 'distinguish'),\n",
       "             (462, 'complementari'),\n",
       "             (463, 'correspondingli'),\n",
       "             (464, 'susceptibleinfecti'),\n",
       "             (465, 'unnecessari'),\n",
       "             (466, 'characterist'),\n",
       "             (467, 'surprisingli'),\n",
       "             (468, 'sundararajan'),\n",
       "             (469, 'intermediari'),\n",
       "             (470, 'superspread'),\n",
       "             (471, 'predetermin'),\n",
       "             (472, 'interdepend'),\n",
       "             (473, 'subrepositori'),\n",
       "             (474, 'distinguish'),\n",
       "             (475, 'metaknwoledg'),\n",
       "             (476, 'metaknowldg'),\n",
       "             (477, 'metaknowleg'),\n",
       "             (478, 'massachusett'),\n",
       "             (479, 'predominantli'),\n",
       "             (480, 'significantli'),\n",
       "             (481, 'epanechnikov'),\n",
       "             (482, 'componentwis'),\n",
       "             (483, 'foreknowledg'),\n",
       "             (484, 'relationship'),\n",
       "             (485, 'supermarket'),\n",
       "             (486, 'rightcensor'),\n",
       "             (487, 'rottentomato'),\n",
       "             (488, 'switzerland'),\n",
       "             (489, 'communitydetect'),\n",
       "             (490, 'distributor'),\n",
       "             (491, 'predictiondriven'),\n",
       "             (492, 'statistician'),\n",
       "             (493, 'microeconometr'),\n",
       "             (494, 'zeitschrift'),\n",
       "             (495, 'wahrscheinlichkeitstheori'),\n",
       "             (496, 'combinatori'),\n",
       "             (497, 'webfountain'),\n",
       "             (498, 'architectur'),\n",
       "             (499, 'rusmevichientong'),\n",
       "             (500, 'isoperimetri'),\n",
       "             (501, 'infinitedimension'),\n",
       "             (502, 'unconstrain'),\n",
       "             (503, 'movingaverag'),\n",
       "             (504, 'autoregress'),\n",
       "             (505, 'heteroskedast'),\n",
       "             (506, 'preliminari'),\n",
       "             (507, 'portmanteau'),\n",
       "             (508, 'dimensioanl'),\n",
       "             (509, 'distinguish'),\n",
       "             (510, 'straightforward'),\n",
       "             (511, 'maxhammingdist'),\n",
       "             (512, 'preliminari'),\n",
       "             (513, 'turingreduc'),\n",
       "             (514, 'introductori'),\n",
       "             (515, 'tovconstruct'),\n",
       "             (516, 'characterist'),\n",
       "             (517, 'nearestcodewordcomplet'),\n",
       "             (518, 'accordingli'),\n",
       "             (519, 'uniquenessl'),\n",
       "             (520, 'counterexampl'),\n",
       "             (521, 'relationship'),\n",
       "             (522, 'unconstrain'),\n",
       "             (523, 'distinguish'),\n",
       "             (524, 'hyperresolut'),\n",
       "             (525, 'mathematisch'),\n",
       "             (526, 'zeitschrift'),\n",
       "             (527, 'philadelphia'),\n",
       "             (528, 'relationenalgebren'),\n",
       "             (529, 'wissenschaften'),\n",
       "             (530, 'kibernetika'),\n",
       "             (531, 'preliminari'),\n",
       "             (532, 'filterlabel'),\n",
       "             (533, 'unseenlabel'),\n",
       "             (534, 'multidimension'),\n",
       "             (535, 'rejectionprecis'),\n",
       "             (536, 'facedatabas'),\n",
       "             (537, 'goldenstein'),\n",
       "             (538, 'counterexampl'),\n",
       "             (539, 'universiteit'),\n",
       "             (540, 'unnecessari'),\n",
       "             (541, 'disadvantag'),\n",
       "             (542, 'nondifferenti'),\n",
       "             (543, 'randomovector'),\n",
       "             (544, 'incorrectli'),\n",
       "             (545, 'surprisingli'),\n",
       "             (546, 'characterist'),\n",
       "             (547, 'handwritten'),\n",
       "             (548, 'distinguish'),\n",
       "             (549, 'lightweight'),\n",
       "             (550, 'determinist'),\n",
       "             (551, 'redistribut'),\n",
       "             (552, 'importantli'),\n",
       "             (553, 'arbitrarili'),\n",
       "             (554, 'straightforward'),\n",
       "             (555, 'supplementari'),\n",
       "             (556, 'neighborhood'),\n",
       "             (557, 'determinist'),\n",
       "             (558, 'satisfactori'),\n",
       "             (559, 'oscillatori'),\n",
       "             (560, 'assistantship'),\n",
       "             (561, 'cultuurfond'),\n",
       "             (562, 'chakrabarti'),\n",
       "             (563, 'vishwanathan'),\n",
       "             (564, 'nondetermin'),\n",
       "             (565, 'astonishingli'),\n",
       "             (566, 'architectur'),\n",
       "             (567, 'causalminim'),\n",
       "             (568, 'multiprocess'),\n",
       "             (569, 'interprocess'),\n",
       "             (570, 'highlyconcurr'),\n",
       "             (571, 'simpowersystem'),\n",
       "             (572, 'significantli'),\n",
       "             (573, 'disadvantag'),\n",
       "             (574, 'diplomarbeit'),\n",
       "             (575, 'environment'),\n",
       "             (576, 'particularli'),\n",
       "             (577, 'loglikelihood'),\n",
       "             (578, 'blockdiagon'),\n",
       "             (579, 'interiorpoint'),\n",
       "             (580, 'subdifferenti'),\n",
       "             (581, 'coordinatewis'),\n",
       "             (582, 'customarili'),\n",
       "             (583, 'dimensionless'),\n",
       "             (584, 'sparsityenhanc'),\n",
       "             (585, 'cartographi'),\n",
       "             (586, 'waterschoot'),\n",
       "             (587, 'vandenbergh'),\n",
       "             (588, 'titterington'),\n",
       "             (589, 'sparsityawar'),\n",
       "             (590, 'econometrica'),\n",
       "             (591, 'shcherbakov'),\n",
       "             (592, 'underdetermin'),\n",
       "             (593, 'cornelissen'),\n",
       "             (594, 'counterexampl'),\n",
       "             (595, 'reconstruct'),\n",
       "             (596, 'modeltheoret'),\n",
       "             (597, 'hypersurfac'),\n",
       "             (598, 'combinatori'),\n",
       "             (599, 'straightforward'),\n",
       "             (600, 'interdepend'),\n",
       "             (601, 'prolegomena'),\n",
       "             (602, 'numerierungen'),\n",
       "             (603, 'novosibirsk'),\n",
       "             (604, 'grothendieck'),\n",
       "             (605, 'arithmetischen'),\n",
       "             (606, 'algebraischen'),\n",
       "             (607, 'automorphismengrupp'),\n",
       "             (608, 'stoltenberg'),\n",
       "             (609, 'epistemolog'),\n",
       "             (610, 'straightforward'),\n",
       "             (611, 'nonstandard'),\n",
       "             (612, 'uncontroversi'),\n",
       "             (613, 'importantli'),\n",
       "             (614, 'resoundingli'),\n",
       "             (615, 'unnecessarili'),\n",
       "             (616, 'preliminari'),\n",
       "             (617, 'australasian'),\n",
       "             (618, 'uncertainti'),\n",
       "             (619, 'informatiqu'),\n",
       "             (620, 'philosophica'),\n",
       "             (621, 'contributor'),\n",
       "             (622, 'prolegomena'),\n",
       "             (623, 'explanatori'),\n",
       "             (624, 'combinatori'),\n",
       "             (625, 'particularli'),\n",
       "             (626, 'preliminari'),\n",
       "             (627, 'canonicalform'),\n",
       "             (628, 'significantli'),\n",
       "             (629, 'pasquarelli'),\n",
       "             (630, 'reconstruct'),\n",
       "             (631, 'jahresbericht'),\n",
       "             (632, 'vereinigung'),\n",
       "             (633, 'quadratischen'),\n",
       "             (634, 'matematicheskogo'),\n",
       "             (635, 'encyclopedia'),\n",
       "             (636, 'preliminari'),\n",
       "             (637, 'multidimension'),\n",
       "             (638, 'cienciarelli'),\n",
       "             (639, 'contrastingli'),\n",
       "             (640, 'unnecessari'),\n",
       "             (641, 'nonetheless'),\n",
       "             (642, 'nevertheless'),\n",
       "             (643, 'metalanguag'),\n",
       "             (644, 'subcategori'),\n",
       "             (645, 'relationship'),\n",
       "             (646, 'subramanian'),\n",
       "             (647, 'cenciarelli'),\n",
       "             (648, 'surprisingli'),\n",
       "             (649, 'cryptograph'),\n",
       "             (650, 'straightforward'),\n",
       "             (651, 'correspondingli'),\n",
       "             (652, 'reinterpret'),\n",
       "             (653, 'significantli'),\n",
       "             (654, 'microarchitectur'),\n",
       "             (655, 'multiplyaccumul'),\n",
       "             (656, 'determinist'),\n",
       "             (657, 'lightweight'),\n",
       "             (658, 'unexpectedli'),\n",
       "             (659, 'hadjieleftheri'),\n",
       "             (660, 'variablelengthstringhash'),\n",
       "             (661, 'ramakrishna'),\n",
       "             (662, 'krishnamurthi'),\n",
       "             (663, 'complementari'),\n",
       "             (664, 'contradictori'),\n",
       "             (665, 'interconnect'),\n",
       "             (666, 'universitat'),\n",
       "             (667, 'springerbrief'),\n",
       "             (668, 'southampton'),\n",
       "             (669, 'nonsingular'),\n",
       "             (670, 'departamento'),\n",
       "             (671, 'universitario'),\n",
       "             (672, 'universidad'),\n",
       "             (673, 'guadalajara'),\n",
       "             (674, 'preliminari'),\n",
       "             (675, 'springerverlag'),\n",
       "             (676, 'redistribut'),\n",
       "             (677, 'tostringstyl'),\n",
       "             (678, 'distinguish'),\n",
       "             (679, 'getownertyp'),\n",
       "             (680, 'getupperbound'),\n",
       "             (681, 'getlowerbound'),\n",
       "             (682, 'tamburrelli'),\n",
       "             (683, 'uncertainti'),\n",
       "             (684, 'evolutionari'),\n",
       "             (685, 'complementari'),\n",
       "             (686, 'distinguish'),\n",
       "             (687, 'significantli'),\n",
       "             (688, 'characterist'),\n",
       "             (689, 'handwritten'),\n",
       "             (690, 'importantli'),\n",
       "             (691, 'cristianini'),\n",
       "             (692, 'probabilist'),\n",
       "             (693, 'premachandran'),\n",
       "             (694, 'ramakrishna'),\n",
       "             (695, 'correntropi'),\n",
       "             (696, 'combinatori'),\n",
       "             (697, 'preliminari'),\n",
       "             (698, 'necessarili'),\n",
       "             (699, 'importantli'),\n",
       "             (700, 'unnecessarili'),\n",
       "             (701, 'particularli'),\n",
       "             (702, 'anticlockwis'),\n",
       "             (703, 'finitelydefin'),\n",
       "             (704, 'complementari'),\n",
       "             (705, 'seethakathi'),\n",
       "             (706, 'cryptograph'),\n",
       "             (707, 'reconstruct'),\n",
       "             (708, 'importantli'),\n",
       "             (709, 'increasingli'),\n",
       "             (710, 'uncertainti'),\n",
       "             (711, 'intriguingli'),\n",
       "             (712, 'northwestern'),\n",
       "             (713, 'necessarili'),\n",
       "             (714, 'boustrophedon'),\n",
       "             (715, 'ramachandran'),\n",
       "             (716, 'chandrasekhar'),\n",
       "             (717, 'subramanian'),\n",
       "             (718, 'variabilita'),\n",
       "             (719, 'mutuabilita'),\n",
       "             (720, 'distribuzioni'),\n",
       "             (721, 'chakraborti'),\n",
       "             (722, 'chakrabarti'),\n",
       "             (723, 'mohenjodaro'),\n",
       "             (724, 'chineseenglish'),\n",
       "             (725, 'pyramidtext'),\n",
       "             (726, 'markvygusdictionari'),\n",
       "             (727, 'positionspecif'),\n",
       "             (728, 'wordfrequencyfi'),\n",
       "             (729, 'teachmehebrew'),\n",
       "             (730, 'chandrabindu'),\n",
       "             (731, 'japaneseword'),\n",
       "             (732, 'frequencyword'),\n",
       "             (733, 'thiruppavai'),\n",
       "             (734, 'chennailibrari'),\n",
       "             (735, 'mesopotamia'),\n",
       "             (736, 'urduhighfreqword'),\n",
       "             (737, 'nevertheless'),\n",
       "             (738, 'champollion'),\n",
       "             (739, 'polyconsonant'),\n",
       "             (740, 'lexicographi'),\n",
       "             (741, 'grammatolog'),\n",
       "             (742, 'environment'),\n",
       "             (743, 'scholarship'),\n",
       "             (744, 'relationship'),\n",
       "             (745, 'superlinear'),\n",
       "             (746, 'necessarili'),\n",
       "             (747, 'arbitrarili'),\n",
       "             (748, 'determinist'),\n",
       "             (749, 'particularli'),\n",
       "             (750, 'quantumwork'),\n",
       "             (751, 'characterist'),\n",
       "             (752, 'necessarili'),\n",
       "             (753, 'seventeenth'),\n",
       "             (754, 'macchiavello'),\n",
       "             (755, 'twentyeighth'),\n",
       "             (756, 'algorithmica'),\n",
       "             (757, 'arbitrarili'),\n",
       "             (758, 'redistribut'),\n",
       "             (759, 'necessaryclass'),\n",
       "             (760, 'resolveclass'),\n",
       "             (761, 'cofficlasssourc'),\n",
       "             (762, 'resolvefromclass'),\n",
       "             (763, 'coffimethodsourc'),\n",
       "             (764, 'cofficmethodsourc'),\n",
       "             (765, 'dalvikclasssourc'),\n",
       "             (766, 'dalvikmethodsourc'),\n",
       "             (767, 'distinguish'),\n",
       "             (768, 'intbitstofloat'),\n",
       "             (769, 'verifyerror'),\n",
       "             (770, 'mxtilecount'),\n",
       "             (771, 'mytilecount'),\n",
       "             (772, 'specialinvok'),\n",
       "             (773, 'infastructur'),\n",
       "             (774, 'pallergabor'),\n",
       "             (775, 'androidblog'),\n",
       "             (776, 'reconstruct'),\n",
       "             (777, 'bhattacharyya'),\n",
       "             (778, 'monitorexit'),\n",
       "             (779, 'relationship'),\n",
       "             (780, 'nevertheless'),\n",
       "             (781, 'probabilist'),\n",
       "             (782, 'characterist'),\n",
       "             (783, 'equilibrium'),\n",
       "             (784, 'accordingli'),\n",
       "             (785, 'interestingli'),\n",
       "             (786, 'surprisingli'),\n",
       "             (787, 'progressivespecif'),\n",
       "             (788, 'significantli'),\n",
       "             (789, 'neuroscientist'),\n",
       "             (790, 'submodulairti'),\n",
       "             (791, 'chakrabarti'),\n",
       "             (792, 'anthropolog'),\n",
       "             (793, 'straightforward'),\n",
       "             (794, 'determinist'),\n",
       "             (795, 'interestingli'),\n",
       "             (796, 'arbitrarili'),\n",
       "             (797, 'architectur'),\n",
       "             (798, 'moscardelli'),\n",
       "             (799, 'algorithmica'),\n",
       "             (800, 'constantino'),\n",
       "             (801, 'seventeenth'),\n",
       "             (802, 'uncertainti'),\n",
       "             (803, 'maximumcost'),\n",
       "             (804, 'nomenclatur'),\n",
       "             (805, 'relationship'),\n",
       "             (806, 'characterist'),\n",
       "             (807, 'disadvantag'),\n",
       "             (808, 'predetermin'),\n",
       "             (809, 'uncertainti'),\n",
       "             (810, 'lexicograph'),\n",
       "             (811, 'multiresolut'),\n",
       "             (812, 'introductori'),\n",
       "             (813, 'eigenspectrum'),\n",
       "             (814, 'hyperparamet'),\n",
       "             (815, 'importantli'),\n",
       "             (816, 'matematicheskikh'),\n",
       "             (817, 'multitarget'),\n",
       "             (818, 'intelligenc'),\n",
       "             (819, 'zamolotskikh'),\n",
       "             (820, 'encyclopedia'),\n",
       "             (821, 'cristianini'),\n",
       "             (822, 'christensen'),\n",
       "             (823, 'bemerkungen'),\n",
       "             (824, 'beschrnkten'),\n",
       "             (825, 'bilinearformen'),\n",
       "             (826, 'vernderlichen'),\n",
       "             (827, 'informatica'),\n",
       "             (828, 'transcendent'),\n",
       "             (829, 'statistician'),\n",
       "             (830, 'characterist'),\n",
       "             (831, 'accessiblilti'),\n",
       "             (832, 'probabilist'),\n",
       "             (833, 'importantli'),\n",
       "             (834, 'distinguish'),\n",
       "             (835, 'interestingli'),\n",
       "             (836, 'metropolitan'),\n",
       "             (837, 'pennsylvania'),\n",
       "             (838, 'distancetransit'),\n",
       "             (839, 'correspondingli'),\n",
       "             (840, 'straightforwardli'),\n",
       "             (841, 'increasingli'),\n",
       "             (842, 'neighborhood'),\n",
       "             (843, 'pseudoivers'),\n",
       "             (844, 'pseudoinvers'),\n",
       "             (845, 'econometrica'),\n",
       "             (846, 'microeconom'),\n",
       "             (847, 'unidimension'),\n",
       "             (848, 'encyclopedia'),\n",
       "             (849, 'nonbayesian'),\n",
       "             (850, 'antifragilti'),\n",
       "             (851, 'interconnect'),\n",
       "             (852, 'environment'),\n",
       "             (853, 'arbitrarili'),\n",
       "             (854, 'temporarili'),\n",
       "             (855, 'architectur'),\n",
       "             (856, 'infrastructur'),\n",
       "             (857, 'izrailevski'),\n",
       "             (858, 'collablegaci'),\n",
       "             (859, 'probabilist'),\n",
       "             (860, 'bibliographi'),\n",
       "             (861, 'nominalstyl'),\n",
       "             (862, 'contraposit'),\n",
       "             (863, 'thisssyntax'),\n",
       "             (864, 'acomprehens'),\n",
       "             (865, 'reconstruct'),\n",
       "             (866, 'nonelementari'),\n",
       "             (867, 'anniversari'),\n",
       "             (868, 'straightforward'),\n",
       "             (869, 'breakthrough'),\n",
       "             (870, 'revolutionari'),\n",
       "             (871, 'nondeterminist'),\n",
       "             (872, 'nevertheless'),\n",
       "             (873, 'relationship'),\n",
       "             (874, 'observatoir'),\n",
       "             (875, 'interuniversitair'),\n",
       "             (876, 'stranglehold'),\n",
       "             (877, 'straightforward'),\n",
       "             (878, 'trustworthi'),\n",
       "             (879, 'distinguish'),\n",
       "             (880, 'controversi'),\n",
       "             (881, 'counterpart'),\n",
       "             (882, 'interestingli'),\n",
       "             (883, 'surprisingli'),\n",
       "             (884, 'unsurprisingli'),\n",
       "             (885, 'infrastructur'),\n",
       "             (886, 'compellingli'),\n",
       "             (887, 'scientometr'),\n",
       "             (888, 'characterist'),\n",
       "             (889, 'uncertainti'),\n",
       "             (890, 'indistinguish'),\n",
       "             (891, 'necessarili'),\n",
       "             (892, 'nonparametr'),\n",
       "             (893, 'ramakrishnan'),\n",
       "             (894, 'rajasegarar'),\n",
       "             (895, 'acknowledgmentbas'),\n",
       "             (896, 'architectur'),\n",
       "             (897, 'multipleaccess'),\n",
       "             (898, 'colorfulnod'),\n",
       "             (899, 'individuallyrestrain'),\n",
       "             (900, 'bhattacharje'),\n",
       "             (901, 'korzeniowski'),\n",
       "             (902, 'rajasekaran'),\n",
       "             (903, 'multiaccess'),\n",
       "             (904, 'inicharacteris'),\n",
       "             (905, 'geneneralis'),\n",
       "             (906, 'proposiproof'),\n",
       "             (907, 'contraposit'),\n",
       "             (908, 'characterist'),\n",
       "             (909, 'informatica'),\n",
       "             (910, 'nondetermin'),\n",
       "             (911, 'ehrenfeucht'),\n",
       "             (912, 'beklemishev'),\n",
       "             (913, 'bloomington'),\n",
       "             (914, 'perpendicular'),\n",
       "             (915, 'nevertheless'),\n",
       "             (916, 'circumcircl'),\n",
       "             (917, 'quadrilater'),\n",
       "             (918, 'zachariasen'),\n",
       "             (919, 'algorithmica'),\n",
       "             (920, 'bisectionand'),\n",
       "             (921, 'bioinformat'),\n",
       "             (922, 'southeastern'),\n",
       "             (923, 'surprisingli'),\n",
       "             (924, 'arbitrarili'),\n",
       "             (925, 'significantli'),\n",
       "             (926, 'optimizatoin'),\n",
       "             (927, 'semidefinit'),\n",
       "             (928, 'simonandschust'),\n",
       "             (929, 'introductori'),\n",
       "             (930, 'electromagnet'),\n",
       "             (931, 'complementari'),\n",
       "             (932, 'spatialspectr'),\n",
       "             (933, 'significantli'),\n",
       "             (934, 'characterist'),\n",
       "             (935, 'counterpart'),\n",
       "             (936, 'localitypreserv'),\n",
       "             (937, 'gorodnitski'),\n",
       "             (938, 'unsatisfactori'),\n",
       "             (939, 'reconstruct'),\n",
       "             (940, 'nonetheless'),\n",
       "             (941, 'testcollect'),\n",
       "             (942, 'schizophrenia'),\n",
       "             (943, 'classifierd'),\n",
       "             (944, 'disadvantag'),\n",
       "             (945, 'probabilist'),\n",
       "             (946, 'correspondingli'),\n",
       "             (947, 'neymanpearson'),\n",
       "             (948, 'necessarili'),\n",
       "             (949, 'discriminatori'),\n",
       "             (950, 'proteinprotein'),\n",
       "             (951, 'preliminari'),\n",
       "             (952, 'metaheurstica'),\n",
       "             (953, 'bioinspirado'),\n",
       "             (954, 'vachtsevano'),\n",
       "             (955, 'heisterkamp'),\n",
       "             (956, 'evolutionari'),\n",
       "             (957, 'counterexampl'),\n",
       "             (958, 'springerverlag'),\n",
       "             (959, 'encyclopedia'),\n",
       "             (960, 'mobilemasquerad'),\n",
       "             (961, 'portstewart'),\n",
       "             (962, 'systemexperi'),\n",
       "             (963, 'steganographi'),\n",
       "             (964, 'microstructur'),\n",
       "             (965, 'semiconductor'),\n",
       "             (966, 'acceleromet'),\n",
       "             (967, 'balasubramanian'),\n",
       "             (968, 'multicriteria'),\n",
       "             (969, 'decisionmak'),\n",
       "             (970, 'electromagnet'),\n",
       "             (971, 'baryshnikov'),\n",
       "             (972, 'correspondingli'),\n",
       "             (973, 'contributor'),\n",
       "             (974, 'importantli'),\n",
       "             (975, 'surprisingli'),\n",
       "             (976, 'relationship'),\n",
       "             (977, 'counterclockwis'),\n",
       "             (978, 'wattsstrogatz'),\n",
       "             (979, 'significantli'),\n",
       "             (980, 'nonuniformli'),\n",
       "             (981, 'retransmiss'),\n",
       "             (982, 'trigonometri'),\n",
       "             (983, 'krishnamachari'),\n",
       "             (984, 'combinatori'),\n",
       "             (985, 'mediterranean'),\n",
       "             (986, 'universitext'),\n",
       "             (987, 'papadopoulo'),\n",
       "             (988, 'mattfinalthesi'),\n",
       "             (989, 'polytechnica'),\n",
       "             (990, 'proprietari'),\n",
       "             (991, 'scholarship'),\n",
       "             (992, 'polylogarithm'),\n",
       "             (993, 'necessarili'),\n",
       "             (994, 'determinist'),\n",
       "             (995, 'accordingli'),\n",
       "             (996, 'preliminari'),\n",
       "             (997, 'importantli'),\n",
       "             (998, 'withorespect'),\n",
       "             (999, 'straightforward'),\n",
       "             ...])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palabras_raras = collections.OrderedDict()\n",
    "palabras_tres_caracteres = collections.OrderedDict()\n",
    "i = 0\n",
    "for documento, words in bag_of_words.items():\n",
    "    for word, values in words.items():\n",
    "        if len(word) > 10 and values['freq'] < 2:\n",
    "            palabras_raras[i] = word\n",
    "            i+=1\n",
    "        if bool(re.search(r'((\\w)\\2{2,})', word)):\n",
    "            palabras_tres_caracteres[word] = values['freq']\n",
    "palabras_raras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('www', 1),\n",
       "             ('ieee', 5),\n",
       "             ('ccce', 1),\n",
       "             ('ieeexplor', 1),\n",
       "             ('judddb', 25),\n",
       "             ('iii', 1),\n",
       "             ('aaai', 4),\n",
       "             ('viii', 2),\n",
       "             ('lll', 4),\n",
       "             ('ieeecomputersocieti', 1),\n",
       "             ('sss', 2),\n",
       "             ('lsss', 22),\n",
       "             ('xviii', 1),\n",
       "             ('hhh', 1),\n",
       "             ('aaa', 1),\n",
       "             ('eccc', 4),\n",
       "             ('adddit', 1),\n",
       "             ('nnnnnnn', 4),\n",
       "             ('xxxx', 2),\n",
       "             ('sssr', 1),\n",
       "             ('lnnn', 1),\n",
       "             ('xxxxx', 1),\n",
       "             ('jjj', 2),\n",
       "             ('iiit', 1),\n",
       "             ('xxx', 1),\n",
       "             ('classsourc', 1),\n",
       "             ('cofficlasssourc', 1),\n",
       "             ('dalvikclasssourc', 1),\n",
       "             ('eee', 1),\n",
       "             ('thisssyntax', 1),\n",
       "             ('ccc', 1),\n",
       "             ('cccp', 1),\n",
       "             ('ppp', 35),\n",
       "             ('ssss', 1),\n",
       "             ('ppppp', 2),\n",
       "             ('pppp', 2),\n",
       "             ('commmun', 1),\n",
       "             ('hhhp', 1),\n",
       "             ('xiiiov', 1),\n",
       "             ('xiii', 1),\n",
       "             ('tieee', 1),\n",
       "             ('iccc', 1),\n",
       "             ('msssim', 2),\n",
       "             ('xxviii', 1),\n",
       "             ('cccg', 1),\n",
       "             ('kakkk', 14),\n",
       "             ('kkk', 3),\n",
       "             ('ababaaaaaaabaaaaabababaaaaab', 1),\n",
       "             ('bbb', 1),\n",
       "             ('nnn', 1),\n",
       "             ('aaaaaaaaaaaaaaaababa', 1),\n",
       "             ('aaaababa', 1),\n",
       "             ('iiitd', 2),\n",
       "             ('bbbbbb', 6),\n",
       "             ('bsbbbbbbbbbbb', 1),\n",
       "             ('bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb', 1),\n",
       "             ('bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb',\n",
       "              1),\n",
       "             ('bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb', 1),\n",
       "             ('ddd', 1),\n",
       "             ('yyy', 2),\n",
       "             ('siiijsjj', 1),\n",
       "             ('rrr', 1),\n",
       "             ('aaab', 7),\n",
       "             ('aaaab', 1),\n",
       "             ('crosssect', 1),\n",
       "             ('ttt', 1),\n",
       "             ('ttjjj', 1),\n",
       "             ('ffff', 5),\n",
       "             ('fffff', 2),\n",
       "             ('xxxxxxxx', 1),\n",
       "             ('fff', 1),\n",
       "             ('ffffff', 1),\n",
       "             ('zzz', 1),\n",
       "             ('yyyi', 29),\n",
       "             ('eeee', 1),\n",
       "             ('ieeee', 1),\n",
       "             ('subtreeerror', 1),\n",
       "             ('crossspectr', 1),\n",
       "             ('sttt', 1),\n",
       "             ('betweeen', 1),\n",
       "             ('uxxx', 2),\n",
       "             ('uuxxx', 1),\n",
       "             ('dddash', 1),\n",
       "             ('claaas', 1),\n",
       "             ('ieeetran', 1),\n",
       "             ('rrrr', 4),\n",
       "             ('freeenergi', 1),\n",
       "             ('ehhhp', 1),\n",
       "             ('sssp', 22),\n",
       "             ('iiia', 2),\n",
       "             ('iiid', 1),\n",
       "             ('iiib', 1),\n",
       "             ('iiic', 1),\n",
       "             ('bbaaab', 1),\n",
       "             ('abbbi', 1),\n",
       "             ('ldpccc', 3),\n",
       "             ('logiccc', 1),\n",
       "             ('xxiii', 1),\n",
       "             ('icccn', 1),\n",
       "             ('gaussseidel', 1),\n",
       "             ('vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv',\n",
       "              1),\n",
       "             ('pppv', 27),\n",
       "             ('pppvk', 3),\n",
       "             ('pppvi', 1),\n",
       "             ('looooooooooooooooooooooooooooooomooooooooooooooooooooooooooooooon',\n",
       "              1),\n",
       "             ('pppvh', 2),\n",
       "             ('pppe', 2),\n",
       "             ('looooooooooooomooooooooooooon', 1),\n",
       "             ('pppeq', 3),\n",
       "             ('ieeestd', 1),\n",
       "             ('ysss', 1),\n",
       "             ('yssss', 1),\n",
       "             ('salomaaa', 1),\n",
       "             ('qqq', 3),\n",
       "             ('mjqxxxx', 1),\n",
       "             ('hormannn', 1),\n",
       "             ('kkkik', 1),\n",
       "             ('proceeed', 1),\n",
       "             ('crossscal', 2),\n",
       "             ('classspecif', 1),\n",
       "             ('aaaa', 1),\n",
       "             ('baaaaa', 1),\n",
       "             ('microprocesss', 1),\n",
       "             ('qqqq', 3),\n",
       "             ('artxxx', 1),\n",
       "             ('xxxxxxx', 2),\n",
       "             ('yyyyyyy', 2),\n",
       "             ('appprop', 1),\n",
       "             ('fffk', 29),\n",
       "             ('cfffk', 11),\n",
       "             ('hotnetsiii', 1),\n",
       "             ('freeentangl', 1),\n",
       "             ('xxxi', 1),\n",
       "             ('diii', 6),\n",
       "             ('niii', 4),\n",
       "             ('riii', 2),\n",
       "             ('siii', 2),\n",
       "             ('loooooooooooooomoooooooooooooon', 1),\n",
       "             ('appplic', 1),\n",
       "             ('ieeel', 1),\n",
       "             ('hhiii', 2),\n",
       "             ('suppp', 3),\n",
       "             ('supppx', 2),\n",
       "             ('xxxiii', 1),\n",
       "             ('wwwopt', 1),\n",
       "             ('caaac', 1),\n",
       "             ('vuuu', 1),\n",
       "             ('lllreduc', 1),\n",
       "             ('wwwinter', 1),\n",
       "             ('zooom', 1),\n",
       "             ('rosenblattth', 1),\n",
       "             ('measuraiii', 1),\n",
       "             ('dsuppp', 2),\n",
       "             ('drrr', 1),\n",
       "             ('prrrsq', 1),\n",
       "             ('pppj', 1),\n",
       "             ('apppli', 1),\n",
       "             ('yyyyy', 56),\n",
       "             ('nynnn', 2),\n",
       "             ('nnnyn', 2),\n",
       "             ('yyyni', 8),\n",
       "             ('yynnn', 2),\n",
       "             ('finallli', 1),\n",
       "             ('sssa', 2),\n",
       "             ('iiith', 4),\n",
       "             ('meeet', 1),\n",
       "             ('employeeemploy', 1),\n",
       "             ('ppproposit', 1),\n",
       "             ('kanaaa', 1),\n",
       "             ('stressstrain', 1),\n",
       "             ('threeeven', 1),\n",
       "             ('ssspr', 1),\n",
       "             ('lllbase', 1),\n",
       "             ('gotzmannnumb', 1),\n",
       "             ('tsss', 3),\n",
       "             ('rrrp', 3),\n",
       "             ('rrru', 3),\n",
       "             ('calll', 1),\n",
       "             ('ieeei', 1),\n",
       "             ('elicccvx', 4),\n",
       "             ('connn', 8),\n",
       "             ('ippaaaq', 1),\n",
       "             ('bbbq', 1),\n",
       "             ('aabbb', 1),\n",
       "             ('hkkkkkkkkkkkikkkkkkkkkkkj', 1),\n",
       "             ('hkkkikkkj', 1),\n",
       "             ('bbaaabbccccaabbbaa', 1),\n",
       "             ('bbaaabb', 1),\n",
       "             ('cccaa', 1),\n",
       "             ('aaabbbbaaccccaaaacbbbcccbb', 1),\n",
       "             ('hpminplqqq', 1),\n",
       "             ('wwwc', 1),\n",
       "             ('aisss', 1),\n",
       "             ('apppear', 1),\n",
       "             ('mmm', 3),\n",
       "             ('patttern', 1),\n",
       "             ('xxxiv', 1),\n",
       "             ('styledcelllabelprovid', 1),\n",
       "             ('pppperspect', 1),\n",
       "             ('berrri', 1),\n",
       "             ('khhhn', 1),\n",
       "             ('ooo', 1),\n",
       "             ('oooo', 1),\n",
       "             ('pppbj', 1),\n",
       "             ('hvccc', 1),\n",
       "             ('psuppp', 1),\n",
       "             ('wwwuser', 1),\n",
       "             ('pppqq', 25),\n",
       "             ('ppqqq', 10),\n",
       "             ('pppqqc', 11),\n",
       "             ('pppnqq', 1),\n",
       "             ('ppqqqc', 3),\n",
       "             ('pppqqq', 1),\n",
       "             ('ofaaaa', 1),\n",
       "             ('aaaaaaa', 1),\n",
       "             ('aaaibarri', 1),\n",
       "             ('wwwsearch', 1),\n",
       "             ('ieeescc', 1),\n",
       "             ('macroprocesss', 1),\n",
       "             ('supppos', 1),\n",
       "             ('cooooool', 1),\n",
       "             ('xxxxxxxxxx', 1),\n",
       "             ('cacgcaccccctcg', 2),\n",
       "             ('ccctcaccctcacg', 2),\n",
       "             ('gagggc', 1),\n",
       "             ('aaaaaa', 2),\n",
       "             ('duddduf', 1),\n",
       "             ('sammms', 3),\n",
       "             ('acmmm', 2),\n",
       "             ('channnel', 1),\n",
       "             ('kkkf', 1),\n",
       "             ('seee', 1),\n",
       "             ('appport', 1)])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palabras_tres_caracteres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosas Varias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'palabras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-e930dc9807e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#buscar palabrasde mas de 15 caracteres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mpalabra\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpalabras\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpalabra\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpalabra\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'palabras' is not defined"
     ]
    }
   ],
   "source": [
    "#Buscar documentos con X palabra\n",
    "#palabras\n",
    "raras = []\n",
    "#bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb\n",
    "for documento, words in bag_of_words.items():\n",
    "    if 'integrationsreihenfolg' in words:\n",
    "        raras.append(documento)\n",
    "\n",
    "#buscar palabrasde mas de 15 caracteres       \n",
    "for palabra in palabras:\n",
    "    if len(palabra) > 15:\n",
    "        print(palabra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'einhauser'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-f8c215a18aeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mwordnet_lemmatizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstemmer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"v\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misalpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Longitud mayor a 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'einhauser'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'einhauser'"
     ]
    }
   ],
   "source": [
    "#/opt/datasets/mcda-pi1-20191/papers-txt/1501.02741.txt\n",
    "bag_of_words['/opt/datasets/mcda-pi1-20191/papers-txt/1501.02741.txt']['user']\n",
    "\n",
    "input_file = open('/opt/datasets/mcda-pi1-20191/papers-txt/1501.02741.txt',\"r\",encoding='utf-8')\n",
    "texto = input_file.read()\n",
    "#texto = re.sub('[^A-Za-z0-9]+',' ',texto) # Caracteres especiales\n",
    "tokens = texto.split()\n",
    "stemmer = PorterStemmer()\n",
    "stemmer2 = LancasterStemmer()\n",
    "tokens = [wordnet_lemmatizer.lemmatize(stemmer.stem(w.lower()), pos=\"v\") for w in tokens if (len(w)>1) and w.isalpha() and w not in sw] # Longitud mayor a 1\n",
    "counter=collections.Counter(tokens)\n",
    "dict(counter)['einhauser']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'english'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Traductor\n",
    "def detect_language(text):\n",
    "\n",
    "    languages_ratios = {}\n",
    "    tokens = tokens = texto.split()\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    # Compute per language included in nltk number of unique stopwords appearing in analyzed text\n",
    "    for language in stopwords.fileids():\n",
    "        stopwords_set = set(stopwords.words(language))\n",
    "        words_set = set(tokens)\n",
    "        common_elements = words_set.intersection(stopwords_set)\n",
    "        languages_ratios[language] = len(common_elements) # language \"score\"\n",
    "    return max(languages_ratios, key=languages_ratios.get)\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "input_file = open(files_txt[0],\"r\",encoding='utf-8')\n",
    "texto = input_file.read()\n",
    "language = detect_language(texto)\n",
    "language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'einhauser' in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.6(conda)",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
