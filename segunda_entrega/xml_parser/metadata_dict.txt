{"0704.3504": "Smooth R\\'enyi Entropy of Ergodic Quantum Information Sources,Schoenmakers, BerryTjoelker, JillesTuyls, PimVerbitskiy, Evgeny,Quantum PhysicsComputer Science - Information Theory,We prove that the average smooth Renyi entropy rate will approach the entropy\nrate of a stationary, ergodic information source, which is equal to the Shannon\nentropy rate for a classical information source and the von Neumann entropy\nrate for a quantum information source.Comment: 5 pages, no figures, ISIT 2007", "0706.1402": "Analyzing Design Process and Experiments on the AnITA Generic Tutoring\n  System,Brust, Matthias R.Rothkugel, Steffen,Computer Science - Computers and SocietyComputer Science - Human-Computer Interaction,In the field of tutoring systems, investigations have shown that there are\nmany tutoring systems specific to a specific domain that, because of their\nstatic architecture, cannot be adapted to other domains. As consequence, often\nneither methods nor knowledge can be reused. In addition, the knowledge\nengineer must have programming skills in order to enhance and evaluate the\nsystem. One particular challenge is to tackle these problems with the\ndevelopment of a generic tutoring system. AnITA, as a stand-alone application,\nhas been developed and implemented particularly for this purpose. However, in\nthe testing phase, we discovered that this architecture did not fully match the\nuser's intuitive understanding of the use of a learning tool. Therefore, AnITA\nhas been redesigned to exclusively work as a client/server application and\nrenamed to AnITA2. This paper discusses the evolvements made on the AnITA\ntutoring system, the goal of which is to use generic principles for system\nre-use in any domain. Two experiments were conducted, and the results are\npresented in this paper.Comment: Published in: Proceedings of International Conference on Education\n  and Information Systems (EISTA 04), 2004, ISBN 980-6560-11-6", "0710.0736": "Colour image segmentation by the vector-valued Allen-Cahn phase-field\n  model: a multigrid solution,Kay, David ATomasi, Alessandro,Computer Science - Computer Vision and Pattern RecognitionComputer Science - Numerical AnalysisI.4.6G.1.8,We propose a new method for the numerical solution of a PDE-driven model for\ncolour image segmentation and give numerical examples of the results. The\nmethod combines the vector-valued Allen-Cahn phase field equation with initial\ndata fitting terms. This method is known to be closely related to the\nMumford-Shah problem and the level set segmentation by Chan and Vese. Our\nnumerical solution is performed using a multigrid splitting of a finite element\nspace, thereby producing an efficient and robust method for the segmentation of\nlarge images.Comment: 17 pages, 9 figures", "0803.2570": "Unequal Error Protection: An Information Theoretic Perspective,Borade, ShashiNakiboglu, BarisZheng, Lizhong,Computer Science - Information TheoryComputer Science - Discrete MathematicsMathematics - Combinatorics,An information theoretic framework for unequal error protection is developed\nin terms of the exponential error bounds. The fundamental difference between\nthe bit-wise and message-wise unequal error protection (UEP) is demonstrated,\nfor fixed length block codes on DMCs without feedback. Effect of feedback is\ninvestigated via variable length block codes. It is shown that, feedback\nresults in a significant improvement in both bit-wise and message-wise UEP\n(except the single message case for missed detection). The distinction between\nfalse-alarm and missed-detection formalizations for message-wise UEP is also\nconsidered. All results presented are at rates close to capacity.Comment: 45 pages, 6 figures, Submitted to IEEE Transaction on Information\n  Theory. Corrected typos", "0808.0084": "On the hitting times of quantum versus random walks,Magniez, FredericNayak, AshwinRichter, Peter C.Santha, Miklos,Quantum PhysicsComputer Science - Data Structures and Algorithms,In this paper we define new Monte Carlo type classical and quantum hitting\ntimes, and we prove several relationships among these and the already existing\nLas Vegas type definitions. In particular, we show that for some marked state\nthe two types of hitting time are of the same order in both the classical and\nthe quantum case.\n  Further, we prove that for any reversible ergodic Markov chain $P$, the\nquantum hitting time of the quantum analogue of $P$ has the same order as the\nsquare root of the classical hitting time of $P$. We also investigate the\n(im)possibility of achieving a gap greater than quadratic using an alternative\nquantum walk.\n  Finally, we present new quantum algorithms for the detection and finding\nproblems. The complexities of both algorithms are related to the new,\npotentially smaller, quantum hitting times. The detection algorithm is based on\nphase estimation and is particularly simple. The finding algorithm combines a\nsimilar phase estimation based procedure with ideas of Tulsi from his recent\ntheorem for the 2D grid. Extending his result, we show that for any\nstate-transitive Markov chain with unique marked state, the quantum hitting\ntime is of the same order for both the detection and finding problems.", "0811.1254": "Coding Theory and Algebraic Combinatorics,Huber, Michael,Mathematics - CombinatoricsComputer Science - Information Theory,This chapter introduces and elaborates on the fruitful interplay of coding\ntheory and algebraic combinatorics, with most of the focus on the interaction\nof codes with combinatorial designs, finite geometries, simple groups, sphere\npackings, kissing numbers, lattices, and association schemes. In particular,\nspecial interest is devoted to the relationship between codes and combinatorial\ndesigns. We describe and recapitulate important results in the development of\nthe state of the art. In addition, we give illustrative examples and\nconstructions, and highlight recent advances. Finally, we provide a collection\nof significant open problems and challenges concerning future research.Comment: 33 pages; handbook chapter, to appear in: \"Selected Topics in\n  Information and Coding Theory\", ed. by I. Woungang et al., World Scientific,\n  Singapore, 2010", "0811.2853": "Generating Random Networks Without Short Cycles,Bayati, MohsenMontanari, AndreaSaberi, Amin,Computer Science - Data Structures and AlgorithmsComputer Science - Information Theory,Random graph generation is an important tool for studying large complex\nnetworks. Despite abundance of random graph models, constructing models with\napplication-driven constraints is poorly understood. In order to advance\nstate-of-the-art in this area, we focus on random graphs without short cycles\nas a stylized family of graphs, and propose the RandGraph algorithm for\nrandomly generating them. For any constant k, when m=O(n^{1+1/[2k(k+3)]}),\nRandGraph generates an asymptotically uniform random graph with n vertices, m\nedges, and no cycle of length at most k using O(n^2m) operations. We also\ncharacterize the approximation error for finite values of n. To the best of our\nknowledge, this is the first polynomial-time algorithm for the problem.\nRandGraph works by sequentially adding $m$ edges to an empty graph with n\nvertices. Recently, such sequential algorithms have been successful for random\nsampling problems. Our main contributions to this line of research includes\nintroducing a new approach for sequentially approximating edge-specific\nprobabilities at each step of the algorithm, and providing a new method for\nanalyzing such algorithms.Comment: 36 pages, 1 figure, accepted to Operations Research", "0812.2709": "Variations on a theme by Schalkwijk and Kailath,Gallager, Robert G.Nakiboglu, Baris,Computer Science - Information Theory,Schalkwijk and Kailath (1966) developed a class of block codes for Gaussian\nchannels with ideal feedback for which the probability of decoding error\ndecreases as a second-order exponent in block length for rates below capacity.\nThis well-known but surprising result is explained and simply derived here in\nterms of a result by Elias (1956) concerning the minimum mean-square distortion\nachievable in transmitting a single Gaussian random variable over multiple uses\nof the same Gaussian channel. A simple modification of the Schalkwijk-Kailath\nscheme is then shown to have an error probability that decreases with an\nexponential order which is linearly increasing with block length. In the\ninfinite bandwidth limit, this scheme produces zero error probability using\nbounded expected energy at all rates below capacity. A lower bound on error\nprobability for the finite bandwidth case is then derived in which the error\nprobability decreases with an exponential order which is linearly increasing in\nblock length at the same rate as the upper bound.Comment: 18 Pages, 4 figures (added reference)", "0903.0197": "Rotation Distance is Fixed-Parameter Tractable,Cleary, SeanJohn, Katherine St.,Computer Science - Data Structures and Algorithms,Rotation distance between trees measures the number of simple operations it\ntakes to transform one tree into another. There are no known polynomial-time\nalgorithms for computing rotation distance. In the case of ordered rooted\ntrees, we show that the rotation distance between two ordered trees is\nfixed-parameter tractable, in the parameter, k, the rotation distance. The\nproof relies on the kernalization of the initial trees to trees with size\nbounded by 7k.Comment: 9 pages, 3 figures", "0903.0199": "A Linear-Time Approximation Algorithm for Rotation Distance,Cleary, SeanJohn, Katherine St.,Computer Science - Data Structures and Algorithms,Rotation distance between rooted binary trees measures the number of simple\noperations it takes to transform one tree into another. There are no known\npolynomial-time algorithms for computing rotation distance. We give an\nefficient, linear-time approximation algorithm, which estimates the rotation\ndistance, within a provable factor of 2, between ordered rooted binary trees. .Comment: 5 pages, 1 figure", "0903.1291": "The quantum query complexity of certification,Ambainis, AndrisChilds, Andrew M.Gall, Fran\u00e7ois LeTani, Seiichiro,Quantum PhysicsComputer Science - Computational Complexity,We study the quantum query complexity of finding a certificate for a\nd-regular, k-level balanced NAND formula. Up to logarithmic factors, we show\nthat the query complexity is Theta(d^{(k+1)/2}) for 0-certificates, and\nTheta(d^{k/2}) for 1-certificates. In particular, this shows that the\nzero-error quantum query complexity of evaluating such formulas is\nO(d^{(k+1)/2}) (again neglecting a logarithmic factor). Our lower bound relies\non the fact that the quantum adversary method obeys a direct sum theorem.Comment: 8 pages; Updated to reflect changes in final journal version and to\n  point out that the main result only applies for k>1", "0903.2923": "On uncertainty principles in the finite dimensional setting,Ghobber, SaifallahJaming, Philippe,Mathematics - Classical Analysis and ODEsComputer Science - Information Theory,The aim of this paper is to prove an uncertainty principle for the\nrepresentation of a vector in two bases. Our result extends previously known\nqualitative uncertainty principles into quantitative estimates. We then show\nhow to transfer this result to the discrete version of the Short Time Fourier\nTransform. An application to trigonometric polynomials is also given.", "0903.4386": "Error-and-Erasure Decoding for Block Codes with Feedback,Nakiboglu, BarisZheng, Lizhong,Computer Science - Information Theory,Inner and outer bounds are derived on the optimal performance of fixed length\nblock codes on discrete memoryless channels with feedback and\nerrors-and-erasures decoding. First an inner bound is derived using a two phase\nencoding scheme with communication and control phases together with the optimal\ndecoding rule for the given encoding scheme, among decoding rules that can be\nrepresented in terms of pairwise comparisons between the messages. Then an\nouter bound is derived using a generalization of the straight-line bound to\nerrors-and-erasures decoders and the optimal error exponent trade off of a\nfeedback encoder with two messages. In addition upper and lower bounds are\nderived, for the optimal erasure exponent of error free block codes in terms of\nthe rate. Finally we present a proof of the fact that the optimal trade off\nbetween error exponents of a two message code does not increase with feedback\non DMCs.Comment: 33 pages, 1 figures", "0904.2051": "Joint-sparse recovery from multiple measurements,Berg, Ewout van denFriedlander, Michael P.,Computer Science - Information Theory,The joint-sparse recovery problem aims to recover, from sets of compressed\nmeasurements, unknown sparse matrices with nonzero entries restricted to a\nsubset of rows. This is an extension of the single-measurement-vector (SMV)\nproblem widely studied in compressed sensing. We analyze the recovery\nproperties for two types of recovery algorithms. First, we show that recovery\nusing sum-of-norm minimization cannot exceed the uniform recovery rate of\nsequential SMV using $\\ell_1$ minimization, and that there are problems that\ncan be solved with one approach but not with the other. Second, we analyze the\nperformance of the ReMBo algorithm [M. Mishali and Y. Eldar, IEEE Trans. Sig.\nProc., 56 (2008)] in combination with $\\ell_1$ minimization, and show how\nrecovery improves as more measurements are taken. From this analysis it follows\nthat having more measurements than number of nonzero rows does not improve the\npotential theoretical recovery rate.Comment: 19 pages, 9 figures", "0907.3220": "Inter Genre Similarity Modelling For Automatic Music Genre\n  Classification,Bagci, UlasErzin, Engin,Computer Science - SoundComputer Science - Artificial IntelligenceStatistics - Machine LearningH.5.5I.5,Music genre classification is an essential tool for music information\nretrieval systems and it has been finding critical applications in various\nmedia platforms. Two important problems of the automatic music genre\nclassification are feature extraction and classifier design. This paper\ninvestigates inter-genre similarity modelling (IGS) to improve the performance\nof automatic music genre classification. Inter-genre similarity information is\nextracted over the mis-classified feature population. Once the inter-genre\nsimilarity is modelled, elimination of the inter-genre similarity reduces the\ninter-genre confusion and improves the identification rates. Inter-genre\nsimilarity modelling is further improved with iterative IGS modelling(IIGS) and\nscore modelling for IGS elimination(SMIGS). Experimental results with promising\nclassification improvements are provided.Comment: Dafx 2006 submission", "0907.3965": "P != NP Proof,Barbosa, Andr\u00e9 Luiz,Computer Science - Computational Complexity68Q15 (Primary), 68Q17 (Secondary),This paper demonstrates that P \\not= NP. The way was to generalize the\ntraditional definitions of the classes P and NP, to construct an artificial\nproblem (a generalization to SAT: The XG-SAT, much more difficult than the\nformer) and then to demonstrate that it is in NP but not in P (where the\nclasses P and NP are generalized and called too simply P and NP in this paper,\nand then it is explained why the traditional classes P and NP should be fixed\nand replaced by these generalized ones into Theory of Computer Science). The\ndemonstration consists of: 1. Definition of Restricted Type X Program; 2.\nDefinition of the General Extended Problem of Satisfiability of a Boolean\nFormula - XG-SAT; 3. Generalization to classes P and NP; 4. Demonstration that\nthe XG-SAT is in NP; 5. Demonstration that the XG-SAT is not in P; 6.\nDemonstration that the Baker-Gill-Solovay Theorem does not refute the proof; 7.\nDemonstration that the Razborov-Rudich Theorem does not refute the proof; 8.\nDemonstration that the Aaronson-Wigderson Theorem does not refute the proof.Comment: 25 pages and 3 new ideas", "0910.2912": "Universally Composable Quantum Multi-Party Computation,Unruh, Dominique,Quantum PhysicsComputer Science - Cryptography and Security,The Universal Composability model (UC) by Canetti (FOCS 2001) allows for\nsecure composition of arbitrary protocols. We present a quantum version of the\nUC model which enjoys the same compositionality guarantees. We prove that in\nthis model statistically secure oblivious transfer protocols can be constructed\nfrom commitments. Furthermore, we show that every statistically classically UC\nsecure protocol is also statistically quantum UC secure. Such implications are\nnot known for other quantum security definitions. As a corollary, we get that\nquantum UC secure protocols for general multi-party computation can be\nconstructed from commitments.", "0910.5577": "On the stability of two-chunk file-sharing systems,Norros, IlkkaReittu, HannuEirola, Timo,Computer Science - Operating SystemsMathematics - Probability60K25, 68M14,We consider five different peer-to-peer file sharing systems with two chunks,\nwith the aim of finding chunk selection algorithms that have provably stable\nperformance with any input rate and assuming non-altruistic peers who leave the\nsystem immediately after downloading the second chunk. We show that many\nalgorithms that first looked promising lead to unstable or oscillating\nbehavior. However, we end up with a system with desirable properties. Most of\nour rigorous results concern the corresponding deterministic large system\nlimits, but in two simplest cases we provide proofs for the stochastic systems\nalso.Comment: 19 pages, 7 figures", "0911.1507": "MAC Layer Hurdles in BSNs,Ullah, SanaKhan, PervezChoi, Young-WooLee, Hyung-SooKwak, Kyung Sup,Computer Science - Networking and Internet Architecture,The last few decades have seen considerable research progress in\nmicroelectronics and integrated circuits, system-on-chip design, wireless\ncommunication, and sensor technology. This progress has enabled the seamless\nintegration of autonomous wireless sensor nodes around a human body to create a\nBody Sensor Network (BSN). The development of a proactive and ambulatory BSN\ninduces a number of enormous issues and challenges. This paper presents the\ntechnical hurdles during the design and implementation of a low-power Medium\nAccess Control (MAC) protocol for in-body and on-body sensor networks. We\nanalyze the performance of IEEE 802.15.4 protocol for the on-body sensor\nnetwork. We also provide a comprehensive insight into the heterogeneous\ncharacteristics of the in-body sensor network. A low-power technique called\nPattern-Based Wake-up Table is proposed to handle the normal traffic in a BSN.\nThe proposed technique provides a reliable solution towards low-power\ncommunication in the in-body sensor network.Comment: ICACT 2009", "0911.1509": "On the Development of Low Power MAC Protocol for WBANs,Ullah, SanaKhan, PervezKwak, Kyung Sup,Computer Science - Networking and Internet Architecture,Current advances in wireless communication, microelectronics, semiconductor\ntechnologies, and intelligent sensors have contributed to the development of\nunobtrusive WBANs. These networks provide long term health monitoring of\npatients without any constraint in their normal activities. Traditional MAC\nprotocols do not accommodate the assorted WBAN traffic requirements in a power\nefficient manner. In this paper, we present a brief discussion on the\ndevelopment process of a low power MAC protocol for WBANs. We observe the\nbehavior of a beacon-enabled IEEE 802.15.4 for on-body sensor networks. We\nfurther propose a low power technique called traffic based wakeup mechanism for\na WBAN that exploits the traffic patterns of the BAN Nodes to ensure power\nefficient and reliable communication.Comment: IMECS 2009", "0911.1544": "Towards Power Efficient MAC Protocol for In-Body and On-Body Sensor\n  Networks,Ullah, SanaAn, XizhiKwak, Kyung Sup,Computer Science - Networking and Internet Architecture,This paper presents an empirical discussion on the design and implementation\nof a power-efficient Medium Access Control (MAC) protocol for in-body and\non-body sensor networks. We analyze the performance of a beacon-enabled IEEE\n802.15.4, PB-TDMA, and S-MAC protocols for on-body sensor networks. We further\npresent a Traffic Based Wakeup Mechanism that utilizes the traffic patterns of\nthe BAN Nodes (BNs) to accommodate the entire BSN traffic. To enable a logical\nconnection between different BNs working on different frequency bands, a method\ncalled Bridging function is proposed. The Bridging function integrates all BNs\nworking on different bands into a complete BSN.Comment: 11 pages, 5 figures, 3 tables,KES AMSTA 09, LNAI 5559, pp.335-345,\n  Uppsala, June 2009. arXiv admin note: text overlap with arXiv:0911.1507", "0911.1546": "A Study of Implanted and Wearable Body Sensor Networks,Ullah, SanaHiggins, HenrySiddiqui, M. ArifKwak, Kyung Sup,Computer Science - Networking and Internet Architecture,Recent advances in intelligent sensors, microelectronics and integrated\ncircuit, system-on-chip design and low power wireless communication introduced\nthe development of miniaturised and autonomous sensor nodes. These tiny sensor\nnodes can be deployed to develop a proactive Body Sensor Network (BSN). The\nrapid advancement in ultra low-power RF (radio frequency) technology enables\ninvasive and non-invasive devices to communicate with a remote station. This\ncommunication revolutionizes healthcare system by enabling long term health\nmonitoring of a patient and providing real time feedback to the medical\nexperts. In this paper, we present In-body and On-body communication networks\nwith a special focus on the methodologies of wireless communication between\nimplanted medical devices with external monitoring equipment and recent\ntechnological growth in both areas. We also discuss open issues and challenges\nin a BSN.Comment: KES-AMSTA 08, LNAI 4953, pp. 464-473, Incheon, March 2008", "0911.2538": "Euclidean versus hyperbolic congestion in idealized versus experimental\n  networks,Jonckheere, EdmondLou, MingjiBonahon, FrancisBaryshnikov, Yuliy,Computer Science - Networking and Internet Architecture,This paper proposes a mathematical justification of the phenomenon of extreme\ncongestion at a very limited number of nodes in very large networks. It is\nargued that this phenomenon occurs as a combination of the negative curvature\nproperty of the network together with minimum length routing. More\nspecifically, it is shown that, in a large n-dimensional hyperbolic ball B of\nradius R viewed as a roughly similar model of a Gromov hyperbolic network, the\nproportion of traffic paths transiting through a small ball near the center is\nindependent of the radius R whereas, in a Euclidean ball, the same proportion\nscales as 1/R^{n-1}. This discrepancy persists for the traffic load, which at\nthe center of the hyperbolic ball scales as the square of the volume, whereas\nthe same traffic load scales as the volume to the power (n+1)/n in the\nEuclidean ball. This provides a theoretical justification of the experimental\nexponent discrepancy observed by Narayan and Saniee between traffic loads in\nGromov-hyperbolic networks from the Rocketfuel data base and synthetic\nEuclidean lattice networks. It is further conjectured that for networks that do\nnot enjoy the obvious symmetry of hyperbolic and Euclidean balls, the point of\nmaximum traffic is near the center of mass of the network.Comment: 23 pages, 4 figures", "0911.2746": "Model Selection: Two Fundamental Measures of Coherence and Their\n  Algorithmic Significance,Bajwa, Waheed U.Calderbank, RobertJafarpour, Sina,Computer Science - Information TheoryMathematics - Statistics Theory,The problem of model selection arises in a number of contexts, such as\ncompressed sensing, subset selection in linear regression, estimation of\nstructures in graphical models, and signal denoising. This paper generalizes\nthe notion of \\emph{incoherence} in the existing literature on model selection\nand introduces two fundamental measures of coherence---termed as the worst-case\ncoherence and the average coherence---among the columns of a design matrix. In\nparticular, it utilizes these two measures of coherence to provide an in-depth\nanalysis of a simple one-step thresholding (OST) algorithm for model selection.\nOne of the key insights offered by the ensuing analysis is that OST is feasible\nfor model selection as long as the design matrix obeys an easily verifiable\nproperty. In addition, the paper also characterizes the model-selection\nperformance of OST in terms of the worst-case coherence, \\mu, and establishes\nthat OST performs near-optimally in the low signal-to-noise ratio regime for N\nx C design matrices with \\mu = O(N^{-1/2}). Finally, in contrast to some of the\nexisting literature on model selection, the analysis in the paper is\nnonasymptotic in nature, it does not require knowledge of the true model order,\nit is applicable to generic (random or deterministic) design matrices, and it\nneither requires submatrices of the design matrix to have full rank, nor does\nit assume a statistical prior on the values of the nonzero entries of the data\nvector.Comment: 5 pages; Accepted for Proc. 2010 IEEE International Symposium on\n  Information Theory (ISIT 2010)", "0911.5153": "Self-Reference Ultra-Wideband Systems,Lioumpas, Athanasios S.,Computer Science - Networking and Internet Architecture,Towards employing low complexity transceivers for signal reception in\nUltra-Wideband (UWB) systems, Transmitted Reference (TR) and Differential TR\n(DTR) schemes have attracted researchers attention. In this letter, we\nintroduce an alternative, less complex scheme, called Self Reference (SR) UWB\ntransceiver, which uses a modified replica of the received signal itself as\nreference pulse, resulting in double data rates compared to TR schemes.\nMoreover, SR eliminates the need for delay lines at the receiver side, which\nconstitute a major drawback of the conventional TR and DTR schemes, while it\nalso requires no channel estimations, resulting in lower complexity\nimplementations and power savings. The performance of the SR scheme is\ninvestigated in high-frequency (HF) channels, showing that it offers a better\nor comparable performance to that of DTR, depending on the channel conditions.Comment: Submitted", "1001.1435": "JBotSim, a Tool for Fast Prototyping of Distributed Algorithms in\n  Dynamic Networks,Casteigts, Arnaud,Computer Science - Mathematical SoftwareComputer Science - Distributed, Parallel, and Cluster ComputingComputer Science - Networking and Internet Architecture,JBotSim is a java library that offers basic primitives for prototyping,\nrunning, and visualizing distributed algorithms in dynamic networks. With\nJBotSim, one can implement an idea in minutes and interact with it ({\\it e.g.},\nadd, move, or delete nodes) while it is running. JBotSim is well suited to\nprepare live demonstrations of your algorithms to colleagues or students; it\ncan also be used to evaluate performance at the algorithmic level (number of\nmessages, number of rounds, etc.). Unlike most tools, JBotSim is not an\nintegrated environment. It is a lightweight library to be used in your program.\nIn this paper, we present an overview of its distinctive features and\narchitecture.Comment: A shorter version appeared in SIMUTOOLS 2015. For up to date\n  information and tutorials, visit http://jbotsim.io", "1001.3780": "Combinatorial Bounds and Characterizations of Splitting Authentication\n  Codes,Huber, Michael,Computer Science - Cryptography and SecurityComputer Science - Information TheoryG.2.3,We present several generalizations of results for splitting authentication\ncodes by studying the aspect of multi-fold security. As the two primary\nresults, we prove a combinatorial lower bound on the number of encoding rules\nand a combinatorial characterization of optimal splitting authentication codes\nthat are multi-fold secure against spoofing attacks. The characterization is\nbased on a new type of combinatorial designs, which we introduce and for which\nbasic necessary conditions are given regarding their existence.Comment: 13 pages; to appear in \"Cryptography and Communications\"", "1002.0747": "Efficient Bayesian Learning in Social Networks with Gaussian Estimators,Mossel, ElchananOlsman, NoahTamuz, Omer,Statistics - ApplicationsComputer Science - Machine LearningStatistics - Machine Learning,We consider a group of Bayesian agents who try to estimate a state of the\nworld $\\theta$ through interaction on a social network. Each agent $v$\ninitially receives a private measurement of $\\theta$: a number $S_v$ picked\nfrom a Gaussian distribution with mean $\\theta$ and standard deviation one.\nThen, in each discrete time iteration, each reveals its estimate of $\\theta$ to\nits neighbors, and, observing its neighbors' actions, updates its belief using\nBayes' Law.\n  This process aggregates information efficiently, in the sense that all the\nagents converge to the belief that they would have, had they access to all the\nprivate measurements. We show that this process is computationally efficient,\nso that each agent's calculation can be easily carried out. We also show that\non any graph the process converges after at most $2N \\cdot D$ steps, where $N$\nis the number of agents and $D$ is the diameter of the network. Finally, we\nshow that on trees and on distance transitive-graphs the process converges\nafter $D$ steps, and that it preserves privacy, so that agents learn very\nlittle about the private signal of most other agents, despite the efficient\naggregation of information. Our results extend those in an unpublished\nmanuscript of the first and last authors.Comment: Added coauthor. Added proofs for fast convergence on trees and\n  distance transitive graphs. Also, now analyzing a notion of privacy", "1003.1628": "Having Fun with Lambert W(x) Function,Veberic, Darko,Computer Science - Mathematical SoftwareComputer Science - Numerical AnalysisMathematics - Numerical Analysis,This short note presents the Lambert W(x) function and its possible\napplication in the framework of physics related to the Pierre Auger\nObservatory. The actual numerical implementation in C++ consists of Halley's\nand Fritsch's iteration with branch-point expansion, asymptotic series and\nrational fits as initial approximations.Comment: 15 pages, 11 figures, 4 tables, updated link to sources", "1004.0208": "Delay-rate tradeoff in ergodic interference alignment,Johnson, OliverAldridge, MatthewPiechocki, Robert,Computer Science - Information TheoryMathematics - Probability,Ergodic interference alignment, as introduced by Nazer et al (NGJV), is a\ntechnique that allows high-rate communication in n-user interference networks\nwith fast fading. It works by splitting communication across a pair of fading\nmatrices. However, it comes with the overhead of a long time delay until\nmatchable matrices occur: the delay is q^n^2 for field size q.\n  In this paper, we outline two new families of schemes, called JAP and JAP-B,\nthat reduce the expected delay, sometimes at the cost of a reduction in rate\nfrom the NGJV scheme. In particular, we give examples of good schemes for\nnetworks with few users, and show that in large n-user networks, the delay\nscales like q^T, where T is quadratic in n for a constant per-user rate and T\nis constant for a constant sum-rate. We also show that half the single-user\nrate can be achieved while reducing NGJV's delay from q^n^2 to q^(n-1)(n-2).\n  This extended version includes complete proofs and more details of good\nschemes for small n.Comment: Extended version of a paper presented at the 2012 International\n  Symposium on Information Theory. 7 pages, 1 figure", "1004.4940": "FauxCrypt - A Method of Text Obfuscation,Gualtieri, Devlin M.,Computer Science - Cryptography and SecurityD.4.6,Warnings have been raised about the steady diminution of privacy. More and\nmore personal information, such as that contained electronic mail, is moving to\ncloud computing servers where it might be machine-searched and indexed.\nFauxCrypt is an algorithm for modification of a plaintext document that leaves\nit generally readable by a person but not readily searched or indexed by\nmachine. The algorithm employs a dictionary substitution of selected words, and\nan obfuscating transposition of letters in other words. The obfuscation is\ndesigned to leave the words understandable, although they are badly spelled.\nFauxCrypt is free, open source software, with source code available.Comment: Source code attached as an appendix", "1005.2894": "Optimal Gradient Clock Synchronization in Dynamic Networks,Kuhn, FabianLenzen, ChristophLocher, ThomasOshman, Rotem,Computer Science - Distributed, Parallel, and Cluster ComputingComputer Science - Data Structures and AlgorithmsF.2.2G.2.2,We study the problem of clock synchronization in highly dynamic networks,\nwhere communication links can appear or disappear at any time. The nodes in the\nnetwork are equipped with hardware clocks, but the rate of the hardware clocks\ncan vary arbitrarily within specific bounds, and the estimates that nodes can\nobtain about the clock values of other nodes are inherently inaccurate. Our\ngoal in this setting is to output a logical clock at each node such that the\nlogical clocks of any two nodes are not too far apart, and nodes that remain\nclose to each other in the network for a long time are better synchronized than\ndistant nodes. This property is called gradient clock synchronization.\n  Gradient clock synchronization has been widely studied in the static setting,\nwhere the network topology does not change. We show that the asymptotically\noptimal bounds obtained for the static case also apply to our highly dynamic\nsetting: if two nodes remain at distance $d$ from each other for sufficiently\nlong, it is possible to upper bound the difference between their clock values\nby $O(d \\log (D / d))$, where $D$ is the diameter of the network. This is known\nto be optimal even for static networks. Furthermore, we show that our algorithm\nhas optimal stabilization time: when a path of length $d$ appears between two\nnodes, the time required until the clock skew between the two nodes is reduced\nto $O(d \\log (D / d))$ is $O(D)$, which we prove to be optimal. Finally, the\ntechniques employed for the more intricate analysis of the algorithm for\ndynamic graphs provide additional insights that are also of interest for the\nstatic setting. In particular, we establish self-stabilization of the gradient\nproperty within $O(D)$ time.Comment: 68 pages; conference version: 29th Annual ACM Symposium on Principles\n  of Distributed Computing (PODC 2010)", "1005.3010": "A Proof for P =? NP Problem,Wan, Changlin,Computer Science - Computational ComplexityF.1.3G.2.1,The $\\textbf{P} =? \\textbf{NP}$ problem is an important problem in\ncontemporary mathematics and theoretical computer science. Many proofs have\nbeen proposed to this problem. This paper proposes a theoretic proof for\n$\\textbf{P} =? \\textbf{NP}$ problem. The central idea of this proof is a\nrecursive definition for Turing machine (shortly TM) that accepts the encoding\nstrings of valid TMs within any given alphabet. As the concepts \"Tao\", \"Yin\"\nand \"Yang\" described in Chinese philosopy, an infinite sequence of TM, within\nany given alphabet, is constructed recursively, and it is proven that the\nsequence includes all valid TMs, and each of them run in polynomial time. Based\non these TMs, the class \\textbf{D} that includes all decidable languages is\ndefined, and then the class $\\textbf{P}$ and $\\textbf{NP}$ are defined. By\nproving $\\textbf{P} \\subseteq \\textbf{NP}$ and $\\textbf{NP} \\subseteq\n\\textbf{P}$, the result $\\textbf{P}=\\textbf{NP}$ is proven.Comment: 10 pages, 1 figure", "1006.0719": "Why Gabor Frames? Two Fundamental Measures of Coherence and Their Role\n  in Model Selection,Bajwa, Waheed U.Calderbank, RobertJafarpour, Sina,Mathematics - Statistics TheoryComputer Science - Information TheoryStatistics - Machine Learning,This paper studies non-asymptotic model selection for the general case of\narbitrary design matrices and arbitrary nonzero entries of the signal. In this\nregard, it generalizes the notion of incoherence in the existing literature on\nmodel selection and introduces two fundamental measures of coherence---termed\nas the worst-case coherence and the average coherence---among the columns of a\ndesign matrix. It utilizes these two measures of coherence to provide an\nin-depth analysis of a simple, model-order agnostic one-step thresholding (OST)\nalgorithm for model selection and proves that OST is feasible for exact as well\nas partial model selection as long as the design matrix obeys an easily\nverifiable property. One of the key insights offered by the ensuing analysis in\nthis regard is that OST can successfully carry out model selection even when\nmethods based on convex optimization such as the lasso fail due to the rank\ndeficiency of the submatrices of the design matrix. In addition, the paper\nestablishes that if the design matrix has reasonably small worst-case and\naverage coherence then OST performs near-optimally when either (i) the energy\nof any nonzero entry of the signal is close to the average signal energy per\nnonzero entry or (ii) the signal-to-noise ratio in the measurement system is\nnot too high. Finally, two other key contributions of the paper are that (i) it\nprovides bounds on the average coherence of Gaussian matrices and Gabor frames,\nand (ii) it extends the results on model selection using OST to low-complexity,\nmodel-order agnostic recovery of sparse signals with arbitrary nonzero entries.Comment: 31 pages, 4 figures; This paper is a full-length journal version of a\n  shorter paper that was presented at the IEEE International Symposium on\n  Information Theory, Austin, TX, June 2010", "1006.1029": "Chi-square-based scoring function for categorization of MEDLINE\n  citations,Kastrin, AndrejPeterlin, BorutHristovski, Dimitar,Computer Science - Information RetrievalStatistics - ApplicationsStatistics - Machine Learning,Objectives: Text categorization has been used in biomedical informatics for\nidentifying documents containing relevant topics of interest. We developed a\nsimple method that uses a chi-square-based scoring function to determine the\nlikelihood of MEDLINE citations containing genetic relevant topic. Methods: Our\nprocedure requires construction of a genetic and a nongenetic domain document\ncorpus. We used MeSH descriptors assigned to MEDLINE citations for this\ncategorization task. We compared frequencies of MeSH descriptors between two\ncorpora applying chi-square test. A MeSH descriptor was considered to be a\npositive indicator if its relative observed frequency in the genetic domain\ncorpus was greater than its relative observed frequency in the nongenetic\ndomain corpus. The output of the proposed method is a list of scores for all\nthe citations, with the highest score given to those citations containing MeSH\ndescriptors typical for the genetic domain. Results: Validation was done on a\nset of 734 manually annotated MEDLINE citations. It achieved predictive\naccuracy of 0.87 with 0.69 recall and 0.64 precision. We evaluated the method\nby comparing it to three machine learning algorithms (support vector machines,\ndecision trees, na\\\"ive Bayes). Although the differences were not statistically\nsignificantly different, results showed that our chi-square scoring performs as\ngood as compared machine learning algorithms. Conclusions: We suggest that the\nchi-square scoring is an effective solution to help categorize MEDLINE\ncitations. The algorithm is implemented in the BITOLA literature-based\ndiscovery support system as a preprocessor for gene symbol disambiguation\nprocess.Comment: 34 pages, 2 figures", "1006.1030": "Rasch-based high-dimensionality data reduction and class prediction with\n  applications to microarray gene expression data,Kastrin, AndrejPeterlin, Borut,Computer Science - Artificial IntelligenceStatistics - ApplicationsStatistics - MethodologyStatistics - Machine Learning,Class prediction is an important application of microarray gene expression\ndata analysis. The high-dimensionality of microarray data, where number of\ngenes (variables) is very large compared to the number of samples (obser-\nvations), makes the application of many prediction techniques (e.g., logistic\nregression, discriminant analysis) difficult. An efficient way to solve this\nprob- lem is by using dimension reduction statistical techniques. Increasingly\nused in psychology-related applications, Rasch model (RM) provides an appealing\nframework for handling high-dimensional microarray data. In this paper, we\nstudy the potential of RM-based modeling in dimensionality reduction with\nbinarized microarray gene expression data and investigate its prediction ac-\ncuracy in the context of class prediction using linear discriminant analysis.\nTwo different publicly available microarray data sets are used to illustrate a\ngeneral framework of the approach. Performance of the proposed method is\nassessed by re-randomization scheme using principal component analysis (PCA) as\na benchmark method. Our results show that RM-based dimension reduction is as\neffective as PCA-based dimension reduction. The method is general and can be\napplied to the other high-dimensional data problems.", "1006.5892": "Computational complexity of reconstruction and isomorphism testing for\n  designs and line graphs,Huber, Michael,Computer Science - Computational ComplexityComputer Science - Discrete MathematicsF.2.2G.2.2,Graphs with high symmetry or regularity are the main source for\nexperimentally hard instances of the notoriously difficult graph isomorphism\nproblem. In this paper, we study the computational complexity of isomorphism\ntesting for line graphs of $t$-$(v,k,\\lambda)$ designs. For this class of\nhighly regular graphs, we obtain a worst-case running time of $O(v^{\\log v +\nO(1)})$ for bounded parameters $t,k,\\lambda$. In a first step, our approach\nmakes use of the Babai--Luks algorithm to compute canonical forms of\n$t$-designs. In a second step, we show that $t$-designs can be reconstructed\nfrom their line graphs in polynomial-time. The first is algebraic in nature,\nthe second purely combinatorial. For both, profound structural knowledge in\ndesign theory is required. Our results extend earlier complexity results about\nisomorphism testing of graphs generated from Steiner triple systems and block\ndesigns.Comment: 12 pages; to appear in: \"Journal of Combinatorial Theory, Series A\"", "1007.5491": "The Coarsest Precongruences Respecting Safety and Liveness Properties,van Glabbeek, Rob,Computer Science - Logic in Computer Science,This paper characterises the coarsest refinement preorders on labelled\ntransition systems that are precongruences for renaming and partially\nsynchronous interleaving operators, and respect all safety, liveness, and\nconditional liveness properties, respectively.Comment: 2018: A reference to Lamport has been corrected into one to Alpern &\n  Schneider", "1008.0851": "Identification of Parametric Underspread Linear Systems and\n  Super-Resolution Radar,Bajwa, Waheed U.Gedalyahu, KfirEldar, Yonina C.,Computer Science - Information Theory,Identification of time-varying linear systems, which introduce both\ntime-shifts (delays) and frequency-shifts (Doppler-shifts), is a central task\nin many engineering applications. This paper studies the problem of\nidentification of underspread linear systems (ULSs), whose responses lie within\na unit-area region in the delay Doppler space, by probing them with a known\ninput signal. It is shown that sufficiently-underspread parametric linear\nsystems, described by a finite set of delays and Doppler-shifts, are\nidentifiable from a single observation as long as the time bandwidth product of\nthe input signal is proportional to the square of the total number of delay\nDoppler pairs in the system. In addition, an algorithm is developed that\nenables identification of parametric ULSs from an input train of pulses in\npolynomial time by exploiting recent results on sub-Nyquist sampling for time\ndelay estimation and classical results on recovery of frequencies from a sum of\ncomplex exponentials. Finally, application of these results to super-resolution\ntarget detection using radar is discussed. Specifically, it is shown that the\nproposed procedure allows to distinguish between multiple targets with very\nclose proximity in the delay Doppler space, resulting in a resolution that\nsubstantially exceeds that of standard matched-filtering based techniques\nwithout introducing leakage effects inherent in recently proposed compressed\nsensing-based radar methods.Comment: Revised version of a journal paper submitted to IEEE Trans. Signal\n  Processing: 30 pages, 17 figures", "1009.5894": "Some Theorems on the Algorithmic Approach to Probability Theory and\n  Information Theory,Levin, Leonid A.,Computer Science - Information Theory,This is a 1971 dissertation. Only its extended abstract was published at the\ntime. While some results appeared in other publications, a number of details\nremained unpublished and may still have relevance.Comment: 14 pages, 1 figure", "1011.0774": "Leaders, Followers, and Community Detectio,Parthasarathy, DhruvShah, DevavratZaman, Tauhid,Statistics - Machine LearningComputer Science - Social and Information NetworksPhysics - Physics and Society,Communities in social networks or graphs are sets of well-connected,\noverlapping vertices. The effectiveness of a community detection algorithm is\ndetermined by accuracy in finding the ground-truth communities and ability to\nscale with the size of the data. In this work, we provide three contributions.\nFirst, we show that a popular measure of accuracy known as the F1 score, which\nis between 0 and 1, with 1 being perfect detection, has an information lower\nbound is 0.5. We provide a trivial algorithm that produces communities with an\nF1 score of 0.5 for any graph! Somewhat surprisingly, we find that popular\nalgorithms such as modularity optimization, BigClam and CESNA have F1 scores\nless than 0.5 for the popular IMDB graph. To rectify this, as the second\ncontribution we propose a generative model for community formation, the\nsequential community graph, which is motivated by the formation of social\nnetworks. Third, motivated by our generative model, we propose the\nleader-follower algorithm (LFA). We prove that it recovers all communities for\nsequential community graphs by establishing a structural result that sequential\ncommunity graphs are chordal. For a large number of popular social networks, it\nrecovers communities with a much higher F1 score than other popular algorithms.\nFor the IMDB graph, it obtains an F1 score of 0.81. We also propose a\nmodification to the LFA called the fast leader-follower algorithm (FLFA) which\nin addition to being highly accurate, is also fast, with a scaling that is\nalmost linear in the network size.Comment: 11 pages, 6 figures", "1012.4019": "Constructing elliptic curve isogenies in quantum subexponential time,Childs, Andrew M.Jao, DavidSoukharev, Vladimir,Quantum PhysicsComputer Science - Computational ComplexityMathematics - Number Theory,Given two elliptic curves over a finite field having the same cardinality and\nendomorphism ring, it is known that the curves admit an isogeny between them,\nbut finding such an isogeny is believed to be computationally difficult. The\nfastest known classical algorithm takes exponential time, and prior to our work\nno faster quantum algorithm was known. Recently, public-key cryptosystems based\non the presumed hardness of this problem have been proposed as candidates for\npost-quantum cryptography. In this paper, we give a subexponential-time quantum\nalgorithm for constructing isogenies, assuming the Generalized Riemann\nHypothesis (but with no other assumptions). Our algorithm is based on a\nreduction to a hidden shift problem, together with a new subexponential-time\nalgorithm for evaluating isogenies from kernel ideals (under only GRH), and\nrepresents the first nontrivial application of Kuperberg's quantum algorithm\nfor the hidden shift problem. This result suggests that isogeny-based\ncryptosystems may be uncompetitive with more mainstream quantum-resistant\ncryptosystems such as lattice-based cryptosystems.Comment: Errata: Remark 5.5 is incorrect as stated. For full discussion see\n  https://eprint.iacr.org/2017/774 section 7.0.1", "1012.4290": "Bit recycling for scaling random number generators,Mennucci, Andrea C. G.,Computer Science - Information TheoryMathematics - Numerical AnalysisMathematics - Probability,Many Random Number Generators (RNG) are available nowadays; they are divided\nin two categories, hardware RNG, that provide \"true\" random numbers, and\nalgorithmic RNG, that generate pseudo random numbers (PRNG). Both types usually\ngenerate random numbers $(X_n)$ as independent uniform samples in a range\n$0,\\cdots,2^{b-1}$, with $b = 8, 16, 32$ or $b = 64$. In applications, it is\ninstead sometimes desirable to draw random numbers as independent uniform\nsamples $(Y_n)$ in a range $1, \\cdots, M$, where moreover M may change between\ndrawings. Transforming the sequence $(X_n)$ to $(Y_n)$ is sometimes known as\nscaling. We discuss different methods for scaling the RNG, both in term of\nmathematical efficiency and of computational speed.", "1101.1169": "Almost Settling the Hardness of Noncommutative Determinant,Chien, SteveHarsha, PrahladhSinclair, AlistairSrinivasan, Srikanth,Computer Science - Computational Complexity,In this paper, we study the complexity of computing the determinant of a\nmatrix over a non-commutative algebra. In particular, we ask the question,\n\"over which algebras, is the determinant easier to compute than the permanent?\"\nTowards resolving this question, we show the following hardness and easiness of\nnoncommutative determinant computation.\n  * [Hardness] Computing the determinant of an n \\times n matrix whose entries\nare themselves 2 \\times 2 matrices over a field is as hard as computing the\npermanent over the field. This extends the recent result of Arvind and\nSrinivasan, who proved a similar result which however required the entries to\nbe of linear dimension.\n  * [Easiness] Determinant of an n \\times n matrix whose entries are themselves\nd \\times d upper triangular matrices can be computed in poly(n^d) time.\n  Combining the above with the decomposition theorem of finite dimensional\nalgebras (in particular exploiting the simple structure of 2 \\times 2 matrix\nalgebras), we can extend the above hardness and easiness statements to more\ngeneral algebras as follows. Let A be a finite dimensional algebra over a\nfinite field with radical R(A).\n  * [Hardness] If the quotient A/R(A) is non-commutative, then computing the\ndeterminant over the algebra A is as hard as computing the permanent.\n  * [Easiness] If the quotient A/R(A) is commutative and furthermore, R(A) has\nnilpotency index d (i.e., the smallest d such that R(A)d = 0), then there\nexists a poly(n^d)-time algorithm that computes determinants over the algebra\nA.\n  In particular, for any constant dimensional algebra A over a finite field,\nsince the nilpotency index of R(A) is at most a constant, we have the following\ndichotomy theorem: if A/R(A) is commutative, then efficient determinant\ncomputation is feasible and otherwise determinant is as hard as permanent.Comment: 20 pages, 3 figures", "1101.1477": "Asynchronous Code-Division Random Access Using Convex Optimization,Applebaum, LorneBajwa, Waheed U.Duarte, Marco F.Calderbank, Robert,Computer Science - Information Theory,Many applications in cellular systems and sensor networks involve a random\nsubset of a large number of users asynchronously reporting activity to a base\nstation. This paper examines the problem of multiuser detection (MUD) in random\naccess channels for such applications. Traditional orthogonal signaling ignores\nthe random nature of user activity in this problem and limits the total number\nof users to be on the order of the number of signal space dimensions.\nContention-based schemes, on the other hand, suffer from delays caused by\ncolliding transmissions and the hidden node problem. In contrast, this paper\npresents a novel pairing of an asynchronous non-orthogonal code-division random\naccess scheme with a convex optimization-based MUD algorithm that overcomes the\nissues associated with orthogonal signaling and contention-based methods. Two\nkey distinguishing features of the proposed MUD algorithm are that it does not\nrequire knowledge of the delay or channel state information of every user and\nit has polynomial-time computational complexity. The main analytical\ncontribution of this paper is the relationship between the performance of the\nproposed MUD algorithm in the presence of arbitrary or random delays and two\nsimple metrics of the set of user codewords. The study of these metrics is then\nfocused on two specific sets of codewords, random binary codewords and\nspecially constructed algebraic codewords, for asynchronous random access. The\nensuing analysis confirms that the proposed scheme together with either of\nthese two codeword sets significantly outperforms the orthogonal\nsignaling-based random access in terms of the total number of users in the\nsystem.Comment: Journal version of work presented at 2010 Allerton Conference on\n  Communication, Control and Computing. Version 2 includes additional analysis\n  of randomly distributed user delays as well as a comparison with a matched\n  filter receiver", "1101.1640": "Restarting Automata with Auxiliary Symbols and Small Lookahead,Schluter, Natalie,Computer Science - Formal Languages and Automata Theory,We present a study on lookahead hierarchies for restarting automata with\nauxiliary symbols and small lookahead. In particular, we show that there are\njust two different classes of languages recognised RRWW automata, through the\nrestriction of lookahead size. We also show that the respective (left-)\nmonotone restarting automaton models characterise the context-free languages\nand that the respective right-left-monotone restarting automata characterise\nthe linear languages both with just lookahead length 2.Comment: Full version of the paper accepted to LATA 2011", "1101.1934": "Bit-wise Unequal Error Protection for Variable Length Block Codes with\n  Feedback,Nakiboglu, BarisGorantla, Siva K.Zheng, LizhongColeman, Todd P.,Computer Science - Information Theory,The bit-wise unequal error protection problem, for the case when the number\nof groups of bits $\\ell$ is fixed, is considered for variable length block\ncodes with feedback. An encoding scheme based on fixed length block codes with\nerasures is used to establish inner bounds to the achievable performance for\nfinite expected decoding time. A new technique for bounding the performance of\nvariable length block codes is used to establish outer bounds to the\nperformance for a given expected decoding time. The inner and the outer bounds\nmatch one another asymptotically and characterize the achievable region of\nrate-exponent vectors, completely. The single message message-wise unequal\nerror protection problem for variable length block codes with feedback is also\nsolved as a necessary step on the way.Comment: 41 pages, 3 figures", "1101.5460": "A Human-Centric Approach to Group-Based Context-Awareness,Ghadiri, NasserBaraani-Dastjerdi, AhmadGhasem-Aghaee, NasserNematbakhsh, Mohammad A.,Computer Science - Artificial IntelligenceComputer Science - Human-Computer Interaction,The emerging need for qualitative approaches in context-aware information\nprocessing calls for proper modeling of context information and efficient\nhandling of its inherent uncertainty resulted from human interpretation and\nusage. Many of the current approaches to context-awareness either lack a solid\ntheoretical basis for modeling or ignore important requirements such as\nmodularity, high-order uncertainty management and group-based\ncontext-awareness. Therefore, their real-world application and extendability\nremains limited. In this paper, we present f-Context as a service-based\ncontext-awareness framework, based on language-action perspective (LAP) theory\nfor modeling. Then we identify some of the complex, informational parts of\ncontext which contain high-order uncertainties due to differences between\nmembers of the group in defining them. An agent-based perceptual computer\narchitecture is proposed for implementing f-Context that uses computing with\nwords (CWW) for handling uncertainty. The feasibility of f-Context is analyzed\nusing a realistic scenario involving a group of mobile users. We believe that\nthe proposed approach can open the door to future research on context-awareness\nby offering a theoretical foundation based on human communication, and a\nservice-based layered architecture which exploits CWW for context-aware,\ngroup-based and platform-independent access to information systems.", "1102.0969": "On the Complexity of Newman's Community Finding Approach for Biological\n  and Social Networks,DasGupta, BhaskarDesai, Devendra,Physics - Physics and SocietyComputer Science - Computational ComplexityComputer Science - Discrete MathematicsComputer Science - Social and Information Networks68Q25, 68R01, 05C85F.2.2G.2.2,Given a graph of interactions, a module (also called a community or cluster)\nis a subset of nodes whose fitness is a function of the statistical\nsignificance of the pairwise interactions of nodes in the module. The topic of\nthis paper is a model-based community finding approach, commonly referred to as\nmodularity clustering, that was originally proposed by Newman and has\nsubsequently been extremely popular in practice. Various heuristic methods are\ncurrently employed for finding the optimal solution. However, the exact\ncomputational complexity of this approach is still largely unknown.\n  To this end, we initiate a systematic study of the computational complexity\nof modularity clustering. Due to the specific quadratic nature of the\nmodularity function, it is necessary to study its value on sparse graphs and\ndense graphs separately. Our main results include a (1+\\eps)-inapproximability\nfor dense graphs and a logarithmic approximation for sparse graphs. We make use\nof several combinatorial properties of modularity to get these results. These\nare the first non-trivial approximability results beyond the previously known\nNP-hardness results.Comment: Journal of Computer and System Sciences, 2012", "1102.4802": "A generalization of heterochromatic graphs,Suzuki, Kazuhiro,Mathematics - CombinatoricsComputer Science - Discrete Mathematics05C05, 05C15,In 2006, Suzuki, and Akbari & Alipour independently presented a necessary and\nsufficient condition for edge-colored graphs to have a heterochromatic spanning\ntree, where a heterochromatic spanning tree is a spanning tree whose edges have\ndistinct colors. In this paper, we propose $f$-chromatic graphs as a\ngeneralization of heterochromatic graphs. An edge-colored graph is\n$f$-chromatic if each color $c$ appears on at most $f(c)$ edges. We also\npresent a necessary and sufficient condition for edge-colored graphs to have an\n$f$-chromatic spanning forest with exactly $m$ components. Moreover, using this\ncriterion, we show that a $g$-chromatic graph $G$ of order $n$ with\n$|E(G)|>\\binom{n-m}{2}$ has an $f$-chromatic spanning forest with exactly $m$\n($1 \\le m \\le n-1$) components if $g(c) \\le \\frac{|E(G)|}{n-m}f(c)$ for any\ncolor $c$.Comment: 14 pages, 4 figures", "1103.1091": "A generalization of Hopcroft-Karp algorithm for semi-matchings and\n  covers in bipartite graphs (Maximum semi-matching problem in bipartite\n  graphs),Katrenic, J\u00e1nSemanisin, Gabriel,Computer Science - Data Structures and Algorithms,An $(f,g)$-semi-matching in a bipartite graph $G=(U \\cup V,E)$ is a set of\nedges $M \\subseteq E$ such that each vertex $u\\in U$ is incident with at most\n$f(u)$ edges of $M$, and each vertex $v\\in V$ is incident with at most $g(v)$\nedges of $M$. In this paper we give an algorithm that for a graph with $n$\nvertices and $m$ edges, $n\\le m$, constructs a maximum $(f,g)$-semi-matching in\nrunning time $O(m\\cdot \\min (\\sqrt{\\sum_{u\\in U}f(u)}, \\sqrt{\\sum_{v\\in\nV}g(v)}))$. Using the reduction of [5], our result on maximum\n$(f,g)$-semi-matching problem directly implies an algorithm for the optimal\nsemi-matching problem with running time $O(\\sqrt{n}m \\log n)$.", "1103.1951": "Constructive proof of the existence of equilibrium in competitive\n  economy with sequentially locally non-constant excess demand functions,Tanaka, Yasuhito,Mathematics - LogicComputer Science - Computer Science and Game Theory,We present a constructive proof of the existence of an equilibrium in a\ncompetitive economy with sequentially locally non-constant excess demand\nfunctions. And we will show that the existence of such an equilibrium implies\nSperner's lemma. Since the existence of an equilibrium is derived from the\nexistence an approximate fixed point of uniformly continuous functions, which\nis derived from Sperner's lemma, the existence of an equilibrium in a\ncompetitive economy with sequentially locally non-constant excess demand\nfunctions is equivalent to Sperner's lemma.", "1103.1980": "Constructive proof of the existence of Nash Equilibrium in a finite\n  strategic game with sequentially locally non-constant payoff functions by\n  Sperner's lemma,Tanaka, Yasuhito,Mathematics - LogicComputer Science - Computer Science and Game Theory,Using Sperner's lemma for modified partition of a simplex we will\nconstructively prove the existence of a Nash equilibrium in a finite strategic\ngame with sequentially locally non-constant payoff functions. We follow the\nBishop style constructive mathematics.", "1104.0471": "Quantum Bayesian implementation,Wu, Haoyang,Physics - Data Analysis, Statistics and ProbabilityComputer Science - Computer Science and Game Theory,Bayesian implementation concerns decision making problems when agents have\nincomplete information. This paper proposes that the traditional sufficient\nconditions for Bayesian implementation shall be amended by virtue of a quantum\nBayesian mechanism. In addition, by using an algorithmic Bayesian mechanism,\nthis amendment holds in the macro world.Comment: 14 pages, 3 figures", "1104.0746": "Quantifier Elimination over Finite Fields Using Gr\\\"obner Bases,Gao, SicunPlatzer, Andr\u00e9Clarke, Edmund M.,Computer Science - Symbolic ComputationComputer Science - Logic in Computer Science,We give an algebraic quantifier elimination algorithm for the first-order\ntheory over any given finite field using Gr\\\"obner basis methods. The algorithm\nrelies on the strong Nullstellensatz and properties of elimination ideals over\nfinite fields. We analyze the theoretical complexity of the algorithm and show\nits application in the formal analysis of a biological controller model.Comment: A shorter version is to appear in International Conference on\n  Algebraic Informatics 2011", "1104.2373": "Hybrid Deterministic-Stochastic Methods for Data Fitting,Friedlander, Michael P.Schmidt, Mark,Computer Science - Numerical AnalysisComputer Science - Systems and ControlMathematics - Optimization and ControlStatistics - Machine Learning,Many structured data-fitting applications require the solution of an\noptimization problem involving a sum over a potentially large number of\nmeasurements. Incremental gradient algorithms offer inexpensive iterations by\nsampling a subset of the terms in the sum. These methods can make great\nprogress initially, but often slow as they approach a solution. In contrast,\nfull-gradient methods achieve steady convergence at the expense of evaluating\nthe full objective and gradient on each iteration. We explore hybrid methods\nthat exhibit the benefits of both approaches. Rate-of-convergence analysis\nshows that by controlling the sample size in an incremental gradient algorithm,\nit is possible to maintain the steady convergence rates of full-gradient\nmethods. We detail a practical quasi-Newton implementation based on this\napproach. Numerical experiments illustrate its potential benefits.Comment: 26 pages. Revised proofs of Theorems 2.6 and 3.1, results unchanged", "1104.4465": "Randomness and Differentiability,Brattka, VascoMiller, Joseph S.Nies, Andr\u00e9,Mathematics - LogicComputer Science - Logic in Computer Science03D32, 03F60, 26A27, 26A48, 26A45,We characterize some major algorithmic randomness notions via\ndifferentiability of effective functions.\n  (1) As the main result we show that a real number z in [0,1] is computably\nrandom if and only if each nondecreasing computable function [0,1]->R is\ndifferentiable at z.\n  (2) We prove that a real number z in [0,1] is weakly 2-random if and only if\neach almost everywhere differentiable computable function [0,1]->R is\ndifferentiable at z.\n  (3) Recasting in classical language results dating from 1975 of the\nconstructivist Demuth, we show that a real z is ML random if and only if every\ncomputable function of bounded variation is differentiable at z, and similarly\nfor absolutely continuous functions.\n  We also use our analytic methods to show that computable randomness of a real\nis base invariant, and to derive other preservation results for randomness\nnotions.Comment: 39 pages", "1104.4987": "An improved bound on the number of point-surface incidences in three\n  dimensions,Zahl, Joshua,Mathematics - CombinatoricsComputer Science - Computational Geometry,We show that $m$ points and $n$ smooth algebraic surfaces of bounded degree\nin $\\mathbb{R}^3$ satisfying suitable nondegeneracy conditions can have at most\n$O(m^{\\frac{2k}{3k-1}}n^{\\frac{3k-3}{3k-1}}+m+n)$ incidences, provided that any\ncollection of $k$ points have at most O(1) surfaces passing through all of\nthem, for some $k\\geq 3$. In the case where the surfaces are spheres and no\nthree spheres meet in a common circle, this implies there are $O((mn)^{3/4} + m\n+n)$ point-sphere incidences. This is a slight improvement over the previous\nbound of $O((mn)^{3/4} \\beta(m,n)+ m +n)$ for $\\beta(m,n)$ an (explicit) very\nslowly growing function. We obtain this bound by using the discrete polynomial\nham sandwich theorem to cut $\\mathbb{R}^3$ into open cells adapted to the set\nof points, and within each cell of the decomposition we apply a Turan-type\ntheorem to obtain crude control on the number of point-surface incidences. We\nthen perform a second polynomial ham sandwich decomposition on the irreducible\ncomponents of the variety defined by the first decomposition. As an\napplication, we obtain a new bound on the maximum number of unit distances\namongst $m$ points in $\\mathbb{R}^3$.Comment: 17 pages, revised based on referee comments", "1104.5286": "Doubly Robust Smoothing of Dynamical Processes via Outlier Sparsity\n  Constraints,Farahmand, ShahrokhGiannakis, Georgios B.Angelosante, Daniele,Computer Science - Systems and ControlMathematics - Optimization and ControlStatistics - Applications,Coping with outliers contaminating dynamical processes is of major importance\nin various applications because mismatches from nominal models are not uncommon\nin practice. In this context, the present paper develops novel fixed-lag and\nfixed-interval smoothing algorithms that are robust to outliers simultaneously\npresent in the measurements {\\it and} in the state dynamics. Outliers are\nhandled through auxiliary unknown variables that are jointly estimated along\nwith the state based on the least-squares criterion that is regularized with\nthe $\\ell_1$-norm of the outliers in order to effect sparsity control. The\nresultant iterative estimators rely on coordinate descent and the alternating\ndirection method of multipliers, are expressed in closed form per iteration,\nand are provably convergent. Additional attractive features of the novel doubly\nrobust smoother include: i) ability to handle both types of outliers; ii)\nuniversality to unknown nominal noise and outlier distributions; iii)\nflexibility to encompass maximum a posteriori optimal estimators with reliable\nperformance under nominal conditions; and iv) improved performance relative to\ncompeting alternatives at comparable complexity, as corroborated via simulated\ntests.Comment: Submitted to IEEE Trans. on Signal Processing", "1104.5288": "Tracking Target Signal Strengths on a Grid using Sparsity,Farahmand, ShahrokhGiannakis, Georgios B.Leus, GeertTian, Zhi,Computer Science - Systems and ControlMathematics - Optimization and ControlStatistics - Applications,Multi-target tracking is mainly challenged by the nonlinearity present in the\nmeasurement equation, and the difficulty in fast and accurate data association.\nTo overcome these challenges, the present paper introduces a grid-based model\nin which the state captures target signal strengths on a known spatial grid\n(TSSG). This model leads to \\emph{linear} state and measurement equations,\nwhich bypass data association and can afford state estimation via\nsparsity-aware Kalman filtering (KF). Leveraging the grid-induced sparsity of\nthe novel model, two types of sparsity-cognizant TSSG-KF trackers are\ndeveloped: one effects sparsity through $\\ell_1$-norm regularization, and the\nother invokes sparsity as an extra measurement. Iterative extended KF and\nGauss-Newton algorithms are developed for reduced-complexity tracking, along\nwith accurate error covariance updates for assessing performance of the\nresultant sparsity-aware state estimators. Based on TSSG state estimates, more\ninformative target position and track estimates can be obtained in a follow-up\nstep, ensuring that track association and position estimation errors do not\npropagate back into TSSG state estimates. The novel TSSG trackers do not\nrequire knowing the number of targets or their signal strengths, and exhibit\nconsiderably lower complexity than the benchmark hidden Markov model filter,\nespecially for a large number of targets. Numerical simulations demonstrate\nthat sparsity-cognizant trackers enjoy improved root mean-square error\nperformance at reduced complexity when compared to their sparsity-agnostic\ncounterparts.Comment: Submitted to IEEE Trans. on Signal Processing", "1105.1302": "A Modified Cross Correlation Algorithm for Reference-free Image\n  Alignment of Non-Circular Projections in Single-Particle Electron Microscopy,Park, WooramChirikjian, Gregory S.,Quantitative Biology - Quantitative MethodsComputer Science - Computer Vision and Pattern RecognitionMathematics - Numerical Analysis,In this paper we propose a modified cross correlation method to align images\nfrom the same class in single-particle electron microscopy of highly\nnon-spherical structures. In this new method, First we coarsely align\nprojection images, and then re-align the resulting images using the cross\ncorrelation (CC) method. The coarse alignment is obtained by matching the\ncenters of mass and the principal axes of the images. The distribution of\nmisalignment in this coarse alignment can be quantified based on the\nstatistical properties of the additive background noise. As a consequence, the\nsearch space for re-alignment in the cross correlation method can be reduced to\nachieve better alignment. In order to overcome problems associated with false\npeaks in the cross correlations function, we use artificially blurred images\nfor the early stage of the iterative cross correlation method and segment the\nintermediate class average from every iteration step. These two additional\nmanipulations combined with the reduced search space size in the cross\ncorrelation method yield better alignments for low signal-to-noise ratio images\nthan both classical cross correlation and maximum likelihood(ML) methods.Comment: 29pages", "1106.1445": "From Classical to Quantum Shannon Theory,Wilde, Mark M.,Quantum PhysicsComputer Science - Information Theory,The aim of this book is to develop \"from the ground up\" many of the major,\nexciting, pre- and post-millenium developments in the general area of study\nknown as quantum Shannon theory. As such, we spend a significant amount of time\non quantum mechanics for quantum information theory (Part II), we give a\ncareful study of the important unit protocols of teleportation, super-dense\ncoding, and entanglement distribution (Part III), and we develop many of the\ntools necessary for understanding information transmission or compression (Part\nIV). Parts V and VI are the culmination of this book, where all of the tools\ndeveloped come into play for understanding many of the important results in\nquantum Shannon theory.Comment: v7: 774 pages, 301 exercises, 81 figures; this draft, pre-publication\n  copy is available under a Creative Commons\n  Attribution-NonCommercial-ShareAlike license (see\n  http://creativecommons.org/licenses/by-nc-sa/3.0/), \"Quantum Information\n  Theory, Second Edition\" will be available for purchase from Cambridge\n  University Press", "1106.2327": "A framework for coupled deformation-diffusion analysis with application\n  to degradation/healing,Mudunuru, M. K.Nakshatrala, K. B.,Computer Science - Numerical AnalysisComputer Science - Computational Engineering, Finance, and ScienceMathematics - Numerical AnalysisPhysics - Computational Physics,This paper deals with the formulation and numerical implementation of a fully\ncoupled continuum model for deformation-diffusion in linearized elastic solids.\nThe mathematical model takes into account the effect of the deformation on the\ndiffusion process, and the affect of the transport of an inert chemical species\non the deformation of the solid. We then present a robust computational\nframework for solving the proposed mathematical model, which consists of\ncoupled non-linear partial differential equations. It should be noted that many\npopular numerical formulations may produce unphysical negative values for the\nconcentration, particularly, when the diffusion process is anisotropic. The\nviolation of the non-negative constraint by these numerical formulations is not\nmere numerical noise. In the proposed computational framework we employ a novel\nnumerical formulation that will ensure that the concentration of the diffusant\nbe always non-negative, which is one of the main contributions of this paper.\nRepresentative numerical examples are presented to show the robustness,\nconvergence, and performance of the proposed computational framework. Another\ncontribution of this paper is to systematically study the affect of transport\nof the diffusant on the deformation of the solid and vice-versa, and their\nimplication in modeling degradation/healing of materials. We show that the\ncoupled response is both qualitatively and quantitatively different from the\nuncoupled response.", "1106.2441": "An f-chromatic spanning forest of edge-colored complete bipartite graphs,Suzuki, Kazuhiro,Mathematics - CombinatoricsComputer Science - Discrete Mathematics05C05, 05C15,In 2001, Brualdi and Hollingsworth proved that an edge-colored balanced\ncomplete bipartite graph Kn,n with a color set C = {1,2,3,..., 2n-1} has a\nheterochromatic spanning tree if the number of edges colored with colors in R\nis more than |R|^2 /4 for any non-empty subset R \\subseteq C, where a\nheterochromatic spanning tree is a spanning tree whose edges have distinct\ncolors, namely, any color appears at most once. In 2010, Suzuki generalized\nheterochromatic graphs to f-chromatic graphs, where any color c appears at most\nf(c). Moreover, he presented a necessary and sufficient condition for graphs to\nhave an f-chromatic spanning forest with exactly w components. In this paper,\nusing this necessary and sufficient condition, we generalize the\nBrualdi-Hollingsworth theorem above.Comment: 8 pages, 3 figures", "1106.5130": "Some Properties of R\\'{e}nyi Entropy over Countably Infinite Alphabets,Kova\u010devi\u0107, MladenStanojevi\u0107, Ivan\u0160enk, Vojin,Computer Science - Information Theory94A17H.1.1,In this paper we study certain properties of R\\'{e}nyi entropy functionals\n$H_\\alpha(\\mathcal{P})$ on the space of probability distributions over\n$\\mathbb{Z}_+$. Primarily, continuity and convergence issues are addressed.\nSome properties shown parallel those known in the finite alphabet case, while\nothers illustrate a quite different behaviour of R\\'enyi entropy in the\ninfinite case. In particular, it is shown that, for any distribution $\\mathcal\nP$ and any $r\\in[0,\\infty]$, there exists a sequence of distributions\n$\\mathcal{P}_n$ converging to $\\mathcal{P}$ with respect to the total variation\ndistance, such that $\\lim_{n\\to\\infty}\\lim_{\\alpha\\to{1+}}\nH_\\alpha(\\mathcal{P}_n) = \\lim_{\\alpha\\to{1+}}\\lim_{n\\to\\infty}\nH_\\alpha(\\mathcal{P}_n) + r$.Comment: 13 pages (single-column)", "1107.0088": "Sparse Sums of Positive Semidefinite Matrices,Silva, Marcel K. de CarliHarvey, Nicholas J. A.Sato, Cristiane M.,Computer Science - Discrete MathematicsComputer Science - Data Structures and AlgorithmsComputer Science - Numerical AnalysisMathematics - Combinatorics,Recently there has been much interest in \"sparsifying\" sums of rank one\nmatrices: modifying the coefficients such that only a few are nonzero, while\napproximately preserving the matrix that results from the sum. Results of this\nsort have found applications in many different areas, including sparsifying\ngraphs. In this paper we consider the more general problem of sparsifying sums\nof positive semidefinite matrices that have arbitrary rank.\n  We give several algorithms for solving this problem. The first algorithm is\nbased on the method of Batson, Spielman and Srivastava (2009). The second\nalgorithm is based on the matrix multiplicative weights update method of Arora\nand Kale (2007). We also highlight an interesting connection between these two\nalgorithms.\n  Our algorithms have numerous applications. We show how they can be used to\nconstruct graph sparsifiers with auxiliary constraints, sparsifiers of\nhypergraphs, and sparse solutions to semidefinite programs.", "1107.2465": "An Efficient Algorithm for Maximum-Entropy Extension of Block-Circulant\n  Covariance Matrices,Carli, Francesca P.Ferrante, AugustoPavon, MichelePicci, Giorgio,Mathematics - Optimization and ControlComputer Science - Information TheoryComputer Science - Systems and Control,This paper deals with maximum entropy completion of partially specified\nblock-circulant matrices. Since positive definite symmetric circulants happen\nto be covariance matrices of stationary periodic processes, in particular of\nstationary reciprocal processes, this problem has applications in signal\nprocessing, in particular to image modeling. In fact it is strictly related to\nmaximum likelihood estimation of bilateral AR-type representations of acausal\nsignals subject to certain conditional independence constraints. The maximum\nentropy completion problem for block-circulant matrices has recently been\nsolved by the authors, although leaving open the problem of an efficient\ncomputation of the solution. In this paper, we provide an effcient algorithm\nfor computing its solution which compares very favourably with existing\nalgorithms designed for positive definite matrix extension problems. The\nproposed algorithm benefits from the analysis of the relationship between our\nproblem and the band-extension problem for block-Toeplitz matrices also\ndeveloped in this paper.Comment: 25 pages", "1108.1915": "Noise effects in the quantum search algorithm from the computational\n  complexity point of view,Gawron, PiotrKlamka, JerzyWiniarczyk, Ryszard,Quantum PhysicsComputer Science - Computational Complexity,We analyse the resilience of the quantum search algorithm in the presence of\nquantum noise modelled as trace preserving completely positive maps. We study\nthe influence of noise on computational complexity of the quantum search\nalgorithm. We show that only for small amounts of noise the quantum search\nalgorithm is still more efficient than any classical algorithm.Comment: 7 pages, 2 figures", "1109.0345": "Planar and Poly-Arc Lombardi Drawings,Duncan, Christian A.Eppstein, DavidGoodrich, Michael T.Kobourov, Stephen G.L\u00f6ffler, Maarten,Computer Science - Computational GeometryComputer Science - Discrete Mathematics05C10, 68R10G.2.2F.2.2,In Lombardi drawings of graphs, edges are represented as circular arcs, and\nthe edges incident on vertices have perfect angular resolution. However, not\nevery graph has a Lombardi drawing, and not every planar graph has a planar\nLombardi drawing. We introduce k-Lombardi drawings, in which each edge may be\ndrawn with k circular arcs, noting that every graph has a smooth 2-Lombardi\ndrawing. We show that every planar graph has a smooth planar 3-Lombardi drawing\nand further investigate topics connecting planarity and Lombardi drawings.Comment: Expanded version of paper appearing in the 19th International\n  Symposium on Graph Drawing (GD 2011). 16 pages, 8 figures", "1109.2162": "The Complexity of the Empire Colouring Problem,McGrae, Andrew R. A.Zito, Michele,Computer Science - Computational Complexity,We investigate the computational complexity of the empire colouring problem\n(as defined by Percy Heawood in 1890) for maps containing empires formed by\nexactly $r > 1$ countries each. We prove that the problem can be solved in\npolynomial time using $s$ colours on maps whose underlying adjacency graph has\nno induced subgraph of average degree larger than $s/r$. However, if $s \\geq\n3$, the problem is NP-hard even if the graph is a forest of paths of arbitrary\nlengths (for any $r \\geq 2$, provided $s < 2r - \\sqrt(2r + 1/4+ 3/2)$.\nFurthermore we obtain a complete characterization of the problem's complexity\nfor the case when the input graph is a tree, whereas our result for arbitrary\nplanar graphs fall just short of a similar dichotomy. Specifically, we prove\nthat the empire colouring problem is NP-hard for trees, for any $r \\geq 2$, if\n$3 \\leq s \\leq 2r-1$ (and polynomial time solvable otherwise). For arbitrary\nplanar graphs we prove NP-hardness if $s<7$ for $r=2$, and $s < 6r-3$, for $r\n\\geq 3$. The result for planar graphs also proves the NP-hardness of colouring\nwith less than 7 colours graphs of thickness two and less than $6r-3$ colours\ngraphs of thickness $r \\geq 3$.Comment: 23 pages, 12 figures", "1109.2984": "A Statistically Modelling Method for Performance Limits in Sensor\n  Localization,Huang, BaoqiLi, TaoAnderson, Brian D. O.Yu, Changbin,Computer Science - Systems and ControlMathematics - Optimization and Control,In this paper, we study performance limits of sensor localization from a\nnovel perspective. Specifically, we consider the Cramer-Rao Lower Bound (CRLB)\nin single-hop sensor localization using measurements from received signal\nstrength (RSS), time of arrival (TOA) and bearing, respectively, but\ndifferently from the existing work, we statistically analyze the trace of the\nassociated CRLB matrix (i.e. as a scalar metric for performance limits of\nsensor localization) by assuming anchor locations are random. By the Central\nLimit Theorems for $U$-statistics, we show that as the number of the anchors\nincreases, this scalar metric is asymptotically normal in the RSS/bearing case,\nand converges to a random variable which is an affine transformation of a\nchi-square random variable of degree 2 in the TOA case. Moreover, we provide\nformulas quantitatively describing the relationship among the mean and standard\ndeviation of the scalar metric, the number of the anchors, the parameters of\ncommunication channels, the noise statistics in measurements and the spatial\ndistribution of the anchors. These formulas, though asymptotic in the number of\nthe anchors, in many cases turn out to be remarkably accurate in predicting\nperformance limits, even if the number is small. Simulations are carried out to\nconfirm our results.", "1110.0685": "Energy Aware Scheduling for Weighted Completion Time and Weighted\n  Tardiness,Carrasco, Rodrigo A.Iyengar, GarudStein, Cliff,Computer Science - Discrete MathematicsMathematics - Combinatorics,The ever increasing adoption of mobile devices with limited energy storage\ncapacity, on the one hand, and more awareness of the environmental impact of\nmassive data centres and server pools, on the other hand, have both led to an\nincreased interest in energy management algorithms.\n  The main contribution of this paper is to present several new constant factor\napproximation algorithms for energy aware scheduling problems where the\nobjective is to minimize weighted completion time plus the cost of the energy\nconsumed, in the one machine non-preemptive setting, while allowing release\ndates and deadlines.Unlike previous known algorithms these new algorithms can\nhandle general job-dependent energy cost functions, extending the application\nof these algorithms to settings outside the typical CPU-energy one. These new\nsettings include problems where in addition, or instead, of energy costs we\nalso have maintenance costs, wear and tear, replacement costs, etc., which in\ngeneral depend on the speed at which the machine runs but also depend on the\ntypes of jobs processed. Our algorithms also extend to approximating weighted\ntardiness plus energy cost, an inherently more difficult problem that has not\nbeen addressed in the literature.Comment: 17 pages", "1110.0895": "Robust inversion via semistochastic dimensionality reduction,Aravkin, AleksandrFriedlander, Michael P.van Leeuwen, Tristan,Computer Science - Computational Engineering, Finance, and ScienceComputer Science - Numerical Analysis,We consider a class of inverse problems where it is possible to aggregate the\nresults of multiple experiments. This class includes problems where the forward\nmodel is the solution operator to linear ODEs or PDEs. The tremendous size of\nsuch problems motivates dimensionality reduction techniques based on randomly\nmixing experiments. These techniques break down, however, when robust\ndata-fitting formulations are used, which are essential in cases of missing\ndata, unusually large errors, and systematic features in the data unexplained\nby the forward model. We survey robust methods within a statistical framework,\nand propose a semistochastic optimization approach that allows dimensionality\nreduction. The efficacy of the methods are demonstrated for a large-scale\nseismic inverse problem using the robust Student's t-distribution, where a\nuseful synthetic velocity model is recovered in the extreme scenario of 60%\ndata missing at random. The semistochastic approach achieves this recovery\nusing 20% of the effort required by a direct robust approach.Comment: Mathematical Programming, 2012", "1110.2053": "Steps Towards a Theory of Visual Information: Active Perception,\n  Signal-to-Symbol Conversion and the Interplay Between Sensing and Control,Soatto, Stefano,Computer Science - Computer Vision and Pattern Recognition,This manuscript describes the elements of a theory of information tailored to\ncontrol and decision tasks and specifically to visual data. The concept of\nActionable Information is described, that relates to a notion of information\nchampioned by J. Gibson, and a notion of \"complete information\" that relates to\nthe minimal sufficient statistics of a complete representation. It is shown\nthat the \"actionable information gap\" between the two can be reduced by\nexercising control on the sensing process. Thus, senging, control and\ninformation are inextricably tied. This has consequences in the so-called\n\"signal-to-symbol barrier\" problem, as well as in the analysis and design of\nactive sensing systems. It has ramifications in vision-based control,\nnavigation, 3-D reconstruction and rendering, as well as detection,\nlocalization, recognition and categorization of objects and scenes in live\nvideo.\n  This manuscript has been developed from a set of lecture notes for a summer\ncourse at the First International Computer Vision Summer School (ICVSS) in\nScicli, Italy, in July of 2008. They were later expanded and amended for\nsubsequent lectures in the same School in July 2009. Starting on November 1,\n2009, they were further expanded for a special topics course, CS269, taught at\nUCLA in the Spring term of 2010.Comment: 151 pages; preliminary version TR UCLA-CSD100028 of September 13,\n  20010", "1111.0235": "New Methods for Handling Singular Sample Covariance Matrices,Tucci, Gabriel H.Wang, Ke,Mathematics - ProbabilityComputer Science - Information TheoryMathematics - Statistics Theory15B52, 60B20,The estimation of a covariance matrix from an insufficient amount of data is\none of the most common problems in fields as diverse as multivariate\nstatistics, wireless communications, signal processing, biology, learning\ntheory and finance. In a joint work of Marzetta, Tucci and Simon, a new\napproach to handle singular covariance matrices was suggested. The main idea\nwas to use dimensionality reduction in conjunction with an average over the\nStiefel manifold. In this paper we continue with this research and we consider\nsome new approaches to solve this problem. One of the methods is called the\nEwens estimator and uses a randomization of the sample covariance matrix over\nall the permutation matrices with respect to the Ewens measure. The techniques\nused to attack this problem are broad and run from random matrix theory to\ncombinatorics.Comment: Final version. Rewrote Section 5. Accepted by IEEE Transactions on\n  Information Theory", "1111.0284": "A topological interpretation of the walk distances,Chebotarev, PavelDeza, Michel,Mathematics - CombinatoricsComputer Science - Discrete MathematicsComputer Science - Social and Information NetworksMathematics - Metric Geometry05C12, 05C50, 51K05, 15A09, 15A15,The walk distances in graphs have no direct interpretation in terms of walk\nweights, since they are introduced via the \\emph{logarithms} of walk weights.\nOnly in the limiting cases where the logarithms vanish such representations\nfollow straightforwardly. The interpretation proposed in this paper rests on\nthe identity $\\ln\\det B=\\tr\\ln B$ applied to the cofactors of the matrix\n$I-tA,$ where $A$ is the weighted adjacency matrix of a weighted multigraph and\n$t$ is a sufficiently small positive parameter. In addition, this\ninterpretation is based on the power series expansion of the logarithm of a\nmatrix. Kasteleyn (1967) was probably the first to apply the foregoing approach\nto expanding the determinant of $I-A$. We show that using a certain linear\ntransformation the same approach can be extended to the cofactors of $I-tA,$\nwhich provides a topological interpretation of the walk distances.Comment: 13 pages, 1 figure. Version #3", "1111.2480": "The Distance Function on a Computable Graph,Calvert, WesleyMiller, RussellReimann, Jennifer Chubb,Mathematics - LogicComputer Science - Logic in Computer Science,We apply the techniques of computable model theory to the distance function\nof a graph. This task leads us to adapt the definitions of several truth-table\nreducibilities so that they apply to functions as well as to sets, and we prove\nassorted theorems about the new reducibilities and about functions which have\nnonincreasing computable approximations. Finally, we show that the spectrum of\nthe distance function can consist of an arbitrary single btt-degree which is\napproximable from above, or of all such btt-degrees at once, or of the\nbT-degrees of exactly those functions approximable from above in at most n\nsteps.Comment: submitted for publication 9 November 2011", "1111.3048": "On a Connection Between Small Set Expansions and Modularity Clustering\n  in Social Networks,DasGupta, BhaskarDesai, Devendra,Computer Science - Social and Information NetworksComputer Science - Computational ComplexityPhysics - Physics and Society68Q25, 68W25F.2.2J.4,In this paper we explore a connection between two seemingly different\nproblems from two different domains: the small-set expansion problem studied in\nunique games conjecture, and a popular community finding approach for social\nnetworks known as the modularity clustering approach. We show that a\nsub-exponential time algorithm for the small-set expansion problem leads to a\nsub-exponential time constant factor approximation for some hard input\ninstances of the modularity clustering problem.Comment: Information Processing Letters, 2014", "1111.4662": "Traffic distributions and independence: permutation invariant random\n  matrices and the three notions of independence,Male, Camille,Mathematics - ProbabilityComputer Science - Discrete MathematicsMathematics - CombinatoricsMathematics - Operator Algebras,Voiculescu's notion of asymptotic free independence is known for a large\nclass of random matrices including independent unitary invariant matrices. This\nnotion is extended for independent random matrices invariant in law by\nconjugation by permutation matrices. This fact leads naturally to an extension\nof free probability, formalized under the notions of traffic probability. We\nfirst establish this construction for random matrices. We define the traffic\ndistribution of random matrices, which is richer than the *-distribution of\nfree probability. The knowledge of the individual traffic distributions of\nindependent permutation invariant families of matrices is sufficient to compute\nthe limiting distribution of the join family. Under a factorization assumption,\nwe call traffic independence the asymptotic rule that plays the role of\nindependence with respect to traffic distributions. Wigner matrices, Haar\nunitary matrices and uniform permutation matrices converge in traffic\ndistributions, a fact which yields new results on the limiting *-distributions\nof several matrices we can construct from them. Then we define the abstract\ntraffic spaces as non commutative probability spaces with more structure. We\nprove that at an algebraic level, traffic independence in some sense unifies\nthe three canonical notions of tensor, free and Boolean independence. A central\nlimiting theorem is stated in this context, interpolating between the tensor,\nfree and Boolean central limit theorems.Comment: Final version. Accepted for publication on Memoirs of the AMS (will\n  be released on 2020, because of very large backlog)", "1111.7013": "A Taxation Policy for Maximizing Social Welfare in Networks: A General\n  Framework,Kakhbod, AliKoo, JosephTeneketzis, Demosthenis,Mathematics - Optimization and ControlComputer Science - Computer Science and Game Theory,We present a simple tatonnement process based on a decomposition method which\nis simple to implement and achieves the maximal social welfare, under the\nassumption that the utility function of each [price-taking] individual will be\nhis own private information and need not be known by the designer. At each\niteration, very little information needs to be exchanged among the individuals\nin order to achieve the optimal allocation. Furthermore, the given tatonnement\nprocess is always balanced at equilibrium and off equilibrium.", "1112.0857": "I/O efficient bisimulation partitioning on very large directed acyclic\n  graphs,Hellings, JelleFletcher, George H. L.Haverkort, Herman,Computer Science - Data Structures and AlgorithmsComputer Science - Databases,In this paper we introduce the first efficient external-memory algorithm to\ncompute the bisimilarity equivalence classes of a directed acyclic graph (DAG).\nDAGs are commonly used to model data in a wide variety of practical\napplications, ranging from XML documents and data provenance models, to web\ntaxonomies and scientific workflows. In the study of efficient reasoning over\nmassive graphs, the notion of node bisimilarity plays a central role. For\nexample, grouping together bisimilar nodes in an XML data set is the first step\nin many sophisticated approaches to building indexing data structures for\nefficient XPath query evaluation. To date, however, only internal-memory\nbisimulation algorithms have been investigated. As the size of real-world DAG\ndata sets often exceeds available main memory, storage in external memory\nbecomes necessary. Hence, there is a practical need for an efficient approach\nto computing bisimulation in external memory.\n  Our general algorithm has a worst-case IO-complexity of O(Sort(|N| + |E|)),\nwhere |N| and |E| are the numbers of nodes and edges, resp., in the data graph\nand Sort(n) is the number of accesses to external memory needed to sort an\ninput of size n. We also study specializations of this algorithm to common\nvariations of bisimulation for tree-structured XML data sets. We empirically\nverify efficient performance of the algorithms on graphs and XML documents\nhaving billions of nodes and edges, and find that the algorithms can process\nsuch graphs efficiently even when very limited internal memory is available.\nThe proposed algorithms are simple enough for practical implementation and use,\nand open the door for further study of external-memory bisimulation algorithms.\nTo this end, the full open-source C++ implementation has been made freely\navailable.", "1112.2275": "On Problems as Hard as CNFSAT,Cygan, MarekDell, HolgerLokshtanov, DanielMarx, DanielNederlof, JesperOkamoto, YoshioPaturi, RamamohanSaurabh, SaketWahlstrom, Magnus,Computer Science - Data Structures and AlgorithmsComputer Science - Computational ComplexityComputer Science - Discrete Mathematics,The field of exact exponential time algorithms for NP-hard problems has\nthrived over the last decade. While exhaustive search remains asymptotically\nthe fastest known algorithm for some basic problems, difficult and non-trivial\nexponential time algorithms have been found for a myriad of problems, including\nGraph Coloring, Hamiltonian Path, Dominating Set and 3-CNF-Sat. In some\ninstances, improving these algorithms further seems to be out of reach. The\nCNF-Sat problem is the canonical example of a problem for which the trivial\nexhaustive search algorithm runs in time O(2^n), where n is the number of\nvariables in the input formula. While there exist non-trivial algorithms for\nCNF-Sat that run in time o(2^n), no algorithm was able to improve the growth\nrate 2 to a smaller constant, and hence it is natural to conjecture that 2 is\nthe optimal growth rate. The strong exponential time hypothesis (SETH) by\nImpagliazzo and Paturi [JCSS 2001] goes a little bit further and asserts that,\nfor every epsilon<1, there is a (large) integer k such that that k-CNF-Sat\ncannot be computed in time 2^{epsilon n}.\n  In this paper, we show that, for every epsilon < 1, the problems Hitting Set,\nSet Splitting, and NAE-Sat cannot be computed in time O(2^{epsilon n}) unless\nSETH fails. Here n is the number of elements or variables in the input. For\nthese problems, we actually get an equivalence to SETH in a certain sense. We\nconjecture that SETH implies a similar statement for Set Cover, and prove that,\nunder this assumption, the fastest known algorithms for Steinter Tree,\nConnected Vertex Cover, Set Partitioning, and the pseudo-polynomial time\nalgorithm for Subset Sum cannot be significantly improved. Finally, we justify\nour assumption about the hardness of Set Cover by showing that the parity of\nthe number of set covers cannot be computed in time O(2^{epsilon n}) for any\nepsilon<1 unless SETH fails.Comment: 25 pages, 1 figure", "1201.0490": "Scikit-learn: Machine Learning in Python,Pedregosa, FabianVaroquaux, Ga\u00eblGramfort, AlexandreMichel, VincentThirion, BertrandGrisel, OlivierBlondel, MathieuM\u00fcller, AndreasNothman, JoelLouppe, GillesPrettenhofer, PeterWeiss, RonDubourg, VincentVanderplas, JakePassos, AlexandreCournapeau, DavidBrucher, MatthieuPerrot, MatthieuDuchesnay, \u00c9douard,Computer Science - Machine LearningComputer Science - Mathematical Software,Scikit-learn is a Python module integrating a wide range of state-of-the-art\nmachine learning algorithms for medium-scale supervised and unsupervised\nproblems. This package focuses on bringing machine learning to non-specialists\nusing a general-purpose high-level language. Emphasis is put on ease of use,\nperformance, documentation, and API consistency. It has minimal dependencies\nand is distributed under the simplified BSD license, encouraging its use in\nboth academic and commercial settings. Source code, binaries, and documentation\ncan be downloaded from http://scikit-learn.org.Comment: Update authors list and URLs", "1201.2845": "Competition through selective inhibitory synchrony,Rutishauser, UeliSlotine, Jean-JacquesDouglas, Rodney J.,Quantitative Biology - Neurons and CognitionComputer Science - Neural and Evolutionary Computing,Models of cortical neuronal circuits commonly depend on inhibitory feedback\nto control gain, provide signal normalization, and to selectively amplify\nsignals using winner-take-all (WTA) dynamics. Such models generally assume that\nexcitatory and inhibitory neurons are able to interact easily, because their\naxons and dendrites are co-localized in the same small volume. However,\nquantitative neuroanatomical studies of the dimensions of axonal and dendritic\ntrees of neurons in the neocortex show that this co-localization assumption is\nnot valid. In this paper we describe a simple modification to the WTA circuit\ndesign that permits the effects of distributed inhibitory neurons to be coupled\nthrough synchronization, and so allows a single WTA to be distributed widely in\ncortical space, well beyond the arborization of any single inhibitory neuron,\nand even across different cortical areas. We prove by non-linear contraction\nanalysis, and demonstrate by simulation that distributed WTA sub-systems\ncombined by such inhibitory synchrony are inherently stable. We show\nanalytically that synchronization is substantially faster than winner\nselection. This circuit mechanism allows networks of independent WTAs to fully\nor partially compete with each other.Comment: in press at Neural computation; 4 figures", "1201.3416": "Verifying Real-time Commit Protocols Using Dense-time Model Checking\n  Technology,Al-Bataineh, Omar I.Reynolds, Mark,Computer Science - Software Engineering,The timed-based automata model, introduced by Alur and Dill, provides a\nuseful formalism for describing real-time systems. Over the last two decades,\nseveral dense-time model checking tools have been developed based on that\nmodel. The paper considers the verification of real-time distributed commit\nprotocols using dense-time model checking technology. More precisely, we model\nand verify the well-known timed two phase commit protocol in three different\nstate-of-the-art real-time model checkers: UPPAAL, Rabbit, and RED, and compare\nthe results.", "1201.5921": "An iterative algorithm for parametrization of shortest length shift\n  registers over finite rings,Kuijper, M.Pinto, R.,Computer Science - Information TheoryComputer Science - Symbolic Computation94A55, 11T71,The construction of shortest feedback shift registers for a finite sequence\nS_1,...,S_N is considered over the finite ring Z_{p^r}. A novel algorithm is\npresented that yields a parametrization of all shortest feedback shift\nregisters for the sequence of numbers S_1,...,S_N, thus solving an open problem\nin the literature. The algorithm iteratively processes each number, starting\nwith S_1, and constructs at each step a particular type of minimal Gr\\\"obner\nbasis. The construction involves a simple update rule at each step which leads\nto computational efficiency. It is shown that the algorithm simultaneously\ncomputes a similar parametrization for the reciprocal sequence S_N,...,S_1.Comment: Submitted", "1201.6371": "Standard decomposition of expansive ergodically supported dynamics,Sobottka, Marcelo,Mathematics - Dynamical SystemsComputer Science - Information TheoryMathematics - Group Theory20N05, 17C10, 94A55, 68P30,In this work we introduce the notion of weak quasigroups, that are quasigroup\noperations defined almost everywhere on some set. Then we prove that the\ntopological entropy and the ergodic period of an invertible expansive\nergodically supported dynamical system $(X,T)$ with the shadowing property\nestablishes a sufficient criterion for the existence of quasigroup operations\ndefined almost everywhere outside of universally null sets and for which $T$ is\nan automorphism. Furthermore, we find a decomposition of the dynamics of $T$ in\nterms of $T$-invariant weak topological subquasigroups.Comment: 18 pages, the conditions on the entropy in Theorem 3.5 was improved.\n  Some small changes in the text, by adding more explanations", "1202.3538": "Refinement Modal Logic,Bozzelli, Lauravan Ditmarsch, HansFrench, TimHales, JamesPinchinat, Sophie,Computer Science - Logic in Computer ScienceComputer Science - Artificial Intelligence,In this paper we present {\\em refinement modal logic}. A refinement is like a\nbisimulation, except that from the three relational requirements only `atoms'\nand `back' need to be satisfied. Our logic contains a new operator 'all' in\naddition to the standard modalities 'box' for each agent. The operator 'all'\nacts as a quantifier over the set of all refinements of a given model. As a\nvariation on a bisimulation quantifier, this refinement operator or refinement\nquantifier 'all' can be seen as quantifying over a variable not occurring in\nthe formula bound by it. The logic combines the simplicity of multi-agent modal\nlogic with some powers of monadic second-order quantification. We present a\nsound and complete axiomatization of multi-agent refinement modal logic. We\nalso present an extension of the logic to the modal mu-calculus, and an\naxiomatization for the single-agent version of this logic. Examples and\napplications are also discussed: to software verification and design (the set\nof agents can also be seen as a set of actions), and to dynamic epistemic\nlogic. We further give detailed results on the complexity of satisfiability,\nand on succinctness.", "1202.3733": "Lipschitz Parametrization of Probabilistic Graphical Models,Honorio, Jean,Computer Science - Machine LearningStatistics - Machine Learning,We show that the log-likelihood of several probabilistic graphical models is\nLipschitz continuous with respect to the lp-norm of the parameters. We discuss\nseveral implications of Lipschitz parametrization. We present an upper bound of\nthe Kullback-Leibler divergence that allows understanding methods that penalize\nthe lp-norm of differences of parameters as the minimization of that upper\nbound. The expected log-likelihood is lower bounded by the negative lp-norm,\nwhich allows understanding the generalization ability of probabilistic models.\nThe exponential of the negative lp-norm is involved in the lower bound of the\nBayes error rate, which shows that it is reasonable to use parameters as\nfeatures in algorithms that rely on metric spaces (e.g. classification,\ndimensionality reduction, clustering). Our results do not rely on specific\nalgorithms for learning the structure or parameters. We show preliminary\nresults for activity recognition and temporal segmentation.", "1202.4707": "A para-model agent for dynamical systems,Michel, Lo\u00efc,Mathematics - Optimization and ControlComputer Science - Systems and Control,Consider a dynamical system $u \\mapsto x, \\dot{x} = f_{nl}(x,u)$ where\n$f_{nl}$ is a nonlinear (convex or nonconvex) function, or a combination of\nnonlinear functions that can eventually switch. We present, in this preliminary\nwork, a generalization of the standard model-free control, that can either\ncontrol the dynamical system, given an output reference trajectory, or optimize\nthe dynamical system as a derivative-free optimization based \"extremum-seeking\"\nprocedure. Multiple applications are presented and the robustness of the\nproposed method is studied in simulation.Comment: 41 pages, 38 figures, partially presented at the French Symposium of\n  Electrical Engineering in Grenoble, Jun. 2016 and at the Sparse days in St\n  Girons III, Jul. 2015", "1202.4910": "Distributed Private Heavy Hitters,Hsu, JustinKhanna, SanjeevRoth, Aaron,Computer Science - Data Structures and AlgorithmsComputer Science - Cryptography and SecurityComputer Science - Databases,In this paper, we give efficient algorithms and lower bounds for solving the\nheavy hitters problem while preserving differential privacy in the fully\ndistributed local model. In this model, there are n parties, each of which\npossesses a single element from a universe of size N. The heavy hitters problem\nis to find the identity of the most common element shared amongst the n\nparties. In the local model, there is no trusted database administrator, and so\nthe algorithm must interact with each of the $n$ parties separately, using a\ndifferentially private protocol. We give tight information-theoretic upper and\nlower bounds on the accuracy to which this problem can be solved in the local\nmodel (giving a separation between the local model and the more common\ncentralized model of privacy), as well as computationally efficient algorithms\neven in the case where the data universe N may be exponentially large.", "1202.4961": "Strongly universal string hashing is fast,Kaser, OwenLemire, Daniel,Computer Science - DatabasesComputer Science - Data Structures and Algorithms,We present fast strongly universal string hashing families: they can process\ndata at a rate of 0.2 CPU cycle per byte. Maybe surprisingly, we find that\nthese families---though they require a large buffer of random numbers---are\noften faster than popular hash functions with weaker theoretical guarantees.\nMoreover, conventional wisdom is that hash functions with fewer multiplications\nare faster. Yet we find that they may fail to be faster due to operation\npipelining. We present experimental results on several processors including\nlow-powered processors. Our tests include hash functions designed for\nprocessors with the Carry-Less Multiplication (CLMUL) instruction set. We also\nprove, using accessible proofs, the strong universality of our families.Comment: Software is available at\n  http://code.google.com/p/variablelengthstringhashing/ and\n  https://github.com/lemire/StronglyUniversalStringHashing", "1203.3341": "A Comparison of the Embedding Method to Multi-Parametric Programming,\n  Mixed-Integer Programming, Gradient-Descent, and Hybrid Minimum Principle\n  Based Methods,Meyer, Richard\u017defran, Milo\u0161DeCarlo, Raymond A.,Mathematics - Optimization and ControlComputer Science - Systems and Control,In recent years, the embedding approach for solving switched optimal control\nproblems has been developed in a series of papers. However, the embedding\napproach, which advantageously converts the hybrid optimal control problem to a\nclassical nonlinear optimization, has not been extensively compared to\nalternative solution approaches. The goal of this paper is thus to compare the\nembedding approach to multi-parametric programming, mixed-integer programming\n(e.g., CPLEX), and gradient-descent based methods in the context of five\nrecently published examples: a spring-mass system, moving-target tracking for a\nmobile robot, two-tank filling, DC-DC boost converter, and skid-steered\nvehicle. A sixth example, an autonomous switched 11-region linear system, is\nused to compare a hybrid minimum principle method and traditional numerical\nprogramming. For a given performance index for each case, cost and solution\ntimes are presented. It is shown that there are numerical advantages of the\nembedding approach: lower performance index cost (except in some instances when\nautonomous switches are present), generally faster solution time, and\nconvergence to a solution when other methods may fail. In addition, the\nembedding method requires no ad hoc assumptions (e.g., predetermined mode\nsequences) or specialized control models. Theoretical advantages of the\nembedding approach over the other methods are also described: guaranteed\nexistence of a solution under mild conditions, convexity of the embedded hybrid\noptimization problem (under the customary conditions on the performance index),\nsolvability with traditional techniques (e.g., sequential quadratic\nprogramming) avoiding the combinatorial complexity in the number of\nmodes/discrete variables of mixed-integer programming, applicability to affine\nnonlinear systems, and no need to explicitly assign discrete/mode variables to\nautonomous switches.Comment: Accepted to IEEE Transactions on Control Systems Technology", "1203.4600": "A Szemeredi-Trotter type theorem in $\\mathbb{R}^4$,Zahl, Joshua,Mathematics - CombinatoricsComputer Science - Computational Geometry,We show that $m$ points and $n$ two-dimensional algebraic surfaces in\n$\\mathbb{R}^4$ can have at most\n$O(m^{\\frac{k}{2k-1}}n^{\\frac{2k-2}{2k-1}}+m+n)$ incidences, provided that the\nalgebraic surfaces behave like pseudoflats with $k$ degrees of freedom, and\nthat $m\\leq n^{\\frac{2k+2}{3k}}$. As a special case, we obtain a\nSzemer\\'edi-Trotter type theorem for 2--planes in $\\mathbb{R}^4$, provided\n$m\\leq n$ and the planes intersect transversely. As a further special case, we\nobtain a Szemer\\'edi-Trotter type theorem for complex lines in $\\mathbb{C}^2$\nwith no restrictions on $m$ and $n$ (this theorem was originally proved by\nT\\'oth using a different method). As a third special case, we obtain a\nSzemer\\'edi-Trotter type theorem for complex unit circles in $\\mathbb{C}^2$. We\nobtain our results by combining several tools, including a two-level analogue\nof the discrete polynomial partitioning theorem and the crossing lemma.Comment: 50 pages. V3: final version. To appear in Discrete and Computational\n  Geometry", "1203.5184": "A Universal Model of Commuting Networks,Lenormand, MaximeHuet, SylvieGargiulo, FlorianaDeffuant, Guillaume,Mathematics - Statistics TheoryComputer Science - Social and Information NetworksPhysics - Physics and Society,We test a recently proposed model of commuting networks on 80 case studies\nfrom different regions of the world (Europe and United-States) and with\ngeographic units of different sizes (municipality, county, region). The model\ntakes as input the number of commuters coming in and out of each geographic\nunit and generates the matrix of commuting flows betwen the geographic units.\nWe show that the single parameter of the model, which rules the compromise\nbetween the influence of the distance and job opportunities, follows a\nuniversal law that depends only on the average surface of the geographic units.\nWe verified that the law derived from a part of the case studies yields\naccurate results on other case studies. We also show that our model\nsignificantly outperforms the two other approaches proposing a universal\ncommuting model (Balcan et al. (2009); Simini et al. (2012)), particularly when\nthe geographic units are small (e.g. municipalities).Comment: 11 pages, 5 figures", "1203.5188": "Semi-Automatically Extracting FAQs to Improve Accessibility of Software\n  Development Knowledge,Hen\u00df, StefanMonperrus, MartinMezini, Mira,Computer Science - Software EngineeringComputer Science - Computation and LanguageComputer Science - Information Retrieval,Frequently asked questions (FAQs) are a popular way to document software\ndevelopment knowledge. As creating such documents is expensive, this paper\npresents an approach for automatically extracting FAQs from sources of software\ndevelopment discussion, such as mailing lists and Internet forums, by combining\ntechniques of text mining and natural language processing. We apply the\napproach to popular mailing lists and carry out a survey among software\ndevelopers to show that it is able to extract high-quality FAQs that may be\nfurther improved by experts.Comment: ICSE - 34th International Conference on Software Engineering (2012)", "1203.5414": "Clique problem, cutting plane proofs and communication complexity,Jukna, S.,Computer Science - Computational ComplexityComputer Science - Discrete Mathematics,Motivated by its relation to the length of cutting plane proofs for the\nMaximum Biclique problem, we consider the following communication game on a\ngiven graph G, known to both players. Let K be the maximal number of vertices\nin a complete bipartite subgraph of G, which is not necessarily an induced\nsubgraph if G is not bipartite. Alice gets a set A of vertices, and Bob gets a\ndisjoint set B of vertices such that |A|+|B|>K. The goal is to find a nonedge\nof G between A and B. We show that O(\\log n) bits of communication are enough\nfor every n-vertex graph.Comment: 10 pages. Theorem 1 in the previous version holds only for bipartite\n  graphs, the non-bipartite case remains open. I now separate the bipartite and\n  non-bipartite cases (by switching from independent sets to cliques, hence a\n  new title). Some new open problems as well as references are added", "1203.5706": "Effective de Rham Cohomology - The General Case,Scheiblechner, Peter,Mathematics - Algebraic GeometryComputer Science - Computational ComplexityMathematics - Commutative Algebra14Q20, 14Q15, 68W30, 34C07,Grothendieck has proved that each class in the de Rham cohomology of a smooth\ncomplex affine variety can be represented by a differential form with\npolynomial coefficients. After having proved a single exponential bound for the\ndegrees of these forms in the case of a hypersurface, here we generalize this\nresult to arbitrary codimension. More precisely, we show that the p-th de Rham\ncohomology of a smooth affine variety of dimension m and degree D can be\nrepresented by differential forms of degree (pD)^{O(pm)}. This result is\nrelevant for the algorithmic computation of the cohomology, but is also\nmotivated by questions in the theory of ordinary differential equations related\nto the infinitesimal Hilbert 16th problem.Comment: 36 pages", "1203.6152": "The FO^2 alternation hierarchy is decidable,Kufleitner, ManfredWeil, Pascal,Computer Science - Logic in Computer ScienceComputer Science - Formal Languages and Automata Theory,We consider the two-variable fragment FO^2[<] of first-order logic over\nfinite words. Numerous characterizations of this class are known. Th\\'erien and\nWilke have shown that it is decidable whether a given regular language is\ndefinable in FO^2[<]. From a practical point of view, as shown by Weis, FO^2[<]\nis interesting since its satisfiability problem is in NP. Restricting the\nnumber of quantifier alternations yields an infinite hierarchy inside the class\nof FO^2[<]-definable languages. We show that each level of this hierarchy is\ndecidable. For this purpose, we relate each level of the hierarchy with a\ndecidable variety of finite monoids. Our result implies that there are many\ndifferent ways of climbing up the FO^2[<]-quantifier alternation hierarchy:\ndeterministic and co-deterministic products, Mal'cev products with definite and\nreverse definite semigroups, iterated block products with J-trivial monoids,\nand some inductively defined omega-term identities. A combinatorial tool in the\nprocess of ascension is that of condensed rankers, a refinement of the rankers\nof Weis and Immerman and the turtle programs of Schwentick, Th\\'erien, and\nVollmer.", "1203.6286": "On the Easiest and Hardest Fitness Functions,He, JunChen, TianshiYao, Xin,Computer Science - Neural and Evolutionary Computing,The hardness of fitness functions is an important research topic in the field\nof evolutionary computation. In theory, the study can help understanding the\nability of evolutionary algorithms. In practice, the study may provide a\nguideline to the design of benchmarks. The aim of this paper is to answer the\nfollowing research questions: Given a fitness function class, which functions\nare the easiest with respect to an evolutionary algorithm? Which are the\nhardest? How are these functions constructed? The paper provides theoretical\nanswers to these questions. The easiest and hardest fitness functions are\nconstructed for an elitist (1+1) evolutionary algorithm to maximise a class of\nfitness functions with the same optima. It is demonstrated that the unimodal\nfunctions are the easiest and deceptive functions are the hardest in terms of\nthe time-fitness landscape. The paper also reveals that the easiest fitness\nfunction to one algorithm may become the hardest to another algorithm, and vice\nversa.", "1203.6566": "New Combinatorial Construction Techniques for Low-Density Parity-Check\n  Codes and Systematic Repeat-Accumulate Codes,Gruner, AlexanderHuber, Michael,Computer Science - Information TheoryComputer Science - Discrete MathematicsMathematics - Combinatorics,This paper presents several new construction techniques for low-density\nparity-check (LDPC) and systematic repeat-accumulate (RA) codes. Based on\nspecific classes of combinatorial designs, the improved code design focuses on\nhigh-rate structured codes with constant column weights 3 and higher. The\nproposed codes are efficiently encodable and exhibit good structural\nproperties. Experimental results on decoding performance with the sum-product\nalgorithm show that the novel codes offer substantial practical application\npotential, for instance, in high-speed applications in magnetic recording and\noptical communications channels.Comment: 10 pages; to appear in \"IEEE Transactions on Communications\"", "1204.0480": "Deducing Security Goals From Shape Analysis Sentences,Ramsdell, John D.,Computer Science - Cryptography and SecurityComputer Science - Logic in Computer Science,Guttman presented a model-theoretic approach to establishing security goals\nin the context of Strand Space theory. In his approach, a run of the\nCryptographic Protocol Shapes Analyzer (CPSA) produces models that determine if\na goal is satisfied. This paper presents a method for extracting a sentence\nthat completely characterizes a run of CPSA. Logical deduction can then be used\nto determine if a goal is satisfied. This method has been implemented and is\navailable to all.Comment: 19 pages", "1204.0839": "A Constrained Random Demodulator for Sub-Nyquist Sampling,Harms, AndrewBajwa, Waheed U.Calderbank, Robert,Computer Science - Information Theory,This paper presents a significant modification to the Random Demodulator (RD)\nof Tropp et al. for sub-Nyquist sampling of frequency-sparse signals. The\nmodification, termed constrained random demodulator, involves replacing the\nrandom waveform, essential to the operation of the RD, with a constrained\nrandom waveform that has limits on its switching rate because fast switching\nwaveforms may be hard to generate cleanly. The result is a relaxation on the\nhardware requirements with a slight, but manageable, decrease in the recovery\nguarantees. The paper also establishes the importance of properly choosing the\nstatistics of the constrained random waveform. If the power spectrum of the\nrandom waveform matches the distribution on the tones of the input signal\n(i.e., the distribution is proportional to the power spectrum), then recovery\nof the input signal tones is improved. The theoretical guarantees provided in\nthe paper are validated through extensive numerical simulations and phase\ntransition plots.Comment: Preprint of a journal paper accepted for publication in: IEEE Trans.\n  Signal Processing, 2013 (copyright has been transferred to IEEE)", "1204.1160": "Opinion formation in time-varying social networks: The case of the\n  naming game,Maity, Suman KalyanManoj, T. VenkatMukherjee, Animesh,Physics - Physics and SocietyComputer Science - Social and Information Networks,We study the dynamics of the naming game as an opinion formation model on\ntime-varying social networks. This agent-based model captures the essential\nfeatures of the agreement dynamics by means of a memory-based negotiation\nprocess. Our study focuses on the impact of time-varying properties of the\nsocial network of the agents on the naming game dynamics. In particular, we\nperform a computational exploration of this model using simulations on top of\nreal networks. We investigate the outcomes of the dynamics on two different\ntypes of time-varying data - (i) the networks vary on a day-to-day basis and\n(ii) the networks vary within very short intervals of time (20 seconds). In the\nfirst case, we find that networks with strong community structure hinder the\nsystem from reaching global agreement; the evolution of the naming game in\nthese networks maintains clusters of coexisting opinions indefinitely leading\nto metastability. In the second case, we investigate the evolution of the\nnaming game in perfect synchronization with the time evolution of the\nunderlying social network shedding new light on the traditional emergent\nproperties of the game that differ largely from what has been reported in the\nexisting literature.Comment: 12 pages, 14 figures. arXiv admin note: text overlap with\n  arXiv:physics/0511201 by other authors", "1204.1846": "Approximate Revenue Maximization with Multiple Items,Hart, SergiuNisan, Noam,Computer Science - Computer Science and Game Theory,Maximizing the revenue from selling _more than one_ good (or item) to a\nsingle buyer is a notoriously difficult problem, in stark contrast to the\none-good case. For two goods, we show that simple \"one-dimensional\" mechanisms,\nsuch as selling the goods separately, _guarantee_ at least 73% of the optimal\nrevenue when the valuations of the two goods are independent and identically\ndistributed, and at least $50\\%$ when they are independent. For the case of\n$k>2$ independent goods, we show that selling them separately guarantees at\nleast a $c/\\log^2 k$ fraction of the optimal revenue; and, for independent and\nidentically distributed goods, we show that selling them as one bundle\nguarantees at least a $c/\\log k$ fraction of the optimal revenue. Additional\nresults compare the revenues from the two simple mechanisms of selling the\ngoods separately and bundled, identify situations where bundling is optimal,\nand extend the analysis to multiple buyers.Comment: Presented in ACM EC conference, 2012", "1204.1868": "User-based key frame detection in social web video,Chorianopoulos, Konstantinos,Computer Science - MultimediaComputer Science - Human-Computer InteractionComputer Science - Information Retrieval,Video search results and suggested videos on web sites are represented with a\nvideo thumbnail, which is manually selected by the video up-loader among three\nrandomly generated ones (e.g., YouTube). In contrast, we present a grounded\nuser-based approach for automatically detecting interesting key-frames within a\nvideo through aggregated users' replay interactions with the video player.\nPrevious research has focused on content-based systems that have the benefit of\nanalyzing a video without user interactions, but they are monolithic, because\nthe resulting video thumbnails are the same regardless of the user preferences.\nWe constructed a user interest function, which is based on aggregate video\nreplays, and analyzed hundreds of user interactions. We found that the local\nmaximum of the replaying activity stands for the semantics of information rich\nvideos, such as lecture, and how-to. The concept of user-based key-frame\ndetection could be applied to any video on the web, in order to generate a\nuser-based and dynamic video thumbnail in search results.Comment: 4 pages, 4 figures", "1204.2606": "Privacy via the Johnson-Lindenstrauss Transform,Kenthapadi, KrishnaramKorolova, AleksandraMironov, IlyaMishra, Nina,Computer Science - Data Structures and AlgorithmsComputer Science - Computers and SocietyComputer Science - DatabasesComputer Science - Social and Information NetworksK.4.1F.2H.3.5G.3I.5.3H.3.3H.2.8E.1G.1.3,Suppose that party A collects private information about its users, where each\nuser's data is represented as a bit vector. Suppose that party B has a\nproprietary data mining algorithm that requires estimating the distance between\nusers, such as clustering or nearest neighbors. We ask if it is possible for\nparty A to publish some information about each user so that B can estimate the\ndistance between users without being able to infer any private bit of a user.\nOur method involves projecting each user's representation into a random,\nlower-dimensional space via a sparse Johnson-Lindenstrauss transform and then\nadding Gaussian noise to each entry of the lower-dimensional representation. We\nshow that the method preserves differential privacy---where the more privacy is\ndesired, the larger the variance of the Gaussian noise. Further, we show how to\napproximate the true distances between users via only the lower-dimensional,\nperturbed data. Finally, we consider other perturbation methods such as\nrandomized response and draw comparisons to sketch-based methods. While the\ngoal of releasing user-specific data to third parties is more broad than\npreserving distances, this work shows that distance computations with privacy\nis an achievable goal.Comment: 24 pages", "1204.2727": "The Cost of Perfection for Matchings in Graphs,Brazil, Emilio Vitalda Fonseca, Guilherme D.de Figueiredo, CelinaSasaki, Diana,Computer Science - Discrete Mathematics,Perfect matchings and maximum weight matchings are two fundamental\ncombinatorial structures. We consider the ratio between the maximum weight of a\nperfect matching and the maximum weight of a general matching. Motivated by the\ncomputer graphics application in triangle meshes, where we seek to convert a\ntriangulation into a quadrangulation by merging pairs of adjacent triangles, we\nfocus mainly on bridgeless cubic graphs. First, we characterize graphs that\nattain the extreme ratios. Second, we present a lower bound for all bridgeless\ncubic graphs. Third, we present upper bounds for subclasses of bridgeless cubic\ngraphs, most of which are shown to be tight. Additionally, we present tight\nbounds for the class of regular bipartite graphs.", "1204.3850": "Simple Agents Learn to Find Their Way: An Introduction on Mapping\n  Polygons,Chalopin, J\u00e9r\u00e9mieDas, ShantanuDisser, YannMihal\u00e1k, Mat\u00fa\u0161Widmayer, Peter,Computer Science - Computational Geometry,This paper gives an introduction to the problem of mapping simple polygons\nwith autonomous agents. We focus on minimalistic agents that move from vertex\nto vertex along straight lines inside a polygon, using their sensors to gather\nlocal observations at each vertex. Our attention revolves around the question\nwhether a given configuration of sensors and movement capabilities of the\nagents allows them to capture enough data in order to draw conclusions\nregarding the global layout of the polygon. In particular, we study the problem\nof reconstructing the visibility graph of a simple polygon by an agent moving\neither inside or on the boundary of the polygon. Our aim is to provide insight\nabout the algorithmic challenges faced by an agent trying to map a polygon. We\npresent an overview of techniques for solving this problem with agents that are\nequipped with simple sensorial capabilities. We illustrate these techniques on\nexamples with sensors that mea- sure angles between lines of sight or identify\nthe previous location. We give an overview over related problems in\ncombinatorial geometry as well as graph exploration.", "1204.6321": "Efficient Video Indexing on the Web: A System that Leverages User\n  Interactions with a Video Player,Leftheriotis, IoannisGkonela, ChrysoulaChorianopoulos, Konstantinos,Computer Science - MultimediaComputer Science - Digital LibrariesComputer Science - Human-Computer InteractionComputer Science - Information Retrieval,In this paper, we propose a user-based video indexing method, that\nautomatically generates thumbnails of the most important scenes of an online\nvideo stream, by analyzing users' interactions with a web video player. As a\ntest bench to verify our idea we have extended the YouTube video player into\nthe VideoSkip system. In addition, VideoSkip uses a web-database (Google\nApplication Engine) to keep a record of some important parameters, such as the\ntiming of basic user actions (play, pause, skip). Moreover, we implemented an\nalgorithm that selects representative thumbnails. Finally, we populated the\nsystem with data from an experiment with nine users. We found that the\nVideoSkip system indexes video content by leveraging implicit users\ninteractions, such as pause and thirty seconds skip. Our early findings point\ntoward improvements of the web video player and its thumbnail generation\ntechnique. The VideSkip system could compliment content-based algorithms, in\norder to achieve efficient video-indexing in difficult videos, such as lectures\nor sports.Comment: 9 pages, 3 figures, UCMedia 2010: 2nd International ICST Conference\n  on User Centric Media", "1204.6445": "A Complete Dichotomy Rises from the Capture of Vanishing Signatures,Cai, Jin-YiGuo, HengWilliams, Tyson,Computer Science - Computational Complexity68Q17F.1.3G.2.1,We prove a complexity dichotomy theorem for Holant problems over an arbitrary\nset of complex-valued symmetric constraint functions F on Boolean variables.\nThis extends and unifies all previous dichotomies for Holant problems on\nsymmetric constraint functions (taking values without a finite modulus). We\ndefine and characterize all symmetric vanishing signatures. They turned out to\nbe essential to the complete classification of Holant problems. The dichotomy\ntheorem has an explicit tractability criterion expressible in terms of\nholographic transformations. A Holant problem defined by a set of constraint\nfunctions F is solvable in polynomial time if it satisfies this tractability\ncriterion, and is #P-hard otherwise. The tractability criterion can be\nintuitively stated as follows: A set F is tractable if (1) every function in F\nhas arity at most two, or (2) F is transformable to an affine type, or (3) F is\ntransformable to a product type, or (4) F is vanishing, combined with the right\ntype of binary functions, or (5) F belongs to a special category of vanishing\ntype Fibonacci gates. The proof of this theorem utilizes many previous\ndichotomy theorems on Holant problems and Boolean #CSP. Holographic\ntransformations play an indispensable role as both a proof technique and in the\nstatement of the tractability criterion.Comment: Author accepted manuscript", "1205.3576": "Dexpler: Converting Android Dalvik Bytecode to Jimple for Static\n  Analysis with Soot,Bartel, AlexandreKlein, JacquesMonperrus, MartinTraon, Yves Le,Computer Science - Software Engineering,This paper introduces Dexpler, a software package which converts Dalvik\nbytecode to Jimple. Dexpler is built on top of Dedexer and Soot. As Jimple is\nSoot's main internal rep- resentation of code, the Dalvik bytecode can be\nmanipu- lated with any Jimple based tool, for instance for performing point-to\nor flow analysis.Comment: ACM SIGPLAN International Workshop on the State Of the Art in Java\n  Program Analysis(SOAP 2012), Beijing : China (2012)", "1205.4874": "Perfect Secrecy Systems Immune to Spoofing Attacks,Huber, Michael,Computer Science - Cryptography and SecurityComputer Science - Information Theory,We present novel perfect secrecy systems that provide immunity to spoofing\nattacks under equiprobable source probability distributions. On the theoretical\nside, relying on an existence result for $t$-designs by Teirlinck, our\nconstruction method constructively generates systems that can reach an\narbitrary high level of security. On the practical side, we obtain, via cyclic\ndifference families, very efficient constructions of new optimal systems that\nare onefold secure against spoofing. Moreover, we construct, by means of\n$t$-designs for large values of $t$, the first near-optimal systems that are 5-\nand 6-fold secure as well as further systems with a feasible number of keys\nthat are 7-fold secure against spoofing. We apply our results furthermore to a\nrecently extended authentication model, where the opponent has access to a\nverification oracle. We obtain this way novel perfect secrecy systems with\nimmunity to spoofing in the verification oracle model.Comment: 10 pages (double-column); to appear in \"International Journal of\n  Information Security\"", "1205.5770": "Randomized Extended Kaczmarz for Solving Least-Squares,Zouzias, AnastasiosFreris, Nikolaos,Mathematics - Numerical AnalysisComputer Science - Data Structures and Algorithms,We present a randomized iterative algorithm that exponentially converges in\nexpectation to the minimum Euclidean norm least squares solution of a given\nlinear system of equations. The expected number of arithmetic operations\nrequired to obtain an estimate of given accuracy is proportional to the square\ncondition number of the system multiplied by the number of non-zeros entries of\nthe input matrix. The proposed algorithm is an extension of the randomized\nKaczmarz method that was analyzed by Strohmer and Vershynin.Comment: 19 Pages, 5 figures; code is available at\n  https://github.com/zouzias/REK", "1205.6363": "What Should Developers Be Aware Of? An Empirical Study on the Directives\n  of API Documentation,Monperrus, MartinEichberg, MichaelTekes, ElifMezini, Mira,Computer Science - Software Engineering,Application Programming Interfaces (API) are exposed to developers in order\nto reuse software libraries. API directives are natural-language statements in\nAPI documentation that make developers aware of constraints and guidelines\nrelated to the usage of an API. This paper presents the design and the results\nof an empirical study on the directives of API documentation of object-oriented\nlibraries. Its main contribution is to propose and extensively discuss a\ntaxonomy of 23 kinds of API directives.Comment: Empirical Software Engineering (2011)", "1206.1775": "Exponential Time Complexity of the Permanent and the Tutte Polynomial,Dell, HolgerHusfeldt, ThoreMarx, D\u00e1nielTaslaman, NinaW\u00e1hlen, Martin,Computer Science - Computational ComplexityComputer Science - Data Structures and AlgorithmsMathematics - CombinatoricsF.2.1G.2.1,We show conditional lower bounds for well-studied #P-hard problems:\n  (a) The number of satisfying assignments of a 2-CNF formula with n variables\ncannot be counted in time exp(o(n)), and the same is true for computing the\nnumber of all independent sets in an n-vertex graph.\n  (b) The permanent of an n x n matrix with entries 0 and 1 cannot be computed\nin time exp(o(n)).\n  (c) The Tutte polynomial of an n-vertex multigraph cannot be computed in time\nexp(o(n)) at most evaluation points (x,y) in the case of multigraphs, and it\ncannot be computed in time exp(o(n/polylog n)) in the case of simple graphs.\n  Our lower bounds are relative to (variants of) the Exponential Time\nHypothesis (ETH), which says that the satisfiability of n-variable 3-CNF\nformulas cannot be decided in time exp(o(n)). We relax this hypothesis by\nintroducing its counting version #ETH, namely that the satisfying assignments\ncannot be counted in time exp(o(n)). In order to use #ETH for our lower bounds,\nwe transfer the sparsification lemma for d-CNF formulas to the counting\nsetting.", "1206.3431": "Computability and analysis: the legacy of Alan Turing,Avigad, JeremyBrattka, Vasco,Mathematics - LogicComputer Science - Logic in Computer ScienceMathematics - History and Overview,We discuss the legacy of Alan Turing and his impact on computability and\nanalysis.Comment: 49 pages", "1206.3862": "Total coloring of 1-toroidal graphs of maximum degree at least 11 and no\n  adjacent triangles,Wang, Tao,Mathematics - CombinatoricsComputer Science - Discrete Mathematics05C15,A {\\em total coloring} of a graph $G$ is an assignment of colors to the\nvertices and the edges of $G$ such that every pair of adjacent/incident\nelements receive distinct colors. The {\\em total chromatic number} of a graph\n$G$, denoted by $\\chiup''(G)$, is the minimum number of colors in a total\ncoloring of $G$. The well-known Total Coloring Conjecture (TCC) says that every\ngraph with maximum degree $\\Delta$ admits a total coloring with at most $\\Delta\n+ 2$ colors. A graph is {\\em $1$-toroidal} if it can be drawn in torus such\nthat every edge crosses at most one other edge. In this paper, we investigate\nthe total coloring of $1$-toroidal graphs, and prove that the TCC holds for the\n$1$-toroidal graphs with maximum degree at least~$11$ and some restrictions on\nthe triangles. Consequently, if $G$ is a $1$-toroidal graph with maximum degree\n$\\Delta$ at least~$11$ and without adjacent triangles, then $G$ admits a total\ncoloring with at most $\\Delta + 2$ colors.Comment: 10 pages", "1206.4627": "Convergence Rates of Biased Stochastic Optimization for Learning Sparse\n  Ising Models,Honorio, Jean,Computer Science - Machine LearningStatistics - Machine Learning,We study the convergence rate of stochastic optimization of exact (NP-hard)\nobjectives, for which only biased estimates of the gradient are available. We\nmotivate this problem in the context of learning the structure and parameters\nof Ising models. We first provide a convergence-rate analysis of deterministic\nerrors for forward-backward splitting (FBS). We then extend our analysis to\nbiased stochastic errors, by first characterizing a family of samplers and\nproviding a high probability bound that allows understanding not only FBS, but\nalso proximal gradient (PG) methods. We derive some interesting conclusions:\nFBS requires only a logarithmically increasing number of random samples in\norder to converge (although at a very low rate); the required number of random\nsamples is the same for the deterministic and the biased stochastic setting for\nFBS and basic PG; accelerated PG is not guaranteed to converge in the biased\nstochastic setting.Comment: ICML2012", "1206.4656": "Machine Learning that Matters,Wagstaff, Kiri,Computer Science - Machine LearningComputer Science - Artificial IntelligenceStatistics - Machine Learning,Much of current machine learning (ML) research has lost its connection to\nproblems of import to the larger world of science and society. From this\nperspective, there exist glaring limitations in the data sets we investigate,\nthe metrics we employ for evaluation, and the degree to which results are\ncommunicated back to their originating domains. What changes are needed to how\nwe conduct research to increase the impact that ML has? We present six Impact\nChallenges to explicitly focus the field?s energy and attention, and we discuss\nexisting obstacles that must be addressed. We aim to inspire ongoing discussion\nand focus on ML that matters.Comment: ICML2012", "1206.4809": "Connected Choice and the Brouwer Fixed Point Theorem,Brattka, VascoRoux, St\u00e9phane LeMiller, Joseph S.Pauly, Arno,Mathematics - LogicComputer Science - Logic in Computer Science03D30, 03D78, 03F60, 37C25,We study the computational content of the Brouwer Fixed Point Theorem in the\nWeihrauch lattice. Connected choice is the operation that finds a point in a\nnon-empty connected closed set given by negative information. One of our main\nresults is that for any fixed dimension the Brouwer Fixed Point Theorem of that\ndimension is computably equivalent to connected choice of the Euclidean unit\ncube of the same dimension. Another main result is that connected choice is\ncomplete for dimension greater than or equal to two in the sense that it is\ncomputably equivalent to Weak K\\H{o}nig's Lemma. While we can present two\nindependent proofs for dimension three and upwards that are either based on a\nsimple geometric construction or a combinatorial argument, the proof for\ndimension two is based on a more involved inverse limit construction. The\nconnected choice operation in dimension one is known to be equivalent to the\nIntermediate Value Theorem; we prove that this problem is not idempotent in\ncontrast to the case of dimension two and upwards. We also prove that Lipschitz\ncontinuity with Lipschitz constants strictly larger than one does not simplify\nfinding fixed points. Finally, we prove that finding a connectedness component\nof a closed subset of the Euclidean unit cube of any dimension greater or equal\nto one is equivalent to Weak K\\H{o}nig's Lemma. In order to describe these\nresults, we introduce a representation of closed subsets of the unit cube by\ntrees of rational complexes.Comment: 36 pages", "1206.5336": "Near-Optimal Online Multiselection in Internal and External Memory,Barbay, J\u00e9r\u00e9myGupta, AnkurRao, S. SrinivasaSorenson, Jonathan,Computer Science - Data Structures and Algorithms,We introduce an online version of the multiselection problem, in which q\nselection queries are requested on an unsorted array of n elements. We provide\nthe first online algorithm that is 1-competitive with Kaligosi et al. [ICALP\n2005] in terms of comparison complexity. Our algorithm also supports online\nsearch queries efficiently.\n  We then extend our algorithm to the dynamic setting, while retaining online\nfunctionality, by supporting arbitrary insertions and deletions on the array.\nAssuming that the insertion of an element is immediately preceded by a search\nfor that element, we show that our dynamic online algorithm performs an optimal\nnumber of comparisons, up to lower order terms and an additive O(n) term.\n  For the external memory model, we describe the first online multiselection\nalgorithm that is O(1)-competitive. This result improves upon the work of\nSibeyn [Journal of Algorithms 2006] when q > m, where m is the number of blocks\nthat can be stored in main memory. We also extend it to support searches,\ninsertions, and deletions of elements efficiently.", "1208.0713": "On logical hierarchies within FO^2-definable languages,Kufleitner, ManfredWeil, Pascal,Computer Science - Logic in Computer ScienceComputer Science - Formal Languages and Automata TheoryF.4.3F.4.1,We consider the class of languages defined in the 2-variable fragment of the\nfirst-order logic of the linear order. Many interesting characterizations of\nthis class are known, as well as the fact that restricting the number of\nquantifier alternations yields an infinite hierarchy whose levels are varieties\nof languages (and hence admit an algebraic characterization). Using this\nalgebraic approach, we show that the quantifier alternation hierarchy inside\nFO^{2}[<] is decidable within one unit. For this purpose, we relate each level\nof the hierarchy with decidable varieties of languages, which can be defined in\nterms of iterated deterministic and co-deterministic products. A crucial notion\nin this process is that of condensed rankers, a refinement of the rankers of\nWeis and Immerman and the turtle languages of Schwentick, Th\\'erien and\nVollmer.Comment: arXiv admin note: text overlap with arXiv:0904.2894", "1208.3124": "On the computation of zone and double zone diagrams,Reem, Daniel,Computer Science - Computational GeometryMathematics - Functional AnalysisMathematics - Metric Geometry68U05, 47H10, 51M05, 53C22, 46B20, 65D18, 51N05F.2.2G.0I.3.5,Classical objects in computational geometry are defined by explicit\nrelations. Several years ago the pioneering works of T. Asano, J. Matousek and\nT. Tokuyama introduced \"implicit computational geometry\", in which the\ngeometric objects are defined by implicit relations involving sets. An\nimportant member in this family is called \"a zone diagram\". The implicit nature\nof zone diagrams implies, as already observed in the original works, that their\ncomputation is a challenging task. In a continuous setting this task has been\naddressed (briefly) only by these authors in the Euclidean plane with point\nsites. We discuss the possibility to compute zone diagrams in a wide class of\nspaces and also shed new light on their computation in the original setting.\nThe class of spaces, which is introduced here, includes, in particular,\nEuclidean spheres and finite dimensional strictly convex normed spaces. Sites\nof a general form are allowed and it is shown that a generalization of the\niterative method suggested by Asano, Matousek and Tokuyama converges to a\ndouble zone diagram, another implicit geometric object whose existence is known\nin general. Occasionally a zone diagram can be obtained from this procedure.\nThe actual (approximate) computation of the iterations is based on a simple\nalgorithm which enables the approximate computation of Voronoi diagrams in a\ngeneral setting. Our analysis also yields a few byproducts of independent\ninterest, such as certain topological properties of Voronoi cells (e.g., that\nin the considered setting their boundaries cannot be \"fat\").Comment: Very slight improvements (mainly correction of a few typos); add DOI;\n  Ref [51] points to a freely available computer application which implements\n  the algorithms; to appear in Discrete & Computational Geometry (available\n  online)", "1208.3251": "Toward Resource-Optimal Consensus over the Wireless Medium,Nokleby, MatthewBajwa, Waheed U.Calderbank, RobertAazhang, Behnaam,Computer Science - Information Theory,We carry out a comprehensive study of the resource cost of averaging\nconsensus in wireless networks. Most previous approaches suppose a graphical\nnetwork, which abstracts away crucial features of the wireless medium, and\nmeasure resource consumption only in terms of the total number of transmissions\nrequired to achieve consensus. Under a path-loss dominated model, we study the\nresource requirements of consensus with respect to three wireless-appropriate\nmetrics: total transmit energy, elapsed time, and time-bandwidth product. First\nwe characterize the performance of several popular gossip algorithms, showing\nthat they may be order-optimal with respect to transmit energy but are strictly\nsuboptimal with respect to elapsed time and time-bandwidth product. Further, we\npropose a new consensus scheme, termed hierarchical averaging, and show that it\nis nearly order-optimal with respect to all three metrics. Finally, we examine\nthe effects of quantization, showing that hierarchical averaging provides a\nnearly order-optimal tradeoff between resource consumption and quantization\nerror.Comment: 12 pages, 3 figures, to appear in IEEE Journal Selected Topics in\n  Signal Processing, April 2013", "1208.6408": "Java Source-code Clustering: Unifying Syntactic and Semantic Features,Misra, JanardanKaulgud, VikrantTitus, GaryKM, AnnervazSengupta, Shubhashis,Computer Science - Software EngineeringD.2.7,This is a companion draft to paper 'Software Clustering: Unifying Syntactic\nand Semantic Features', in proceedings of the 19th Working Conference on\nReverse Engineering (WCRE 2012). It discusses the clustering process in detail,\nwhich appeared in the paper in an abridged form. It also contains certain\nadditional process steps which were not covered in the WCRE paper. The\nclustering process is described for applications with Java source-code.\nHowever, as argued in the WCRE paper, it can be seamlessly adapted to many\nother programming paradigms.", "1209.0521": "Efficient EM Training of Gaussian Mixtures with Missing Data,Delalleau, OlivierCourville, AaronBengio, Yoshua,Computer Science - Machine LearningStatistics - Machine Learning,In data-mining applications, we are frequently faced with a large fraction of\nmissing entries in the data matrix, which is problematic for most discriminant\nmachine learning algorithms. A solution that we explore in this paper is the\nuse of a generative model (a mixture of Gaussians) to compute the conditional\nexpectation of the missing variables given the observed variables. Since\ntraining a Gaussian mixture with many different patterns of missing values can\nbe computationally very expensive, we introduce a spanning-tree based algorithm\nthat significantly speeds up training in these conditions. We also observe that\ngood results can be obtained by using the generative model to fill-in the\nmissing values for a separate discriminant learning algorithm.", "1209.0735": "Lambert W Function for Applications in Physics,Veberic, Darko,Computer Science - Mathematical SoftwareComputer Science - Numerical AnalysisPhysics - Computational Physics,The Lambert W(x) function and its possible applications in physics are\npresented. The actual numerical implementation in C++ consists of Halley's and\nFritsch's iterations with initial approximations based on branch-point\nexpansion, asymptotic series, rational fits, and continued-logarithm recursion.Comment: 9 pages, 12 figures. Extended version of arXiv:1003.1628, updated\n  link to sources", "1209.1711": "Programming Languages for Scientific Computing,Knepley, Matthew G.,Computer Science - Programming LanguagesComputer Science - Computational Engineering, Finance, and ScienceComputer Science - Mathematical Software,Scientific computation is a discipline that combines numerical analysis,\nphysical understanding, algorithm development, and structured programming.\nSeveral yottacycles per year on the world's largest computers are spent\nsimulating problems as diverse as weather prediction, the properties of\nmaterial composites, the behavior of biomolecules in solution, and the quantum\nnature of chemical compounds. This article is intended to review specfic\nlanguages features and their use in computational science. We will review the\nstrengths and weaknesses of different programming styles, with examples taken\nfrom widely used scientific codes.Comment: 21 pages", "1209.5527": "Strategic Learning and the Topology of Social Networks,Mossel, ElchananSly, AllanTamuz, Omer,Computer Science - Computer Science and Game TheoryEconomics - Theoretical EconomicsMathematics - Probability,We consider a group of strategic agents who must each repeatedly take one of\ntwo possible actions. They learn which of the two actions is preferable from\ninitial private signals, and by observing the actions of their neighbors in a\nsocial network.\n  We show that the question of whether or not the agents learn efficiently\ndepends on the topology of the social network. In particular, we identify a\ngeometric \"egalitarianism\" condition on the social network that guarantees\nlearning in infinite networks, or learning with high probability in large\nfinite networks, in any equilibrium. We also give examples of non-egalitarian\nnetworks with equilibria in which learning fails.Comment: 30 pages, one figure", "1209.5785": "Coupling Data Transmission for Multiple-Access Communications,Truhachev, DmitriSchlegel, Christian,Computer Science - Information Theory,We consider a signaling format where the information to be communicated from\none or multiple transmitters to a receiver is modulated via a superposition of\nindependent data streams. Each data stream is formed by error-correction\nencoding, constellation mapping, replication and permutation of symbols, and\napplication of signature sequences. The relations between the data bits and\nmodulation symbols transmitted over the channel can be represented by a sparse\ngraph. In the case where the modulated data streams are transmitted with time\noffsets the receiver observes spatial coupling of the individual graphs into a\ngraph chain enabling efficient demodulation/decoding. We prove that a two-stage\ndemodulation/decoding method, in which iterative demodulation based on symbol\nestimation and interference cancellation is followed by parallel error\ncorrection decoding, achieves capacity on the additive white Gaussian noise\n(AWGN) channel asymptotically. We compare the performance of the two-stage\nreceiver to the receiver which utilizes hard feedback between the\nerror-correction encoders and the iterative demodulator.Comment: IEEE Transactions on Information Theory, under revision", "1209.6626": "On Newton-Raphson iteration for multiplicative inverses modulo prime\n  powers,Dumas, Jean-Guillaume,Computer Science - Symbolic ComputationComputer Science - Mathematical Software,We study algorithms for the fast computation of modular inverses.\nNewton-Raphson iteration over $p$-adic numbers gives a recurrence relation\ncomputing modular inverse modulo $p^m$, that is logarithmic in $m$. We solve\nthe recurrence to obtain an explicit formula for the inverse. Then we study\ndifferent implementation variants of this iteration and show that our explicit\nformula is interesting for small exponent values but slower or large exponent,\nsay of more than $700$ bits. Overall we thus propose a hybrid combination of\nour explicit formula and the best asymptotic variants. This hybrid combination\nyields then a constant factor improvement, also for large exponents.", "1210.2246": "An empirical study to order citation statistics between subject fields,van Zyl, J. Martinvan der Merwe, Sean,Computer Science - Digital LibrariesPhysics - Physics and Society62P99,An empirical study is conducted to compare citations per publication,\nstatistics and observed Hirsch indexes between subject fields using summary\nstatistics of countries. No distributional assumptions are made and ratios are\ncalculated. These ratios can be used to make approximate comparisons between\nresearchers of different subject fields with respect to the Hirsch index.", "1210.2440": "Group Model Selection Using Marginal Correlations: The Good, the Bad and\n  the Ugly,Bajwa, Waheed U.Mixon, Dustin G.,Mathematics - Statistics TheoryComputer Science - Information TheoryStatistics - Machine Learning,Group model selection is the problem of determining a small subset of groups\nof predictors (e.g., the expression data of genes) that are responsible for\nmajority of the variation in a response variable (e.g., the malignancy of a\ntumor). This paper focuses on group model selection in high-dimensional linear\nmodels, in which the number of predictors far exceeds the number of samples of\nthe response variable. Existing works on high-dimensional group model selection\neither require the number of samples of the response variable to be\nsignificantly larger than the total number of predictors contributing to the\nresponse or impose restrictive statistical priors on the predictors and/or\nnonzero regression coefficients. This paper provides comprehensive\nunderstanding of a low-complexity approach to group model selection that avoids\nsome of these limitations. The proposed approach, termed Group Thresholding\n(GroTh), is based on thresholding of marginal correlations of groups of\npredictors with the response variable and is reminiscent of existing\nthresholding-based approaches in the literature. The most important\ncontribution of the paper in this regard is relating the performance of GroTh\nto a polynomial-time verifiable property of the predictors for the general case\nof arbitrary (random or deterministic) predictors and arbitrary nonzero\nregression coefficients.Comment: Accepted for publication in Proc. 50th Annu. Allerton Conf.\n  Communication, Control, and Computing, Monticello, IL, Oct. 1-5, 2012; 8\n  pages and 4 figures", "1210.2540": "On the Automorphism Group of a Binary Self-dual [120, 60, 24] Code,Bouyuklieva, Stefkade la Cruz, JavierWillems, Wolfgang,Mathematics - CombinatoricsComputer Science - Discrete MathematicsMathematics - Group Theory,We prove that an automorphism of order 3 of a putative binary self-dual [120,\n60, 24] code C has no fixed points. Moreover, the order of the automorphism\ngroup of C divides 2^a.3.5.7.19.23.29 where a is a nonegative integer.\nAutomorphisms of odd composite order r may occur only for r=15, 57 or r=115\nwith corresponding cycle structures 15-(0,0,8;0), 57-(2,0,2;0) or\n115-(1,0,1;0), respectively. In case that all involutions act fixed point\nfreely we have |Aut(C)|<=920, and Aut(C) is solvable if it contains an element\nof prime order p>=7. Moreover, the alternating group A_5 is the only\nnon-abelian composition factor which may occur.", "1210.4663": "A PRQ Search Method for Probabilistic Objects,Wang, Jack,Computer Science - DatabasesComputer Science - Computational GeometryComputer Science - Data Structures and AlgorithmsH.2.8H.3.3G.3,This article proposes an PQR search method for probabilistic objects. The\nmain idea of our method is to use a strategy called \\textit{pre-approximation}\nthat can reduce the initial problem to a highly simplified version, implying\nthat it makes the rest of steps easy to tackle. In particular, this strategy\nitself is pretty simple and easy to implement. Furthermore, motivated by the\ncost analysis, we further optimize our solution. The optimizations are mainly\nbased on two insights: (\\romannumeral 1) the number of \\textit{effective\nsubdivision}s is no more than 1; and (\\romannumeral 2) an entity with the\nlarger \\textit{span} is more likely to subdivide a single region. We\ndemonstrate the effectiveness and efficiency of our proposed approaches through\nextensive experiments under various experimental settings.Comment: 33 pages", "1210.4959": "Halving Lines and Their Underlying Graphs,Khovanova, TanyaYang, Dai,Mathematics - CombinatoricsComputer Science - Discrete Mathematics05C30,In this paper we study underlying graphs corresponding to a set of halving\nlines. We establish many properties of such graphs. In addition, we tighten the\nupper bound for the number of halving lines.Comment: 26 pages, 13 figures", "1210.5065": "Realizability algebras III: some examples,Krivine, Jean-Louis,Computer Science - Logic in Computer ScienceMathematics - Logic03E35F.4.1,We use the technique of \"classical realizability\" to build new models of ZF +\nDC in which R is not well ordered. This gives new relative consistency results,\nprobably not obtainable by forcing. This gives also a new method to get\nprograms from proofs of arithmetical formulas with dependent choice.Comment: 30 pages", "1210.7341": "Subset Codes for Packet Networks,Kova\u010devi\u0107, MladenVukobratovi\u0107, Dejan,Computer Science - Information Theory94B60,In this paper, we present a coding-theoretic framework for message\ntransmission over packet-switched networks. Network is modeled as a channel\nwhich can induce packet errors, deletions, insertions, and out of order\ndelivery of packets. The proposed approach can be viewed as an extension of the\none introduced by Koetter and Kschischang for networks based on random linear\nnetwork coding. Namely, while their framework is based on subspace codes and\ndesigned for networks in which network nodes perform random linear combining of\nthe packets, ours is based on the so-called subset codes, and is designed for\nnetworks employing routing in network nodes.Comment: 4 pages", "1210.7638": "Finding Efficient Region in The Plane with Line segments,Wang, Jack,Computer Science - Data Structures and AlgorithmsComputer Science - Computational GeometryF.2I.1.2,Let $\\mathscr O$ be a set of $n$ disjoint obstacles in $\\mathbb{R}^2$,\n$\\mathscr M$ be a moving object. Let $s$ and $l$ denote the starting point and\nmaximum path length of the moving object $\\mathscr M$, respectively. Given a\npoint $p$ in ${R}^2$, we say the point $p$ is achievable for $\\mathscr M$ such\nthat $\\pi(s,p)\\leq l$, where $\\pi(\\cdot)$ denotes the shortest path length in\nthe presence of obstacles. One is to find a region $\\mathscr R$ such that, for\nany point $p\\in \\mathbb{R}^2$, if it is achievable for $\\mathscr M$, then $p\\in\n\\mathscr R$; otherwise, $p\\notin \\mathscr R$. In this paper, we restrict our\nattention to the case of line-segment obstacles. To tackle this problem, we\ndevelop three algorithms. We first present a simpler-version algorithm for the\nsake of intuition. Its basic idea is to reduce our problem to computing the\nunion of a set of circular visibility regions (CVRs). This algorithm takes\n$O(n^3)$ time. By analysing its dominant steps, we break through its bottleneck\nby using the short path map (SPM) technique to obtain those circles\n(unavailable beforehand), yielding an $O(n^2\\log n)$ algorithm. Owing to the\nfinding above, the third algorithm also uses the SPM technique. It however,\ndoes not continue to construct the CVRs. Instead, it directly traverses each\nregion of the SPM to trace the boundaries, the final algorithm obtains $O(n\\log\nn)$ complexity.Comment: 28 pages", "1211.0071": "Randomness and Non-determinism,Levin, Leonid A.,Computer Science - Computational ComplexityComputer Science - Cryptography and SecurityComputer Science - Information Theory,Exponentiation makes the difference between the bit-size of this line and the\nnumber (<< 2^{300}) of particles in the known Universe. The expulsion of\nexponential time algorithms from Computer Theory in the 60's broke its\numbilical cord from Mathematical Logic. It created a deep gap between\ndeterministic computation and -- formerly its unremarkable tools -- randomness\nand non-determinism. Little did we learn in the past decades about the power of\neither of these two basic \"freedoms\" of computation, but some vague pattern is\nemerging in relationships between them. The pattern of similar techniques\ninstrumental for quite different results in this area seems even more\ninteresting. Ideas like multilinear and low-degree multivariate polynomials,\nFourier transformation over low-periodic groups seem very illuminating. The\ntalk surveyed some recent results. One of them, given in a stronger form than\npreviously published, is described below.Comment: 1992 talk at ASL meeting", "1211.0589": "Sharp Bounds on Random Walk Eigenvalues via Spectral Embedding,Lyons, RussellGharan, Shayan Oveis,Mathematics - ProbabilityComputer Science - Discrete MathematicsComputer Science - Data Structures and AlgorithmsMathematics - Spectral Theory,Spectral embedding of graphs uses the top k non-trivial eigenvectors of the\nrandom walk matrix to embed the graph into R^k. The primary use of this\nembedding has been for practical spectral clustering algorithms [SM00,NJW02].\nRecently, spectral embedding was studied from a theoretical perspective to\nprove higher order variants of Cheeger's inequality [LOT12,LRTV12].\n  We use spectral embedding to provide a unifying framework for bounding all\nthe eigenvalues of graphs. For example, we show that for any finite graph with\nn vertices and all k >= 2, the k-th largest eigenvalue is at most\n1-Omega(k^3/n^3), which extends the only other such result known, which is for\nk=2 only and is due to [LO81]. This upper bound improves to 1-Omega(k^2/n^2) if\nthe graph is regular. We generalize these results, and we provide sharp bounds\non the spectral measure of various classes of graphs, including\nvertex-transitive graphs and infinite graphs, in terms of specific graph\nparameters like the volume growth.\n  As a consequence, using the entire spectrum, we provide (improved) upper\nbounds on the return probabilities and mixing time of random walks with\nconsiderably shorter and more direct proofs. Our work introduces spectral\nembedding as a new tool in analyzing reversible Markov chains. Furthermore,\nbuilding on [Lyo05], we design a local algorithm to approximate the number of\nspanning trees of massive graphs.", "1211.0729": "A Simple Algorithm for Computing BOCP,Wang, Jack,Computer Science - Data Structures and AlgorithmsComputer Science - Computational GeometryComputer Science - GraphicsE.1I.3.5I.3.6,In this article, we devise a concise algorithm for computing BOCP. Our method\nis simple, easy-to-implement but without loss of efficiency. Given two\ncircular-arc polygons with $m$ and $n$ edges respectively, our method runs in\n$O(m+n+(l+k)\\log l)$ time, using $O(m+n+k)$ space, where $k$ is the number of\nintersections, and $l$ is the number of {edge}s. Our algorithm has the power to\napproximate to linear complexity when $k$ and $l$ are small. The superiority of\nthe proposed algorithm is also validated through empirical study.Comment: 33 pages", "1211.0877": "Differential Privacy for the Analyst via Private Equilibrium Computation,Hsu, JustinRoth, AaronUllman, Jonathan,Computer Science - Data Structures and AlgorithmsComputer Science - Computer Science and Game Theory,We give new mechanisms for answering exponentially many queries from multiple\nanalysts on a private database, while protecting differential privacy both for\nthe individuals in the database and for the analysts. That is, our mechanism's\nanswer to each query is nearly insensitive to changes in the queries asked by\nother analysts. Our mechanism is the first to offer differential privacy on the\njoint distribution over analysts' answers, providing privacy for data analysts\neven if the other data analysts collude or register multiple accounts. In some\nsettings, we are able to achieve nearly optimal error rates (even compared to\nmechanisms which do not offer analyst privacy), and we are able to extend our\ntechniques to handle non-linear queries. Our analysis is based on a novel view\nof the private query-release problem as a two-player zero-sum game, which may\nbe of independent interest.", "1211.2384": "Strong Bounds for Evolution in Undirected Graphs,Mertzios, George B.Spirakis, Paul G.,Computer Science - Data Structures and AlgorithmsMathematics - ProbabilityG.3E.1,This work studies the generalized Moran process, as introduced by Lieberman\net al. [Nature, 433:312-316, 2005]. We introduce the parameterized notions of\nselective amplifiers and selective suppressors of evolution, i.e. of networks\n(graphs) with many \"strong starts\" and many \"weak starts\" for the mutant,\nrespectively. We first prove the existence of strong selective amplifiers and\nof (quite) strong selective suppressors. Furthermore we provide strong upper\nbounds and almost tight lower bounds (by proving the \"Thermal Theorem\") for the\ntraditional notion of fixation probability of Lieberman et al., i.e. assuming a\nrandom initial placement of the mutant.Comment: 28 pages, 18 fugures", "1211.2662": "Recognizing Interval Bigraphs by Forbidden Patterns,Rafiey, Arash,Computer Science - Data Structures and AlgorithmsComputer Science - Discrete MathematicsMathematics - Combinatorics,Let H be a connected bipartite graph with n nodes and m edges. We give an\nO(nm) time algorithm to decide whether H is an interval bigraph. The best known\nalgorithm has time complexity O(nm^6(m + n) \\log n) and it was developed in\n1997 [18]. Our approach is based on an ordering characterization of interval\nbigraphs introduced by Hell and Huang [13]. We transform the problem of finding\nthe desired ordering to choosing strong components of a pair-digraph without\ncreating conflicts. We make use of the structure of the pair-digraph as well as\ndecomposition of bigraph H based on the special components of the pair-digraph.\nThis way we make explicit what the difficult cases are and gain efficiency by\nisolating such situations.", "1211.3234": "Computational topology and normal surfaces: Theoretical and experimental\n  complexity bounds,Burton, Benjamin A.Paix\u00e3o, Jo\u00e3oSpreer, Jonathan,Mathematics - Geometric TopologyComputer Science - Computational GeometryMathematics - Combinatorics68Q17 (Primary) 68Q15, 68Q15, 57Q35, 57Q35 (Secondary),In three-dimensional computational topology, the theory of normal surfaces is\na tool of great theoretical and practical significance. Although this theory\ntypically leads to exponential time algorithms, very little is known about how\nthese algorithms perform in \"typical\" scenarios, or how far the best known\ntheoretical bounds are from the real worst-case scenarios. Here we study the\ncombinatorial and algebraic complexity of normal surfaces from both the\ntheoretical and experimental viewpoints. Theoretically, we obtain new\nexponential lower bounds on the worst-case complexities in a variety of\nsettings that are important for practical computation. Experimentally, we study\nthe worst-case and average-case complexities over a comprehensive body of\nroughly three billion input triangulations. Many of our lower bounds are the\nfirst known exponential lower bounds in these settings, and experimental\nevidence suggests that many of our theoretical lower bounds on worst-case\ngrowth rates may indeed be asymptotically tight.Comment: A 10-page extended abstract of this work will appear in ALENEX 2013;\n  this is the full version of the paper including details of proofs. 23 pages,\n  10 figures", "1211.4892": "Confusion of Tagged Perturbations in Forward Automatic Differentiation\n  of Higher-Order Functions,Manzyuk, OleksandrPearlmutter, Barak A.Radul, Alexey AndreyevichRush, David R.Siskind, Jeffrey Mark,Computer Science - Symbolic ComputationComputer Science - Mathematical SoftwareMathematics - Differential Geometry,Forward Automatic Differentiation (AD) is a technique for augmenting programs\nto compute derivatives. The essence of Forward AD is to attach perturbations to\neach number, and propagate these through the computation. When derivatives are\nnested, the distinct derivative calculations, and their associated\nperturbations, must be distinguished. This is typically accomplished by\ncreating a unique tag for each derivative calculation, tagging the\nperturbations, and overloading the arithmetic operators. We exhibit a subtle\nbug, present in fielded implementations, in which perturbations are confused\ndespite the tagging machinery. The essence of the bug is this: each invocation\nof a derivative creates a unique tag but a unique tag is needed for each\nderivative calculation. When taking derivatives of higher-order functions,\nthese need not correspond! The derivative of a higher-order function $f$ that\nreturns a function $g$ will be a function $f'$ that returns a function\n$\\bar{g}$ that performs a derivative calculation. A single invocation of $f'$\nwill create a single fresh tag but that same tag will be used for each\nderivative calculation resulting from an invocation of $\\bar{g}$. This\nsituation arises when taking derivatives of curried functions. Two potential\nsolutions are presented, and their serious deficiencies discussed. One requires\neta expansion to delay the creation of fresh tags from the invocation of $f'$\nto the invocation of $\\bar{g}$, which can be difficult or even impossible in\nsome circumstances. The other requires $f'$ to wrap $\\bar{g}$ with tag\nrenaming, which is difficult to implement without violating the desirable\ncomplexity properties of forward AD.", "1211.5608": "Blind Deconvolution using Convex Programming,Ahmed, AliRecht, BenjaminRomberg, Justin,Computer Science - Information Theory,We consider the problem of recovering two unknown vectors, $\\boldsymbol{w}$\nand $\\boldsymbol{x}$, of length $L$ from their circular convolution. We make\nthe structural assumption that the two vectors are members of known subspaces,\none with dimension $N$ and the other with dimension $K$. Although the observed\nconvolution is nonlinear in both $\\boldsymbol{w}$ and $\\boldsymbol{x}$, it is\nlinear in the rank-1 matrix formed by their outer product\n$\\boldsymbol{w}\\boldsymbol{x}^*$. This observation allows us to recast the\ndeconvolution problem as low-rank matrix recovery problem from linear\nmeasurements, whose natural convex relaxation is a nuclear norm minimization\nprogram.\n  We prove the effectiveness of this relaxation by showing that for \"generic\"\nsignals, the program can deconvolve $\\boldsymbol{w}$ and $\\boldsymbol{x}$\nexactly when the maximum of $N$ and $K$ is almost on the order of $L$. That is,\nwe show that if $\\boldsymbol{x}$ is drawn from a random subspace of dimension\n$N$, and $\\boldsymbol{w}$ is a vector in a subspace of dimension $K$ whose\nbasis vectors are \"spread out\" in the frequency domain, then nuclear norm\nminimization recovers $\\boldsymbol{w}\\boldsymbol{x}^*$ without error.\n  We discuss this result in the context of blind channel estimation in\ncommunications. If we have a message of length $N$ which we code using a random\n$L\\times N$ coding matrix, and the encoded message travels through an unknown\nlinear time-invariant channel of maximum length $K$, then the receiver can\nrecover both the channel response and the message when $L\\gtrsim N+K$, to\nwithin constant and log factors.Comment: 40 pages, 8 Figures", "1211.5773": "Circuit complexity and Problem structure in Hamming space,Kobayashi, Koji,Computer Science - Computational Complexity,This paper describes about relation between circuit complexity and accept\ninputs structure in Hamming space by using almost all monotone circuit that\nemulate deterministic Turing machine (DTM).\n  Circuit family that emulate DTM are almost all monotone circuit family except\nsome NOT-gate which connect input variables (like negation normal form (NNF)).\nTherefore, we can analyze DTM limitation by using this NNF Circuit family.\n  NNF circuit have symmetry of OR-gate input line, so NNF circuit cannot\nidentify from OR-gate output line which of OR-gate input line is 1. So NNF\ncircuit family cannot compute sandwich structure effectively (Sandwich\nstructure is two accept inputs that sandwich reject inputs in Hamming space).\nNNF circuit have to use unique AND-gate to identify each different vector of\nsandwich structure. That is, we can measure problem complexity by counting\ndifferent vectors.\n  Some decision problem have characteristic in sandwich structure. Different\nvectors of Negate HornSAT problem are at most constant length because we can\ndelete constant part of each negative literal in Horn clauses by using definite\nclauses. Therefore, number of these different vector is at most polynomial\nsize. The other hand, we can design high complexity problem with almost perfct\nnonlinear (APN) function.Comment: 14 pages, 9 figures", "1211.6468": "Using Isabelle to verify special relativity, with application to\n  hypercomputation theory,Stannett, MikeN\u00e9meti, Istv\u00e1n,Computer Science - Logic in Computer ScienceGeneral Relativity and Quantum CosmologyF.4.1J.2,Logicians at the R\\'enyi Mathematical Institute in Budapest have spent\nseveral years developing versions of relativity theory (special, general, and\nother variants) based wholly on first order logic, and have argued in favour of\nthe physical decidability, via exploitation of cosmological phenomena, of\nformally undecidable questions such as the Halting Problem and the consistency\nof set theory.\n  The Hungarian theories are very extensive, and their associated proofs are\nintuitively very satisfying, but this brings its own risks since intuition can\nsometimes be misleading. As part of a joint project, researchers at Sheffield\nhave recently started generating rigorous machine-verified versions of the\nHungarian proofs, so as to demonstrate the soundness of their work. In this\npaper, we explain the background to the project and demonstrate an Isabelle\nproof of the theorem \"No inertial observer can travel faster than light\".\n  This approach to physical theories and physical computability has several\npay-offs: (a) we can be certain our intuition hasn't led us astray (or if it\nhas, we can identify where this has happened); (b) we can identify which axioms\nare specifically required in the proof of each theorem and to what extent those\naxioms can be weakened (the fewer assumptions we make up-front, the stronger\nthe results); and (c) we can identify whether new formal proof techniques and\ntactics are needed when tackling physical as opposed to mathematical theories.Comment: 14 pages, reformatted with minor corrections", "1211.6470": "A new class of SETI beacons that contain information (22-aug-2010),Harp, G. R.Ackermann, R. F.Blair, Samantha K.Arbunich, J.Backus, P. R.Tarter, J. C.Team, the ATA,Astrophysics - Instrumentation and Methods for AstrophysicsComputer Science - Other Computer Science,In the cm-wavelength range, an extraterrestrial electromagnetic narrow band\n(sine wave) beacon is an excellent choice to get alien attention across\ninterstellar distances because 1) it is not strongly affected by interstellar /\ninterplanetary dispersion or scattering, and 2) searching for narrowband\nsignals is computationally efficient (scales as Ns log(Ns) where Ns = number of\nvoltage samples). Here we consider a special case wideband signal where two or\nmore delayed copies of the same signal are transmitted over the same frequency\nand bandwidth, with the result that ISM dispersion and scattering cancel out\nduring the detection stage. Such a signal is both a good beacon (easy to find)\nand carries arbitrarily large information rate (limited only by the atmospheric\ntransparency to about 10 GHz). The discovery process uses an autocorrelation\nalgorithm, and we outline a compute scheme where the beacon discovery search\ncan be accomplished with only 2x the processing of a conventional sine wave\nsearch, and discuss signal to background response for sighting the beacon. Once\nthe beacon is discovered, the focus turns to information extraction.\nInformation extraction requires similar processing as for generic wideband\nsignal searches, but since we have already identified the beacon, the\nefficiency of information extraction is negligible.Comment: 33 pages, 8 figures, 1 table", "1212.1095": "The projector algorithm: a simple parallel algorithm for computing\n  Voronoi diagrams and Delaunay graphs,Reem, Daniel,Computer Science - Computational GeometryComputer Science - Distributed, Parallel, and Cluster ComputingComputer Science - Data Structures and Algorithms68U05, 68W10, 65D18, 68W40, 52B05D.1.3D.3.2F.1.2F.2.2G.1.0G.2.1G.4I.1.2I.3.5,The Voronoi diagram is a certain geometric data structure which has numerous\napplications in various scientific and technological fields. The theory of\nalgorithms for computing 2D Euclidean Voronoi diagrams of point sites is rich\nand useful, with several different and important algorithms. However, this\ntheory has been quite steady during the last few decades in the sense that no\nessentially new algorithms have entered the game. In addition, most of the\nknown algorithms are serial in nature and hence cast inherent difficulties on\nthe possibility to compute the diagram in parallel. In this paper we present\nthe projector algorithm: a new and simple algorithm which enables the\n(combinatorial) computation of 2D Voronoi diagrams. The algorithm is\nsignificantly different from previous ones and some of the involved concepts in\nit are in the spirit of linear programming and optics. Parallel implementation\nis naturally supported since each Voronoi cell can be computed independently of\nthe other cells. A new combinatorial structure for representing the cells (and\nany convex polytope) is described along the way and the computation of the\ninduced Delaunay graph is obtained almost automatically.Comment: This is a major revision; re-organization and better presentation of\n  some parts; correction of several inaccuracies; improvement of some proofs\n  and figures; added references; modification of the title; the paper is long\n  but more than half of it is composed of proofs and references: it is\n  sufficient to look at pages 5, 7--11 in order to understand the algorithm", "1212.1149": "Threshold Digraphs,Cloteaux, BrianLaMar, M. DrewMoseman, ElizabethShook, James,Mathematics - CombinatoricsComputer Science - Discrete Mathematics05C20,A digraph whose degree sequence has a unique vertex labeled realization is\ncalled threshold. In this paper we present several characterizations of\nthreshold digraphs and their degree sequences, and show these characterizations\nto be equivalent. One of the characterizations is new, and allows for a shorter\nproof of the equivalence of the two known characterizations as well as proving\nthe final characterization which appears without proof in the literature. Using\nthis result, we obtain a new, short proof of the Fulkerson-Chen theorem on\ndegree sequences of general digraphs.", "1212.1710": "The information and its observer: external and internal information\n  processes, information cooperation, and the origin of the observer intellect,Lerner, Vladimir S.,Nonlinear Sciences - Adaptation and Self-Organizing SystemsComputer Science - Information Theory58J65, 60J65, 93B52, 93E02, 93E15, 93E30H.1.1,In observing interactive processes, conversion of observed uncertainty to\nobserver certainty is natural phenomenon creating Yes-No actions of information\nBit and its information observer. Observer emerges from interacting random\nfield of Kolmogorov probabilities which link Kolmogorov 0-1 law probabilities\nand Bayesian probabilities observing Markov diffusion process by probabilistic\n0-1 impulses. Each No-0 action cuts maximum of impulse minimal entropy while\nfollowing Yes-1 action transfers maxim between impulses performing dual\nprinciple of converting process entropy to information. Merging Yes-No actions\ngenerate microprocess within bordered impulse producing Bit with free\ninformation when the microprocess probability approaches 1. Interacting bits\nmemorizes each impulse free information which attracts multiple Bits moving\nmacroprocess that self-joins triplet macrounits. Each memorized information\nbinds reversible microprocess within impulse with irreversible macroprocess.\nThe observation automatically converts cutting entropy to information\nmacrounits. Macrounits logically self-organize information networks IN encoding\nthe units in geometrical structures enclosing triplet code. Multiple IN binds\ntheir ending triplets which encloses observer information cognition and\nintelligence. The observer cognition assembles common units through multiple\nattraction and resonances at forming IN triplet hierarchy which accept only\nunits that recognizes each IN node. Maximal number of accepted triplet levels\nin multiple IN measures the observer maximum comparative information\nintelligence. The observation process carries probabilistic and certain wave\nfunction which self-organizes the space hierarchical structures.These\ninformation regularities create integral logic and intelligence self-operating\nmultiple IN up to physical reality matter.Comment: 66 pages include 16 figures", "1212.6751": "Computably Categorical Fields via Fermat's Last Theorem,Miller, RussellSchoutens, Hans,Mathematics - LogicComputer Science - Logic in Computer Science03C57 (Primary), 03D45, 12L05 (Secondary),We construct a computable, computably categorical field of infinite\ntranscendence degree over the rational numbers, using the Fermat polynomials\nand assorted results from algebraic geometry. We also show that this field has\nan intrinsically computable (infinite) transcendence basis.Comment: to appear in the journal Computability", "1212.6879": "On two conjectures of Maurer concerning basis graphs of matroids,Chalopin, J\u00e9r\u00e9mieChepoi, VictorOsajda, Damian,Mathematics - CombinatoricsComputer Science - Discrete Mathematics05B35, 05C12, 57M10, 57M20,We characterize 2-dimensional complexes associated canonically with basis\ngraphs of matroids as simply connected triangle-square complexes satisfying\nsome local conditions. This proves a version of a (disproved) conjecture by\nStephen Maurer (Conjecture 3 of S. Maurer, Matroid basis graphs I, JCTB 14\n(1973), 216-240). We also establish Conjecture 1 from the same paper about the\nredundancy of the conditions in the characterization of basis graphs. We\nindicate positive-curvature-like aspects of the local properties of the studied\ncomplexes. We characterize similarly the corresponding 2-dimensional complexes\nof even $\\Delta$-matroids.Comment: 28 pages", "1301.1027": "On online energy harvesting in multiple access communication systems,Khuzani, Masoud BadieiMitran, Patrick,Computer Science - Information Theory,We investigate performance limits of a multiple access communication system\nwith energy harvesting nodes where the utility function is taken to be the\nlong-term average sum-throughput. We assume a causal structure for energy\narrivals and study the problem in the continuous time regime. For this setting,\nwe first characterize a storage dam model that captures the dynamics of a\nbattery with energy harvesting and variable transmission power. Using this\nmodel, we next establish an upper bound on the throughput problem as a function\nof battery capacity. We also formulate a non-linear optimization problem to\ndetermine optimal achievable power policies for transmitters. Applying a\ncalculus of variation technique, we then derive Euler-Lagrange equations as\nnecessary conditions for optimum power policies in terms of a system of coupled\npartial integro-differential equations (PIDEs). Based on a Gauss-Seidel\nalgorithm, we devise an iterative algorithm to solve these equations. We also\npropose a fixed-point algorithm for the symmetric multiple access setting in\nwhich the statistical descriptions of energy harvesters are identical. Along\nwith the analysis and to support our iterative algorithms, comprehensive\nnumerical results are also obtained.Comment: 14 pages, 4 figures, 2 tables. In this version, the font size and\n  format is changed to the standard double column IEEE (v4)", "1301.1071": "Direct QR factorizations for tall-and-skinny matrices in MapReduce\n  architectures,Benson, Austin R.Gleich, David F.Demmel, James,Computer Science - Distributed, Parallel, and Cluster ComputingComputer Science - Numerical Analysis,The QR factorization and the SVD are two fundamental matrix decompositions\nwith applications throughout scientific computing and data analysis. For\nmatrices with many more rows than columns, so-called \"tall-and-skinny\nmatrices,\" there is a numerically stable, efficient, communication-avoiding\nalgorithm for computing the QR factorization. It has been used in traditional\nhigh performance computing and grid computing environments. For MapReduce\nenvironments, existing methods to compute the QR decomposition use a\nnumerically unstable approach that relies on indirectly computing the Q factor.\nIn the best case, these methods require only two passes over the data. In this\npaper, we describe how to compute a stable tall-and-skinny QR factorization on\na MapReduce architecture in only slightly more than 2 passes over the data. We\ncan compute the SVD with only a small change and no difference in performance.\nWe present a performance comparison between our new direct TSQR method, a\nstandard unstable implementation for MapReduce (Cholesky QR), and the classic\nstable algorithm implemented for MapReduce (Householder QR). We find that our\nnew stable method has a large performance advantage over the Householder QR\nmethod. This holds both in a theoretical performance model as well as in an\nactual implementation.", "1301.1107": "Spectral Condition-Number Estimation of Large Sparse Matrices,Avron, HaimDruinsky, AlexToledo, Sivan,Computer Science - Numerical AnalysisMathematics - Numerical Analysis,We describe a randomized Krylov-subspace method for estimating the spectral\ncondition number of a real matrix A or indicating that it is numerically rank\ndeficient. The main difficulty in estimating the condition number is the\nestimation of the smallest singular value \\sigma_{\\min} of A. Our method\nestimates this value by solving a consistent linear least-squares problem with\na known solution using a specific Krylov-subspace method called LSQR. In this\nmethod, the forward error tends to concentrate in the direction of a right\nsingular vector corresponding to \\sigma_{\\min}. Extensive experiments show that\nthe method is able to estimate well the condition number of a wide array of\nmatrices. It can sometimes estimate the condition number when running a dense\nSVD would be impractical due to the computational cost or the memory\nrequirements. The method uses very little memory (it inherits this property\nfrom LSQR) and it works equally well on square and rectangular matrices.", "1301.2158": "Artificial Intelligence Framework for Simulating Clinical\n  Decision-Making: A Markov Decision Process Approach,Bennett, Casey C.Hauser, Kris,Computer Science - Artificial IntelligenceStatistics - Machine Learning,In the modern healthcare system, rapidly expanding costs/complexity, the\ngrowing myriad of treatment options, and exploding information streams that\noften do not effectively reach the front lines hinder the ability to choose\noptimal treatment decisions over time. The goal in this paper is to develop a\ngeneral purpose (non-disease-specific) computational/artificial intelligence\n(AI) framework to address these challenges. This serves two potential\nfunctions: 1) a simulation environment for exploring various healthcare\npolicies, payment methodologies, etc., and 2) the basis for clinical artificial\nintelligence - an AI that can think like a doctor. This approach combines\nMarkov decision processes and dynamic decision networks to learn from clinical\ndata and develop complex plans via simulation of alternative sequential\ndecision paths while capturing the sometimes conflicting, sometimes synergistic\ninteractions of various components in the healthcare system. It can operate in\npartially observable environments (in the case of missing observations or data)\nby maintaining belief states about patient health status and functions as an\nonline agent that plans and re-plans. This framework was evaluated using real\npatient data from an electronic health record. Such an AI framework easily\noutperforms the current treatment-as-usual (TAU) case-rate/fee-for-service\nmodels of healthcare (Cost per Unit Change: $189 vs. $497) while obtaining a\n30-35% increase in patient outcomes. Tweaking certain model parameters further\nenhances this advantage, obtaining roughly 50% more improvement for roughly\nhalf the costs. Given careful design and problem formulation, an AI simulation\nframework can approximate optimal decisions even in complex and uncertain\nenvironments. Future work is described that outlines potential lines of\nresearch and integration of machine learning algorithms for personalized\nmedicine.Comment: Keywords: Markov Decision Process; Dynamic Decision Network;\n  Multi-Agent System; Clinical Artificial Intelligence; Medical Decision\n  Making; Chronic Illness; (2013) Artificial Intelligence in Medicine", "1301.2959": "New elements for a network (including brain) general theory during\n  learning period,Piniello, Jean,Nonlinear Sciences - Adaptation and Self-Organizing SystemsComputer Science - Neural and Evolutionary ComputingNonlinear Sciences - Chaotic Dynamics,This study deals with the evolution of the so called 'intelligent' networks\n(insect society without leader, cells of an organism, brain,...) during their\nlearning period. First we summarize briefly the Version 2 (published in\nFrench), whose the main characteristics are: 1) A network connected to its\nenvironment is considered as immersed into an information field created by this\nenvironment which so dictates to it the learning constraints. 2) The used\nformalism draws one's inspiration from the one of the Quantum field theory\n(Principle of stationary action, gauge fields, invariance by symmetry\ntransformations,...). 3) We obtain Lagrange equations whose solutions describe\nthe network evolution during the whole learning period. 4) Then, while\nproceeding with the same formalism inspiration, we suggest other study ways\ncapable of evolving the knowledge in the considered scope. In a second part,\nafter a reminder of the points to be improved, we exhibit the Version 5 which\nbrings, we think, relevant improvements. Indeed: 5) We consider the weighted\naverages of the variables; this introduces probabilities. 6) We define two\nobservables (L average of information flux and A activity of the network) which\ncould be measured and so be compared with experimental results. 7) We find that\nL , weighted average of information flows, is an invariant. 8) Finally, we\npropose two expressions for the conactance, from which we deduce the\ncorresponding Lagrange equations which have to be solved to know the evolution\nof the considered weighted averages. But, at the present stage, we think that\nwe can progress only by carrying out experiments (see projects like Human brain\nproject) and discovering invariants, symmetries which would allow us, like in\nPhysics, to classify networks and above all to understand better the\nconnections between them. Indeed, and that is what we propose among the future\nresearch ways, the underlying problem is to understand how, after their\nlearning period, several networks can connect together to produce, in the brain\ncase for instance, what we call mental states.Comment: The Version 3 (in english) brought relevant improvements to Version 2\n  (in french). The Version 4 is similar to Version 3, except from the fact that\n  it includes REFERENCES BIBLIOGRAPHY. The Version 5 brings some considerations\n  about ARTIFICIAL INTELLIGENCE", "1301.3605": "Feature Learning in Deep Neural Networks - Studies on Speech Recognition\n  Tasks,Yu, DongSeltzer, Michael L.Li, JinyuHuang, Jui-TingSeide, Frank,Computer Science - Machine LearningComputer Science - Computation and LanguageComputer Science - Neural and Evolutionary ComputingElectrical Engineering and Systems Science - Audio and Speech Processing,Recent studies have shown that deep neural networks (DNNs) perform\nsignificantly better than shallow networks and Gaussian mixture models (GMMs)\non large vocabulary speech recognition tasks. In this paper, we argue that the\nimproved accuracy achieved by the DNNs is the result of their ability to\nextract discriminative internal representations that are robust to the many\nsources of variability in speech signals. We show that these representations\nbecome increasingly insensitive to small perturbations in the input with\nincreasing network depth, which leads to better speech recognition performance\nwith deeper networks. We also show that DNNs cannot extrapolate to test samples\nthat are substantially different from the training examples. If the training\ndata are sufficiently representative, however, internal features learned by the\nDNN are relatively stable with respect to speaker differences, bandwidth\ndifferences, and environment distortion. This enables DNN-based recognizers to\nperform as well or better than state-of-the-art systems based on GMMs or\nshallow networks without the need for explicit model adaptation or feature\nnormalization.Comment: ICLR 2013, 9 pages, 4 figures", "1301.5055": "Nested Recursions, Simultaneous Parameters and Tree Superpositions,Isgur, AbrahamKuznetsov, VitalyRahman, MustazeeTanny, Stephen,Mathematics - CombinatoricsComputer Science - Discrete Mathematics11B37, 05C05 (Primary) 05A15, 05A19 (Secondary),We apply a tree-based methodology to solve new, very broadly defined families\nof nested recursions of the general form R(n)=sum_{i=1}^k R(n-a_i-sum_{j=1}^p\nR(n-b_{ij})), where a_i are integers, b_{ij} are natural numbers, and k,p are\nnatural numbers that we use to denote \"arity\" and \"order,\" respectively, and\nwith some specified initial conditions. The key idea of the tree-based solution\nmethod is to associate such recursions with infinite labelled trees in a\nnatural way so that the solution to the recursions solves a counting question\nrelating to the corresponding trees. We characterize certain recursion families\nwithin R(n) by introducing \"simultaneous parameters\" that appear both within\nthe recursion itself and that also specify structural properties of the\ncorresponding tree. First, we extend and unify recently discovered results\nconcerning two families of arity k=2, order p=1 recursions. Next, we\ninvestigate the solution of nested recursion families by taking linear\ncombinations of solution sequence frequencies for simpler nested recursions,\nwhich correspond to superpositions of the associated trees; this leads us to\nidentify and solve two new recursion families for arity k=2 and general order\np. Finally, we extend these results to general arity k>2. We conclude with\nseveral related open problems.Comment: 38 pages, 20 figures", "1301.5293": "Approximately counting semismooth integers,Bach, EricSorenson, Jonathan,Computer Science - Data Structures and AlgorithmsMathematics - Number Theory11y16, 11y05, 11a51F.2.1I.1.2,An integer $n$ is $(y,z)$-semismooth if $n=pm$ where $m$ is an integer with\nall prime divisors $\\le y$ and $p$ is 1 or a prime $\\le z$. arge quantities of\nsemismooth integers are utilized in modern integer factoring algorithms, such\nas the number field sieve, that incorporate the so-called large prime variant.\nThus, it is useful for factoring practitioners to be able to estimate the value\nof $\\Psi(x,y,z)$, the number of $(y,z)$-semismooth integers up to $x$, so that\nthey can better set algorithm parameters and minimize running times, which\ncould be weeks or months on a cluster supercomputer. In this paper, we explore\nseveral algorithms to approximate $\\Psi(x,y,z)$ using a generalization of\nBuchstab's identity with numeric integration.Comment: To appear in ISSAC 2013, Boston MA", "1301.5522": "On Gaussian Half-Duplex Relay Networks,Cardone, MartinaTuninetti, DanielaKnopp, RaymondSalim, Umer,Computer Science - Information Theory,This paper considers Gaussian relay networks where a source transmits a\nmessage to a sink terminal with the help of one or more relay nodes. The relays\nwork in half-duplex mode, in the sense that they can not transmit and receive\nat the same time. For the case of one relay, the generalized Degrees-of-Freedom\nis characterized first and then it is shown that capacity can be achieved to\nwithin a constant gap regardless of the actual value of the channel parameters.\nDifferent achievable schemes are presented with either deterministic or random\nswitch for the relay node. It is shown that random switch in general achieves\nhigher rates than deterministic switch. For the case of K relays, it is shown\nthat the generalized Degrees-of-Freedom can be obtained by solving a linear\nprogram and that capacity can be achieved to within a constant gap of\nK/2log(4K). This gap may be further decreased by considering more structured\nnetworks such as, for example, the diamond network.", "1301.7023": "The Capacity of Adaptive Group Testing,Baldassini, LeonardoJohnson, OliverAldridge, Matthew,Computer Science - Information Theory,We define capacity for group testing problems and deduce bounds for the\ncapacity of a variety of noisy models, based on the capacity of equivalent\nnoisy communication channels. For noiseless adaptive group testing we prove an\ninformation-theoretic lower bound which tightens a bound of Chan et al. This\ncan be combined with a performance analysis of a version of Hwang's adaptive\ngroup testing algorithm, in order to deduce the capacity of noiseless and\nerasure group testing models.Comment: 5 pages", "1302.1211": "Quantum Lyapunov Control Based on the Average Value of an Imaginary\n  Mechanical Quantity,Cong, ShuangMeng, FangfangKuang, Sen,Computer Science - Systems and ControlMathematical Physics,The convergence of closed quantum systems in the degenerate cases to the\ndesired target state by using the quantum Lyapunov control based on the average\nvalue of an imaginary mechanical quantity is studied. On the basis of the\nexisting methods which can only ensure the single-control Hamiltonian systems\nconverge toward a set, we design the control laws to make the multi-control\nHamiltonian systems converge to the desired target state. The convergence of\nthe control system is proved, and the convergence to the desired target state\nis analyzed. How to make these conditions of convergence to the target state to\nbe satisfied is proved or analyzed. Finally, numerical simulations for a three\nlevel system in the degenrate case transfering form an initial eigenstate to a\ntarget superposition state are studied to verify the effectiveness of the\nproposed control method.Comment: 14 pages, 2 figures", "1302.2279": "Expressing Second-order Sentences in Intuitionistic Dependence Logic,Yang, Fan,Mathematics - LogicComputer Science - Logic in Computer Science,Intuitionistic dependence logic was introduced by Abramsky and Vaananen\n(2009) as a variant of dependence logic under a general construction of Hodges'\n(trump) team semantics. It was proven that there is a translation from\nintuitionistic dependence logic sentences into second order logic sentences. In\nthis paper, we prove that the other direction is also true, therefore\nintuitionistic dependence logic is equivalent to second order logic on the\nlevel of sentences.Comment: 18 pages", "1302.4118": "Target Estimation in Colocated MIMO Radar via Matrix Completion,Sun, ShunqiaoPetropulu, Athina P.Bajwa, Waheed U.,Computer Science - Information TheoryStatistics - Applications,We consider a colocated MIMO radar scenario, in which the receive antennas\nforward their measurements to a fusion center. Based on the received data, the\nfusion center formulates a matrix which is then used for target parameter\nestimation. When the receive antennas sample the target returns at Nyquist\nrate, and assuming that there are more receive antennas than targets, the data\nmatrix at the fusion center is low-rank. When each receive antenna sends to the\nfusion center only a small number of samples, along with the sample index, the\nreceive data matrix has missing elements, corresponding to the samples that\nwere not forwarded. Under certain conditions, matrix completion techniques can\nbe applied to recover the full receive data matrix, which can then be used in\nconjunction with array processing techniques, e.g., MUSIC, to obtain target\ninformation. Numerical results indicate that good target recovery can be\nachieved with occupancy of the receive data matrix as low as 50%.Comment: 5 pages, ICASSP 2013", "1302.4808": "Verifying the Consistency of Remote Untrusted Services with\n  Conflict-Free Operations,Cachin, ChristianOhrimenko, Olga,Computer Science - Distributed, Parallel, and Cluster Computing,A group of mutually trusting clients outsources a computation service to a\nremote server, which they do not fully trust and that may be subject to\nattacks. The clients do not communicate with each other and would like to\nverify the correctness of the remote computation and the consistency of the\nserver's responses. This paper presents the Conflict-free Operation\nverification Protocol (COP) that ensures linearizability when the server is\ncorrect and preserves fork-linearizability in any other case. All clients that\nobserve each other's operations are consistent, in the sense that their own\noperations and those operations of other clients that they see are\nlinearizable. If the server forks two clients by hiding an operation, these\nclients never again see operations of each other. COP supports wait-free client\noperations in the sense that when executed with a correct server,\nnon-conflicting operations can run without waiting for other clients, allowing\nmore parallelism than earlier protocols. A conflict arises when an operation\ncauses a subsequent operation to produce a different output value for the\nclient who runs it. The paper gives a precise model for the guarantees of COP\nand includes a formal analysis that these are achieved.Comment: A predecessor of this paper with a slightly different title appears\n  in the proceedings of OPODIS 2014, Lecture Notes in Computer Science,\n  vol.~8878, Springer, 2014", "1302.5906": "Achieving AWGN Channel Capacity With Lattice Gaussian Coding,Ling, CongBelfiore, Jean-Claude,Computer Science - Information Theory,We propose a new coding scheme using only one lattice that achieves the\n$\\frac{1}{2}\\log(1+\\SNR)$ capacity of the additive white Gaussian noise (AWGN)\nchannel with lattice decoding, when the signal-to-noise ratio $\\SNR>e-1$. The\nscheme applies a discrete Gaussian distribution over an AWGN-good lattice, but\notherwise does not require a shaping lattice or dither. Thus, it significantly\nsimplifies the default lattice coding scheme of Erez and Zamir which involves a\nquantization-good lattice as well as an AWGN-good lattice. Using the flatness\nfactor, we show that the error probability of the proposed scheme under minimum\nmean-square error (MMSE) lattice decoding is almost the same as that of Erez\nand Zamir, for any rate up to the AWGN channel capacity. We introduce the\nnotion of good constellations, which carry almost the same mutual information\nas that of continuous Gaussian inputs. We also address the implementation of\nGaussian shaping for the proposed lattice Gaussian coding scheme.Comment: This is the authors' own version of a paper published in IEEE Trans.\n  Inform. Theory, vol. 60, no. 10, pp. 5918-5929, Oct. 2014. Corrected an error\n  in Lemma 1 (the old Lemma 1 in arXiv preprint was correct; the Lemma 1 in the\n  last version doesn't hold for $c \\neq 0$)", "1302.6325": "A Note on \"A polynomial-time algorithm for global value numbering\",Nabeezath, SaleenaPaleri, Vineeth,Computer Science - Programming LanguagesComputer Science - Logic in Computer Science,Global Value Numbering(GVN) is a popular method for detecting redundant\ncomputations. A polynomial time algorithm for GVN is presented by Gulwani and\nNecula(2006). Here we present two limitations of this GVN algorithm due to\nwhich detection of certain kinds of redundancies can not be done using this\nalgorithm. The first one is concerning the use of this algorithm in detecting\nsome instances of the classical global common subexpressions, and the second is\nconcerning its use in the detection of some redundancies that a local value\nnumbering algorithm will detect. We suggest improvements that enable the\nalgorithm to detect these kinds of redundancies as well.Comment: 5 pages", "1303.0730": "Diagonalizing by Fixed-Points,Karimi, AhmadSalehi, Saeed,Mathematics - LogicComputer Science - Logic in Computer Science18A10, 18A15, 03B44, 03A05,A universal schema for diagonalization was popularized by N. S. Yanofsky\n(2003) in which the existence of a (diagonolized-out and contradictory) object\nimplies the existence of a fixed-point for a certain function. It was shown\nthat many self-referential paradoxes and diagonally proved theorems can fit in\nthat schema. Here, we fit more theorems in the universal schema of\ndiagonalization, such as Euclid's theorem on the infinitude of the primes and\nnew proofs of Boolos (1997) for Cantor's theorem on the non-equinumerosity of a\nset with its powerset. Then, in Linear Temporal Logic, we show the\nnon-existence of a fixed-point in this logic whose proof resembles the argument\nof Yablo's paradox. Thus, Yablo's paradox turns for the first time into a\ngenuine mathematico-logical theorem in the framework of Linear Temporal Logic.\nAgain the diagonal schema of the paper is used in this proof, and also it is\nshown that G. Priest's inclosure schema (1997) can fit in our universal\ndiagonal/fixed-point schema. We also show the existence of dominating\n(Ackermann-like) functions (which dominate a given countable set of\nfunctions---like primitive recursives) using the schema.Comment: to appear by the title \"Diagonal Arguments and Fixed Points\", The\n  Bulletin of the Iranian Mathematical Society (2016)\n  http://bims.iranjournals.ir/", "1303.0926": "Injectivity w.r.t. Distribution of Elements in the Compressed Sequences\n  Derived from Primitive Sequences over $Z/p^eZ$,Wang, LinHu, Zhi,Computer Science - Information Theory11T71, 11B50,Let $p\\geq3$ be a prime and $e\\geq2$ an integer. Let $\\sigma(x)$ be a\nprimitive polynomial of degree $n$ over $Z/p^eZ$ and $G'(\\sigma(x),p^e)$ the\nset of primitive linear recurring sequences generated by $\\sigma(x)$. A\ncompressing map $\\varphi$ on $Z/p^eZ$ naturally induces a map $\\hat{\\varphi}$\non $G'(\\sigma(x),p^e)$. For a subset $D$ of the image of\n$\\varphi$,$\\hat{\\varphi}$ is called to be injective w.r.t. $D$-uniformity if\nthe distribution of elements of $D$ in the compressed sequence implies all\ninformation of the original primitive sequence. In this correspondence, for at\nleast $1-2(p-1)/(p^n-1)$ of primitive polynomials of degree $n$, a clear\ncriterion on $\\varphi$ is obtained to decide whether $\\hat{\\varphi}$ is\ninjective w.r.t. $D$-uniformity, and the majority of maps on $Z/p^eZ$ induce\ninjective maps on $G'(\\sigma(x),p^e)$. Furthermore, a sufficient condition on\n$\\varphi$ is given to ensure injectivity of $\\hat{\\varphi}$ w.r.t.\n$D$-uniformity. It follows from the sufficient condition that if $\\sigma(x)$ is\nstrongly primitive and the compressing map $\\varphi(x)=f(x_{e-1})$, where\n$f(x_{e-1})$ is a permutation polynomial over $\\mathbb{F}_{p}$, then\n$\\hat{\\varphi}$ is injective w.r.t. $D$-uniformity for $\\emptyset\\neq\nD\\subset\\mathbb{F}_{p}$. Moreover, we give three specific families of\ncompressing maps which induce injective maps on $G'(\\sigma(x),p^e)$.Comment: 42 pages, updated version", "1303.2054": "Mining Representative Unsubstituted Graph Patterns Using Prior\n  Similarity Matrix,Dhifli, WajdiSaidi, RabieNguifo, Engelbert Mephu,Computer Science - Computational Engineering, Finance, and ScienceComputer Science - Machine Learning,One of the most powerful techniques to study protein structures is to look\nfor recurrent fragments (also called substructures or spatial motifs), then use\nthem as patterns to characterize the proteins under study. An emergent trend\nconsists in parsing proteins three-dimensional (3D) structures into graphs of\namino acids. Hence, the search of recurrent spatial motifs is formulated as a\nprocess of frequent subgraph discovery where each subgraph represents a spatial\nmotif. In this scope, several efficient approaches for frequent subgraph\ndiscovery have been proposed in the literature. However, the set of discovered\nfrequent subgraphs is too large to be efficiently analyzed and explored in any\nfurther process. In this paper, we propose a novel pattern selection approach\nthat shrinks the large number of discovered frequent subgraphs by selecting the\nrepresentative ones. Existing pattern selection approaches do not exploit the\ndomain knowledge. Yet, in our approach we incorporate the evolutionary\ninformation of amino acids defined in the substitution matrices in order to\nselect the representative subgraphs. We show the effectiveness of our approach\non a number of real datasets. The results issued from our experiments show that\nour approach is able to considerably decrease the number of motifs while\nenhancing their interestingness.", "1303.3235": "On the Entropy of Couplings,Kova\u010devi\u0107, MladenStanojevi\u0107, Ivan\u0160enk, Vojin,Computer Science - Information Theory94A17, 60E99, 68Q17,In this paper, some general properties of Shannon information measures are\ninvestigated over sets of probability distributions with restricted marginals.\nCertain optimization problems associated with these functionals are shown to be\nNP-hard, and their special cases are found to be essentially\ninformation-theoretic restatements of well-known computational problems, such\nas the SUBSET SUM and the 3-PARTITION. The notion of minimum entropy coupling\nis introduced and its relevance is demonstrated in information-theoretic,\ncomputational, and statistical contexts. Finally, a family of pseudometrics (on\nthe space of discrete probability distributions) defined by these couplings is\nstudied, in particular their relation to the total variation distance, and a\nnew characterization of the conditional entropy is given.Comment: 18 pages (single-column). Compared to v1, the material is\n  reorganized, Section IV.C is removed (the results will possible appear\n  elsewhere), Propositions 3.2 and 3.7 are added. Accepted for publication in\n  Information and Computation", "1303.5613": "Network Detection Theory and Performance,Smith, Steven T.Senne, Kenneth D.Philips, ScottKao, Edward K.Bernstein, Garrett,Computer Science - Social and Information NetworksComputer Science - Machine LearningMathematics - Statistics TheoryPhysics - Physics and SocietyStatistics - Machine Learning,Network detection is an important capability in many areas of applied\nresearch in which data can be represented as a graph of entities and\nrelationships. Oftentimes the object of interest is a relatively small subgraph\nin an enormous, potentially uninteresting background. This aspect characterizes\nnetwork detection as a \"big data\" problem. Graph partitioning and network\ndiscovery have been major research areas over the last ten years, driven by\ninterest in internet search, cyber security, social networks, and criminal or\nterrorist activities. The specific problem of network discovery is addressed as\na special case of graph partitioning in which membership in a small subgraph of\ninterest must be determined. Algebraic graph theory is used as the basis to\nanalyze and compare different network detection methods. A new Bayesian network\ndetection framework is introduced that partitions the graph based on prior\ninformation and direct observations. The new approach, called space-time threat\npropagation, is proved to maximize the probability of detection and is\ntherefore optimum in the Neyman-Pearson sense. This optimality criterion is\ncompared to spectral community detection approaches which divide the global\ngraph into subsets or communities with optimal connectivity properties. We also\nexplore a new generative stochastic model for covert networks and analyze using\nreceiver operating characteristics the detection performance of both classes of\noptimal detection techniques.Comment: Submitted to IEEE Trans. Signal Processing", "1303.5678": "Interference alignment for the MIMO interference channel,Bresler, GuyCartwright, DustinTse, David,Computer Science - Information Theory,We study vector space interference alignment for the MIMO interference\nchannel with no time or frequency diversity, and no symbol extensions. We prove\nboth necessary and sufficient conditions for alignment. In particular, we\ncharacterize the feasibility of alignment for the symmetric three-user channel\nwhere all users transmit along d dimensions, all transmitters have M antennas\nand all receivers have N antennas, as well as feasibility of alignment for the\nfully symmetric (M=N) channel with an arbitrary number of users.\n  An implication of our results is that the total degrees of freedom available\nin a K-user interference channel, using only spatial diversity from the\nmultiple antennas, is at most 2. This is in sharp contrast to the K/2 degrees\nof freedom shown to be possible by Cadambe and Jafar with arbitrarily large\ntime or frequency diversity.\n  Moving beyond the question of feasibility, we additionally discuss\ncomputation of the number of solutions using Schubert calculus in cases where\nthere are a finite number of solutions.Comment: 16 pages, 7 figures, final submitted version", "1303.7037": "Parameterized Complexity of Discrete Morse Theory,Burton, Benjamin A.Lewiner, ThomasPaix\u00e3o, Jo\u00e3oSpreer, Jonathan,Computer Science - Computational GeometryComputer Science - Computational ComplexityMathematics - Geometric Topology68Q17, 68Q15, 57Q15, 58E05, 68R01,Optimal Morse matchings reveal essential structures of cell complexes which\nlead to powerful tools to study discrete geometrical objects, in particular\ndiscrete 3-manifolds. However, such matchings are known to be NP-hard to\ncompute on 3-manifolds, through a reduction to the erasability problem.\n  Here, we refine the study of the complexity of problems related to discrete\nMorse theory in terms of parameterized complexity. On the one hand we prove\nthat the erasability problem is W[P]-complete on the natural parameter. On the\nother hand we propose an algorithm for computing optimal Morse matchings on\ntriangulations of 3-manifolds which is fixed-parameter tractable in the\ntreewidth of the bipartite graph representing the adjacency of the 1- and\n2-simplexes. This algorithm also shows fixed parameter tractability for\nproblems such as erasability and maximum alternating cycle-free matching. We\nfurther show that these results are also true when the treewidth of the dual\ngraph of the triangulated 3-manifold is bounded. Finally, we investigate the\nrespective treewidths of simplicial and generalized triangulations of\n3-manifolds.Comment: To appear in Proceedings of the Twenty-Ninth Annual Symposium on\n  Computational Geometry (SoCG). 25 pages, 8 figures, 2 tables", "1304.0912": "Structures Without Scattered-Automatic Presentation,Kartzow, AlexanderSchlicht, Philipp,Computer Science - Formal Languages and Automata TheoryMathematics - Logic,Bruyere and Carton lifted the notion of finite automata reading infinite\nwords to finite automata reading words with shape an arbitrary linear order L.\nAutomata on finite words can be used to represent infinite structures, the\nso-called word-automatic structures. Analogously, for a linear order L there is\nthe class of L-automatic structures. In this paper we prove the following\nlimitations on the class of L-automatic structures for a fixed L of finite\ncondensation rank 1+\\alpha. Firstly, no scattered linear order with finite\ncondensation rank above \\omega^(\\alpha+1) is L-\\alpha-automatic. In particular,\nevery L-automatic ordinal is below \\omega^\\omega^(\\alpha+1). Secondly, we\nprovide bounds on the (ordinal) height of well-founded order trees that are\nL-automatic. If \\alpha is finite or L is an ordinal, the height of such a tree\nis bounded by \\omega^{\\alpha+1}. Finally, we separate the class of\ntree-automatic structures from that of L-automatic structures for any ordinal\nL: the countable atomless boolean algebra is known to be tree-automatic, but we\nshow that it is not L-automatic.Comment: 10 pages + 20 pages Appendix; accepted for CiE 2013", "1304.1572": "Stable and Informative Spectral Signatures for Graph Matching,Hu, NanRustamov, Raif M.Guibas, Leonidas,Computer Science - Computer Vision and Pattern Recognition,In this paper, we consider the approximate weighted graph matching problem\nand introduce stable and informative first and second order compatibility terms\nsuitable for inclusion into the popular integer quadratic program formulation.\nOur approach relies on a rigorous analysis of stability of spectral signatures\nbased on the graph Laplacian. In the case of the first order term, we derive an\nobjective function that measures both the stability and informativeness of a\ngiven spectral signature. By optimizing this objective, we design new spectral\nnode signatures tuned to a specific graph to be matched. We also introduce the\npairwise heat kernel distance as a stable second order compatibility term; we\njustify its plausibility by showing that in a certain limiting case it\nconverges to the classical adjacency matrix-based second order compatibility\nfunction. We have tested our approach on a set of synthetic graphs, the\nwidely-used CMU house sequence, and a set of real images. These experiments\nshow the superior performance of our first and second order compatibility terms\nas compared with the commonly used ones.Comment: final version for CVPR2014", "1304.2503": "Simulating the Smart Grid,P\u00f6chacker, ManfredSobe, AnitaElmenreich, Wilfried,Computer Science - Systems and Control,Major challenges for the transition of power systems do not only tackle power\nelectronics but also communication technology, power market economy and user\nacceptance studies. Simulation is an important research method therein, as it\nhelps to avoid costly failures. A common smart grid simulation platform is\nstill missing. We introduce a conceptual model of agents in multiple flow\nnetworks. Flow networks extend the depth of established power flow analysis\nthrough use of networks of information flow and financial transactions. We use\nthis model as a basis for comparing different power system simulators.\nFurthermore, a quantitative comparison of simulators is done to facilitate the\ndecision for a suitable tool in comprehensive smart grid simulation.Comment: 6 pages, 2 figures, 2 tables, PowerTech 2013 Conference in Grenoble", "1304.2816": "Asymptotic Behaviour and Ratios of Complexity in Cellular Automata,Zenil, Hector,Nonlinear Sciences - Cellular Automata and Lattice GasesComputer Science - Computational Complexity,We study the asymptotic behaviour of symbolic computing systems, notably\none-dimensional cellular automata (CA), in order to ascertain whether and at\nwhat rate the number of complex versus simple rules dominate the rule space for\nincreasing neighbourhood range and number of symbols (or colours), and how\ndifferent behaviour is distributed in the spaces of different cellular automata\nformalisms. Using two different measures, Shannon's block entropy and\nKolmogorov complexity, the latter approximated by two different methods\n(lossless compressibility and block decomposition), we arrive at the same trend\nof larger complex behavioural fractions. We also advance a notion of asymptotic\nand limit behaviour for individual rules, both over initial conditions and\nruntimes, and we provide a formalisation of Wolfram's classification as a limit\nfunction in terms of Kolmogorov complexity.Comment: 22 pages, 13 figures. As appeared in the International Journal of\n  Bifurcation and Chaos with corrections to the definition of Wolfram class", "1304.3944": "Smart Microgrids: Overview and Outlook,Sobe, AnitaElmenreich, Wilfried,Computer Science - Emerging TechnologiesComputer Science - Computers and SocietyComputer Science - Systems and Control,The idea of changing our energy system from a hierarchical design into a set\nof nearly independent microgrids becomes feasible with the availability of\nsmall renewable energy generators. The smart microgrid concept comes with\nseveral challenges in research and engineering targeting load balancing,\npricing, consumer integration and home automation. In this paper we first\nprovide an overview on these challenges and present approaches that target the\nproblems identified. While there exist promising algorithms for the particular\nfield, we see a missing integration which specifically targets smart\nmicrogrids. Therefore, we propose an architecture that integrates the presented\napproaches and defines interfaces between the identified components such as\ngenerators, storage, smart and \\dq{dumb} devices.Comment: presented at the GI Informatik 2012, Braunschweig Germany, Smart Grid\n  Workshop", "1304.4964": "Newton-Based Optimization for Kullback-Leibler Nonnegative Tensor\n  Factorizations,Hansen, SamanthaPlantenga, ToddKolda, Tamara G.,Mathematics - Numerical AnalysisComputer Science - Numerical Analysis,Tensor factorizations with nonnegative constraints have found application in\nanalyzing data from cyber traffic, social networks, and other areas. We\nconsider application data best described as being generated by a Poisson\nprocess (e.g., count data), which leads to sparse tensors that can be modeled\nby sparse factor matrices. In this paper we investigate efficient techniques\nfor computing an appropriate canonical polyadic tensor factorization based on\nthe Kullback-Leibler divergence function. We propose novel subproblem solvers\nwithin the standard alternating block variable approach. Our new methods\nexploit structure and reformulate the optimization problem as small independent\nsubproblems. We employ bound-constrained Newton and quasi-Newton methods. We\ncompare our algorithms against other codes, demonstrating superior speed for\nhigh accuracy results and the ability to quickly find sparse solutions.Comment: Clarified notation in section 3.1.1, and used simpler score()\n  function in section B.2", "1304.5591": "Parameterized Complexity of 1-Planarity,Bannister, Michael J.Cabello, SergioEppstein, David,Computer Science - Data Structures and Algorithms,We consider the problem of finding a 1-planar drawing for a general graph,\nwhere a 1-planar drawing is a drawing in which each edge participates in at\nmost one crossing. Since this problem is known to be NP-hard we investigate the\nparameterized complexity of the problem with respect to the vertex cover\nnumber, tree-depth, and cyclomatic number. For these parameters we construct\nfixed-parameter tractable algorithms. However, the problem remains NP-complete\nfor graphs of bounded bandwidth, pathwidth, or treewidth.Comment: WADS 2013", "1304.6116": "Selling Multiple Correlated Goods: Revenue Maximization and Menu-Size\n  Complexity (old title: \"The Menu-Size Complexity of Auctions\"),Hart, SergiuNisan, Noam,Computer Science - Computer Science and Game Theory,We consider the well known, and notoriously difficult, problem of a single\nrevenue-maximizing seller selling two or more heterogeneous goods to a single\nbuyer whose private values for the goods are drawn from a (possibly correlated)\nknown distribution, and whose valuation is additive over the goods. We show\nthat when there are two (or more) goods, _simple mechanisms_ -- such as selling\nthe goods separately or as a bundle -- _may yield only a negligible fraction of\nthe optimal revenue_. This resolves the open problem of Briest, Chawla,\nKleinberg, and Weinberg (JET 2015) who prove the result for at least three\ngoods in the related setup of a unit-demand buyer. We also introduce the menu\nsize as a simple measure of the complexity of mechanisms, and show that the\nrevenue may increase polynomially with _menu size_ and that no bounded menu\nsize can ensure any positive fraction of the optimal revenue. The menu size\nalso turns out to \"pin down\" the revenue properties of deterministic\nmechanisms.Comment: Presented at the 2013 ACM EC conference", "1304.6896": "Strongly light subgraphs in the 1-planar graphs with minimum degree 7,Wang, Tao,Mathematics - CombinatoricsComputer Science - Discrete Mathematics05C10,A graph is {\\em $1$-planar} if it can be drawn in the plane such that every\nedge crosses at most one other edge. A connected graph $H$ is {\\em strongly\nlight} in a family of graphs $\\mathfrak{G}$, if there exists a constant\n$\\lambda$, such that every graph $G$ in $\\mathfrak{G}$ contains a subgraph $K$\nisomorphic to $H$ with $\\deg_{G}(v) \\leq \\lambda$ for all $v \\in V(K)$. In this\npaper, we present some strongly light subgraphs in the family of $1$-planar\ngraphs with minimum degree~$7$.Comment: 6 pages, 6 figures,\n  http://amc-journal.eu/index.php/amc/article/view/564. in Ars Mathematica\n  Contemporanea, 2015", "1304.7480": "The Ergodic Capacity of the Multiple Access Channel Under Distributed\n  Scheduling - Order Optimality of Linear Receivers,Kampeas, JosephCohen, AsafGurewitz, Omer,Computer Science - Information Theory,Consider the problem of a Multiple-Input Multiple-Output (MIMO)\nMultiple-Access Channel (MAC) at the limit of large number of users. Clearly,\nin practical scenarios, only a small subset of the users can be scheduled to\nutilize the channel simultaneously. Thus, a problem of user selection arises.\nHowever, since solutions which collect Channel State Information (CSI) from all\nusers and decide on the best subset to transmit in each slot do not scale when\nthe number of users is large, distributed algorithms for user selection are\nadvantageous.\n  In this paper, we analyse a distributed user selection algorithm, which\nselects a group of users to transmit without coordinating between users and\nwithout all users sending CSI to the base station. This threshold-based\nalgorithm is analysed for both Zero-Forcing (ZF) and Minimum Mean Square Error\n(MMSE) receivers, and its expected sum-rate in the limit of large number of\nusers is investigated. It is shown that for large number of users it achieves\nthe same scaling laws as the optimal centralized scheme.Comment: 44 pages, 9 figures", "1305.0750": "Multi-Sided Boundary Labeling,Kindermann, PhilippNiedermann, BenjaminRutter, IgnazSchaefer, MarcusSchulz, Andr\u00e9Wolff, Alexander,Computer Science - Computational Geometry,In the Boundary Labeling problem, we are given a set of $n$ points, referred\nto as sites, inside an axis-parallel rectangle $R$, and a set of $n$ pairwise\ndisjoint rectangular labels that are attached to $R$ from the outside. The task\nis to connect the sites to the labels by non-intersecting rectilinear paths,\nso-called leaders, with at most one bend.\n  In this paper, we study the Multi-Sided Boundary Labeling problem, with\nlabels lying on at least two sides of the enclosing rectangle. We present a\npolynomial-time algorithm that computes a crossing-free leader layout if one\nexists. So far, such an algorithm has only been known for the cases in which\nlabels lie on one side or on two opposite sides of $R$ (here a crossing-free\nsolution always exists). The case where labels may lie on adjacent sides is\nmore difficult. We present efficient algorithms for testing the existence of a\ncrossing-free leader layout that labels all sites and also for maximizing the\nnumber of labeled sites in a crossing-free leader layout. For two-sided\nboundary labeling with adjacent sides, we further show how to minimize the\ntotal leader length in a crossing-free layout.", "1305.2386": "Disappointment in Social Choice Protocols,Javidian, Mohammad AliRamezanian, Rasoul,Computer Science - Multiagent Systems91B14,Social choice theory is a theoretical framework for analysis of combining\nindividual preferences, interests, or welfare to reach a collective decision or\nsocial welfare in some sense. We introduce a new criterion for social choice\nprotocols called social disappointment. Social disappointment happens when the\noutcome of a voting system occurs for those alternatives which are at the end\nof at least half of individual preference profiles. Here we introduce some\nprotocols that prevent social disappointment and prove an impossibility theorem\nbased on this key concept.Comment: 15 pages. arXiv admin note: substantial text overlap with\n  arXiv:1305.2386", "1305.2494": "Computing Solution Operators of Boundary-value Problems for Some Linear\n  Hyperbolic Systems of PDEs,Selivanova, SvetlanaSelivanov, Victor,Computer Science - Numerical AnalysisMathematics - Numerical Analysis03D78, 58J45, 65M06, 65M25F.1.1G.1.8,We discuss possibilities of application of Numerical Analysis methods to\nproving computability, in the sense of the TTE approach, of solution operators\nof boundary-value problems for systems of PDEs. We prove computability of the\nsolution operator for a symmetric hyperbolic system with computable real\ncoefficients and dissipative boundary conditions, and of the Cauchy problem for\nthe same system (we also prove computable dependence on the coefficients) in a\ncube $Q\\subseteq\\mathbb R^m$. Such systems describe a wide variety of physical\nprocesses (e.g. elasticity, acoustics, Maxwell equations). Moreover, many\nboundary-value problems for the wave equation also can be reduced to this case,\nthus we partially answer a question raised in Weihrauch and Zhong (2002).\nCompared with most of other existing methods of proving computability for PDEs,\nthis method does not require existence of explicit solution formulas and is\nthus applicable to a broader class of (systems of) equations.Comment: 31 pages", "1305.4732": "Enabling Self-Powered Autonomous Wireless Sensors with New-Generation\n  I2C-RFID Chips,De Donno, D.Catarinucci, L.Tarricone, L.,Computer Science - Other Computer Science,A self-powered autonomous RFID device with sensing and computing capabilities\nis presented in this paper. Powered by an RF energy-harvesting circuit enhanced\nby a DC-DC voltage booster in silicon-on-insulator (SOI) technology, the device\nrelies on a microcontroller and a new generation I2C-RFID chip to wirelessly\ndeliver sensor data to standard RFID EPC Class-1 Generation-2 (Gen2) readers.\nWhen the RF power received from the interrogating reader is -14 dBm or higher,\nthe device, fabricated on an FR4 substrate using low-cost discrete components,\nis able to produce 2.4-V DC voltage to power its circuitry. The experimental\nresults demonstrate the effectiveness of the device to perform reliable sensor\ndata transmissions up to 5 meters in fully-passive mode. To the best of our\nknowledge, this represents the longest read range ever reported for passive UHF\nRFID sensors compliant with the EPC Gen2 standard.", "1305.4874": "The Query Complexity of Correlated Equilibria,Hart, SergiuNisan, Noam,Computer Science - Computer Science and Game TheoryComputer Science - Data Structures and Algorithms,We consider the complexity of finding a correlated equilibrium of an\n$n$-player game in a model that allows the algorithm to make queries on\nplayers' payoffs at pure strategy profiles. Randomized regret-based dynamics\nare known to yield an approximate correlated equilibrium efficiently, namely,\nin time that is polynomial in the number of players $n$. Here we show that both\nrandomization and approximation are necessary: no efficient deterministic\nalgorithm can reach even an approximate correlated equilibrium, and no\nefficient randomized algorithm can reach an exact correlated equilibrium. The\nresults are obtained by bounding from below the number of payoff queries that\nare needed.", "1305.5592": "Finite-Length and Asymptotic Analysis of Correlogram for Undersampled\n  Data,Shaghaghi, MahdiVorobyov, Sergiy A.,Computer Science - Information Theory,This paper studies a spectrum estimation method for the case that the samples\nare obtained at a rate lower than the Nyquist rate. The method is referred to\nas the correlogram for undersampled data. The algorithm partitions the spectrum\ninto a number of segments and estimates the average power within each spectral\nsegment. This method is able to estimate the power spectrum density of a signal\nfrom undersampled data without essentially requiring the signal to be sparse.\nWe derive the bias and the variance of the spectrum estimator, and show that\nthere is a tradeoff between the accuracy of the estimation, the frequency\nresolution, and the complexity of the estimator. A closed-form approximation of\nthe estimation variance is also derived, which clearly shows how the variance\nis related to different parameters. The asymptotic behavior of the estimator is\nalso investigated, and it is proved that this spectrum estimator is consistent.\nMoreover, the estimation made for different spectral segments becomes\nuncorrelated as the signal length tends to infinity. Finally, numerical\nexamples and simulation results are provided, which approve the theoretical\nconclusions.Comment: 28 pages, 6 figures, submitted to the IEEE Trans. Signal Processing\n  in May 2012 and current version in May 2013. arXiv admin note: text overlap\n  with arXiv:1202.2408", "1305.5670": "What is Visualization Really for?,Chen, MinFloridi, LucianoBorgo, Rita,Computer Science - Human-Computer Interaction,Whenever a visualization researcher is asked about the purpose of\nvisualization, the phrase \"gaining insight\" by and large pops out\ninstinctively. However, it is not absolutely factual that all uses of\nvisualization are for gaining a deep understanding, unless the term insight is\nbroadened to encompass all types of thought. Even when insight is the focus of\na visualization task, it is rather difficult to know what insight is gained,\nhow much, or how accurate. In this paper, we propose that \"saving time\" in\naccomplishing a user's task is the most fundamental objective. By giving\nemphasis to saving time, we can establish a concrete metric, alleviate\nunnecessary contention caused by different interpretations of insight, and\nstimulate new research efforts in some aspects of visualization, such as\nempirical studies, design optimisation and theories of visualization.", "1305.6431": "Certifying Machine Code Safe from Hardware Aliasing: RISC is not\n  necessarily risky,Breuer, Peter T.Bowen, Jonathan P.,Computer Science - Logic in Computer ScienceComputer Science - Software EngineeringD.2.4,Sometimes machine code turns out to be a better target for verification than\nsource code. RISC machine code is especially advantaged with respect to source\ncode in this regard because it has only two instructions that access memory.\nThat architecture forms the basis here for an inference system that can prove\nmachine code safe against `hardware aliasing', an effect that occurs in\nembedded systems. There are programming memes that ensure code is safe from\nhardware aliasing, but we want to certify that a given machine code is provably\nsafe.Comment: First submitted to SEFM 2013 as \"Towards Proving RISC Machine Code\n  not Risky with respect to Memory Aliasing\" (15p+4p Appendix), Resubmitted to\n  and accepted for OpenCert 2013, co-located with SEFM 2013 (16p+6p Appendix)", "1305.7514": "Studying new classes of graph metrics,Chebotarev, Pavel,Mathematics - Metric GeometryComputer Science - Discrete MathematicsMathematics - Combinatorics05C12 05C50 05C05 51K05 15A48 15A51,In data analysis, there is a strong demand for graph metrics that differ from\nthe classical shortest path and resistance distances. Recently, several new\nclasses of graph metrics have been proposed. This paper presents some of them\nfeaturing the cutpoint additive distances. These include the path distances,\nthe reliability distance, the walk distances, and the logarithmic forest\ndistances among others. We discuss a number of connections between these and\nother distances.Comment: Prepared for the Proceedings of GSI2013 - Geometric Science of\n  Information (August 28-30, 2013, Paris). 9 pages, 1 figure", "1306.0760": "Mashup of Meta-Languages and its Implementation in the Kermeta Language\n  Workbench,J\u00e9z\u00e9quel, Jean-MarcCombemale, BenoitBarais, OlivierMonperrus, MartinFouquet, Fran\u00e7ois,Computer Science - Software Engineering,With the growing use of domain-specific languages (DSL) in industry, DSL\ndesign and implementation goes far beyond an activity for a few experts only\nand becomes a challenging task for thousands of software engineers. DSL\nimplementation indeed requires engineers to care for various concerns, from\nabstract syntax, static semantics, behavioral semantics, to extra-functional\nissues such as run-time performance. This paper presents an approach that uses\none meta-language per language implementation concern. We show that the usage\nand combination of those meta-languages is simple and intuitive enough to\ndeserve the term \"mashup\". We evaluate the approach by completely implementing\nthe non trivial fUML modeling language, a semantically sound and executable\nsubset of the Unified Modeling Language (UML).Comment: Published in Software and Systems Modeling (2013)", "1306.1167": "A Graphical Transformation for Belief Propagation: Maximum Weight\n  Matchings and Odd-Sized Cycles,Ahn, SungsooChertkov, MichaelGelfand, Andrew E.Park, SejunShin, Jinwoo,Computer Science - Data Structures and Algorithms,We study the Maximum Weight Matching (MWM) problem for general graphs through\nthe max-product Belief Propagation (BP) and related Linear Programming (LP).\nThe BP approach provides distributed heuristics for finding the Maximum A\nPosteriori (MAP) assignment in a joint probability distribution represented by\na Graphical Model (GM) and respective LPs can be considered as continuous\nrelaxations of the discrete MAP problem. It was recently shown that a BP\nalgorithm converges to the correct MWM assignment under a simple GM formulation\nof MAP/MWM as long as the corresponding LP relaxation is tight. First, under\nthe motivation for forcing the tightness condition, we consider a new GM\nformulation of MWM, say C-GM, using non-intersecting odd-sized cycles in the\ngraph: the new corresponding LP relaxation, say C-LP, becomes tight for more\nMWM instances. However, the tightness of C-LP now does not guarantee such\nconvergence and correctness of the new BP on C-GM. To address the issue, we\nintroduce a novel graph transformation applied to C-GM, which results in\nanother GM formulation of MWM, and prove that the respective BP on it converges\nto the correct MAP/MWM assignment as long as C-LP is tight. Finally, we also\nshow that C-LP always has half-integral solutions, which leads to an efficient\nBP-based MWM heuristic consisting of making sequential, `cutting plane',\nmodifications to the underlying GM. Our experiments show that this BP-based\ncutting plane heuristic performs as well as that based on traditional LP\nsolvers.", "1306.1595": "Layered Separators in Minor-Closed Graph Classes with Applications,Dujmovi\u0107, VidaMorin, PatWood, David R.,Mathematics - CombinatoricsComputer Science - Computational GeometryComputer Science - Discrete Mathematics,Graph separators are a ubiquitous tool in graph theory and computer science.\nHowever, in some applications, their usefulness is limited by the fact that the\nseparator can be as large as $\\Omega(\\sqrt{n})$ in graphs with $n$ vertices.\nThis is the case for planar graphs, and more generally, for proper minor-closed\nclasses. We study a special type of graph separator, called a \"layered\nseparator\", which may have linear size in $n$, but has bounded size with\nrespect to a different measure, called the \"width\". We prove, for example, that\nplanar graphs and graphs of bounded Euler genus admit layered separators of\nbounded width. More generally, we characterise the minor-closed classes that\nadmit layered separators of bounded width as those that exclude a fixed apex\ngraph as a minor.\n  We use layered separators to prove $\\mathcal{O}(\\log n)$ bounds for a number\nof problems where $\\mathcal{O}(\\sqrt{n})$ was a long-standing previous best\nbound. This includes the nonrepetitive chromatic number and queue-number of\ngraphs with bounded Euler genus. We extend these results with a\n$\\mathcal{O}(\\log n)$ bound on the nonrepetitive chromatic number of graphs\nexcluding a fixed topological minor, and a $\\log^{ \\mathcal{O}(1)}n$ bound on\nthe queue-number of graphs excluding a fixed minor. Only for planar graphs were\n$\\log^{ \\mathcal{O}(1)}n$ bounds previously known. Our results imply that every\n$n$-vertex graph excluding a fixed minor has a 3-dimensional grid drawing with\n$n\\log^{ \\mathcal{O}(1)}n$ volume, whereas the previous best bound was\n$\\mathcal{O}(n^{3/2})$.", "1306.2476": "A Systematically Empirical Evaluation of Vulnerability Discovery Models:\n  a Study on Browsers' Vulnerabilities,Nguyen, Viet HungMassacci, Fabio,Computer Science - Cryptography and Security,A precise vulnerability discovery model (VDM) will provide a useful insight\nto assess software security, and could be a good prediction instrument for both\nsoftware vendors and users to understand security trends and plan ahead\npatching schedule accordingly. Thus far, several models have been proposed and\nvalidated. Yet, no systematically independent validation by somebody other than\nthe author exists. Furthermore, there are a number of issues that might bias\nprevious studies in the field. In this work, we fill in the gap by introducing\nan empirical methodology that systematically evaluates the performance of a VDM\nin two aspects: quality and predictability. We further apply this methodology\nto assess existing VDMs. The results show that some models should be rejected\noutright, while some others might be adequate to capture the discovery process\nof vulnerabilities. We also consider different usage scenarios of VDMs and find\nthat the simplest linear model is the most appropriate choice in terms of both\nquality and predictability when browsers are young. Otherwise, logistics-based\nmodels are better choices.Comment: 15 pages", "1306.2595": "Capacity Scaling in MIMO Systems with General Unitarily Invariant Random\n  Matrices,\u00c7akmak, BurakM\u00fcller, Ralf R.Fleury, Bernard H.,Computer Science - Information Theory,We investigate the capacity scaling of MIMO systems with the system\ndimensions. To that end, we quantify how the mutual information varies when the\nnumber of antennas (at either the receiver or transmitter side) is altered. For\na system comprising $R$ receive and $T$ transmit antennas with $R>T$, we find\nthe following: By removing as many receive antennas as needed to obtain a\nsquare system (provided the channel matrices before and after the removal have\nfull rank) the maximum resulting loss of mutual information over all\nsignal-to-noise ratios (SNRs) depends only on $R$, $T$ and the matrix of\nleft-singular vectors of the initial channel matrix, but not on its singular\nvalues. In particular, if the latter matrix is Haar distributed the ergodic\nrate loss is given by $\\sum_{t=1}^{T}\\sum_{r=T+1}^{R}\\frac{1}{r-t}$ nats. Under\nthe same assumption, if $T,R\\to \\infty$ with the ratio $\\phi\\triangleq T/R$\nfixed, the rate loss normalized by $R$ converges almost surely to $H(\\phi)$\nbits with $H(\\cdot)$ denoting the binary entropy function. We also quantify and\nstudy how the mutual information as a function of the system dimensions\ndeviates from the traditionally assumed linear growth in the minimum of the\nsystem dimensions at high SNR.Comment: Accepted for publication in the IEEE Transactions on Information\n  Theory", "1306.3261": "arXiv e-prints and the journal of record: An analysis of roles and\n  relationships,Lariviere, VincentSugimoto, Cassidy R.Macaluso, BenoitMilojevic, StasaCronin, BlaiseThelwall, Mike,Computer Science - Digital Libraries,Since its creation in 1991, arXiv has become central to the diffusion of\nresearch in a number of fields. Combining data from the entirety of arXiv and\nthe Web of Science (WoS), this paper investigates (a) the proportion of papers\nacross all disciplines that are on arXiv and the proportion of arXiv papers\nthat are in the WoS, (b) elapsed time between arXiv submission and journal\npublication, and (c) the aging characteristics and scientific impact of arXiv\ne-prints and their published version. It shows that the proportion of WoS\npapers found on arXiv varies across the specialties of physics and mathematics,\nand that only a few specialties make extensive use of the repository. Elapsed\ntime between arXiv submission and journal publication has shortened but remains\nlonger in mathematics than in physics. In physics, mathematics, as well as in\nastronomy and astrophysics, arXiv versions are cited more promptly and decay\nfaster than WoS papers. The arXiv versions of papers - both published and\nunpublished - have lower citation rates than published papers, although there\nis almost no difference in the impact of the arXiv versions of both published\nand unpublished papers.Comment: 29 pages, 11 figures", "1306.3726": "Automatic functions, linear time and learning,Case, JohnJain, SanjaySeah, SamuelStephan, Frank,Computer Science - Formal Languages and Automata Theory,The present work determines the exact nature of {\\em linear time computable}\nnotions which characterise automatic functions (those whose graphs are\nrecognised by a finite automaton). The paper also determines which type of\nlinear time notions permit full learnability for learning in the limit of\nautomatic classes (families of languages which are uniformly recognised by a\nfinite automaton). In particular it is shown that a function is automatic iff\nthere is a one-tape Turing machine with a left end which computes the function\nin linear time where the input before the computation and the output after the\ncomputation both start at the left end. It is known that learners realised as\nautomatic update functions are restrictive for learning. In the present work it\nis shown that one can overcome the problem by providing work tapes additional\nto a resource-bounded base tape while keeping the update-time to be linear in\nthe length of the largest datum seen so far. In this model, one additional such\nwork tape provides additional learning power over the automatic learner model\nand two additional work tapes give full learning power. Furthermore, one can\nalso consider additional queues or additional stacks in place of additional\nwork tapes and for these devices, one queue or two stacks are sufficient for\nfull learning power while one stack is insufficient.Comment: A preliminary version was presented at the conference CiE 2012\n  (Computability in Europe)", "1306.3875": "Roughening Methods to Prevent Sample Impoverishment in the Particle PHD\n  Filter,Li, TianchengSattar, Tariq P.Han, QingSun, Shudong,Computer Science - Other Computer Science,Mahler's PHD (Probability Hypothesis Density) filter and its particle\nimplementation (as called the particle PHD filter) have gained popularity to\nsolve general MTT (Multi-target Tracking) problems. However, the resampling\nprocedure used in the particle PHD filter can cause sample impoverishment. To\nrejuvenate the diversity of particles, two easy-to-implement roughening\napproaches are presented to enhance the particle PHD filter. One termed as\n\"separate-roughening\" is inspired by Gordon's roughening procedure that is\napplied on the resampled particles. Another termed as \"direct-roughening\" is\nimplemented by increasing the simulation noise of the state propagation of\nparticles. Four proposals are presented to customize the roughening approach.\nSimulations are presented showing that the roughening approach can benefit the\nparticle PHD filter, especially when the sample size is small.Comment: 16th International Conference on Information Fusion(FUSION2013), 9-12\n  July 2013", "1306.4664": "Efficient Two-Stage Group Testing Algorithms for Genetic Screening,Huber, Michael,Computer Science - Data Structures and AlgorithmsMathematics - CombinatoricsQuantitative Biology - Quantitative Methods,Efficient two-stage group testing algorithms that are particularly suited for\nrapid and less-expensive DNA library screening and other large scale biological\ngroup testing efforts are investigated in this paper. The main focus is on\nnovel combinatorial constructions in order to minimize the number of individual\ntests at the second stage of a two-stage disjunctive testing procedure.\nBuilding on recent work by Levenshtein (2003) and Tonchev (2008), several new\ninfinite classes of such combinatorial designs are presented.Comment: 14 pages; to appear in \"Algorithmica\". Part of this work has been\n  presented at the ICALP 2011 Group Testing Workshop; arXiv:1106.3680", "1306.5111": "Low-Density Parity-Check Codes From Transversal Designs With Improved\n  Stopping Set Distributions,Gruner, AlexanderHuber, Michael,Computer Science - Information TheoryComputer Science - Discrete MathematicsMathematics - Combinatorics,This paper examines the construction of low-density parity-check (LDPC) codes\nfrom transversal designs based on sets of mutually orthogonal Latin squares\n(MOLS). By transferring the concept of configurations in combinatorial designs\nto the level of Latin squares, we thoroughly investigate the occurrence and\navoidance of stopping sets for the arising codes. Stopping sets are known to\ndetermine the decoding performance over the binary erasure channel and should\nbe avoided for small sizes. Based on large sets of simple-structured MOLS, we\nderive powerful constraints for the choice of suitable subsets, leading to\nimproved stopping set distributions for the corresponding codes. We focus on\nLDPC codes with column weight 4, but the results are also applicable for the\nconstruction of codes with higher column weights. Finally, we show that a\nsubclass of the presented codes has quasi-cyclic structure which allows\nlow-complexity encoding.Comment: 11 pages; to appear in \"IEEE Transactions on Communications\"", "1306.5585": "Soundness and Completeness of the NRB Verification Logic,Breuer, Peter T.Pickin, Simon J.,Computer Science - Logic in Computer ScienceB.1.2D.2.4,This short paper gives a model for and a proof of completeness of the NRB\nverification logic for deterministic imperative programs, the logic having been\nused in the past as the basis for automated semantic checks of large,\nfast-changing, open source C code archives, such as that of the Linux kernel\nsource. The model is a colored state transitions model that approximates from\nabove the set of transitions possible for a program. Correspondingly, the logic\ncatches all traces that may trigger a particular defect at a given point in the\nprogram, but may also flag false positives.Comment: To appear in OpenCert 2013 Workshop, Sept 23, Madrid, 15p", "1306.5720": "On the Resilience of Bipartite Networks,Heinecke, ShelbyPerkins, WillReyzin, Lev,Computer Science - Data Structures and AlgorithmsComputer Science - Social and Information Networks,Motivated by problems modeling the spread of infections in networks, in this\npaper we explore which bipartite graphs are most resilient to widespread\ninfections under various parameter settings. Namely, we study bipartite\nnetworks with a requirement of a minimum degree $d$ on one side under an\nindependent infection, independent transmission model. We completely\ncharacterize the optimal graphs in the case $d=1$, which already produces\nnon-trivial behavior, and we give extremal results for the more general cases.\nWe show that in the case $d=2$, surprisingly, the optimally resilient set of\ngraphs includes a graph that is not one of the two \"extremes\" found in the case\n$d=1$.\n  Then, we briefly examine the case where we force a connectivity requirement\ninstead of a one-sided degree requirement and again, we find that the set of\nthe most resilient graphs contains more than the two \"extremes.\" We also show\nthat determining the subgraph of an arbitrary bipartite graph most resilient to\ninfection is NP-hard for any one-sided minimal degree $d \\ge 1$.Comment: 12 pages", "1306.6109": "Broadcasting in Ad Hoc Multiple Access Channels,Anantharamu, LakshmiChlebus, Bogdan S.,Computer Science - Networking and Internet Architecture,We study broadcast in multiple access channels in dynamic adversarial\nsettings. There is an unbounded supply of anonymous stations attached to a\nsynchronous channel. There is an adversary who injects packets into stations to\nbe broadcast on the channel. The adversary is restricted by injection rate,\nburstiness, and by how many passive stations can be simultaneously activated by\nproviding them with packets. We consider deterministic distributed broadcast\nalgorithms, which are further categorized by their properties. We investigate\nfor which injection rates can algorithms attain bounded packet latency, when\nadversaries are restricted to be able to activate at most one station per\nround. The rates of algorithms we present make the increasing sequence\nconsisting of $\\frac{1}{3}$, $\\frac{3}{8}$ and $\\frac{1}{2}$, reflecting the\nadditional features of algorithms. We show that injection rate $\\frac{3}{4}$\ncannot be handled with bounded packet latency.", "1306.6458": "Harmony Perception by Periodicity Detection,Stolzenburg, Frieder,Computer Science - Sound,The perception of consonance/dissonance of musical harmonies is strongly\ncorrelated with their periodicity. This is shown in this article by\nconsistently applying recent results from psychophysics and neuroacoustics,\nnamely that the just noticeable difference between pitches for humans is about\n1% for the musically important low frequency range and that periodicities of\ncomplex chords can be detected in the human brain. Based thereon, the concepts\nof relative and logarithmic periodicity with smoothing are introduced as\npowerful measures of harmoniousness. The presented results correlate\nsignificantly with empirical investigations on the perception of chords. Even\nfor scales, plausible results are obtained. For example, all classical church\nmodes appear in the front ranks of all theoretically possible seven-tone\nscales.Comment: extended, revised, and corrected version, 33 pages, 8 figures, 9\n  tables", "1307.0426": "An Empirical Study into Annotator Agreement, Ground Truth Estimation,\n  and Algorithm Evaluation,Lampert, Thomas A.Stumpf, Andr\u00e9Gan\u00e7arski, Pierre,Computer Science - Computer Vision and Pattern RecognitionComputer Science - Artificial IntelligenceComputer Science - Machine LearningI.4.6I.5.4,Although agreement between annotators has been studied in the past from a\nstatistical viewpoint, little work has attempted to quantify the extent to\nwhich this phenomenon affects the evaluation of computer vision (CV) object\ndetection algorithms. Many researchers utilise ground truth (GT) in experiments\nand more often than not this GT is derived from one annotator's opinion. How\ndoes the difference in opinion affect an algorithm's evaluation? Four examples\nof typical CV problems are chosen, and a methodology is applied to each to\nquantify the inter-annotator variance and to offer insight into the mechanisms\nbehind agreement and the use of GT. It is found that when detecting linear\nobjects annotator agreement is very low. The agreement in object position,\nlinear or otherwise, can be partially explained through basic image properties.\nAutomatic object detectors are compared to annotator agreement and it is found\nthat a clear relationship exists. Several methods for calculating GTs from a\nnumber of annotations are applied and the resulting differences in the\nperformance of the object detectors are quantified. It is found that the rank\nof a detector is highly dependent upon the method used to form the GT. It is\nalso found that although the STAPLE and LSML GT estimation methods appear to\nrepresent the mean of the performance measured using the individual\nannotations, when there are few annotations, or there is a large variance in\nthem, these estimates tend to degrade. Furthermore, one of the most commonly\nadopted annotation combination methods--consensus voting--accentuates more\nobvious features, which results in an overestimation of the algorithm's\nperformance. Finally, it is concluded that in some datasets it may not be\npossible to state with any confidence that one algorithm outperforms another\nwhen evaluating upon one GT and a method for calculating confidence bounds is\ndiscussed.Comment: 16 pages", "1307.0449": "Arising information regularities in an observer,Lerner, Vladimir S.,Nonlinear Sciences - Adaptation and Self-Organizing SystemsComputer Science - Information Theory58J65, 60J65, 93B52, 93E02, 93E15, 93E30H.1.1,The approach defines information process from probabilistic observation,\nemerging microprocess,qubit, encoding bits, evolving macroprocess, and extends\nto Observer information self-organization, cognition, intelligence and\nunderstanding communicating information. Studying information originating in\nquantum process focuses not on particle physics but on natural interactive\nimpulse modeling Bit composing information observer. Information emerges from\nKolmogorov probabilities field when sequences of 1-0 probabilities link Markov\nprobabilities modeling arising observer. These objective yes-no probabilities\nvirtually cuts observing entropy hidden in cutting correlation decreasing\nMarkov process entropy and increasing entropy of cutting impulse running\nminimax principle. Merging impulse curves and rotates yes-no conjugated\nentropies in microprocess. The entropies entangle within impulse time interval\nending with beginning space. The opposite curvature lowers potential energy\nconverting entropy to memorized bit. The memorized information binds reversible\nmicroprocess with irreversible information macroprocess. Multiple interacting\nBits self-organize information process encoding causality, logic and\ncomplexity. Trajectory of observation process carries probabilistic and certain\nwave function self-building structural macrounits. Macrounits logically\nself-organize information networks encoding in triplet code. Multiple IN\nenclose observer information cognition and intelligence. Observer cognition\nassembles attracting common units in resonances forming IN hierarchy accepting\nonly units recognizing IN node. Maximal number of accepted triplets measures\nthe observer information intelligence. Intelligent observer recognizes and\nencodes digital images in message transmission enables understanding the\nmessage meaning. Cognitive logic self-controls encoding the intelligence in\ndouble helix code.Comment: 138 pages include 16 figures. arXiv admin note: text overlap with\n  arXiv:1212.1710", "1307.2035": "Periodic Strategies: A New Solution Concept and an Algorithm for\n  NonTrivial Strategic Form Games,Oikonomou, V. K.Jost, J.,Computer Science - Computer Science and Game Theory,We introduce a new solution concept, called periodicity, for selecting\noptimal strategies in strategic form games. This periodicity solution concept\nyields new insight into non-trivial games. In mixed strategy strategic form\ngames, periodic solutions yield values for the utility function of each player\nthat are equal to the Nash equilibrium ones. In contrast to the Nash\nstrategies, here the payoffs of each player are robust against what the\nopponent plays. Sometimes, periodicity strategies yield higher utilities, and\nsometimes the Nash strategies do, but often the utilities of these two\nstrategies coincide. We formally define and study periodic strategies in two\nplayer perfect information strategic form games with pure strategies and we\nprove that every non-trivial finite game has at least one periodic strategy,\nwith non-trivial meaning non-degenerate payoffs. In some classes of games where\nmixed strategies are used, we identify quantitative features. Particularly\ninteresting are the implications for collective action games, since there the\ncollective action strategy can be incorporated in a purely non-cooperative\ncontext. Moreover, we address the periodicity issue when the players have a\ncontinuum set of strategies available.Comment: Revised version, similar to the one published in Advances in Complex\n  Systems", "1307.2559": "General Drift Analysis with Tail Bounds,Lehre, Per KristianWitt, Carsten,Computer Science - Neural and Evolutionary Computing68W20,Drift analysis is one of the state-of-the-art techniques for the runtime\nanalysis of randomized search heuristics (RSHs) such as evolutionary algorithms\n(EAs), simulated annealing etc. The vast majority of existing drift theorems\nyield bounds on the expected value of the hitting time for a target state,\ne.g., the set of optimal solutions, without making additional statements on the\ndistribution of this time. We address this lack by providing a general drift\ntheorem that includes bounds on the upper and lower tail of the hitting time\ndistribution. The new tail bounds are applied to prove very precise\nsharp-concentration results on the running time of a simple EA on standard\nbenchmark problems, including the class of general linear functions.\nSurprisingly, the probability of deviating by an $r$-factor in lower order\nterms of the expected time decreases exponentially with $r$ on all these\nproblems. The usefulness of the theorem outside the theory of RSHs is\ndemonstrated by deriving tail bounds on the number of cycles in random\npermutations. All these results handle a position-dependent (variable) drift\nthat was not covered by previous drift theorems with tail bounds. Moreover, our\ntheorem can be specialized into virtually all existing drift theorems with\ndrift towards the target from the literature. Finally, user-friendly\nspecializations of the general drift theorem are given.Comment: Version 2: minor corrections; application of technique to bound the\n  number of cycles in random permutations added. Version 3: minor corrections;\n  Version 4: generalised statement and simplified proof of additive drift\n  theorem; adjusted notation throughout the paper", "1307.2783": "Coping with Unreliable Workers in Internet-based Computing: An\n  Evaluation of Reputation Mechanisms,Christoforou, EvgeniaAnta, Antonio FernandezGeorgiou, ChryssisMosteiro, Miguel A.Sanchez, Angel,Computer Science - Distributed, Parallel, and Cluster ComputingComputer Science - Computer Science and Game Theory68Q85,We present reputation-based mechanisms for building reliable task computing\nsystems over the Internet. The most characteristic examples of such systems are\nthe volunteer computing and the crowdsourcing platforms. In both examples end\nusers are offering over the Internet their computing power or their human\nintelligence to solve tasks either voluntarily or under payment. While the main\nadvantage of these systems is the inexpensive computational power provided, the\nmain drawback is the untrustworthy nature of the end users. Generally, this\ntype of systems are modeled under the \"master-worker\" setting. A \"master\" has a\nset of tasks to compute and instead of computing them locally she sends these\ntasks to available \"workers\" that compute and report back the task results. We\ncategorize these workers in three generic types: altruistic, malicious and\nrational. Altruistic workers that always return the correct result, malicious\nworkers that always return an incorrect result, and rational workers that\ndecide to reply or not truthfully depending on what increases their benefit. We\ndesign a reinforcement learning mechanism to induce a correct behavior to\nrational workers, while the mechanism is complemented by four reputation\nschemes that cope with malice. The goal of the mechanism is to reach a state of\neventual correctness, that is, a stable state of the system in which the master\nalways obtains the correct task results. Analysis of the system gives provable\nguarantees under which truthful behavior can be ensured. Finally, we observe\nthe behavior of the mechanism through simulations that use realistic system\nparameters values. Simulations not only agree with the analysis but also reveal\ninteresting trade-offs between various metrics and parameters. Finally, the\nfour reputation schemes are assessed against the tolerance to cheaters.Comment: 28 pages, 12 figures", "1307.2968": "Introduction to Queueing Theory and Stochastic Teletraffic Models,Zukerman, Moshe,Mathematics - ProbabilityComputer Science - Information Theory,The aim of this textbook is to provide students with basic knowledge of\nstochastic models that may apply to telecommunications research areas, such as\ntraffic modelling, resource provisioning and traffic management. These study\nareas are often collectively called teletraffic. This book assumes prior\nknowledge of a programming language, mathematics, probability and stochastic\nprocesses normally taught in an electrical engineering course. For students who\nhave some but not sufficiently strong background in probability and stochastic\nprocesses, we provide, in the first few chapters, background on the relevant\nconcepts in these areas.Comment: 284 pages", "1307.3142": "Perfect Codes in the Discrete Simplex,Kova\u010devi\u0107, MladenVukobratovi\u0107, Dejan,Computer Science - Information TheoryComputer Science - Discrete Mathematics94B25, 05B40, 52C17, 05C12, 68R99,We study the problem of existence of (nontrivial) perfect codes in the\ndiscrete $ n $-simplex $ \\Delta_{\\ell}^n := \\left\\{ \\begin{pmatrix} x_0,\n\\ldots, x_n \\end{pmatrix} : x_i \\in \\mathbb{Z}_{+}, \\sum_i x_i = \\ell \\right\\}\n$ under $ \\ell_1 $ metric. The problem is motivated by the so-called multiset\ncodes, which have recently been introduced by the authors as appropriate\nconstructs for error correction in the permutation channels. It is shown that $\ne $-perfect codes in the $ 1 $-simplex $ \\Delta_{\\ell}^1 $ exist for any $ \\ell\n\\geq 2e + 1 $, the $ 2 $-simplex $ \\Delta_{\\ell}^2 $ admits an $ e $-perfect\ncode if and only if $ \\ell = 3e + 1 $, while there are no perfect codes in\nhigher-dimensional simplices. In other words, perfect multiset codes exist only\nover binary and ternary alphabets.Comment: 15 pages (single-column), 5 figures. Minor revisions made. Accepted\n  for publication in Designs, Codes and Cryptography", "1307.3544": "Distributed Bayesian Detection with Byzantine Data,Kailkhura, BhavyaHan, Yunghsiang S.Brahma, SwastikVarshney, Pramod K.,Computer Science - Information TheoryComputer Science - Cryptography and SecurityComputer Science - Distributed, Parallel, and Cluster ComputingComputer Science - Computer Science and Game TheoryStatistics - Applications,In this paper, we consider the problem of distributed Bayesian detection in\nthe presence of Byzantines in the network. It is assumed that a fraction of the\nnodes in the network are compromised and reprogrammed by an adversary to\ntransmit false information to the fusion center (FC) to degrade detection\nperformance. The problem of distributed detection is formulated as a binary\nhypothesis test at the FC based on 1-bit data sent by the sensors. The\nexpression for minimum attacking power required by the Byzantines to blind the\nFC is obtained. More specifically, we show that above a certain fraction of\nByzantine attackers in the network, the detection scheme becomes completely\nincapable of utilizing the sensor data for detection. We analyze the problem\nunder different attacking scenarios and derive results for different\nnon-asymptotic cases. It is found that existing asymptotics-based results do\nnot hold under several non-asymptotic scenarios. When the fraction of\nByzantines is not sufficient to blind the FC, we also provide closed form\nexpressions for the optimal attacking strategies for the Byzantines that most\ndegrade the detection performance.Comment: 32 pages, 4 figures, Submitted to IEEE Transactions on Signal\n  Processing", "1307.4062": "Empirical Evidence of Large-Scale Diversity in API Usage of\n  Object-Oriented Software,Mendez, DiegoBaudry, BenoitMonperrus, Martin,Computer Science - Software Engineering,In this paper, we study how object-oriented classes are used across thousands\nof software packages. We concentrate on \"usage diversity'\", defined as the\ndifferent statically observable combinations of methods called on the same\nobject. We present empirical evidence that there is a significant usage\ndiversity for many classes. For instance, we observe in our dataset that Java's\nString is used in 2460 manners. We discuss the reasons of this observed\ndiversity and the consequences on software engineering knowledge and research.", "1307.4355": "Near Linear Time Approximation Schemes for Uncapacitated and Capacitated\n  b--Matching Problems in Nonbipartite Graphs,Ahn, Kook JinGuha, Sudipto,Computer Science - Data Structures and Algorithms,We present the first near optimal approximation schemes for the\n  maximum weighted (uncapacitated or capacitated) $b$--matching\n  problems for non-bipartite graphs that run in time (near) linear in\n  the number of edges. For any $\\delta>3/\\sqrt{n}$ the algorithm\n  produces a $(1-\\delta)$ approximation in $O(m \\poly(\\delta^{-1},\\log\n  n))$ time. We provide fractional solutions for the standard linear\n  programming formulations for these problems and subsequently also\n  provide (near) linear time approximation schemes\n  for rounding the fractional solutions.\n  Through these problems as a vehicle, we also present several ideas\n  in the context of solving linear programs approximately using fast\n  primal-dual algorithms. First, even though the dual of these\n  problems have exponentially many variables and an efficient exact\n  computation of dual weights is infeasible, we show that we can\n  efficiently compute and use a sparse approximation of the dual\n  weights using a combination of (i) adding perturbation to the\n  constraints of the polytope and (ii) amplification followed by\n  thresholding of the dual weights. Second, we show that\n  approximation algorithms can be used to reduce the width of the\n  formulation, and faster convergence.", "1307.5001": "On Lower Complexity Bounds for Large-Scale Smooth Convex Optimization,Guzman, CristobalNemirovski, Arkadi,Mathematics - Optimization and ControlComputer Science - Computational Complexity,We derive lower bounds on the black-box oracle complexity of large-scale\nsmooth convex minimization problems, with emphasis on minimizing smooth (with\nHolder continuous, with a given exponent and constant, gradient) convex\nfunctions over high-dimensional ||.||_p-balls, 1<=p<=\\infty. Our bounds turn\nout to be tight (up to logarithmic in the design dimension factors), and can be\nviewed as a substantial extension of the existing lower complexity bounds for\nlarge-scale convex minimization covering the nonsmooth case and the 'Euclidean'\nsmooth case (minimization of convex functions with Lipschitz continuous\ngradients over Euclidean balls). As a byproduct of our results, we demonstrate\nthat the classical Conditional Gradient algorithm is near-optimal, in the sense\nof Information-Based Complexity Theory, when minimizing smooth convex functions\nover high-dimensional ||.||_\\infty-balls and their matrix analogies -- spectral\nnorm balls in the spaces of square matrices.Comment: Submitted version (minor changes)", "1307.6033": "Sparse Reconstruction-based Detection of Spatial Dimension Holes in\n  Cognitive Radio Networks,Ezzeldin, Yahya H.Sultan, Radwa A.Seddik, Karim G.,Computer Science - Information TheoryComputer Science - Networking and Internet ArchitectureMathematics - Optimization and Control,In this paper, we investigate a spectrum sensing algorithm for detecting\nspatial dimension holes in Multiple Inputs Multiple Outputs (MIMO)\ntransmissions for OFDM systems using Compressive Sensing (CS) tools. This\nextends the energy detector to allow for detecting transmission opportunities\neven if the band is already energy filled. We show that the task described\nabove is not performed efficiently by regular MIMO decoders (such as MMSE\ndecoder) due to possible sparsity in the transmit signal. Since CS\nreconstruction tools take into account the sparsity order of the signal, they\nare more efficient in detecting the activity of the users. Building on\nsuccessful activity detection by the CS detector, we show that the use of a\nCS-aided MMSE decoders yields better performance rather than using either\nCS-based or MMSE decoders separately. Simulations are conducted to verify the\ngains from using CS detector for Primary user activity detection and the\nperformance gain in using CS-aided MMSE decoders for decoding the PU\ninformation for future relaying.Comment: accepted for PIMRC 2013", "1307.6864": "Convex recovery from interferometric measurements,Demanet, LaurentJugnon, Vincent,Mathematics - Numerical AnalysisComputer Science - Information TheoryMathematics - Optimization and Control,This note formulates a deterministic recovery result for vectors $x$ from\nquadratic measurements of the form $(Ax)_i \\overline{(Ax)_j}$ for some\nleft-invertible $A$. Recovery is exact, or stable in the noisy case, when the\ncouples $(i,j)$ are chosen as edges of a well-connected graph. One possible way\nof obtaining the solution is as a feasible point of a simple semidefinite\nprogram. Furthermore, we show how the proportionality constant in the error\nestimate depends on the spectral gap of a data-weighted graph Laplacian. Such\nquadratic measurements have found applications in phase retrieval, angular\nsynchronization, and more recently interferometric waveform inversion.", "1307.7050": "A Comprehensive Evaluation of Machine Learning Techniques for Cancer\n  Class Prediction Based on Microarray Data,Raza, KhalidHasan, Atif N,Computer Science - Machine LearningComputer Science - Computational Engineering, Finance, and Science,Prostate cancer is among the most common cancer in males and its\nheterogeneity is well known. Its early detection helps making therapeutic\ndecision. There is no standard technique or procedure yet which is full-proof\nin predicting cancer class. The genomic level changes can be detected in gene\nexpression data and those changes may serve as standard model for any random\ncancer data for class prediction. Various techniques were implied on prostate\ncancer data set in order to accurately predict cancer class including machine\nlearning techniques. Huge number of attributes and few number of sample in\nmicroarray data leads to poor machine learning, therefore the most challenging\npart is attribute reduction or non significant gene reduction. In this work we\nhave compared several machine learning techniques for their accuracy in\npredicting the cancer class. Machine learning is effective when number of\nattributes (genes) are larger than the number of samples which is rarely\npossible with gene expression data. Attribute reduction or gene filtering is\nabsolutely required in order to make the data more meaningful as most of the\ngenes do not participate in tumor development and are irrelevant for cancer\nprediction. Here we have applied combination of statistical techniques such as\ninter-quartile range and t-test, which has been effective in filtering\nsignificant genes and minimizing noise from data. Further we have done a\ncomprehensive evaluation of ten state-of-the-art machine learning techniques\nfor their accuracy in class prediction of prostate cancer. Out of these\ntechniques, Bayes Network out performed with an accuracy of 94.11% followed by\nNavie Bayes with an accuracy of 91.17%. To cross validate our results, we\nmodified our training dataset in six different way and found that average\nsensitivity, specificity, precision and accuracy of Bayes Network is highest\namong all other techniques used.Comment: 8 pages, 3 figures and 7 tables", "1307.7087": "Correcting Grain-Errors in Magnetic Media,Gabrys, RyanYaakobi, EitanDolecek, Lara,Computer Science - Information Theory,This paper studies new bounds and constructions that are applicable to the\ncombinatorial granular channel model previously introduced by Sharov and Roth.\nWe derive new bounds on the maximum cardinality of a grain-error-correcting\ncode and propose constructions of codes that correct grain-errors. We\ndemonstrate that a permutation of the classical group codes (e.g.,\nConstantin-Rao codes) can correct a single grain-error. In many cases of\ninterest, our results improve upon the currently best known bounds and\nconstructions. Some of the approaches adopted in the context of grain-errors\nmay have application to other channel models.", "1307.7430": "Holographic Algorithms Beyond Matchgates,Cai, Jin-YiGuo, HengWilliams, Tyson,Computer Science - Data Structures and AlgorithmsComputer Science - Computational Complexity68Q25F.2.1G.2.1,Holographic algorithms introduced by Valiant are composed of two ingredients:\nmatchgates, which are gadgets realizing local constraint functions by weighted\nplanar perfect matchings, and holographic reductions, which show equivalences\namong problems with different descriptions via certain basis transformations.\nIn this paper, we replace matchgates in the paradigm above by the affine type\nand the product type constraint functions, which are known to be tractable in\ngeneral (not necessarily planar) graphs. More specifically, we present\npolynomial-time algorithms to decide if a given counting problem has a\nholographic reduction to another problem defined by the affine or product-type\nfunctions. Our algorithms also find a holographic transformation when one\nexists. We further present polynomial-time algorithms of the same decision and\nsearch problems for symmetric functions, where the complexity is measured in\nterms of the (exponentially more) succinct representations. The algorithm for\nthe symmetric case also shows that the recent dichotomy theorem for Holant\nproblems with symmetric constraints is efficiently decidable. Our proof\ntechniques are mainly algebraic, e.g., using stabilizers and orbits of group\nactions.Comment: Inf. Comput., to appear. Author accepted manuscript", "1307.8371": "The Power of Localization for Efficiently Learning Linear Separators\n  with Noise,Awasthi, PranjalBalcan, Maria FlorinaLong, Philip M.,Computer Science - Machine LearningComputer Science - Computational ComplexityComputer Science - Data Structures and AlgorithmsStatistics - Machine LearningF.2,We introduce a new approach for designing computationally efficient learning\nalgorithms that are tolerant to noise, and demonstrate its effectiveness by\ndesigning algorithms with improved noise tolerance guarantees for learning\nlinear separators.\n  We consider both the malicious noise model and the adversarial label noise\nmodel. For malicious noise, where the adversary can corrupt both the label and\nthe features, we provide a polynomial-time algorithm for learning linear\nseparators in $\\Re^d$ under isotropic log-concave distributions that can\ntolerate a nearly information-theoretically optimal noise rate of $\\eta =\n\\Omega(\\epsilon)$. For the adversarial label noise model, where the\ndistribution over the feature vectors is unchanged, and the overall probability\nof a noisy label is constrained to be at most $\\eta$, we also give a\npolynomial-time algorithm for learning linear separators in $\\Re^d$ under\nisotropic log-concave distributions that can handle a noise rate of $\\eta =\n\\Omega\\left(\\epsilon\\right)$.\n  We show that, in the active learning model, our algorithms achieve a label\ncomplexity whose dependence on the error parameter $\\epsilon$ is\npolylogarithmic. This provides the first polynomial-time active learning\nalgorithm for learning linear separators in the presence of malicious noise or\nadversarial label noise.Comment: Contains improved label complexity analysis communicated to us by\n  Steve Hanneke", "1308.0497": "A note on T\\\"uring's 1936,Cattabriga, Paola,Computer Science - Computational Complexity03D10, 68Qxx,T\\\"uring's argument that there can be no machine computing the diagonal on\nthe enumeration of the computable sequences is not a demonstration.Comment: 4 pages, for more information see\n  http://paolacattabriga.wordpress.com/", "1308.0776": "Dynamic Approximate All-Pairs Shortest Paths: Breaking the O(mn) Barrier\n  and Derandomization,Henzinger, MonikaKrinninger, SebastianNanongkai, Danupon,Computer Science - Data Structures and AlgorithmsF.2.0G.2.2,We study dynamic $(1+\\epsilon)$-approximation algorithms for the all-pairs\nshortest paths problem in unweighted undirected $n$-node $m$-edge graphs under\nedge deletions. The fastest algorithm for this problem is a randomized\nalgorithm with a total update time of $\\tilde O(mn/\\epsilon)$ and constant\nquery time by Roditty and Zwick [FOCS 2004]. The fastest deterministic\nalgorithm is from a 1981 paper by Even and Shiloach [JACM 1981]; it has a total\nupdate time of $O(mn^2)$ and constant query time. We improve these results as\nfollows: (1) We present an algorithm with a total update time of $\\tilde\nO(n^{5/2}/\\epsilon)$ and constant query time that has an additive error of $2$\nin addition to the $1+\\epsilon$ multiplicative error. This beats the previous\n$\\tilde O(mn/\\epsilon)$ time when $m=\\Omega(n^{3/2})$. Note that the additive\nerror is unavoidable since, even in the static case, an $O(n^{3-\\delta})$-time\n(a so-called truly subcubic) combinatorial algorithm with $1+\\epsilon$\nmultiplicative error cannot have an additive error less than $2-\\epsilon$,\nunless we make a major breakthrough for Boolean matrix multiplication [Dor et\nal. FOCS 1996] and many other long-standing problems [Vassilevska Williams and\nWilliams FOCS 2010]. The algorithm can also be turned into a\n$(2+\\epsilon)$-approximation algorithm (without an additive error) with the\nsame time guarantees, improving the recent $(3+\\epsilon)$-approximation\nalgorithm with $\\tilde O(n^{5/2+O(\\sqrt{\\log{(1/\\epsilon)}/\\log n})})$ running\ntime of Bernstein and Roditty [SODA 2011] in terms of both approximation and\ntime guarantees. (2) We present a deterministic algorithm with a total update\ntime of $\\tilde O(mn/\\epsilon)$ and a query time of $O(\\log\\log n)$. The\nalgorithm has a multiplicative error of $1+\\epsilon$ and gives the first\nimproved deterministic algorithm since 1981. It also answers an open question\nraised by Bernstein [STOC 2013].Comment: A preliminary version was presented at the 2013 IEEE 54th Annual\n  Symposium on Foundations of Computer Science (FOCS 2013)", "1308.0801": "Spectral Sequences, Exact Couples and Persistent Homology of filtrations,Basu, SaugataParida, Laxmi,Mathematics - Algebraic TopologyComputer Science - Computational Geometry55T05,In this paper we study the relationship between a very classical algebraic\nobject associated to a filtration of spaces, namely a spectral sequence\nintroduced by Leray in the 1940's, and a more recently invented object that has\nfound many applications -- namely, its persistent homology groups. We show the\nexistence of a long exact sequence of groups linking these two objects and\nusing it derive formulas expressing the dimensions of each individual groups of\none object in terms of the dimensions of the groups in the other object. The\nmain tool used to mediate between these objects is the notion of exact couples\nfirst introduced by Massey in 1952.Comment: Minor typos corrected. Appeared in Expositiones Mathematicae", "1308.1391": "Low-Dimensional Reconciliation for Continuous-Variable Quantum Key\n  Distribution,Gyongyosi, LaszloImre, Sandor,Quantum PhysicsComputer Science - Information Theory,We propose an efficient logical layer-based reconciliation method for\ncontinuous-variable quantum key distribution (CVQKD) to extract binary\ninformation from correlated Gaussian variables. We demonstrate that by\noperating on the raw-data level, the noise of the quantum channel can be\ncorrected in the low-dimensional (scalar) space and the reconciliation can be\nextended to arbitrary dimensions. The CVQKD systems allow an unconditionally\nsecret communication over standard telecommunication networks. To exploit the\nreal potential of CVQKD a robust reconciliation technique is needed. It is\ncurrently unavailable, which makes it impossible to reach the real performance\nof the CVQKD protocols. The reconciliation is a post-processing step separated\nfrom the transmission of quantum states, which is aimed to derive the secret\nkey from the raw data. The reconciliation process of correlated Gaussian\nvariables is a complex problem that requires either tomography in the physical\nlayer that is intractable in a practical scenario, or high-cost calculations in\nthe multidimensional spherical space with strict dimensional limitations. To\navoid these issues we define the low-dimensional reconciliation. We prove that\nthe error probability of one-dimensional reconciliation is zero in any\npractical CVQKD scenario, and provides unconditional security. The results\nallow to significantly improve the currently available key rates and\ntransmission distances of CVQKD.Comment: 43 pages, Journal-ref: Appl. Sci. (accepted)", "1308.1603": "A Note on Topology Preservation in Classification, and the Construction\n  of a Universal Neuron Grid,Volz, Dietmar,Computer Science - Neural and Evolutionary ComputingComputer Science - Artificial IntelligenceNonlinear Sciences - Adaptation and Self-Organizing SystemsStatistics - Machine Learning92F99,It will be shown that according to theorems of K. Menger, every neuron grid\nif identified with a curve is able to preserve the adopted qualitative\nstructure of a data space. Furthermore, if this identification is made, the\nneuron grid structure can always be mapped to a subset of a universal neuron\ngrid which is constructable in three space dimensions. Conclusions will be\ndrawn for established neuron grid types as well as neural fields.", "1308.3987": "Cop and robber game and hyperbolicity,Chalopin, J\u00e9r\u00e9mieChepoi, VictorPapasoglu, PanosPecatte, Timoth\u00e9e,Mathematics - CombinatoricsComputer Science - Discrete Mathematics,In this note, we prove that all cop-win graphs G in the game in which the\nrobber and the cop move at different speeds s and s' with s'<s, are\n\\delta-hyperbolic with \\delta=O(s^2). We also show that the dependency between\n\\delta and s is linear if s-s'=\\Omega(s) and G obeys a slightly stronger\ncondition. This solves an open question from the paper (J. Chalopin et al., Cop\nand robber games when the robber can hide and ride, SIAM J. Discr. Math. 25\n(2011) 333-359). Since any \\delta-hyperbolic graph is cop-win for s=2r and\ns'=r+2\\delta for any r>0, this establishes a new - game-theoretical -\ncharacterization of Gromov hyperbolicity. We also show that for weakly modular\ngraphs the dependency between \\delta and s is linear for any s'<s. Using these\nresults, we describe a simple constant-factor approximation of the\nhyperbolicity \\delta of a graph on n vertices in O(n^2) time when the graph is\ngiven by its distance-matrix.", "1308.4201": "Full-Diversity Space-Time Block Codes for Integer-Forcing Linear\n  Receivers,Harshan, J.Sakzad, AminViterbo, Emanuele,Computer Science - Information Theory,In multiple-input multiple-output (MIMO) fading channels, the design\ncriterion for full-diversity space-time block codes (STBCs) is primarily\ndetermined by the decoding method at the receiver. Although constructions of\nSTBCs have predominantly matched the maximum-likelihood (ML) decoder, design\ncriteria and constructions of full-diversity STBCs have also been reported for\nlow-complexity linear receivers. A new receiver architecture called\nInteger-Forcing (IF) linear receiver has been proposed to MIMO channels by Zhan\net al. which showed promising results for the high-rate V-BLAST encoding\nscheme. In this paper, we address the design of full-diversity STBCs for IF\nlinear receivers. In particular, we are interested in characterizing the\nstructure of STBCs that provide full-diversity with the IF receiver. Along that\ndirection, we derive an upper bound on the probability of decoding error, and\nshow that STBCs that satisfy the restricted non-vanishing singular value (RNVS)\nproperty provide full-diversity for the IF receiver. Furthermore, we prove that\nall known STBCs with the non-vanishing determinant property provide\nfull-diversity with IF receivers, as they guarantee the RNVS property. By using\nthe formulation of RNVS property, we also prove the existence of a\nfull-diversity STBC outside the class of perfect STBCs, thereby adding\nsignificant insights compared to the existing works on STBCs with IF decoding.\nFinally, we present extensive simulation results to demonstrate that linear\ndesigns with RNVS property provide full-diversity for IF receiver.Comment: Contains extension of results in arXiv:1701.03566v1. In\n  arXiv:1701.03566v1, we had formulated the non-vanishing singular value (NVS)\n  property as a design criterion on codes. This submission formulates a new\n  criterion referred to as the Restricted NVS property, which helps to identify\n  larger class of codes that provide full-diversity with integer-forcing linear\n  receivers", "1308.4273": "Adaptive matching pursuit for off-grid compressed sensing,Huang, TianyaoLiu, YiminMeng, HuadongWang, Xiqin,Electrical Engineering and Systems Science - Signal ProcessingComputer Science - Information Theory,Compressive sensing (CS) can effectively recover a signal when it is sparse\nin some discrete atoms. However, in some applications, signals are sparse in a\ncontinuous parameter space, e.g., frequency space, rather than discrete atoms.\nUsually, we divide the continuous parameter into finite discrete grid points\nand build a dictionary from these grid points. However, the actual targets may\nnot exactly lie on the grid points no matter how densely the parameter is\ngrided, which introduces mismatch between the predefined dictionary and the\nactual one. In this article, a novel method, namely adaptive matching pursuit\nwith constrained total least squares (AMP-CTLS), is proposed to find actual\natoms even if they are not included in the initial dictionary. In AMP-CTLS, the\ngrid and the dictionary are adaptively updated to better agree with\nmeasurements. The convergence of the algorithm is discussed, and numerical\nexperiments demonstrate the advantages of AMP-CTLS.Comment: 24 pages. 10 figures", "1308.5146": "Compressive Multiplexing of Correlated Signals,Ahmed, AliRomberg, Justin,Computer Science - Information TheoryStatistics - Applications,We present a general architecture for the acquisition of ensembles of\ncorrelated signals. The signals are multiplexed onto a single line by mixing\neach one against a different code and then adding them together, and the\nresulting signal is sampled at a high rate. We show that if the $M$ signals,\neach bandlimited to $W/2$ Hz, can be approximated by a superposition of $R < M$\nunderlying signals, then the ensemble can be recovered by sampling at a rate\nwithin a logarithmic factor of $RW$ (as compared to the Nyquist rate of $MW$).\nThis sampling theorem shows that the correlation structure of the signal\nensemble can be exploited in the acquisition process even though it is unknown\na priori.\n  The reconstruction of the ensemble is recast as a low-rank matrix recovery\nproblem from linear measurements. The architectures we are considering impose a\ncertain type of structure on the linear operators. Although our results depend\non the mixing forms being random, this imposed structure results in a very\ndifferent type of random projection than those analyzed in the low-rank\nrecovery literature to date.Comment: 38 pages, 11 figures", "1308.6702": "Adversarial hypothesis testing and a quantum Stein's Lemma for\n  restricted measurements,Brandao, Fernando G. S. L.Harrow, Aram W.Lee, James R.Peres, Yuval,Computer Science - Information TheoryMathematics - ProbabilityQuantum Physics,Recall the classical hypothesis testing setting with two convex sets of\nprobability distributions P and Q. One receives either n i.i.d. samples from a\ndistribution p in P or from a distribution q in Q and wants to decide from\nwhich set the points were sampled. It is known that the optimal exponential\nrate at which errors decrease can be achieved by a simple maximum-likelihood\nratio test which does not depend on p or q, but only on the sets P and Q.\n  We consider an adaptive generalization of this model where the choice of p in\nP and q in Q can change in each sample in some way that depends arbitrarily on\nthe previous samples. In other words, in the k'th round, an adversary, having\nobserved all the previous samples in rounds 1,...,k-1, chooses p_k in P and q_k\nin Q, with the goal of confusing the hypothesis test. We prove that even in\nthis case, the optimal exponential error rate can be achieved by a simple\nmaximum-likelihood test that depends only on P and Q.\n  We then show that the adversarial model has applications in hypothesis\ntesting for quantum states using restricted measurements. For example, it can\nbe used to study the problem of distinguishing entangled states from the set of\nall separable states using only measurements that can be implemented with local\noperations and classical communication (LOCC). The basic idea is that in our\nsetup, the deleterious effects of entanglement can be simulated by an adaptive\nclassical adversary.\n  We prove a quantum Stein's Lemma in this setting: In many circumstances, the\noptimal hypothesis testing rate is equal to an appropriate notion of quantum\nrelative entropy between two states. In particular, our arguments yield an\nalternate proof of Li and Winter's recent strengthening of strong subadditivity\nfor quantum relative entropy.Comment: 29 pages. v3. adds detail to proofs", "1309.0671": "BayesOpt: A Library for Bayesian optimization with Robotics Applications,Martinez-Cantin, Ruben,Computer Science - RoboticsComputer Science - Artificial IntelligenceComputer Science - Machine LearningComputer Science - Mathematical Software,The purpose of this paper is twofold. On one side, we present a general\nframework for Bayesian optimization and we compare it with some related fields\nin active learning and Bayesian numerical analysis. On the other hand, Bayesian\noptimization and related problems (bandits, sequential experimental design) are\nhighly dependent on the surrogate model that is selected. However, there is no\nclear standard in the literature. Thus, we present a fast and flexible toolbox\nthat allows to test and combine different models and criteria with little\neffort. It includes most of the state-of-the-art contributions, algorithms and\nmodels. Its speed also removes part of the stigma that Bayesian optimization\nmethods are only good for \"expensive functions\". The software is free and it\ncan be used in many operating systems and computer languages.Comment: Robotics: Science and Systems, Workshop on Active Learning in\n  Robotics: Exploration, Curiosity, and Interaction", "1309.2348": "An Overview of Nominal-Typing versus Structural-Typing in OOP,AbdelGawad, Moez A.,Computer Science - Programming Languages,NOOP is a mathematical model of nominally-typed OOP that proves the\nidentification of inheritance and subtyping in mainstream nominally-typed OO\nprogramming languages and the validity of this identification. This report\ngives an overview of the main notions in OOP relevant to constructing a\nmathematical model of OOP such as NOOP. The emphasis in this report is on\ndefining nominality, nominal typing and nominal subtyping of mainstream\nnominally-typed OO languages, and on contrasting the three notions with their\ncounterparts in structurally-typed OO languages, i.e., with structurality,\nstructural typing and structural subtyping, respectively. An additional\nappendix demonstrates these notions and other related notions, and the\ndifferences between them, using some simple code examples. A detailed, more\ntechnical comparison between nominal typing and structural typing in OOP is\npresented in other publications.Comment: 16 pages", "1309.3014": "Hypercontractivity of spherical averages in Hamming space,Polyanskiy, Yury,Mathematics - ProbabilityComputer Science - Information TheoryMathematics - CombinatoricsMathematics - Functional Analysis,Consider the linear space of functions on the binary hypercube and the linear\noperator $S_\\delta$ acting by averaging a function over a Hamming sphere of\nradius $\\delta n$ around every point. It is shown that this operator has a\ndimension-independent bound on the norm $L_p \\to L_2$ with $p =\n1+(1-2\\delta)^2$. This result evidently parallels a classical estimate of\nBonami and Gross for $L_p \\to L_q$ norms for the operator of convolution with a\nBernoulli noise. The estimate for $S_\\delta$ is harder to obtain since the\nlatter is neither a part of a semigroup, nor a tensor power. The result is\nshown by a detailed study of the eigenvalues of $S_\\delta$ and $L_p\\to L_2$\nnorms of the Fourier multiplier operators $\\Pi_a$ with symbol equal to a\ncharacteristic function of the Hamming sphere of radius $a$ (in the notation\ncommon in boolean analysis $\\Pi_a f=f^{=a}$, where $f^{=a}$ is a degree-$a$\ncomponent of function $f$). A sample application of the result is given: Any\nset $A\\subset \\FF_2^n$ with the property that $A+A$ contains a large portion of\nsome Hamming sphere (counted with multiplicity) must have cardinality a\nconstant multiple of $2^n$.", "1309.3699": "Local Support Vector Machines:Formulation and Analysis,Ganti, RaviGray, Alexander,Statistics - Machine LearningComputer Science - Artificial IntelligenceComputer Science - Machine Learning,We provide a formulation for Local Support Vector Machines (LSVMs) that\ngeneralizes previous formulations, and brings out the explicit connections to\nlocal polynomial learning used in nonparametric estimation literature. We\ninvestigate the simplest type of LSVMs called Local Linear Support Vector\nMachines (LLSVMs). For the first time we establish conditions under which\nLLSVMs make Bayes consistent predictions at each test point $x_0$. We also\nestablish rates at which the local risk of LLSVMs converges to the minimum\nvalue of expected local risk at each point $x_0$. Using stability arguments we\nestablish generalization error bounds for LLSVMs.Comment: 12 pages, 1 figure", "1309.3701": "New and simple algorithms for stable flow problems,Cseh, \u00c1gnesMatuschke, Jannik,Computer Science - Discrete MathematicsComputer Science - Data Structures and AlgorithmsMathematics - Combinatorics,Stable flows generalize the well-known concept of stable matchings to markets\nin which transactions may involve several agents, forwarding flow from one to\nanother. An instance of the problem consists of a capacitated directed network,\nin which vertices express their preferences over their incident edges. A\nnetwork flow is stable if there is no group of vertices that all could benefit\nfrom rerouting the flow along a walk.\n  Fleiner established that a stable flow always exists by reducing it to the\nstable allocation problem. We present an augmenting-path algorithm for\ncomputing a stable flow, the first algorithm that achieves polynomial running\ntime for this problem without using stable allocation as a black-box\nsubroutine. We further consider the problem of finding a stable flow such that\nthe flow value on every edge is within a given interval. For this problem, we\npresent an elegant graph transformation and based on this, we devise a simple\nand fast algorithm, which also can be used to find a solution to the stable\nmarriage problem with forced and forbidden edges.\n  Finally, we study the stable multicommodity flow model introduced by\nKir\\'{a}ly and Pap. The original model is highly involved and allows for\ncommodity-dependent preference lists at the vertices and commodity-specific\nedge capacities. We present several graph-based reductions that show\nequivalence to a significantly simpler model. We further show that it is\nNP-complete to decide whether an integral solution exists.", "1309.3730": "Automatically Extracting Instances of Code Change Patterns with AST\n  Analysis,Martinez, MatiasDuchien, LaurenceMonperrus, Martin,Computer Science - Software Engineering,A code change pattern represents a kind of recurrent modification in\nsoftware. For instance, a known code change pattern consists of the change of\nthe conditional expression of an if statement. Previous work has identified\ndifferent change patterns. Complementary to the identification and definition\nof change patterns, the automatic extraction of pattern instances is essential\nto measure their empirical importance. For example, it enables one to count and\ncompare the number of conditional expression changes in the history of\ndifferent projects. In this paper we present a novel approach for search\npatterns instances from software history. Our technique is based on the\nanalysis of Abstract Syntax Trees (AST) files within a given commit. We\nvalidate our approach by counting instances of 18 change patterns in 6\nopen-source Java projects.Comment: ICSM - 29th IEEE International Conference on Software Maintenance\n  (2013)", "1309.4958": "Approximation of smallest linear tree grammar,Je\u017c, ArturLohrey, Markus,Computer Science - Data Structures and AlgorithmsComputer Science - Formal Languages and Automata TheoryF.4.2F.2.2E.4,A simple linear-time algorithm for constructing a linear context-free tree\ngrammar of size O(rg + r g log (n/r g))for a given input tree T of size n is\npresented, where g is the size of a minimal linear context-free tree grammar\nfor T, and r is the maximal rank of symbols in T (which is a constant in many\napplications). This is the first example of a grammar-based tree compression\nalgorithm with a good, i.e. logarithmic in terms of the size of the input tree,\napproximation ratio. The analysis of the algorithm uses an extension of the\nrecompression technique from strings to trees.Comment: 45 pages, published in Information and Computation. Approximation\n  ratio improved since the first version, figures improved, some examples\n  added. A small calculation error corrected since the previous version (all\n  claims hold as previously)", "1309.5310": "Conditioning of Random Block Subdictionaries with Applications to\n  Block-Sparse Recovery and Regression,Bajwa, Waheed U.Duarte, Marco F.Calderbank, Robert,Mathematics - Statistics TheoryComputer Science - Information Theory,The linear model, in which a set of observations is assumed to be given by a\nlinear combination of columns of a matrix, has long been the mainstay of the\nstatistics and signal processing literature. One particular challenge for\ninference under linear models is understanding the conditions on the dictionary\nunder which reliable inference is possible. This challenge has attracted\nrenewed attention in recent years since many modern inference problems deal\nwith the \"underdetermined\" setting, in which the number of observations is much\nsmaller than the number of columns in the dictionary. This paper makes several\ncontributions for this setting when the set of observations is given by a\nlinear combination of a small number of groups of columns of the dictionary,\ntermed the \"block-sparse\" case. First, it specifies conditions on the\ndictionary under which most block subdictionaries are well conditioned. This\nresult is fundamentally different from prior work on block-sparse inference\nbecause (i) it provides conditions that can be explicitly computed in\npolynomial time, (ii) the given conditions translate into near-optimal scaling\nof the number of columns of the block subdictionaries as a function of the\nnumber of observations for a large class of dictionaries, and (iii) it suggests\nthat the spectral norm and the quadratic-mean block coherence of the dictionary\n(rather than the worst-case coherences) fundamentally limit the scaling of\ndimensions of the well-conditioned block subdictionaries. Second, this paper\ninvestigates the problems of block-sparse recovery and block-sparse regression\nin underdetermined settings. Near-optimal block-sparse recovery and regression\nare possible for certain dictionaries as long as the dictionary satisfies\neasily computable conditions and the coefficients describing the linear\ncombination of groups of columns can be modeled through a mild statistical\nprior.Comment: 39 pages, 3 figures. A revised and expanded version of the paper\n  published in IEEE Transactions on Information Theory (DOI:\n  10.1109/TIT.2015.2429632); this revision includes corrections in the proofs\n  of some of the results", "1309.5568": "Integrating Communications and Merging Messaging via the eXtensible\n  Messaging and Presence Protocol,Coleman, Martin A.,Computer Science - Networking and Internet Architecture,Common problems affecting modern email usage include spam, lack of sender\nverification, lack of built-in security and lack of message integrity. This\npaper looks at how we can utilise the extensible messaging and presence\nprotocol also known as XMPP to, in time, replace email facilities. We present\nseveral methods for initiating a transition away from SMTP for email to rely\nupon the inherent benefits of XMPP with minimal disruption to existing networks\nand email infrastructure. We look at how a program might be used to open an\nexisting POP3/IMAP account, scan for messages that can be sent to a XMPP\nnetwork user, extract the message and then deliver it the XMPP user's client.\nWe show that the system can be implemented and then deployed with a minimum of\nhassle and network disruption to demonstrate XMPP as a reliable and fast\nreplacement for email as we know it today.Comment: 11 pages", "1309.6610": "Adversarial Multiple Access Channels with Individual Injection Rates,Anantharamu, LakshmiChlebus, Bogdan S.Rokicki, Mariusz A.,Computer Science - Distributed, Parallel, and Cluster ComputingComputer Science - Networking and Internet Architecture,We study deterministic distributed broadcasting in synchronous\nmultiple-access channels. Packets are injected into $n$ nodes by a window-type\nadversary that is constrained by a window $w$ and injection rates individually\nassigned to all nodes. We investigate what queue size and packet latency can be\nachieved with the maximum aggregate injection rate of one packet per round,\ndepending on properties of channels and algorithms. We give a non-adaptive\nalgorithm for channels with collision detection and an adaptive algorithm for\nchannels without collision detection that achieve $O(\\min(n+w,w\\log n))$ packet\nlatency. We show that packet latency has to be either $\\Omega(w \\max (1,\\log_w\nn))$, when $w\\le n$, or $\\Omega(w+n)$, when $w>n$, as a matching lower bound to\nthese algorithms. We develop a non-adaptive algorithm for channels without\ncollision detection that achieves $O(n+w)$ queue size and $O(nw)$ packet\nlatency. This is in contrast with the adversarial model of global injection\nrates, in which non-adaptive algorithms with bounded packet latency do not\nexist (Chlebus et al. Distributed Computing 22(2): 93 - 116, 2009). Our\nalgorithm avoids collisions produced by simultaneous transmissions; we show\nthat any algorithm with this property must have $\\Omega(nw)$ packet latency.", "1309.6838": "Inverse Covariance Estimation for High-Dimensional Data in Linear Time\n  and Space: Spectral Methods for Riccati and Sparse Models,Honorio, JeanJaakkola, Tommi S.,Computer Science - Machine LearningStatistics - Machine Learning,We propose maximum likelihood estimation for learning Gaussian graphical\nmodels with a Gaussian (ell_2^2) prior on the parameters. This is in contrast\nto the commonly used Laplace (ell_1) prior for encouraging sparseness. We show\nthat our optimization problem leads to a Riccati matrix equation, which has a\nclosed form solution. We propose an efficient algorithm that performs a\nsingular value decomposition of the training data. Our algorithm is\nO(NT^2)-time and O(NT)-space for N variables and T samples. Our method is\ntailored to high-dimensional problems (N gg T), in which sparseness promoting\nmethods become intractable. Furthermore, instead of obtaining a single solution\nfor a specific regularization parameter, our algorithm finds the whole solution\npath. We show that the method has logarithmic sample complexity under the\nspiked covariance model. We also propose sparsification of the dense solution\nwith provable performance guarantees. We provide techniques for using our\nlearnt models, such as removing unimportant variables, computing likelihoods\nand conditional distributions. Finally, we show promising results in several\ngene expressions datasets.Comment: Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty\n  in Artificial Intelligence (UAI2013)", "1309.6927": "Inclusion-exclusion enhanced by nerve stimulation,Wild, Marcel,Computer Science - Discrete MathematicsMathematics - Combinatorics,When evaluating the lengthy inclusion-exclusion expansion many of its terms\nmay turn out to be zero, and hence should be discarded beforehand. Often this\ncan be done. The main idea is that the index sets of nonzero terms constitute a\nset ideal (called the 'nerve'), which often can be encoded in a compact way\n(Upgrade B). As a further enhancement (Upgrade A), equal nonzero terms can\nsometimes be efficiently collected.Comment: Version 3 has a slightly different title than Version 2, and improves\n  upon it in various ways. Foremost it newly introduces a Vertical Upgrade of\n  the inclusion-exclusion expansion", "1310.0441": "Countering Wrapping Attack on XML Signature in SOAP Message for Cloud\n  Computing,Kouchaksaraei, Hadi RazzaghiChefranov, Alexander G.,Computer Science - Cryptography and Security,It is known that the exchange of information between web applications is done\nby means of the SOAP protocol. Securing this protocol is obviously a vital\nissue for any computer network. However, when it comes to cloud computing\nsystems, the sensitivity of this issue rises, as the clients of system, release\ntheir data to the cloud. XML signature is employed to secure SOAP messages.\nHowever, there are also some weak points that have been identified, named as\nXML signature wrapping attacks, which have been categorized into four major\ngroups; Simple Ancestry Context Attack, Optional element context attacks,\nSibling Value Context Attack, Sibling Order Context. In this paper, two\nexisting methods, for referencing the signed part of SOAP Message, named as ID\nreferencing and XPath method, are analyzed and examined. In addition, a new\nmethod is proposed and tested, to secure the SOAP message. In the new method,\nthe XML any signature wrapping attack is prevented by employing the concept of\nXML digital signature on the SOAP message. The results of conducted experiments\nshow that the proposed method is approximately three times faster than the\nXPath method and even a little faster than ID.Comment: 6 pages, 10 figures", "1310.0833": "Flips in combinatorial pointed pseudo-triangulations with face degree at\n  most four,Aichholzer, OswinHackl, ThomasOrden, DavidPilz, AlexanderSaumell, MariaVogtenhuber, Birgit,Mathematics - CombinatoricsComputer Science - Computational GeometryComputer Science - Discrete Mathematics,In this paper we consider the flip operation for combinatorial pointed\npseudo-triangulations where faces have size 3 or 4, so-called combinatorial\n4-PPTs. We show that every combinatorial 4-PPT is stretchable to a geometric\npseudo-triangulation, which in general is not the case if faces may have size\nlarger than 4. Moreover, we prove that the flip graph of combinatorial 4-PPTs\nis connected and has diameter $O(n^2)$, even in the case of labeled vertices\nwith fixed outer face. For this case we provide an $\\Omega(n\\log n)$ lower\nbound.Comment: 21 pages, 24 figures. Accepted for publication in the special volume\n  of International Journal of Computational Geometry & Applications devoted to\n  the XV Spanish Meeting on Computational Geometry", "1310.1250": "Learning ambiguous functions by neural networks,Ligeiro, RuiMendes, R. Vilela,Computer Science - Neural and Evolutionary ComputingComputer Science - Machine LearningPhysics - Data Analysis, Statistics and Probability68T37, 82C32I.2.6I.5.1I.5.5,It is not, in general, possible to have access to all variables that\ndetermine the behavior of a system. Having identified a number of variables\nwhose values can be accessed, there may still be hidden variables which\ninfluence the dynamics of the system. The result is model ambiguity in the\nsense that, for the same (or very similar) input values, different objective\noutputs should have been obtained. In addition, the degree of ambiguity may\nvary widely across the whole range of input values. Thus, to evaluate the\naccuracy of a model it is of utmost importance to create a method to obtain the\ndegree of reliability of each output result. In this paper we present such a\nscheme composed of two coupled artificial neural networks: the first one being\nresponsible for outputting the predicted value, whereas the other evaluates the\nreliability of the output, which is learned from the error values of the first\none. As an illustration, the scheme is applied to a model for tracking slopes\nin a straw chamber and to a credit scoring model.Comment: 13 pages, 9 figures", "1310.1861": "Physical-Layer Cryptography Through Massive MIMO,Dean, ThomasGoldsmith, Andrea,Computer Science - Information TheoryComputer Science - Cryptography and Security,We propose the new technique of physical-layer cryptography based on using a\nmassive MIMO channel as a key between the sender and desired receiver, which\nneed not be secret. The goal is for low-complexity encoding and decoding by the\ndesired transmitter-receiver pair, whereas decoding by an eavesdropper is hard\nin terms of prohibitive complexity. The decoding complexity is analyzed by\nmapping the massive MIMO system to a lattice. We show that the eavesdropper's\ndecoder for the MIMO system with M-PAM modulation is equivalent to solving\nstandard lattice problems that are conjectured to be of exponential complexity\nfor both classical and quantum computers. Hence, under the widely-held\nconjecture that standard lattice problems are hard to solve in the worst-case,\nthe proposed encryption scheme has a more robust notion of security than that\nof the most common encryption methods used today such as RSA and\nDiffie-Hellman. Additionally, we show that this scheme could be used to\nsecurely communicate without a pre-shared secret and little computational\noverhead. Thus, by exploiting the physical layer properties of the radio\nchannel, the massive MIMO system provides for low-complexity encryption\ncommensurate with the most sophisticated forms of application-layer encryption\nthat are currently known.Comment: Submitted to IEEE Transactions on Information Theory", "1310.2728": "The asymptotic $k$-SAT threshold,Coja-Oghlan, AminPanagiotou, Konstantinos,Mathematics - CombinatoricsComputer Science - Discrete MathematicsMathematics - Probability05C80,Since the early 2000s physicists have developed an ingenious but non-rigorous\nformalism called the cavity method to put forward precise conjectures on phase\ntransitions in random problems [Mezard, Parisi, Zecchina: Science 2002]. The\ncavity method predicts that the satisfiability threshold in the random $k$-SAT\nproblem is $2^k\\ln2-\\frac12(1+\\ln 2)+\\epsilon_k$, with\n$\\lim_{k\\rightarrow\\infty}\\epsilon_k=0$ [Mertens, Mezard, Zecchina: Random\nStructures and Algorithms 2006]. This paper contains a proof of that\nconjecture.", "1310.3389": "Spectra of random networks in the weak clustering regime,Peron, Thomas K. DM.Ji, PengKurths, J\u00fcrgenRodrigues, Francisco A.,Physics - Physics and SocietyCondensed Matter - Statistical MechanicsComputer Science - Social and Information Networks,The asymptotic behaviour of dynamical processes in networks can be expressed\nas a function of spectral properties of the corresponding adjacency and\nLaplacian matrices. Although many theoretical results are known for the spectra\nof traditional configuration models, networks generated through these models\nfail to describe many topological features of real-world networks, in\nparticular non-null values of the clustering coefficient. Here we study effects\nof cycles of order three (triangles) in network spectra. By using recent\nadvances in random matrix theory, we determine the spectral distribution of the\nnetwork adjacency matrix as a function of the average number of triangles\nattached to each node for networks without modular structure and degree-degree\ncorrelations. Implications to network dynamics are discussed. Our findings can\nshed light in the study of how particular kinds of subgraphs influence network\ndynamics.", "1310.4345": "Moser's Shadow Problem,Lagarias, Jeffrey C.Luo, YushengPadrol, Arnau,Mathematics - Metric GeometryComputer Science - Computational GeometryPrimary: 52B10, Secondary: 51N15, 65D18, 68U05, 90C05,Moser's shadow problem asks to estimate the shadow function\n$\\mathfrak{s}_b(n)$, which is the largest number such that for each bounded\nconvex polyhedron $P$ with $n$ vertices in $3$-space there is some direction\n${\\bf v}$ (depending on $P$) such that, when illuminated by parallel light rays\nfrom infinity in direction ${\\bf v}$, the polyhedron casts a shadow having at\nleast $\\mathfrak{s}_b(n)$ vertices. A general version of the problem allows\nunbounded polyhedra as well, and has associated shadow function\n$\\mathfrak{s}_u(n)$. This paper presents correct order of magnitude asymptotic\nbounds on these functions. The bounded case has answer $\\mathfrak{s}_b(n) =\n\\Theta \\big( \\log (n)/ (\\log(\\log (n))\\big$. The unbounded shadow problem is\nshown to have the different asymptotic growth rate $\\mathfrak{s}_u(n) = \\Theta\n\\big(1\\big)$. Results on the bounded shadow problem follow from 1989 work of\nChazelle, Edelsbrunner and Guibas on the (bounded) silhouette span number\n$\\mathfrak{s}_b^{\\ast}(n)$, defined analogously but with arbitrary light\nsources. We complete the picture by showing that the unbounded silhouette span\nnumber $\\mathfrak{s}_u^{\\ast}(n)$ grows as $\\Theta \\big( \\log (n)/ (\\log(\\log\n(n))\\big)$.Comment: v5, 25 pages, additional result added for unbounded silhouette span", "1310.4349": "An Improved Majority-Logic Decoder Offering Massively Parallel Decoding\n  for Real-Time Control in Embedded Systems,Bertram, JulianeHauck, PeterHuber, Michael,Computer Science - Information TheoryComputer Science - Hardware ArchitectureComputer Science - Discrete MathematicsComputer Science - Emerging Technologies94B35, 68P30E.4,We propose an easy-to-implement hard-decision majority-logic decoding\nalgorithm for Reed-Muller codes RM(r,m) with m >= 3, m/2 >= r >= 1. The\npresented algorithm outperforms the best known majority-logic decoding\nalgorithms and offers highly parallel decoding. The result is of special\nimportance for safety- and time-critical applications in embedded systems. A\nsimple combinational circuit can perform the proposed decoding. In particular,\nwe show how our decoder for the three-error-correcting code RM(2,5) of\ndimension 16 and length 32 can be realized on hardware level.Comment: 8 pages; to appear in \"IEEE Transactions on Communications\"", "1310.5251": "Sparsity-Promoting Sensor Selection for Non-linear Measurement Models,Chepuri, Sundeep PrabhakarLeus, Geert,Computer Science - Information TheoryElectrical Engineering and Systems Science - Signal Processing,Sensor selection is an important design problem in large-scale sensor\nnetworks. Sensor selection can be interpreted as the problem of selecting the\nbest subset of sensors that guarantees a certain estimation performance. We\nfocus on observations that are related to a general non-linear model. The\nproposed framework is valid as long as the observations are independent, and\nits likelihood satisfies the regularity conditions. We use several functions of\nthe Cram\\'er-Rao bound (CRB) as a performance measure. We formulate the sensor\nselection problem as the design of a selection vector, which in its original\nform is a nonconvex l0-(quasi) norm optimization problem. We present relaxed\nsensor selection solvers that can be efficiently solved in polynomial time. We\nalso propose a projected subgradient algorithm that is attractive for\nlarge-scale problems and also show how the algorithm can be easily distributed.\nThe proposed framework is illustrated with a number of examples related to\nsensor placement design for localization.Comment: 13 pages, submitted to TSP (revised Mar. 2014)", "1310.6324": "On Jacobian group arithmetic for typical divisors on curves,Khuri-Makdisi, Kamal,Mathematics - Number TheoryComputer Science - Symbolic ComputationMathematics - Algebraic Geometry14Q05 (primary), 11Y16, 14H40, 11G20,In a previous joint article with F. Abu Salem, we gave efficient algorithms\nfor Jacobian group arithmetic of \"typical\" divisor classes on C_{3,4} curves,\nimproving on similar results by other authors. At that time, we could only\nstate that a generic divisor was typical, and hence unlikely to be encountered\nif one implemented these algorithms over a very large finite field. This\narticle pins down an explicit characterization of these typical divisors, for\nan arbitrary smooth projective curve of genus g >= 1 having at least one\nrational point. We give general algorithms for Jacobian group arithmetic with\nthese typical divisors, and prove not only that the algorithms are correct if\nvarious divisors are typical, but also that the success of our algorithms\nprovides a guarantee that the resulting output is correct and that the\nresulting input and/or output divisors are also typical. These results apply in\nparticular to our earlier algorithms for C_{3,4} curves. As a byproduct, we\nobtain a further speedup of approximately 15% on our previous algorithms for\nC_{3,4} curves.Comment: 29 pages, further editing to take into account referee reports.\n  Section 3 reworked to better separate the general results from those for\n  C_{3,4} curves, which are now marked as examples. Section 4 now sets off the\n  results more clearly instead of including them in narrative form in the text", "1310.6398": "Some Remarks on Lower Bounds for Queue Machines (Preliminary Report),Petersen, Holger,Computer Science - Computational ComplexityComputer Science - Formal Languages and Automata Theory,We first give an improved lower bound for the deterministic online simulation\nof tapes or pushdown stores by queues. Then we inspect some proofs in a\nclassical work on queue machines in the area of Formal Languages and outline\nwhy a main argument in the proofs is incomplete. Based on descriptional\ncomplexity, we show the intuition behind the argument to be correct.", "1310.8097": "Guaranteed Collision Detection With Toleranced Motions,Schr\u00f6cker, Hans-PeterWeber, Matthias J.,Computer Science - Computational GeometryComputer Science - Robotics65D18, 70B10,We present a method for guaranteed collision detection with toleranced\nmotions. The basic idea is to consider the motion as a curve in the\n12-dimensional space of affine displacements, endowed with an object-oriented\nEuclidean metric, and cover it with balls. The associated orbits of points,\nlines, planes and polygons have particularly simple shapes that lend themselves\nwell to exact and fast collision queries. We present formulas for elementary\ncollision tests with these orbit shapes and we suggest an algorithm, based on\nmotion subdivision and computation of bounding balls, that can give a\nno-collision guarantee. It allows a robust and efficient implementation and\nparallelization. At hand of several examples we explore the asymptotic behavior\nof the algorithm and compare different implementation strategies.Comment: Accepted for publication in Computer Aided Geometric Design", "1310.8121": "Easy Accurate Reading and Writing of Floating-Point Numbers,Jaffer, Aubrey,Computer Science - Numerical Analysis65G04G.1.0,Presented here are algorithms for converting between (decimal)\nscientific-notation and (binary) IEEE-754 double-precision floating-point\nnumbers. By employing a rounding integer quotient operation these algorithms\nare much simpler than those previously published. The values are stable under\nrepeated conversions between the formats. Unlike Java-1.8, the scientific\nrepresentations generated use only the minimum number of mantissa digits needed\nto convert back to the original binary values.Comment: 8 pages, 6 figures", "1311.0320": "An Improved Solution for Restricted and Uncertain TRQ,Wang, Jack,Computer Science - DatabasesH.3.3G.3G.3.1,CSPTRQ is an interesting problem and its has attracted much attention. The\nCSPTRQ is a variant of the traditional PTRQ. As objects moving in a\nconstrained-space are common, clearly, it can also find many applications. At\nthe first sight, our problem can be easily tackled by extending existing\nmethods used to answer the PTRQ. Unfortunately, those classical techniques are\nnot well suitable for our problem, due to a set of new challenges. We develop\ntargeted solutions and demonstrate the efficiency and effectiveness of the\nproposed methods through extensive experiments.Comment: 39 pages", "1311.0913": "Bidding Games and Efficient Allocations,Kalai, GilMeir, ReshefTennenholtz, Moshe,Computer Science - Computer Science and Game TheoryI.2.11,Richman games are zero-sum games, where in each turn players bid in order to\ndetermine who will play next [Lazarus et al.'99]. We extend the theory to\nimpartial general-sum two player games called \\emph{bidding games}, showing the\nexistence of pure subgame-perfect equilibria (PSPE). In particular, we show\nthat PSPEs form a semilattice, with a unique and natural \\emph{Bottom\nEquilibrium}.\n  Our main result shows that if only two actions available to the players in\neach node, then the Bottom Equilibrium has additional properties: (a) utilities\nare monotone in budget; (b) every outcome is Pareto-efficient; and (c) any\nPareto-efficient outcome is attained for some budget.\n  In the context of combinatorial bargaining, we show that a player with a\nfraction of X% of the total budget prefers her allocation to X% of the possible\nallocations. In addition, we provide a polynomial-time algorithm to compute the\nBottom Equilibrium of a binary bidding game.Comment: A preliminary version of this paper appeared in the 16th ACM\n  Conference on Economics and Computation (EC-2015). Paper accepted to Games\n  and Economic Behavior", "1311.1339": "Zero-Error Capacity of a Class of Timing Channels,Kova\u010devi\u0107, MladenPopovski, Petar,Computer Science - Information TheoryComputer Science - Discrete Mathematics94B25, 94A40, 94A24, 68R05, 65Q30,We analyze the problem of zero-error communication through timing channels\nthat can be interpreted as discrete-time queues with bounded waiting times. The\nchannel model includes the following assumptions: 1) Time is slotted, 2) at\nmost $ N $ \"particles\" are sent in each time slot, 3) every particle is delayed\nin the channel for a number of slots chosen randomly from the set $ \\{0, 1,\n\\ldots, K\\} $, and 4) the particles are identical. It is shown that the\nzero-error capacity of this channel is $ \\log r $, where $ r $ is the unique\npositive real root of the polynomial $ x^{K+1} - x^{K} - N $.\nCapacity-achieving codes are explicitly constructed, and a linear-time decoding\nalgorithm for these codes devised. In the particular case $ N = 1 $, $ K = 1 $,\nthe capacity is equal to $ \\log \\phi $, where $ \\phi = (1 + \\sqrt{5}) / 2 $ is\nthe golden ratio, and the constructed codes give another interpretation of the\nFibonacci sequence.Comment: 5 pages (double-column), 3 figures. v3: Section IV.1 from v2 is\n  replaced with Remark 1, and Section IV.2 is removed. Accepted for publication\n  in IEEE Transactions on Information Theory", "1311.2828": "Private Matchings and Allocations,Hsu, JustinHuang, ZhiyiRoth, AaronRoughgarden, TimWu, Zhiwei Steven,Computer Science - Computer Science and Game TheoryComputer Science - Cryptography and SecurityComputer Science - Data Structures and Algorithms,We consider a private variant of the classical allocation problem: given k\ngoods and n agents with individual, private valuation functions over bundles of\ngoods, how can we partition the goods amongst the agents to maximize social\nwelfare? An important special case is when each agent desires at most one good,\nand specifies her (private) value for each good: in this case, the problem is\nexactly the maximum-weight matching problem in a bipartite graph.\n  Private matching and allocation problems have not been considered in the\ndifferential privacy literature, and for good reason: they are plainly\nimpossible to solve under differential privacy. Informally, the allocation must\nmatch agents to their preferred goods in order to maximize social welfare, but\nthis preference is exactly what agents wish to hide. Therefore, we consider the\nproblem under the relaxed constraint of joint differential privacy: for any\nagent i, no coalition of agents excluding i should be able to learn about the\nvaluation function of agent i. In this setting, the full allocation is no\nlonger published---instead, each agent is told what good to get. We first show\nthat with a small number of identical copies of each good, it is possible to\nefficiently and accurately solve the maximum weight matching problem while\nguaranteeing joint differential privacy. We then consider the more general\nallocation problem, when bidder valuations satisfy the gross substitutes\ncondition. Finally, we prove that the allocation problem cannot be solved to\nnon-trivial accuracy under joint differential privacy without requiring\nmultiple copies of each type of good.Comment: Journal version published in SIAM Journal on Computation; an extended\n  abstract appeared in STOC 2014", "1311.2970": "Coordinated Tethering for Multi-RAT Cellular Networks: An Algorithmic\n  Solution and Performance Analysis,Bithas, Petros S.Lioumpas, Athanasios S.,Computer Science - Networking and Internet Architecture,The exploitation of already deployed wireless local area networks (WLAN)s\n(e.g., WiFi access points (AP)s) has attracted considerable attention, as an\nefficient and practical method to improve the performance of beyond 4G wireless\nnetworks. In this paper, we propose a novel communication paradigm to satisfy\nthe performance demands of future wireless networks: a hybrid Cellular/WLAN\nnetwork architecture with wireless offloading. In contrast to the commonly\nadopted practice of WiFi offloading, where the WLAN APs have a wired backhaul\n(e.g., Digital Subscriber Line), we propose a wireless offloading approach,\nwhere the WLAN APs will share their wireless cellular broadband connection with\nother users. These users will select their serving node, i.e., the macro-cell\neNodeB or a WLAN AP, based on a certain selection criterion. Thus a challenging\nresearch field is originated, where interfering effects and wireless resources\nlimitations play a dominant role. Important performance metrics of the proposed\nhybrid scheme, including the bit error probability, the ergodic capacity and\nthe average signal-to-interference-plus noise ratio, are theoretically studied\nand closed form expressions are derived for the single-user case with multiple\ninterferers, for both identical and non-identical fading conditions. Also,\nbased on the general multi-cellular hybrid WLAN-Cellular concept, we first\npropose a intercell interference minimization approach. Then we present a novel\nscheme for achieving frequency reuse equal to one within a single macro-cell,\nunder specific performance criteria and constraints, that guarantee the overall\ncell or the individual user QoS requirements.Comment: Intellectual properties issues with a patent pending", "1311.3158": "Fingerprinting Codes and the Price of Approximate Differential Privacy,Bun, MarkUllman, JonathanVadhan, Salil,Computer Science - Cryptography and Security,We show new lower bounds on the sample complexity of $(\\varepsilon,\n\\delta)$-differentially private algorithms that accurately answer large sets of\ncounting queries. A counting query on a database $D \\in (\\{0,1\\}^d)^n$ has the\nform \"What fraction of the individual records in the database satisfy the\nproperty $q$?\" We show that in order to answer an arbitrary set $\\mathcal{Q}$\nof $\\gg nd$ counting queries on $D$ to within error $\\pm \\alpha$ it is\nnecessary that $$ n \\geq \\tilde{\\Omega}\\Bigg(\\frac{\\sqrt{d} \\log\n|\\mathcal{Q}|}{\\alpha^2 \\varepsilon} \\Bigg). $$ This bound is optimal up to\npoly-logarithmic factors, as demonstrated by the Private Multiplicative Weights\nalgorithm (Hardt and Rothblum, FOCS'10). In particular, our lower bound is the\nfirst to show that the sample complexity required for accuracy and\n$(\\varepsilon, \\delta)$-differential privacy is asymptotically larger than what\nis required merely for accuracy, which is $O(\\log |\\mathcal{Q}| / \\alpha^2)$.\nIn addition, we show that our lower bound holds for the specific case of\n$k$-way marginal queries (where $|\\mathcal{Q}| = 2^k \\binom{d}{k}$) when\n$\\alpha$ is not too small compared to $d$ (e.g. when $\\alpha$ is any fixed\nconstant).\n  Our results rely on the existence of short \\emph{fingerprinting codes} (Boneh\nand Shaw, CRYPTO'95, Tardos, STOC'03), which we show are closely connected to\nthe sample complexity of differentially private data release. We also give a\nnew method for combining certain types of sample complexity lower bounds into\nstronger lower bounds.Comment: Full version of our STOC 2014 paper. To appear in SIAM Journal on\n  Computing", "1311.3414": "Mining Software Repair Models for Reasoning on the Search Space of\n  Automated Program Fixing,Martinez, MatiasMonperrus, Martin,Computer Science - Software Engineering,This paper is about understanding the nature of bug fixing by analyzing\nthousands of bug fix transactions of software repositories. It then places this\nlearned knowledge in the context of automated program repair. We give extensive\nempirical results on the nature of human bug fixes at a large scale and a fine\ngranularity with abstract syntax tree differencing. We set up mathematical\nreasoning on the search space of automated repair and the time to navigate\nthrough it. By applying our method on 14 repositories of Java software and\n89,993 versioning transactions, we show that not all probabilistic repair\nmodels are equivalent.Comment: Empirical Software Engineering (2013)", "1311.4257": "A parallel directional Fast Multipole Method,Benson, Austin R.Poulson, JackTran, KennethEngquist, Bj\u00f6rnYing, Lexing,Mathematics - Numerical AnalysisComputer Science - Numerical Analysis65Y05, 65Y20, 78A45,This paper introduces a parallel directional fast multipole method (FMM) for\nsolving N-body problems with highly oscillatory kernels, with a focus on the\nHelmholtz kernel in three dimensions. This class of oscillatory kernels\nrequires a more restrictive low-rank criterion than that of the low-frequency\nregime, and thus effective parallelizations must adapt to the modified data\ndependencies. We propose a simple partition at a fixed level of the octree and\nshow that, if the partitions are properly balanced between p processes, the\noverall runtime is essentially O(N log N/p+ p). By the structure of the\nlow-rank criterion, we are able to avoid communication at the top of the\noctree. We demonstrate the effectiveness of our parallelization on several\nchallenging models.", "1311.4766": "Notions of Symmetry for Finite Strategic-Form Games,Ham, Nicholas,Mathematics - CombinatoricsComputer Science - Computer Science and Game Theory,In this paper we survey various notions of symmetry for finite strategic-form\ngames; show that game bijections and game isomorphisms form groupoids;\nintroduce matchings as a convenient characterisation of strategy triviality;\nand outline how to construct and partially order parameterised symmetric games\nwith numerous examples that range all combinations of surveyed symmetry\nnotions.Comment: 17 pages", "1311.4821": "On the Complexity of Random Satisfiability Problems with Planted\n  Solutions,Feldman, VitalyPerkins, WillVempala, Santosh,Computer Science - Computational ComplexityComputer Science - Discrete MathematicsComputer Science - Data Structures and AlgorithmsMathematics - CombinatoricsMathematics - Probability,The problem of identifying a planted assignment given a random $k$-SAT\nformula consistent with the assignment exhibits a large algorithmic gap: while\nthe planted solution becomes unique and can be identified given a formula with\n$O(n\\log n)$ clauses, there are distributions over clauses for which the best\nknown efficient algorithms require $n^{k/2}$ clauses. We propose and study a\nunified model for planted $k$-SAT, which captures well-known special cases. An\ninstance is described by a planted assignment $\\sigma$ and a distribution on\nclauses with $k$ literals. We define its distribution complexity as the largest\n$r$ for which the distribution is not $r$-wise independent ($1 \\le r \\le k$ for\nany distribution with a planted assignment).\n  Our main result is an unconditional lower bound, tight up to logarithmic\nfactors, for statistical (query) algorithms [Kearns 1998, Feldman et. al 2012],\nmatching known upper bounds, which, as we show, can be implemented using a\nstatistical algorithm. Since known approaches for problems over distributions\nhave statistical analogues (spectral, MCMC, gradient-based, convex optimization\netc.), this lower bound provides a rigorous explanation of the observed\nalgorithmic gap. The proof introduces a new general technique for the analysis\nof statistical query algorithms. It also points to a geometric paring\nphenomenon in the space of all planted assignments.\n  We describe consequences of our lower bounds to Feige's refutation hypothesis\n[Feige 2002] and to lower bounds on general convex programs that solve planted\n$k$-SAT. Our bounds also extend to other planted $k$-CSP models, and, in\nparticular, provide concrete evidence for the security of Goldreich's one-way\nfunction and the associated pseudorandom generator when used with a\nsufficiently hard predicate [Goldreich 2000].Comment: Extended abstract appeared in STOC 2015", "1311.6126": "An energy function and its application to the periodic behavior of\n  k-reversible processes,Oliveira, Leonardo I. L.Barbosa, Valmir C.Protti, F\u00e1bio,Computer Science - Data Structures and Algorithms,We consider the graph dynamical systems known as k-reversible processes. In\nsuch processes, each vertex in the graph has one of two possible states at each\ndiscrete time step. Each vertex changes its state between the current time and\nthe next if and only if it currently has at least k neighbors in a state\ndifferent than its own. For such processes, we present a monotonic function\nsimilar to the decreasing energy functions used to study threshold networks.\nUsing this new function, we show an alternative proof for the maximum period\nlength in a k-reversible process and provide better upper bounds on the\ntransient length in both the general case and the case of trees.", "1311.6876": "Want a Good Answer? Ask a Good Question First!,Yao, YuanTong, HanghangXie, TaoAkoglu, LemanXu, FengLu, Jian,Computer Science - DatabasesComputer Science - Artificial IntelligenceComputer Science - Information RetrievalComputer Science - Software Engineering,Community Question Answering (CQA) websites have become valuable repositories\nwhich host a massive volume of human knowledge. To maximize the utility of such\nknowledge, it is essential to evaluate the quality of an existing question or\nanswer, especially soon after it is posted on the CQA website.\n  In this paper, we study the problem of inferring the quality of questions and\nanswers through a case study of a software CQA (Stack Overflow). Our key\nfinding is that the quality of an answer is strongly positively correlated with\nthat of its question. Armed with this observation, we propose a family of\nalgorithms to jointly predict the quality of questions and answers, for both\nquantifying numerical quality scores and differentiating the high-quality\nquestions/answers from those of low quality. We conduct extensive experimental\nevaluations to demonstrate the effectiveness and efficiency of our methods.", "1312.0049": "One-Class Classification: Taxonomy of Study and Review of Techniques,Khan, Shehroz S.Madden, Michael G.,Computer Science - Machine LearningComputer Science - Artificial Intelligence,One-class classification (OCC) algorithms aim to build classification models\nwhen the negative class is either absent, poorly sampled or not well defined.\nThis unique situation constrains the learning of efficient classifiers by\ndefining class boundary just with the knowledge of positive class. The OCC\nproblem has been considered and applied under many research themes, such as\noutlier/novelty detection and concept learning. In this paper we present a\nunified view of the general problem of OCC by presenting a taxonomy of study\nfor OCC problems, which is based on the availability of training data,\nalgorithms used and the application domains applied. We further delve into each\nof the categories of the proposed taxonomy and present a comprehensive\nliterature review of the OCC algorithms, techniques and methodologies with a\nfocus on their significance, limitations and applications. We conclude our\npaper by discussing some open research problems in the field of OCC and present\nour vision for future research.Comment: 24 pages + 11 pages of references, 8 figures", "1312.0233": "On Optimal Disc Covers and a New Characterization of the Steiner Center,Yankelevsky, YaelBruckstein, Alfred M.,Computer Science - Computational Geometry,Given N points in the plane $P_1 P_2...P_N$ and a location $\\Omega$, the\nunion of discs with diameters $[\\Omega P_i], i = 1, 2,...N$ covers the convex\nhull of the points. The location $\\Omega_s$ minimizing the area covered by the\nunion of discs, is shown to be the Steiner center of the convex hull of the\npoints. Similar results for $d$-dimensional Euclidean space are conjectured.Comment: 14 pages, 11 figures; minor corrections, revised proof of theorem 2", "1312.0461": "Abmash: Mashing Up Legacy Web Applications by Automated Imitation of\n  Human Actions,Ortac, AlperMonperrus, MartinMezini, Mira,Computer Science - Software Engineering,Many business web-based applications do not offer applications programming\ninterfaces (APIs) to enable other applications to access their data and\nfunctions in a programmatic manner. This makes their composition difficult (for\ninstance to synchronize data between two applications). To address this\nchallenge, this paper presents Abmash, an approach to facilitate the\nintegration of such legacy web applications by automatically imitating human\ninteractions with them. By automatically interacting with the graphical user\ninterface (GUI) of web applications, the system supports all forms of\nintegrations including bi-directional interactions and is able to interact with\nAJAX-based applications. Furthermore, the integration programs are easy to\nwrite since they deal with end-user, visual user-interface elements. The\nintegration code is simple enough to be called a \"mashup\".Comment: Software: Practice and Experience (2013) -", "1312.1001": "Optimal detection of intersections between convex polyhedra,Barba, LuisLangerman, Stefan,Computer Science - Computational Geometry,For a polyhedron $P$ in $\\mathbb{R}^d$, denote by $|P|$ its combinatorial\ncomplexity, i.e., the number of faces of all dimensions of the polyhedra. In\nthis paper, we revisit the classic problem of preprocessing polyhedra\nindependently so that given two preprocessed polyhedra $P$ and $Q$ in\n$\\mathbb{R}^d$, each translated and rotated, their intersection can be tested\nrapidly.\n  For $d=3$ we show how to perform such a test in $O(\\log |P| + \\log |Q|)$ time\nafter linear preprocessing time and space. This running time is the best\npossible and improves upon the last best known query time of $O(\\log|P|\n\\log|Q|)$ by Dobkin and Kirkpatrick (1990).\n  We then generalize our method to any constant dimension $d$, achieving the\nsame optimal $O(\\log |P| + \\log |Q|)$ query time using a representation of size\n$O(|P|^{\\lfloor d/2\\rfloor + \\varepsilon})$ for any $\\varepsilon>0$ arbitrarily\nsmall. This answers an even older question posed by Dobkin and Kirkpatrick 30\nyears ago.\n  In addition, we provide an alternative $O(\\log |P| + \\log |Q|)$ algorithm to\ntest the intersection of two convex polygons $P$ and $Q$ in the plane.", "1312.1277": "Bandits and Experts in Metric Spaces,Kleinberg, RobertSlivkins, AleksandrsUpfal, Eli,Computer Science - Data Structures and AlgorithmsComputer Science - Machine Learning,In a multi-armed bandit problem, an online algorithm chooses from a set of\nstrategies in a sequence of trials so as to maximize the total payoff of the\nchosen strategies. While the performance of bandit algorithms with a small\nfinite strategy set is quite well understood, bandit problems with large\nstrategy sets are still a topic of very active investigation, motivated by\npractical applications such as online auctions and web advertisement. The goal\nof such research is to identify broad and natural classes of strategy sets and\npayoff functions which enable the design of efficient solutions.\n  In this work we study a very general setting for the multi-armed bandit\nproblem in which the strategies form a metric space, and the payoff function\nsatisfies a Lipschitz condition with respect to the metric. We refer to this\nproblem as the \"Lipschitz MAB problem\". We present a solution for the\nmulti-armed bandit problem in this setting. That is, for every metric space we\ndefine an isometry invariant which bounds from below the performance of\nLipschitz MAB algorithms for this metric space, and we present an algorithm\nwhich comes arbitrarily close to meeting this bound. Furthermore, our technique\ngives even better results for benign payoff functions. We also address the\nfull-feedback (\"best expert\") version of the problem, where after every round\nthe payoffs from all arms are revealed.Comment: This manuscript is a merged and definitive version of (R. Kleinberg,\n  Slivkins, Upfal: STOC 2008) and (R. Kleinberg, Slivkins: SODA 2010), with a\n  significantly revised presentation", "1312.1529": "Instruction sequences expressing multiplication algorithms,Bergstra, J. A.Middelburg, C. A.,Computer Science - Programming LanguagesF.1.1F.2.1,For each function on bit strings, its restriction to bit strings of any given\nlength can be computed by a finite instruction sequence that contains only\ninstructions to set and get the content of Boolean registers, forward jump\ninstructions, and a termination instruction. We describe instruction sequences\nof this kind that compute the function on bit strings that models\nmultiplication on natural numbers less than $2^N$ with respect to their binary\nrepresentation by bit strings of length $N$, for a fixed but arbitrary $N > 0$,\naccording to the long multiplication algorithm and the Karatsuba multiplication\nalgorithm. We find among other things that the instruction sequence expressing\nthe former algorithm is longer than the one expressing the latter algorithm\nonly if the length of the bit strings involved is greater than $2^8$. We also\ngo into the use of an instruction sequence with backward jump instructions for\nexpressing the long multiplication algorithm. This leads to an instruction\nsequence that it is shorter than the other two if the length of the bit strings\ninvolved is greater than $2$.Comment: 14 pages, the preliminaries of this paper and arXiv:1308.0219 are the\n  same; 16 pages, results sharpened and presentation improved; 22 pages,\n  combined with arXiv:1312.1812; 22 pages, typos corrected and explanation\n  added", "1312.1559": "Outerstring graphs are $\\chi$-bounded,Rok, AlexandreWalczak, Bartosz,Mathematics - CombinatoricsComputer Science - Computational GeometryComputer Science - Discrete Mathematics05C62, 05C15,An outerstring graph is an intersection graph of curves that lie in a common\nhalf-plane and have one endpoint on the boundary of that half-plane. We prove\nthat the class of outerstring graphs is $\\chi$-bounded, which means that their\nchromatic number is bounded by a function of their clique number. This\ngeneralizes a series of previous results on $\\chi$-boundedness of outerstring\ngraphs with various additional restrictions on the shape of curves or the\nnumber of times the pairs of curves can cross. The assumption that each curve\nhas an endpoint on the boundary of the half-plane is justified by the known\nfact that triangle-free intersection graphs of straight-line segments can have\narbitrarily large chromatic number.Comment: Introduction extended by a survey of results on (outer)string graphs,\n  some minor corrections", "1312.1664": "Simplicial Homology for Future Cellular Networks,Vergne, Ana\u00efsDecreusefond, LaurentMartins, Philippe,Computer Science - Networking and Internet Architecture,Simplicial homology is a tool that provides a mathematical way to compute the\nconnectivity and the coverage of a cellular network without any node location\ninformation. In this article, we use simplicial homology in order to not only\ncompute the topology of a cellular network, but also to discover the clusters\nof nodes still with no location information. We propose three algorithms for\nthe management of future cellular networks. The first one is a frequency\nauto-planning algorithm for the self-configuration of future cellular networks.\nIt aims at minimizing the number of planned frequencies while maximizing the\nusage of each one. Then, our energy conservation algorithm falls into the\nself-optimization feature of future cellular networks. It optimizes the energy\nconsumption of the cellular network during off-peak hours while taking into\naccount both coverage and user traffic. Finally, we present and discuss the\nperformance of a disaster recovery algorithm using determinantal point\nprocesses to patch coverage holes.", "1312.2048": "The False Premises and Promises of Bitcoin,Hanley, Brian P.,Computer Science - Computational Engineering, Finance, and ScienceQuantitative Finance - General FinanceJ.4.1,Designed to compete with fiat currencies, bitcoin proposes it is a\ncrypto-currency alternative. Bitcoin makes a number of false claims, including:\nsolving the double-spending problem is a good thing; bitcoin can be a reserve\ncurrency for banking; hoarding equals saving, and that we should believe\nbitcoin can expand by deflation to become a global transactional currency\nsupply. Bitcoin's developers combine technical implementation proficiency with\nignorance of currency and banking fundamentals. This has resulted in a failed\nattempt to change finance. A set of recommendations to change finance are\nprovided in the Afterword: Investment/venture banking for the masses; Venture\nbanking to bring back what investment banks once were; Open-outcry exchange for\nall CDS contracts; Attempting to develop CDS type contracts on investments in\nstartup and existing enterprises; and Improving the connection between startup\ntech/ideas, business organization and investment.Comment: 28 pages, 6 figures. JEL: E21, E22, E42, E51, G21, G29, G28 Section\n  2.6 has been broken out into a separate paper, and that unwieldy section is\n  replaced by a short bit referencing that new paper titled, \"A zero-sum\n  monetary system, interest rates, and implications.\"", "1312.2226": "On two Algorithmic Problems about Synchronizing Automata,Berlinkov, Mikhail V.,Computer Science - Formal Languages and Automata TheoryComputer Science - Computational ComplexityF.2.0F.4.3,Under the assumption $\\mathcal{P} \\neq \\mathcal{NP}$, we prove that two\nnatural problems from the theory of synchronizing automata cannot be solved in\npolynomial time. The first problem is to decide whether a given reachable\npartial automaton is synchronizing. The second one is, given an $n$-state\nbinary complete synchronizing automaton, to compute its reset threshold within\nperformance ratio less than $d \\ln{(n)}$ for a specific constant $d>0$.Comment: Revised and reviewed version, in particular, the result of complexity\n  of synchronization of partial automata was fixed", "1312.2674": "Silent error detection in numerical time-stepping schemes,Benson, Austin R.Schmit, SvenSchreiber, Robert,Computer Science - Numerical AnalysisComputer Science - Mathematical SoftwareMathematics - Numerical Analysis,Errors due to hardware or low level software problems, if detected, can be\nfixed by various schemes, such as recomputation from a checkpoint. Silent\nerrors are errors in application state that have escaped low-level error\ndetection. At extreme scale, where machines can perform astronomically many\noperations per second, silent errors threaten the validity of computed results.\n  We propose a new paradigm for detecting silent errors at the application\nlevel. Our central idea is to frequently compare computed values to those\nprovided by a cheap checking computation, and to build error detectors based on\nthe difference between the two output sequences. Numerical analysis provides us\nwith usable checking computations for the solution of initial-value problems in\nODEs and PDEs, arguably the most common problems in computational science.\nHere, we provide, optimize, and test methods based on Runge-Kutta and linear\nmultistep methods for ODEs, and on implicit and explicit finite difference\nschemes for PDEs. We take the heat equation and Navier-Stokes equations as\nexamples. In tests with artificially injected errors, this approach effectively\ndetects almost all meaningful errors, without significant slowdown.", "1312.3614": "Multiple Access Multicarrier Continuous-Variable Quantum Key\n  Distribution,Gyongyosi, LaszloImre, Sandor,Quantum PhysicsComputer Science - Information Theory,One of the most important practical realizations of the fundamentals of\nquantum mechanics is continuous-variable quantum key distribution (CVQKD). Here\nwe propose the adaptive multicarrier quadrature division-multiuser quadrature\nallocation (AMQD-MQA) multiple access technique for continuous-variable quantum\nkey distribution. The MQA scheme is based on the AMQD modulation, which\ngranulates the inputs of the users into Gaussian subcarrier\ncontinuous-variables (CVs). In an AMQD-MQA multiple access scenario, the\nsimultaneous reliable transmission of the users is handled by the dynamic\nallocation of the Gaussian subcarrier CVs. We propose two different settings of\nAMQD-MQA for multiple input-multiple output communication. We introduce a\nrate-selection strategy that tunes the modulation variances and allocates\nadaptively the quadratures of the users over the sub-channels. We also prove\nthe rate formulas if only partial channel side information is available for the\nusers of the sub-channel conditions. We show a technique for the compensation\nof a nonideal Gaussian input modulation, which allows the users to overwhelm\nthe modulation imperfections to reach optimal capacity-achieving communication\nover the Gaussian sub-channels. We investigate the diversity amplification of\nthe sub-channel transmittance coefficients and reveal that a strong diversity\ncan be exploited by opportunistic Gaussian modulation.Comment: 38 pages, Journal-ref: Chaos, Solitons & Fractals", "1312.3748": "On Eavesdropper-Tolerance Capability of Two-Hop Wireless Networks,Zhang, YuanyuShen, YulongWang, HuaJiang, Xiaohong,Computer Science - Information Theory,Two-hop wireless network serves as the basic net-work model for the study of\ngeneral wireless networks, while cooperative jamming is a promising scheme to\nachieve the physi-cal layer security. This paper establishes a theoretical\nframework for the study of eavesdropper-tolerance capability (i.e., the exact\nmaximum number of eavesdroppers that can be tolerated) in a two-hop wireless\nnetwork, where the cooperative jamming is adopted to ensure security defined by\nsecrecy outage probability (SOP) and opportunistic relaying is adopted to\nguarantee relia-bility defined by transmission outage probability (TOP). For\nthe concerned network, closed form modeling for both SOP and TOP is first\nconducted based on the Central Limit Theorem. With the help of SOP and TOP\nmodels and also the Stochastic Ordering Theory, the model for\neavesdropper-tolerance capability analysis is then developed. Finally,\nextensive simulation and numerical results are provided to illustrate the\nefficiency of our theoretical framework as well as the eavesdropper-tolerance\ncapability of the concerned network from adopting cooperative jamming and\nopportunistic relaying.", "1312.3876": "The Symmetric Convex Ordering: A Novel Partial Order for B-DMCs Ordering\n  the Information Sets of Polar Codes,Alsan, Mine,Computer Science - Information Theory,In this paper, we propose a novel partial order for binary discrete\nmemoryless channels that we call the symmetric convex ordering. We show that\nAr{\\i}kan's polar transform preserves 'symmetric convex orders'. Furthermore,\nwe show that while for symmetric channels this ordering turns out to be\nequivalent to the stochastic degradation ordering already known to order the\ninformation sets of polar codes, a strictly weaker partial order is obtained\nwhen at least one of the channels is asymmetric. In between, we also discuss\ntwo tools which can be useful for verifying this ordering: a criterion known as\nthe cut criterion and channel symmetrization. Finally, we discuss potential\napplications of the results to polar coding over non-stationary channels.Comment: This manuscript was submitted to IEEE Transactions on Information\n  Theory on 01-Nov-2015 as a revision of an earlier version submitted on\n  21-Aug-2014", "1312.4510": "On the genericity of Whitehead minimality,Bassino, Fr\u00e9d\u00e9riqueNicaud, CyrilWeil, Pascal,Mathematics - Group TheoryComputer Science - Computational ComplexityMathematics - Combinatorics,We show that a finitely generated subgroup of a free group, chosen uniformly\nat random, is strictly Whitehead minimal with overwhelming probability.\nWhitehead minimality is one of the key elements of the solution of the orbit\nproblem in free groups. The proofs strongly rely on combinatorial tools,\nnotably those of analytic combinatorics. The result we prove actually depends\nimplicitly on the choice of a distribution on finitely generated subgroups, and\nwe establish it for the two distributions which appear in the literature on\nrandom subgroups.", "1312.6809": "The Micro Dynamics of Collective Violence,Bruggeman, Jeroen,Physics - Physics and SocietyComputer Science - Social and Information Networks,Collective violence in direct confrontations between two opposing groups\nhappens in short bursts wherein small subgroups briefly attack small numbers of\nopponents, while the others form a non-fighting audience. The mechanism is\nfighters' synchronization of intentionalities during preliminary interactions,\nby which they feel one and overcome their fear. To explain these bursts,\nsubgroups' small sizes and leaders' role, a social influence model and a\nsynchronization model are compared.", "1401.1061": "Learning optimization models in the presence of unknown relations,Verwer, SiccoZhang, YingqianYe, Qing Chuan,Computer Science - Artificial IntelligenceComputer Science - Computer Science and Game TheoryF.5.3K.3K.4,In a sequential auction with multiple bidding agents, it is highly\nchallenging to determine the ordering of the items to sell in order to maximize\nthe revenue due to the fact that the autonomy and private information of the\nagents heavily influence the outcome of the auction.\n  The main contribution of this paper is two-fold. First, we demonstrate how to\napply machine learning techniques to solve the optimal ordering problem in\nsequential auctions. We learn regression models from historical auctions, which\nare subsequently used to predict the expected value of orderings for new\nauctions. Given the learned models, we propose two types of optimization\nmethods: a black-box best-first search approach, and a novel white-box approach\nthat maps learned models to integer linear programs (ILP) which can then be\nsolved by any ILP-solver. Although the studied auction design problem is hard,\nour proposed optimization methods obtain good orderings with high revenues.\n  Our second main contribution is the insight that the internal structure of\nregression models can be efficiently evaluated inside an ILP solver for\noptimization purposes. To this end, we provide efficient encodings of\nregression trees and linear regression models as ILP constraints. This new way\nof using learned models for optimization is promising. As the experimental\nresults show, it significantly outperforms the black-box best-first search in\nnearly all settings.Comment: 37 pages. Working paper", "1401.1140": "Efficient random sampling of binary and unary-binary trees via holonomic\n  equations,Bacher, AxelBodini, OlivierJacquot, Alice,Computer Science - Data Structures and AlgorithmsMathematics - Combinatorics,We present a new uniform random sampler for binary trees with $n$ internal\nnodes consuming $2n + \\Theta(\\log(n)^2)$ random bits on average. This makes it\nquasi-optimal and out-performs the classical Remy algorithm. We also present a\nsampler for unary-binary trees with $n$ nodes taking $\\Theta(n)$ random bits on\naverage. Both are the first linear-time algorithms to be optimal up to a\nconstant.", "1401.1333": "Time series forecasting using neural networks,Oancea, BogdanCiucu, \u015eTefan Cristian,Computer Science - Neural and Evolutionary Computing,Recent studies have shown the classification and prediction power of the\nNeural Networks. It has been demonstrated that a NN can approximate any\ncontinuous function. Neural networks have been successfully used for\nforecasting of financial data series. The classical methods used for time\nseries prediction like Box-Jenkins or ARIMA assumes that there is a linear\nrelationship between inputs and outputs. Neural Networks have the advantage\nthat can approximate nonlinear functions. In this paper we compared the\nperformances of different feed forward and recurrent neural networks and\ntraining algorithms for predicting the exchange rate EUR/RON and USD/RON. We\nused data series with daily exchange rates starting from 2005 until 2013.Comment: Proceedings of the CKS 2013 International Conference", "1401.1671": "Distributed Energy Efficient Channel Allocation,Naparstek, OshriZafaruddin, S. M.Leshem, AmirJorswieck, Eduard,Computer Science - Networking and Internet ArchitectureComputer Science - Information Theory,Design of energy efficient protocols for modern wireless systems has become\nan important area of research. In this paper, we propose a distributed\noptimization algorithm for the channel assignment problem for multiple\ninterfering transceiver pairs that cannot communicate with each other. We first\nmodify the auction algorithm for maximal energy efficiency and show that the\nproblem can be solved without explicit message passing using the carrier sense\nmultiple access (CSMA) protocols. We then develop a novel scheme by converting\nthe channel assignment problem into perfect matchings on bipartite graphs. The\nproposed scheme improves the energy efficiency and does not require any\nexplicit message passing or a shared memory between the users. We derive bounds\non the convergence rate and show that the proposed algorithm converges faster\nthan the distributed auction algorithm and achieves near-optimal performance\nunder Rayleigh fading channels. We also present an asymptotic performance\nanalysis of the fast matching algorithm for energy efficient resource\nallocation and prove the optimality for large enough number of users and number\nof channels. Finally, we provide numerical assessments that confirm the energy\nefficiency gains compared to the state of the art.Comment: 12 pages, 7 figures, 3 Tables. This work has been submitted to the\n  IEEE for possible publication", "1401.1861": "Empirical Patterns in Google Scholar Citation Counts,Breuer, Peter T.Bowen, Jonathan P.,Computer Science - Digital Libraries62P99, 01A90I.5.1I.7.5,Scholarly impact may be metricized using an author's total number of\ncitations as a stand-in for real worth, but this measure varies in\napplicability between disciplines. The detail of the number of citations per\npublication is nowadays mapped in much more detail on the Web, exposing certain\nempirical patterns. This paper explores those patterns, using the citation data\nfrom Google Scholar for a number of authors.Comment: 6 pages, 8 figures, submitted to Cyberpatterns 2014", "1401.2411": "Clustering, Coding, and the Concept of Similarity,McCarty, L. Thorne,Computer Science - Machine Learning,This paper develops a theory of clustering and coding which combines a\ngeometric model with a probabilistic model in a principled way. The geometric\nmodel is a Riemannian manifold with a Riemannian metric, ${g}_{ij}({\\bf x})$,\nwhich we interpret as a measure of dissimilarity. The probabilistic model\nconsists of a stochastic process with an invariant probability measure which\nmatches the density of the sample input data. The link between the two models\nis a potential function, $U({\\bf x})$, and its gradient, $\\nabla U({\\bf x})$.\nWe use the gradient to define the dissimilarity metric, which guarantees that\nour measure of dissimilarity will depend on the probability measure. Finally,\nwe use the dissimilarity metric to define a coordinate system on the embedded\nRiemannian manifold, which gives us a low-dimensional encoding of our original\ndata.Comment: Revised and expanded in response to referee reports. Current version:\n  65 pages, 18 figures", "1401.3580": "Bits Through Bufferless Queues,Tavan, MehrnazYates, Roy D.Bajwa, Waheed U.,Computer Science - Information Theory,This paper investigates the capacity of a channel in which information is\nconveyed by the timing of consecutive packets passing through a queue with\nindependent and identically distributed service times. Such timing channels are\ncommonly studied under the assumption of a work-conserving queue. In contrast,\nthis paper studies the case of a bufferless queue that drops arriving packets\nwhile a packet is in service. Under this bufferless model, the paper provides\nupper bounds on the capacity of timing channels and establishes achievable\nrates for the case of bufferless M/M/1 and M/G/1 queues. In particular, it is\nshown that a bufferless M/M/1 queue at worst suffers less than 10% reduction in\ncapacity when compared to an M/M/1 work-conserving queue.Comment: 8 pages, 3 figures, accepted in 51st Annual Allerton Conference on\n  Communication, Control, and Computing, University of Illinois, Monticello,\n  Illinois, Oct 2-4, 2013", "1401.3667": "Group Testing with Prior Statistics,Li, TongxinChan, Chun LamHuang, WenhaoKaced, TarikJaggi, Sidharth,Computer Science - Information Theory,We consider a new group testing model wherein each item is a binary random\nvariable defined by an a priori probability of being defective. We assume that\neach probability is small and that items are independent, but not necessarily\nidentically distributed. The goal of group testing algorithms is to identify\nwith high probability the subset of defectives via non-linear (disjunctive)\nbinary measurements. Our main contributions are two classes of algorithms: (1)\nadaptive algorithms with tests based either on a maximum entropy principle, or\non a Shannon-Fano/Huffman code; (2) non-adaptive algorithms. Under loose\nassumptions and with high probability, our algorithms only need a number of\nmeasurements that is close to the information-theoretic lower bound, up to an\nexplicitly-calculated universal constant factor. We provide simulations to\nsupport our results.Comment: 23 pages, 12 figures, presented in ISIT 2014, Honolulu", "1401.5277": "Towards a Uniform Theory of Effectful State Machines,Goncharov, SergeyMilius, StefanSilva, Alexandra,Computer Science - Logic in Computer ScienceComputer Science - Formal Languages and Automata Theory,We use recent developments on coalgebraic and monad-based semantics to obtain\na generic notion of a T-automaton, where T is a monad. This enables a uniform\nstudy of various notions of machines: e.g. finite state machines, multi-stack\nmachines, Turing machines, valence automata, and weighted automata. We use the\ngeneralized powerset construction to define a generic language semantics for\nT-automata, and we show by numerous examples that it correctly instantiates for\nsome known classes of machines/languages, including regular, context-free,\nrecursively-enumerable and various subclasses of context free languages (e.g.\ndeterministic and real-time ones). Moreover, our approach provides new generic\ntechniques for studying expressivity power of various machine-based models.Comment: journal version", "1401.5791": "Advanced Signal Processing Techniqes to Study Normal and Epileptic EEG,Dash, Debadatta,Computer Science - Computational Engineering, Finance, and Science,EEG monitoring has an important milestone provide valuable information of\nthose candidates who suffer from epilepsy.In this paper human normal and\nepileptic Electroencephalogram signals are analyzed with popular and efficient\nsignal processing techniques like Fourier and Wavelet transform. The delta,\ntheta, alpha, beta and gamma sub bands of EEG are obtained and studied for\ndetection of seizure and epilepsy. The extracted feature is then applied to ANN\nfor classification of the EEG signals.", "1401.6312": "Predicate Logic as a Modelling Language: The IDP System,De Cat, BroesBogaerts, BartBruynooghe, MauriceJanssens, GerdaDenecker, Marc,Computer Science - Logic in Computer Science,With the technology of the time, Kowalski's seminal 1974 paper {\\em Predicate\nLogic as a Programming Language} was a breakthrough for the use of logic in\ncomputer science. It introduced two fundamental ideas: on the declarative side,\nthe use of the Horn clause logic fragment of classical logic, which was soon\nextended with negation as failure, on the procedural side the procedural\ninterpretation which made it possible to write algorithms in the formalism.\n  Since then, strong progress was made both on the declarative understanding of\nthe logic programming formalism and in automated reasoning technologies,\nparticularly in SAT solving, Constraint Programming and Answer Set Programming.\nThis has paved the way for the development of an extension of logic programming\nthat embodies a more pure view of logic as a modelling language and its role\nfor problem solving.\n  In this paper, we present the \\idp language and system. The language is\nessentially classical logic extended with one of logic programmings most\nimportant contributions to knowledge representation: the representation of\ncomplex definitions as rule sets under well-founded semantics. The system is a\nknowledge base system: a system in which complex declarative information is\nstored in a knowledge base which can be used to solve different computational\nproblems by applying multiple forms of inference. In this view, theories are\ndeclarative modellings, bags of information, descriptions of possible states of\naffairs. They are neither procedures nor descriptions of computational\nproblems. As such, the \\idp language and system preserve the fundamental idea\nof a declarative reading of logic programs, while they break with the\nfundamental idea of the procedural interpretation of logic programs.", "1401.6681": "On giant components and treewidth in the layers model,Feige, UrielHermon, JonathanReichman, Daniel,Computer Science - Discrete MathematicsMathematics - Combinatorics,Given an undirected $n$-vertex graph $G(V,E)$ and an integer $k$, let\n$T_k(G)$ denote the random vertex induced subgraph of $G$ generated by ordering\n$V$ according to a random permutation $\\pi$ and including in $T_k(G)$ those\nvertices with at most $k-1$ of their neighbors preceding them in this order.\nThe distribution of subgraphs sampled in this manner is called the \\emph{layers\nmodel with parameter} $k$. The layers model has found applications in studying\n$\\ell$-degenerate subgraphs, the design of algorithms for the maximum\nindependent set problem, and in bootstrap percolation.\n  In the current work we expand the study of structural properties of the\nlayers model.\n  We prove that there are $3$-regular graphs $G$ for which with high\nprobability $T_3(G)$ has a connected component of size $\\Omega(n)$. Moreover,\nthis connected component has treewidth $\\Omega(n)$. This lower bound on the\ntreewidth extends to many other random graph models. In contrast, $T_2(G)$ is\nknown to be a forest (hence of treewidth~1), and we establish that if $G$ is of\nbounded degree then with high probability the largest connected component in\n$T_2(G)$ is of size $O(\\log n)$. We also consider the infinite two-dimensional\ngrid, for which we prove that the first four layers contain a unique infinite\nconnected component with probability $1$.", "1401.7860": "Motion planning and control of a planar polygonal linkage,Panina, GaianeSiersma, Dirk,Mathematics - Metric GeometryComputer Science - Robotics57Q99 52C99 57Q55,For a polygonal linkage, we produce a fast navigation algorithm on its\nconfiguration space. The basic idea is to approximate the configuration space\nby the vertex-edge graph of its cell decomposition discovered by the first\nauthor. The algorithm has three aspects: (1) the number of navigation steps\ndoes not exceed 15 (independent of the linkage), (2) each step is a disguised\nflex of a quadrilateral from one triangular configuration to another, which is\na well understood type of flex, and (3) each step can be performed explicitly\nby adding some extra bars and obtaining a mechanism with one degree of freedom.Comment: to appear in J. Symb. Comp", "1401.8219": "On the Properties of the Priority Deriving Procedure in the Pairwise\n  Comparisons Method,Ku\u0142akowski, Konrad,Computer Science - Discrete MathematicsComputer Science - Computer Science and Game Theory,The pairwise comparisons method is a convenient tool used when the relative\norder of preferences among different concepts (alternatives) needs to be\ndetermined. There are several popular implementations of this method, including\nthe Eigenvector Method, the Least Squares Method, the Chi Squares Method and\nothers. Each of the above methods comes with one or more inconsistency indices\nthat help to decide whether the consistency of input guarantees obtaining a\nreliable output, thus taking the optimal decision. This article explores the\nrelationship between inconsistency of input and discrepancy of output. A global\nranking discrepancy describes to what extent the obtained results correspond to\nthe single expert's assessments. On the basis of the inconsistency and\ndiscrepancy indices, two properties of the weight deriving procedure are\nformulated. These properties are proven for Eigenvector Method and Koczkodaj's\nInconsistency Index. Several estimates using Koczkodaj's Inconsistency Index\nfor a principal eigenvalue, Saaty's inconsistency index and the Condition of\nOrder Preservation are also provided.Comment: 11 pages", "1402.0485": "Local algorithms for independent sets are half-optimal,Rahman, MustazeeVirag, Balint,Mathematics - ProbabilityComputer Science - Distributed, Parallel, and Cluster ComputingMathematics - Combinatorics,We show that the largest density of factor of i.i.d. independent sets on the\nd-regular tree is asymptotically at most (log d)/d as d tends to infinity. This\nmatches the lower bound given by previous constructions. It follows that the\nlargest independent sets given by local algorithms on random d-regular graphs\nhave the same asymptotic density. In contrast, the density of the largest\nindependent sets on these graphs is asymptotically 2(log d)/d. We also prove\nanalogous results for Poisson-Galton-Watson trees, which yield bounds for local\nalgorithms on sparse Erdos-Renyi graphs.Comment: Exposition has been clarified in the new version", "1402.1526": "Dual Query: Practical Private Query Release for High Dimensional Data,Gaboardi, MarcoArias, Emilio Jes\u00fas GallegoHsu, JustinRoth, AaronWu, Zhiwei Steven,Computer Science - Data Structures and AlgorithmsComputer Science - Cryptography and SecurityComputer Science - DatabasesComputer Science - Machine Learning,We present a practical, differentially private algorithm for answering a\nlarge number of queries on high dimensional datasets. Like all algorithms for\nthis task, ours necessarily has worst-case complexity exponential in the\ndimension of the data. However, our algorithm packages the computationally hard\nstep into a concisely defined integer program, which can be solved\nnon-privately using standard solvers. We prove accuracy and privacy theorems\nfor our algorithm, and then demonstrate experimentally that our algorithm\nperforms well in practice. For example, our algorithm can efficiently and\naccurately answer millions of queries on the Netflix dataset, which has over\n17,000 attributes; this is an improvement on the state of the art by multiple\norders of magnitude.", "1402.1607": "Generalized Signal Alignment For MIMO Two-Way X Relay Channels,Liu, KangqiTao, MeixiaXiang, ZhengzhengLong, Xin,Computer Science - Information Theory,We study the degrees of freedom (DoF) of MIMO two-way X relay channels.\nPrevious work studied the case $N < 2M$, where $N$ and $M$ denote the number of\nantennas at the relay and each source, respectively, and showed that the\nmaximum DoF of $2N$ is achievable when $N \\leq \\lfloor\\frac{8M}{5}\\rfloor$ by\napplying signal alignment (SA) for network coding and interference cancelation.\nThis work considers the case $N>2M$ where the performance is limited by the\nnumber of antennas at each source node and conventional SA is not feasible. We\npropose a \\textit{generalized signal alignment} (GSA) based transmission\nscheme. The key is to let the signals to be exchanged between every source node\nalign in a transformed subspace, rather than the direct subspace, at the relay\nso as to form network-coded signals. This is realized by jointly designing the\nprecoding matrices at all source nodes and the processing matrix at the relay.\nMoreover, the aligned subspaces are orthogonal to each other. By applying the\nGSA, we show that the DoF upper bound $4M$ is achievable when $M \\leq\n\\lfloor\\frac{2N}{5}\\rfloor$ ($M$ is even) or $M \\leq\n\\lfloor\\frac{2N-1}{5}\\rfloor$ ($M$ is odd). Numerical results also demonstrate\nthat our proposed transmission scheme is feasible and effective.Comment: 6 pages, 6 figures, to appear in IEEE ICC 2014", "1402.1794": "In silico Proteome Cleavage Reveals Iterative Digestion Strategy for\n  High Sequence Coverage,Meyer, Jesse G.,Quantitative Biology - GenomicsComputer Science - Computational Engineering, Finance, and Science,In the post-genome era, biologists have sought to measure the complete\ncomplement of proteins, termed proteomics. Currently, the most effective method\nto measure the proteome is with shotgun, or bottom-up, proteomics, in which the\nproteome is digested into peptides that are identified followed by protein\ninference. Despite continuous improvements to all steps of the shotgun\nproteomics workflow, observed proteome coverage is often low; some proteins are\nidentified by a single peptide sequence. Complete proteome sequence coverage\nwould allow comprehensive characterization of RNA splicing variants and all\npost translational modifications, which would drastically improve the accuracy\nof biological models. There are many reasons for the sequence coverage deficit,\nbut ultimately peptide length determines sequence observability. Peptides that\nare too short are lost because they match many protein sequences and their true\norigin is ambiguous. The maximum observable peptide length is determined by\nseveral analytical challenges. This paper explores computationally how peptide\nlengths produced from several common proteome digestion methods limit\nobservable proteome coverage. Iterative proteome cleavage strategies are also\nexplored. These simulations reveal that maximized proteome coverage can be\nachieved by use of an iterative digestion protocol involving multiple proteases\nand chemical cleavages that theoretically allow 91.1% proteome coverage.Comment: 10 pages of text/references followed by figure/table legends, six\n  figures, and one table", "1402.2016": "Leveraging Long-Term Predictions and Online-Learning in Agent-based\n  Multiple Person Tracking,Liu, WenxiChan, Antoni B.Lau, Rynson W. H.Manocha, Dinesh,Computer Science - Computer Vision and Pattern Recognition,We present a multiple-person tracking algorithm, based on combining particle\nfilters and RVO, an agent-based crowd model that infers collision-free\nvelocities so as to predict pedestrian's motion. In addition to position and\nvelocity, our tracking algorithm can estimate the internal goals (desired\ndestination or desired velocity) of the tracked pedestrian in an online manner,\nthus removing the need to specify this information beforehand. Furthermore, we\nleverage the longer-term predictions of RVO by deriving a higher-order particle\nfilter, which aggregates multiple predictions from different prior time steps.\nThis yields a tracker that can recover from short-term occlusions and spurious\nnoise in the appearance model. Experimental results show that our tracking\nalgorithm is suitable for predicting pedestrians' behaviors online without\nneeding scene priors or hand-annotated goal information, and improves tracking\nin real-world crowded scenes under low frame rates.", "1402.2760": "Rendezvous in Networks in Spite of Delay Faults,Chalopin, J\u00e9r\u00e9mieDieudonn\u00e9, YoannLabourel, ArnaudPelc, Andrzej,Computer Science - Data Structures and Algorithms,Two mobile agents, starting from different nodes of an unknown network, have\nto meet at the same node. Agents move in synchronous rounds using a\ndeterministic algorithm. Each agent has a different label, which it can use in\nthe execution of the algorithm, but it does not know the label of the other\nagent. Agents do not know any bound on the size of the network. In each round\nan agent decides if it remains idle or if it wants to move to one of the\nadjacent nodes. Agents are subject to delay faults: if an agent incurs a fault\nin a given round, it remains in the current node, regardless of its decision.\nIf it planned to move and the fault happened, the agent is aware of it. We\nconsider three scenarios of fault distribution: random (independently in each\nround and for each agent with constant probability 0 < p < 1), unbounded adver-\nsarial (the adversary can delay an agent for an arbitrary finite number of\nconsecutive rounds) and bounded adversarial (the adversary can delay an agent\nfor at most c consecutive rounds, where c is unknown to the agents). The\nquality measure of a rendezvous algorithm is its cost, which is the total\nnumber of edge traversals. For random faults, we show an algorithm with cost\npolynomial in the size n of the network and polylogarithmic in the larger label\nL, which achieves rendezvous with very high probability in arbitrary networks.\nBy contrast, for unbounded adversarial faults we show that rendezvous is not\nfeasible, even in the class of rings. Under this scenario we give a rendezvous\nalgorithm with cost O(nl), where l is the smaller label, working in arbitrary\ntrees, and we show that \\Omega(l) is the lower bound on rendezvous cost, even\nfor the two-node tree. For bounded adversarial faults, we give a rendezvous\nalgorithm working for arbitrary networks, with cost polynomial in n, and\nlogarithmic in the bound c and in the larger label L.", "1402.3175": "Information-Geometric Equivalence of Transportation Polytopes,Kova\u010devi\u0107, MladenStanojevi\u0107, Ivan\u0160enk, Vojin,Computer Science - Information TheoryMathematics - Combinatorics94A17, 52B11, 52B12, 62B10, 62H17, 54C99,This paper deals with transportation polytopes in the probability simplex\n(that is, sets of categorical bivariate probability distributions with\nprescribed marginals). Information projections between such polytopes are\nstudied, and a sufficient condition is described under which these mappings are\nhomeomorphisms.Comment: 6 pages, 1 figure. v2: A remark concerning Frechet-Hoeffding bounds\n  is added", "1402.3210": "On the Convergence of Approximate Message Passing with Arbitrary\n  Matrices,Rangan, SundeepSchniter, PhilipFletcher, Alyson K.Sarkar, Subrata,Computer Science - Information Theory,Approximate message passing (AMP) methods and their variants have attracted\nconsiderable recent attention for the problem of estimating a random vector\n$\\mathbf{x}$ observed through a linear transform $\\mathbf{A}$. In the case of\nlarge i.i.d. zero-mean Gaussian $\\mathbf{A}$, the methods exhibit fast\nconvergence with precise analytic characterizations on the algorithm behavior.\nHowever, the convergence of AMP under general transforms $\\mathbf{A}$ is not\nfully understood. In this paper, we provide sufficient conditions for the\nconvergence of a damped version of the generalized AMP (GAMP) algorithm in the\ncase of quadratic cost functions (i.e., Gaussian likelihood and prior). It is\nshown that, with sufficient damping, the algorithm is guaranteed to converge,\nalthough the amount of damping grows with peak-to-average ratio of the squared\nsingular values of the transforms $\\mathbf{A}$. This result explains the good\nperformance of AMP on i.i.d. Gaussian transforms $\\mathbf{A}$, but also their\ndifficulties with ill-conditioned or non-zero-mean transforms $\\mathbf{A}$. A\nrelated sufficient condition is then derived for the local stability of the\ndamped GAMP method under general cost functions, assuming certain strict\nconvexity conditions.", "1402.3329": "Differential Privacy: An Economic Method for Choosing Epsilon,Hsu, JustinGaboardi, MarcoHaeberlen, AndreasKhanna, SanjeevNarayan, ArjunPierce, Benjamin C.Roth, Aaron,Computer Science - Databases,Differential privacy is becoming a gold standard for privacy research; it\noffers a guaranteed bound on loss of privacy due to release of query results,\neven under worst-case assumptions. The theory of differential privacy is an\nactive research area, and there are now differentially private algorithms for a\nwide range of interesting problems.\n  However, the question of when differential privacy works in practice has\nreceived relatively little attention. In particular, there is still no rigorous\nmethod for choosing the key parameter $\\epsilon$, which controls the crucial\ntradeoff between the strength of the privacy guarantee and the accuracy of the\npublished results.\n  In this paper, we examine the role that these parameters play in concrete\napplications, identifying the key questions that must be addressed when\nchoosing specific values. This choice requires balancing the interests of two\ndifferent parties: the data analyst and the prospective participant, who must\ndecide whether to allow their data to be included in the analysis. We propose a\nsimple model that expresses this balance as formulas over a handful of\nparameters, and we use our model to choose $\\epsilon$ on a series of simple\nstatistical studies. We also explore a surprising insight: in some\ncircumstances, a differentially private study can be more accurate than a\nnon-private study for the same cost, under our model. Finally, we discuss the\nsimplifying assumptions in our model and outline a research agenda for possible\nrefinements.", "1402.3427": "Indian Buffet Process Deep Generative Models for Semi-Supervised\n  Classification,Chatzis, Sotirios P.,Computer Science - Machine Learning,Deep generative models (DGMs) have brought about a major breakthrough, as\nwell as renewed interest, in generative latent variable models. However, DGMs\ndo not allow for performing data-driven inference of the number of latent\nfeatures needed to represent the observed data. Traditional linear formulations\naddress this issue by resorting to tools from the field of nonparametric\nstatistics. Indeed, linear latent variable models imposed an Indian Buffet\nProcess (IBP) prior have been extensively studied by the machine learning\ncommunity; inference for such models can been performed either via exact\nsampling or via approximate variational techniques. Based on this inspiration,\nin this paper we examine whether similar ideas from the field of Bayesian\nnonparametrics can be utilized in the context of modern DGMs in order to\naddress the latent variable dimensionality inference problem. To this end, we\npropose a novel DGM formulation, based on the imposition of an IBP prior. We\ndevise an efficient Black-Box Variational inference algorithm for our model,\nand exhibit its efficacy in a number of semi-supervised classification\nexperiments. In all cases, we use popular benchmark datasets, and compare to\nstate-of-the-art DGMs.", "1402.3631": "Privately Solving Linear Programs,Hsu, JustinRoth, AaronRoughgarden, TimUllman, Jonathan,Computer Science - Data Structures and AlgorithmsComputer Science - Cryptography and SecurityComputer Science - Machine Learning,In this paper, we initiate the systematic study of solving linear programs\nunder differential privacy. The first step is simply to define the problem: to\nthis end, we introduce several natural classes of private linear programs that\ncapture different ways sensitive data can be incorporated into a linear\nprogram. For each class of linear programs we give an efficient, differentially\nprivate solver based on the multiplicative weights framework, or we give an\nimpossibility result.", "1402.4178": "A reclaimer scheduling problem arising in coal stockyard management,Angelelli, EnricoKalinowski, ThomasKapoor, ReenaSavelsbergh, Martin W. P.,Computer Science - Data Structures and Algorithms,We study a number of variants of an abstract scheduling problem inspired by\nthe scheduling of reclaimers in the stockyard of a coal export terminal. We\nanalyze the complexity of each of the variants, providing complexity proofs for\nsome and polynomial algorithms for others. For one, especially interesting\nvariant, we also develop a constant factor approximation algorithm.Comment: 26 pages", "1402.4327": "Unification and Logarithmic Space,Aubert, Cl\u00e9mentBagnol, Marc,Computer Science - Logic in Computer Science,We present an algebraic characterization of the complexity classes Logspace\nand NLogspace, using an algebra with a composition law based on unification.\nThis new bridge between unification and complexity classes is inspired from\nproof theory and more specifically linear logic and Geometry of Interaction.\n  We show how unification can be used to build a model of computation by means\nof specific subalgebras associated to finite permutations groups. We then prove\nthat whether an observation (the algebraic counterpart of a program) accepts a\nword can be decided within logarithmic space. We also show that the\nconstruction can naturally represent pointer machines, an intuitive way of\nunderstanding logarithmic space computing.", "1402.4338": "Proof Complexity and the Kneser-Lov\\'asz Theorem,Istrate, GabrielCr\u0103ciun, Adrian,Computer Science - Computational ComplexityComputer Science - Logic in Computer Science,We investigate the proof complexity of a class of propositional formulas\nexpressing a combinatorial principle known as the Kneser-Lov\\'{a}sz Theorem.\nThis is a family of propositional tautologies, indexed by an nonnegative\ninteger parameter $k$ that generalizes the Pigeonhole Principle (obtained for\n$k=1$).\n  We show, for all fixed $k$, $2^{\\Omega(n)}$ lower bounds on resolution\ncomplexity and exponential lower bounds for bounded depth Frege proofs. These\nresults hold even for the more restricted class of formulas encoding\nSchrijver's strenghtening of the Kneser-Lov\\'{a}sz Theorem. On the other hand\nfor the cases $k=2,3$ (for which combinatorial proofs of the Kneser-Lov\\'{a}sz\nTheorem are known) we give polynomial size Frege ($k=2$), respectively extended\nFrege ($k=3$) proofs. The paper concludes with a brief announcement of the\nresults (presented in subsequent work) on the proof complexity of the general\ncase of the Kneser-Lov\\'{a}sz theorem.", "1402.5208": "Densely Entangled Financial Systems,DasGupta, BhaskarKaligounder, Lakshmi,Quantitative Finance - Risk ManagementComputer Science - Computational Engineering, Finance, and Science91G99, 91B30J.1J.4,In [1] Zawadoski introduces a banking network model in which the asset and\ncounter-party risks are treated separately and the banks hedge their assets\nrisks by appropriate OTC contracts. In his model, each bank has only two\ncounter-party neighbors, a bank fails due to the counter-party risk only if at\nleast one of its two neighbors default, and such a counter-party risk is a low\nprobability event. Informally, the author shows that the banks will hedge their\nasset risks by appropriate OTC contracts, and, though it may be socially\noptimal to insure against counter-party risk, in equilibrium banks will {\\em\nnot} choose to insure this low probability event.\n  In this paper, we consider the above model for more general network\ntopologies, namely when each node has exactly 2r counter-party neighbors for\nsome integer r>0. We extend the analysis of [1] to show that as the number of\ncounter-party neighbors increase the probability of counter-party risk also\nincreases, and in particular the socially optimal solution becomes privately\nsustainable when each bank hedges its risk to at least n/2 banks, where n is\nthe number of banks in the network, i.e., when 2r is at least n/2, banks not\nonly hedge their asset risk but also hedge its counter-party risk.Comment: to appear in Network Models in Economics and Finance, V. Kalyagin, P.\n  M. Pardalos and T. M. Rassias (editors), Springer Optimization and Its\n  Applications series, Springer, 2014", "1402.5481": "From Predictive to Prescriptive Analytics,Bertsimas, DimitrisKallus, Nathan,Statistics - Machine LearningComputer Science - Machine LearningMathematics - Optimization and Control,In this paper, we combine ideas from machine learning (ML) and operations\nresearch and management science (OR/MS) in developing a framework, along with\nspecific methods, for using data to prescribe optimal decisions in OR/MS\nproblems. In a departure from other work on data-driven optimization and\nreflecting our practical experience with the data available in applications of\nOR/MS, we consider data consisting, not only of observations of quantities with\ndirect effect on costs/revenues, such as demand or returns, but predominantly\nof observations of associated auxiliary quantities. The main problem of\ninterest is a conditional stochastic optimization problem, given imperfect\nobservations, where the joint probability distributions that specify the\nproblem are unknown. We demonstrate that our proposed solution methods, which\nare inspired by ML methods such as local regression, CART, and random forests,\nare generally applicable to a wide range of decision problems. We prove that\nthey are tractable and asymptotically optimal even when data is not iid and may\nbe censored. We extend this to the case where decision variables may directly\naffect uncertainty in unknown ways, such as pricing's effect on demand. As an\nanalogue to R^2, we develop a metric P termed the coefficient of\nprescriptiveness to measure the prescriptive content of data and the efficacy\nof a policy from an operations perspective. To demonstrate the power of our\napproach in a real-world setting we study an inventory management problem faced\nby the distribution arm of an international media conglomerate, which ships an\naverage of 1bil units per year. We leverage internal data and public online\ndata harvested from IMDb, Rotten Tomatoes, and Google to prescribe operational\ndecisions that outperform baseline measures. Specifically, the data we collect,\nleveraged by our methods, accounts for an 88\\% improvement as measured by our\nP.", "1402.6208": "The Anatomy of a Modular System for Media Content Analysis,Flaounas, IliasLansdall-Welfare, ThomasAntonakaki, PanagiotaCristianini, Nello,Computer Science - Multiagent SystemsComputer Science - Artificial IntelligenceComputer Science - Distributed, Parallel, and Cluster Computing,Intelligent systems for the annotation of media content are increasingly\nbeing used for the automation of parts of social science research. In this\ndomain the problem of integrating various Artificial Intelligence (AI)\nalgorithms into a single intelligent system arises spontaneously. As part of\nour ongoing effort in automating media content analysis for the social\nsciences, we have built a modular system by combining multiple AI modules into\na flexible framework in which they can cooperate in complex tasks. Our system\ncombines data gathering, machine translation, topic classification, extraction\nand annotation of entities and social networks, as well as many other tasks\nthat have been perfected over the past years of AI research. Over the last few\nyears, it has allowed us to realise a series of scientific studies over a vast\nrange of applications including comparative studies between news outlets and\nmedia content in different countries, modelling of user preferences, and\nmonitoring public mood. The framework is flexible and allows the design and\nimplementation of modular agents, where simple modules cooperate in the\nannotation of a large dataset without central coordination.Comment: Updated to include previously missing figures", "1402.6787": "Learning multifractal structure in large networks,Benson, Austin R.Riquelme, CarlosSchmit, Sven,Computer Science - Social and Information NetworksH.4.0E.1,Generating random graphs to model networks has a rich history. In this paper,\nwe analyze and improve upon the multifractal network generator (MFNG)\nintroduced by Palla et al. We provide a new result on the probability of\nsubgraphs existing in graphs generated with MFNG. From this result it follows\nthat we can quickly compute moments of an important set of graph properties,\nsuch as the expected number of edges, stars, and cliques. Specifically, we show\nhow to compute these moments in time complexity independent of the size of the\ngraph and the number of recursive levels in the generative model. We leverage\nthis theory to a new method of moments algorithm for fitting large networks to\nMFNG. Empirically, this new approach effectively simulates properties of\nseveral social and information networks. In terms of matching subgraph counts,\nour method outperforms similar algorithms used with the Stochastic Kronecker\nGraph model. Furthermore, we present a fast approximation algorithm to generate\ngraph instances following the multi- fractal structure. The approximation\nscheme is an improvement over previous methods, which ran in time complexity\nquadratic in the number of vertices. Combined, our method of moments and fast\nsampling scheme provide the first scalable framework for effectively modeling\nlarge networks with MFNG.", "1402.6964": "Scalable methods for nonnegative matrix factorizations of near-separable\n  tall-and-skinny matrices,Benson, Austin R.Lee, Jason D.Rajwa, BartekGleich, David F.,Computer Science - Machine LearningComputer Science - Distributed, Parallel, and Cluster ComputingComputer Science - Numerical AnalysisStatistics - Machine LearningG.1.3G.1.6,Numerous algorithms are used for nonnegative matrix factorization under the\nassumption that the matrix is nearly separable. In this paper, we show how to\nmake these algorithms efficient for data matrices that have many more rows than\ncolumns, so-called \"tall-and-skinny matrices\". One key component to these\nimproved methods is an orthogonal matrix transformation that preserves the\nseparability of the NMF problem. Our final methods need a single pass over the\ndata matrix and are suitable for streaming, multi-core, and MapReduce\narchitectures. We demonstrate the efficacy of these algorithms on\nterabyte-sized synthetic matrices and real-world matrices from scientific\ncomputing and bioinformatics.", "1402.7242": "Percolation with small clusters on random graphs,Rahman, Mustazee,Mathematics - ProbabilityComputer Science - Discrete MathematicsMathematics - Combinatorics,Consider the problem of determining the maximal induced subgraph in a random\n$d$-regular graph such that its components remain bounded as the size of the\ngraph becomes arbitrarily large. We show, for asymptotically large $d$, that\nany such induced subgraph has size density at most $2(\\log d)/d$ with high\nprobability. A matching lower bound is known for independent sets. We also\nprove the analogous result for sparse Erd\\H{o}s-R\\'{e}nyi graphs.Comment: The main result (Theorem 1) has been improved significantly and\n  references have been updated", "1403.0505": "A search for quantum coin-flipping protocols using optimization\n  techniques,Nayak, AshwinSikora, JamieTun\u00e7el, Levent,Mathematics - Optimization and ControlComputer Science - Cryptography and SecurityQuantum Physics,Coin-flipping is a cryptographic task in which two physically separated,\nmistrustful parties wish to generate a fair coin-flip by communicating with\neach other. Chailloux and Kerenidis (2009) designed quantum protocols that\nguarantee coin-flips with near optimal bias. The probability of any outcome in\nthese protocols is provably at most $1/\\sqrt{2} + \\delta$ for any given $\\delta\n> 0$. However, no explicit description of these protocols is known, and the\nnumber of rounds in the protocols tends to infinity as $\\delta$ goes to 0. In\nfact, the smallest bias achieved by known explicit protocols is $1/4$\n(Ambainis, 2001).\n  We take a computational optimization approach, based mostly on convex\noptimization, to the search for simple and explicit quantum strong\ncoin-flipping protocols. We present a search algorithm to identify protocols\nwith low bias within a natural class, protocols based on bit-commitment (Nayak\nand Shor, 2003) restricting to commitment states used by Mochon (2005). An\nanalysis of the resulting protocols via semidefinite programs (SDPs) unveils a\nsimple structure. For example, we show that the SDPs reduce to second-order\ncone programs. We devise novel cheating strategies in the protocol by\nrestricting the semidefinite programs and use the strategies to prune the\nsearch.\n  The techniques we develop enable a computational search for protocols given\nby a mesh over the parameter space. The protocols have up to six rounds of\ncommunication, with messages of varying dimension and include the best known\nexplicit protocol (with bias 1/4). We conduct two kinds of search: one for\nprotocols with bias below 0.2499, and one for protocols in the neighbourhood of\nprotocols with bias 1/4. Neither of these searches yields better bias. Based on\nthe mathematical ideas behind the search algorithm, we prove a lower bound on\nthe bias of a class of four-round protocols.Comment: 74 pages (plus 16 page appendix), 27 tables, 3 figures. Comments\n  welcome", "1403.0734": "Clique counting in MapReduce: theory and experiments,Finocchi, IreneFinocchi, MarcoFusco, Emanuele G.,Computer Science - Distributed, Parallel, and Cluster ComputingComputer Science - Data Structures and Algorithms,We tackle the problem of counting the number of $k$-cliques in large-scale\ngraphs, for any constant $k \\ge 3$. Clique counting is essential in a variety\nof applications, among which social network analysis. Due to its\ncomputationally intensive nature, we settle for parallel solutions in the\nMapReduce framework, which has become in the last few years a {\\em de facto}\nstandard for batch processing of massive data sets. We give both theoretical\nand experimental contributions.\n  On the theory side, we design the first exact scalable algorithm for counting\n(and listing) $k$-cliques. Our algorithm uses $O(m^{3/2})$ total space and\n$O(m^{k/2})$ work, where $m$ is the number of graph edges. This matches the\nbest-known bounds for triangle listing when $k=3$ and is work-optimal in the\nworst case for any $k$, while keeping the communication cost independent of\n$k$. We also design a sampling-based estimator that can dramatically reduce the\nrunning time and space requirements of the exact approach, while providing very\naccurate solutions with high probability.\n  We then assess the effectiveness of different clique counting approaches\nthrough an extensive experimental analysis over the Amazon EC2 platform,\nconsidering both our algorithms and their state-of-the-art competitors. The\nexperimental results clearly highlight the algorithm of choice in different\nscenarios and prove our exact approach to be the most effective when the number\nof $k$-cliques is large, gracefully scaling to non-trivial values of $k$ even\non clusters of small/medium size. Our approximation algorithm achieves\nextremely accurate estimates and large speedups, especially on the toughest\ninstances for the exact algorithms. As a side effect, our study also sheds\nlight on the number of $k$-cliques of several real-world graphs, mainly social\nnetworks, and on its growth rate as a function of $k$.", "1403.1080": "New Ideas for Brain Modelling,Greer, Kieran,Computer Science - Artificial IntelligenceQuantitative Biology - Neurons and Cognition,This paper describes some biologically-inspired processes that could be used\nto build the sort of networks that we associate with the human brain. New to\nthis paper, a 'refined' neuron will be proposed. This is a group of neurons\nthat by joining together can produce a more analogue system, but with the same\nlevel of control and reliability that a binary neuron would have. With this new\nstructure, it will be possible to think of an essentially binary system in\nterms of a more variable set of values. The paper also shows how recent\nresearch associated with the new model, can be combined with established\ntheories, to produce a more complete picture. The propositions are largely in\nline with conventional thinking, but possibly with one or two more radical\nsuggestions. An earlier cognitive model can be filled in with more specific\ndetails, based on the new research results, where the components appear to fit\ntogether almost seamlessly. The intention of the research has been to describe\nplausible 'mechanical' processes that can produce the appropriate brain\nstructures and mechanisms, but that could be used without the magical\n'intelligence' part that is still not fully understood. There are also some\nimportant updates from an earlier version of this paper.", "1403.1142": "Automated analysis of security protocols with global state,Kremer, SteveK\u00fcnnemann, Robert,Computer Science - Cryptography and Security,Security APIs, key servers and protocols that need to keep the status of\ntransactions, require to maintain a global, non-monotonic state, e.g., in the\nform of a database or register. However, most existing automated verification\ntools do not support the analysis of such stateful security protocols -\nsometimes because of fundamental reasons, such as the encoding of the protocol\nas Horn clauses, which are inherently monotonic. A notable exception is the\nrecent tamarin prover which allows specifying protocols as multiset rewrite\n(msr) rules, a formalism expressive enough to encode state. As multiset\nrewriting is a \"low-level\" specification language with no direct support for\nconcurrent message passing, encoding protocols correctly is a difficult and\nerror-prone process. We propose a process calculus which is a variant of the\napplied pi calculus with constructs for manipulation of a global state by\nprocesses running in parallel. We show that this language can be translated to\nmsr rules whilst preserving all security properties expressible in a dedicated\nfirst-order logic for security properties. The translation has been implemented\nin a prototype tool which uses the tamarin prover as a backend. We apply the\ntool to several case studies among which a simplified fragment of PKCS\\#11, the\nYubikey security token, and an optimistic contract signing protocol.", "1403.1639": "Optimal Patching in Clustered Malware Epidemics,Eshghi, SoheilKhouzani, MHR.Sarkar, SaswatiVenkatesh, Santosh S.,Computer Science - Cryptography and SecurityComputer Science - Networking and Internet ArchitectureComputer Science - Social and Information NetworksComputer Science - Systems and ControlMathematics - Optimization and Control,Studies on the propagation of malware in mobile networks have revealed that\nthe spread of malware can be highly inhomogeneous. Platform diversity, contact\nlist utilization by the malware, clustering in the network structure, etc. can\nalso lead to differing spreading rates. In this paper, a general formal\nframework is proposed for leveraging such heterogeneity to derive optimal\npatching policies that attain the minimum aggregate cost due to the spread of\nmalware and the surcharge of patching. Using Pontryagin's Maximum Principle for\na stratified epidemic model, it is analytically proven that in the mean-field\ndeterministic regime, optimal patch disseminations are simple single-threshold\npolicies. Through numerical simulations, the behavior of optimal patching\npolicies is investigated in sample topologies and their advantages are\ndemonstrated.Comment: 18 pages, 6 figures", "1403.1642": "Optimal Energy-Aware Epidemic Routing in DTNs,Eshghi, SoheilKhouzani, MHR.Sarkar, SaswatiShroff, Ness B.Venkatesh, Santosh S.,Computer Science - Systems and ControlComputer Science - Distributed, Parallel, and Cluster ComputingComputer Science - Networking and Internet ArchitectureMathematics - Optimization and Control,In this work, we investigate the use of epidemic routing in energy\nconstrained Delay Tolerant Networks (DTNs). In epidemic routing, messages are\nrelayed by intermediate nodes at contact opportunities, i.e., when pairs of\nnodes come within the transmission range of each other. Each node needs to\ndecide whether to forward its message upon contact with a new node based on its\nown residual energy level and the age of that message. We mathematically\ncharacterize the fundamental trade-off between energy conservation and a\nmeasure of Quality of Service as a dynamic energy-dependent optimal control\nproblem. We prove that in the mean-field regime, the optimal dynamic forwarding\ndecisions follow simple threshold-based structures in which the forwarding\nthreshold for each node depends on its current remaining energy. We then\ncharacterize the nature of this dependence. Our simulations reveal that the\noptimal dynamic policy significantly outperforms heuristics.Comment: 17 pages, 9 figures", "1403.2975": "Optimal ancilla-free Clifford+T approximation of z-rotations,Ross, Neil J.Selinger, Peter,Quantum PhysicsComputer Science - Emerging Technologies,We consider the problem of approximating arbitrary single-qubit z-rotations\nby ancilla-free Clifford+T circuits, up to given epsilon. We present a fast new\nprobabilistic algorithm for solving this problem optimally, i.e., for finding\nthe shortest possible circuit whatsoever for the given problem instance. The\nalgorithm requires a factoring oracle (such as a quantum computer). Even in the\nabsence of a factoring oracle, the algorithm is still near-optimal under a mild\nnumber-theoretic hypothesis. In this case, the algorithm finds a solution of\nT-count m + O(log(log(1/epsilon))), where m is the T-count of the\nsecond-to-optimal solution. In the typical case, this yields circuit\napproximations of T-count 3log_2(1/epsilon) + O(log(log(1/epsilon))). Our\nalgorithm is efficient in practice, and provably efficient under the\nabove-mentioned number-theoretic hypothesis, in the sense that its expected\nruntime is O(polylog(1/epsilon)).Comment: 40 pages. New in v3: added a section on worst-case behavior", "1403.3772": "Study of Behaviours via Visitable Paths,Fouquer\u00e9, ChristopheQuatrini, Myriam,Computer Science - Logic in Computer ScienceF.4.1,Around 2000, J.-Y. Girard developed a logical theory, called Ludics. This\ntheory was a step in his program of Geometry of Interaction, the aim of which\nbeing to account for the dynamics of logical proofs. In Ludics, objects called\ndesigns keep only what is relevant for the cut elimination process, hence the\ndynamics of a proof: a design is an abstraction of a formal proof. The notion\nof behaviour is the counterpart in Ludics of the notion of type or the logical\nnotion of formula. Formally a behaviour is a closed set of designs. Our aim is\nto explore the constructions of behaviours and to analyse their properties. In\nthis paper a design is viewed as a set of coherent paths. We recall or give\nvariants of properties concerning visitable paths, where a visitable path is a\npath in a design or a set of designs that may be traversed by interaction with\na design of the orthogonal of the set. We are then able to answer the following\nquestion: which properties should satisfy a set of paths for being exactly the\nset of visitable paths of a behaviour? Such a set and its dual should be\nprefix-closed, daimon-closed and satisfy two saturation properties. This allows\nus to have a means for defining the whole set of visitable paths of a given set\nof designs without closing it explicitly, that is without computing the\northogonal of this set of designs. We finally apply all these results for\nmaking explicit the structure of a behaviour generated by constants and\nmultiplicative/additive connectives. We end by proposing an oriented tensor for\nwhich we give basic properties.", "1403.4143": "P is not equal to NP by Modus Tollens,Kim, Joonmo,Computer Science - Computational Complexity,An artificially designed Turing Machine algorithm $\\mathbf{M}_{}^{o}$\ngenerates the instances of the satisfiability problem, and check their\nsatisfiability. Under the assumption $\\mathcal{P}=\\mathcal{NP}$, we show that\n$\\mathbf{M}_{}^{o}$ has a certain property, which, without the assumption,\n$\\mathbf{M}_{}^{o}$ does not have. This leads to $\\mathcal{P}\\neq\\mathcal{NP}$\n$ $ by modus tollens.Comment: 7 pages. Caution: this solution should not be reported to be correct\n  while this caution stands. Actually, it is quite unlikely that this simple\n  solution is correct. I am sharing this e-print to get comments on the\n  probable mistake that I could not have found yet. If you have a conceptual\n  grasp on Cooks Theory and some related glossaries then there will be no\n  difficulty in reading this paper", "1403.4539": "Occam Bound on Lowest Complexity of Elements,Levin, Leonid A.,Computer Science - Computational Complexity,The combined universal probability M(D) of strings x in sets D is close to\nmax_{x \\in D} M({x}): their ~ logs differ by at most D's information j = I(D:H)\nabout the halting sequence H. Thus if all x have complexity K(x) > k, D carries\n> i bits of information on each x where i+j ~ k. Note, there are no ways\n(whether natural or artificial) to generate D with significant I(D:H).Comment: 4 pages, minor clarifications", "1403.4622": "Complete simultaneous conjugacy invariants in Artin's braid groups,Kalka, ArkadiusTsaban, BoazVinokur, Gary,Mathematics - Group TheoryComputer Science - Computational ComplexityComputer Science - Cryptography and Security20F36, 20F65, 20C40,We solve the simultaneous conjugacy problem in Artin's braid groups and, more\ngenerally, in Garside groups, by means of a complete, effectively computable,\nfinite invariant. This invariant generalizes the one-dimensional notion of\nsuper summit set to arbitrary dimensions. One key ingredient in our solution is\nthe introduction of a provable high-dimensional version of the Birman--Ko--Lee\ncycling theorem. The complexity of this solution is a small degree polynomial\nin the cardinalities of our generalized super summit sets and the input\nparameters. Computer experiments suggest that the cardinality of this\ninvariant, for a list of order $N$ independent elements of Artin's braid group\n$B_N$, is generically close to~1.Comment: Improved some aspects, added a discussion of Garside families. Paper\n  ready for submission", "1403.4861": "Improved Approximation Algorithms for Box Contact Representations,Bekos, Michael A.van Dijk, Thomas C.Fink, MartinKindermann, PhilippKobourov, StephenPupyrev, SergeySpoerhase, JoachimWolff, Alexander,Computer Science - Data Structures and Algorithms,We study the following geometric representation problem: Given a graph whose\nvertices correspond to axis-aligned rectangles with fixed dimensions, arrange\nthe rectangles without overlaps in the plane such that two rectangles touch if\nthe graph contains an edge between them. This problem is called \\textsc{Contact\nRepresentation of Word Networks} (\\textsc{Crown}) since it formalizes the\ngeometric problem behind drawing word clouds in which semantically related\nwords are close to each other. \\textsc{Crown} is known to be NP-hard, and there\nare approximation algorithms for certain graph classes for the optimization\nversion, \\textsc{Max-Crown}, in which realizing each desired adjacency yields a\ncertain profit. We present the first $O(1)$-approximation algorithm for the\ngeneral case, when the input is a complete weighted graph, and for the\nbipartite case. Since the subgraph of realized adjacencies is necessarily\nplanar, we also consider several planar graph classes (namely stars, trees,\nouterplanar, and planar graphs), improving upon the known results. For some\ngraph classes, we also describe improvements in the unweighted case, where each\nadjacency yields the same profit. Finally, we show that the problem is APX-hard\non bipartite graphs of bounded maximum degree.", "1403.5361": "Parameter Estimation of Social Forces in Crowd Dynamics Models via a\n  Probabilistic Method,Corbetta, AlessandroMuntean, AdrianToschi, FedericoVafayi, Kiamars,Physics - Data Analysis, Statistics and ProbabilityComputer Science - Social and Information NetworksMathematics - ProbabilityMathematics - Statistics TheoryPhysics - Physics and Society,Focusing on a specific crowd dynamics situation, including real life\nexperiments and measurements, our paper targets a twofold aim: (1) we present a\nBayesian probabilistic method to estimate the value and the uncertainty (in the\nform of a probability density function) of parameters in crowd dynamic models\nfrom the experimental data; and (2) we introduce a fitness measure for the\nmodels to classify a couple of model structures (forces) according to their\nfitness to the experimental data, preparing the stage for a more general\nmodel-selection and validation strategy inspired by probabilistic data\nanalysis. Finally, we review the essential aspects of our experimental setup\nand measurement technique.Comment: 20 pages, 9 figures", "1403.5543": "Disaster Recovery in Wireless Networks: A Homology-Based Algorithm,Vergne, Ana\u00efsFlint, IanDecreusefond, LaurentMartins, Philippe,Mathematics - ProbabilityComputer Science - Networking and Internet Architecture,In this paper, we present an algorithm for the recovery of wireless networks\nafter a disaster. Considering a damaged wireless network, presenting coverage\nholes or/and many disconnected components, we propose a disaster recovery\nalgorithm which repairs the network. It provides the list of locations where to\nput new nodes in order to patch the coverage holes and mend the disconnected\ncomponents. In order to do this we first consider the simplicial complex\nrepresentation of the network, then the algorithm adds supplementary vertices\nin excessive number, and afterwards runs a reduction algorithm in order to\nreach an optimal result. One of the novelty of this work resides in the\nproposed method for the addition of vertices. We use a determinantal point\nprocess: the Ginibre point process which has inherent repulsion between\nvertices, and has never been simulated before for wireless networks\nrepresentation. We compare both the determinantal point process addition method\nwith other vertices addition methods, and the whole disaster recovery algorithm\nto the greedy algorithm for the set cover problem.Comment: arXiv admin note: substantial text overlap with arXiv:1312.1664", "1403.5715": "Mining Attribute-Based Access Control Policies from Logs,Xu, ZhongyuanStoller, Scott D.,Computer Science - Cryptography and SecurityComputer Science - Databases,Attribute-based access control (ABAC) provides a high level of flexibility\nthat promotes security and information sharing. ABAC policy mining algorithms\nhave potential to significantly reduce the cost of migration to ABAC, by\npartially automating the development of an ABAC policy from information about\nthe existing access-control policy and attribute data. This paper presents an\nalgorithm for mining ABAC policies from operation logs and attribute data. To\nthe best of our knowledge, it is the first algorithm for this problem.Comment: arXiv admin note: substantial text overlap with arXiv:1306.2401", "1403.6322": "Do the Fix Ingredients Already Exist? An Empirical Inquiry into the\n  Redundancy Assumptions of Program Repair Approaches,Martinez, MatiasWeimer, WestleyMonperrus, Martin,Computer Science - Software Engineering,Much initial research on automatic program repair has focused on experimental\nresults to probe their potential to find patches and reduce development effort.\nRelatively less effort has been put into understanding the hows and whys of\nsuch approaches. For example, a critical assumption of the GenProg technique is\nthat certain bugs can be fixed by copying and re-arranging existing code. In\nother words, GenProg assumes that the fix ingredients already exist elsewhere\nin the code. In this paper, we formalize these assumptions around the concept\nof ''temporal redundancy''. A temporally redundant commit is only composed of\nwhat has already existed in previous commits. Our experiments show that a large\nproportion of commits that add existing code are temporally redundant. This\nvalidates the fundamental redundancy assumption of GenProg.Comment: ICSE - 36th IEEE International Conference on Software Engineering\n  (2014)", "1404.1008": "Spectral concentration and greedy k-clustering,Dey, Tamal K.Peng, PanRossi, AlfredSidiropoulos, Anastasios,Computer Science - Data Structures and AlgorithmsComputer Science - Computational Geometry,A popular graph clustering method is to consider the embedding of an input\ngraph into R^k induced by the first k eigenvectors of its Laplacian, and to\npartition the graph via geometric manipulations on the resulting metric space.\nDespite the practical success of this methodology, there is limited\nunderstanding of several heuristics that follow this framework. We provide\ntheoretical justification for one such natural and computationally efficient\nvariant.\n  Our result can be summarized as follows. A partition of a graph is called\nstrong if each cluster has small external conductance, and large internal\nconductance. We present a simple greedy spectral clustering algorithm which\nreturns a partition that is provably close to a suitably strong partition,\nprovided that such a partition exists. A recent result shows that strong\npartitions exist for graphs with a sufficiently large spectral gap between the\nk-th and (k+1)-st eigenvalues. Taking this together with our main theorem gives\na spectral algorithm which finds a partition close to a strong one for graphs\nwith large enough spectral gap. We also show how this simple greedy algorithm\ncan be implemented in near-linear time for any fixed k and error guarantee.\nFinally, we evaluate our algorithm on some real-world and synthetic inputs.Comment: 21 pages, 6 figures", "1404.1864": "Sublinear algorithms for local graph centrality estimation,Bressan, MarcoPeserico, EnochPretto, Luca,Computer Science - Data Structures and AlgorithmsComputer Science - Information RetrievalComputer Science - Social and Information Networks,We study the complexity of local graph centrality estimation, with the goal\nof approximating the centrality score of a given target node while exploring\nonly a sublinear number of nodes/arcs of the graph and performing a sublinear\nnumber of elementary operations. We develop a technique, that we apply to the\nPageRank and Heat Kernel centralities, for building a low-variance score\nestimator through a local exploration of the graph. We obtain an algorithm\nthat, given any node in any graph of $m$ arcs, with probability $(1-\\delta)$\ncomputes a multiplicative $(1\\pm\\epsilon)$-approximation of its score by\nexamining only $\\tilde{O}(\\min(m^{2/3} \\Delta^{1/3} d^{-2/3},\\, m^{4/5}\nd^{-3/5}))$ nodes/arcs, where $\\Delta$ and $d$ are respectively the maximum and\naverage outdegree of the graph (omitting for readability\n$\\operatorname{poly}(\\epsilon^{-1})$ and $\\operatorname{polylog}(\\delta^{-1})$\nfactors). A similar bound holds for computational complexity. We also prove a\nlower bound of $\\Omega(\\min(m^{1/2} \\Delta^{1/2} d^{-1/2}, \\, m^{2/3}\nd^{-1/3}))$ for both query complexity and computational complexity. Moreover,\nour technique yields a $\\tilde{O}(n^{2/3})$ query complexity algorithm for the\ngraph access model of [Brautbar et al., 2010], widely used in social network\nmining; we show this algorithm is optimal up to a sublogarithmic factor. These\nare the first algorithms yielding worst-case sublinear bounds for general\ndirected graphs and any choice of the target node.Comment: 29 pages, 1 figure", "1404.2329": "Duality and Optimality of Auctions for Uniform Distributions,Giannakopoulos, YiannisKoutsoupias, Elias,Computer Science - Computer Science and Game Theory,We develop a general duality-theory framework for revenue maximization in\nadditive Bayesian auctions. The framework extends linear programming duality\nand complementarity to constraints with partial derivatives. The dual system\nreveals the geometric nature of the problem and highlights its connection with\nthe theory of bipartite graph matchings. We demonstrate the power of the\nframework by applying it to a multiple-good monopoly setting where the buyer\nhas uniformly distributed valuations for the items, the canonical long-standing\nopen problem in the area. We propose a deterministic selling mechanism called\nStraight-Jacket Auction (SJA), which we prove to be exactly optimal for up to 6\nitems, and conjecture its optimality for any number of goods. The duality\nframework is used not only for proving optimality, but perhaps more importantly\nfor deriving the optimal mechanism itself; as a result, SJA is defined by\nnatural geometric constraints.", "1404.2458": "r-Extreme Signalling for Congestion Control,Marecek, JakubShorten, RobertYu, Jia Yuan,Mathematics - Optimization and ControlComputer Science - Artificial IntelligenceComputer Science - Multiagent Systems,In many \"smart city\" applications, congestion arises in part due to the\nnature of signals received by individuals from a central authority. In the\nmodel of Marecek et al. [arXiv:1406.7639, Int. J. Control 88(10), 2015], each\nagent uses one out of multiple resources at each time instant. The per-use cost\nof a resource depends on the number of concurrent users. A central authority\nhas up-to-date knowledge of the congestion across all resources and uses\nrandomisation to provide a scalar or an interval for each resource at each\ntime. In this paper, the interval to broadcast per resource is obtained by\ntaking the minima and maxima of costs observed within a time window of length\nr, rather than by randomisation. We show that the resulting distribution of\nagents across resources also converges in distribution, under plausible\nassumptions about the evolution of the population over time.", "1404.2743": "Infinite dimensional finitely forcible graphon,Glebov, RomanKlimosova, TerezaKral, Daniel,Mathematics - CombinatoricsComputer Science - Discrete Mathematics,Graphons are analytic objects associated with convergent sequences of dense\ngraphs. Finitely forcible graphons, i.e., those determined by finitely many\nsubgraph densities, are of particular interest because of their relation to\nvarious problems in extremal combinatorics and theoretical computer science.\nLovasz and Szegedy conjectured that the topological space of typical vertices\nof a finitely forcible graphon always has finite dimension, which would have\nimplications on the minimum number of parts in its weak eps-regular partition.\nWe disprove the conjecture by constructing a finitely forcible graphon with the\nspace of typical vertices that has infinite dimension.", "1404.3056": "Principles of Antifragile Software,Monperrus, Martin,Computer Science - Software Engineering,The goal of this paper is to study and define the concept of \"antifragile\nsoftware\". For this, I start from Taleb's statement that antifragile systems\nlove errors, and discuss whether traditional software dependability fits into\nthis class. The answer is somewhat negative, although adaptive fault tolerance\nis antifragile: the system learns something when an error happens, and always\nimrpoves. Automatic runtime bug fixing is changing the code in response to\nerrors, fault injection in production means injecting errors in business\ncritical software. I claim that both correspond to antifragility. Finally, I\nhypothesize that antifragile development processes are better at producing\nantifragile software systems.Comment: see https://refuses.github.io/", "1404.3186": "Automatic Repair of Buggy If Conditions and Missing Preconditions with\n  SMT,Demarco, FavioXuan, JifengBerre, Daniel LeMonperrus, Martin,Computer Science - Software Engineering,We present Nopol, an approach for automatically repairing buggy if conditions\nand missing preconditions. As input, it takes a program and a test suite which\ncontains passing test cases modeling the expected behavior of the program and\nat least one failing test case embodying the bug to be repaired. It consists of\ncollecting data from multiple instrumented test suite executions, transforming\nthis data into a Satisfiability Modulo Theory (SMT) problem, and translating\nthe SMT result -- if there exists one -- into a source code patch. Nopol\nrepairs object oriented code and allows the patches to contain nullness checks\nas well as specific method calls.Comment: CSTVA'2014, India (2014)", "1404.3311": "Generating Synchronizing Automata with Large Reset Lengths,Kisielewicz, AndrzejSzyku\u0142a, Marek,Computer Science - Formal Languages and Automata Theory,We study synchronizing automata with the shortest reset words of relatively\nlarge length. First, we refine the Frankl-Pin result on the length of the\nshortest words of rank $m$, and the B\\'eal, Berlinkov, Perrin, and Steinberg\nresults on the length of the shortest reset words in one-cluster automata. The\nobtained results are useful in computation aimed in extending the class of\nsmall automata for which the \\v{C}ern\\'y conjecture is verified and discovering\nnew automata with special properties regarding synchronization.", "1404.3368": "Near-optimal sample compression for nearest neighbors,Gottlieb, Lee-AdKontorovich, AryehNisnevitch, Pinhas,Computer Science - Machine LearningComputer Science - Computational Complexity,We present the first sample compression algorithm for nearest neighbors with\nnon-trivial performance guarantees. We complement these guarantees by\ndemonstrating almost matching hardness lower bounds, which show that our bound\nis nearly optimal. Our result yields new insight into margin-based nearest\nneighbor classification in metric spaces and allows us to significantly sharpen\nand simplify existing bounds. Some encouraging empirical results are also\npresented.", "1404.3442": "Optimal versus Nash Equilibrium Computation for Networked Resource\n  Allocation,Etesami, S. Rasoul,Computer Science - Computer Science and Game TheoryComputer Science - Discrete MathematicsComputer Science - Systems and ControlMathematics - Combinatorics,Motivated by emerging resource allocation and data placement problems such as\nweb caches and peer-to-peer systems, we consider and study a class of resource\nallocation problems over a network of agents (nodes). In this model, nodes can\nstore only a limited number of resources while accessing the remaining ones\nthrough their closest neighbors. We consider this problem under both\noptimization and game-theoretic frameworks. In the case of optimal resource\nallocation we will first show that when there are only k=2 resources, the\noptimal allocation can be found efficiently in O(n^2\\log n) steps, where n\ndenotes the total number of nodes. However, for k>2 this problem becomes\nNP-hard with no polynomial time approximation algorithm with a performance\nguarantee better than 1+1/102k^2, even under metric access costs. We then\nprovide a 3-approximation algorithm for the optimal resource allocation which\nruns only in linear time O(n). Subsequently, we look at this problem under a\nselfish setting formulated as a noncooperative game and provide a\n3-approximation algorithm for obtaining its pure Nash equilibria under metric\naccess costs. We then establish an equivalence between the set of pure Nash\nequilibria and flip-optimal solutions of the Max-k-Cut problem over a specific\nweighted complete graph. Using this reduction, we show that finding the\nlexicographically smallest Nash equilibrium for k> 2 is NP-hard, and provide an\nalgorithm to find it in O(n^3 2^n) steps. While the reduction to weighted\nMax-k-Cut suggests that finding a pure Nash equilibrium using best response\ndynamics might be PLS-hard, it allows us to use tools from quadratic\nprogramming to devise more systematic algorithms towards obtaining Nash\nequilibrium points.", "1404.3626": "Optimal Power Flow as a Polynomial Optimization Problem,Ghaddar, BissanMarecek, JakubMevissen, Martin,Mathematics - Optimization and ControlComputer Science - Systems and Control,Formulating the alternating current optimal power flow (ACOPF) as a\npolynomial optimization problem makes it possible to solve large instances in\npractice and to guarantee asymptotic convergence in theory.Comment: A more concise version, which also fixes a number of minor issues", "1404.5029": "Using Covert Topological Information for Defense Against Malicious\n  Attacks on DC State Estimation,Bi, SuzhiZhang, Ying Jun,Computer Science - Cryptography and Security,Accurate state estimation is of paramount importance to maintain the power\nsystem operating in a secure and efficient state. The recently identified\ncoordinated data injection attacks to meter measurements can bypass the current\nsecurity system and introduce errors to the state estimates. The conventional\nwisdom to mitigate such attacks is by securing meter measurements to evade\nmalicious injections. In this paper, we provide a novel alternative to defend\nagainst false-data injection attacks using covert power network topological\ninformation. By keeping the exact reactance of a set of transmission lines from\nattackers, no false data injection attack can be launched to compromise any set\nof state variables. We first investigate from the attackers' perspective the\nnecessary condition to perform injection attack. Based on the arguments, we\ncharacterize the optimal protection problem, which protects the state variables\nwith minimum cost, as a well-studied Steiner tree problem in a graph. Besides,\nwe also propose a mixed defending strategy that jointly considers the use of\ncovert topological information and secure meter measurements when either method\nalone is costly or unable to achieve the protection objective. A mixed integer\nlinear programming (MILP) formulation is introduced to obtain the optimal mixed\ndefending strategy. To tackle the NP-hardness of the problem, a tree\npruning-based heuristic is further presented to produce an approximate solution\nin polynomial time. The advantageous performance of the proposed defending\nmechanisms is verified in IEEE standard power system testcases.Comment: Accepted for publication by Journal of Selected Areas in\n  Communications (JSAC). arXiv admin note: substantial text overlap with\n  arXiv:1304.4151", "1404.6898": "Quantum Attacks on Classical Proof Systems - The Hardness of Quantum\n  Rewinding,Ambainis, AndrisRosmanis, AnsisUnruh, Dominique,Quantum PhysicsComputer Science - Cryptography and Security,Quantum zero-knowledge proofs and quantum proofs of knowledge are inherently\ndifficult to analyze because their security analysis uses rewinding. Certain\ncases of quantum rewinding are handled by the results by Watrous (SIAM J\nComput, 2009) and Unruh (Eurocrypt 2012), yet in general the problem remains\nelusive. We show that this is not only due to a lack of proof techniques:\nrelative to an oracle, we show that classically secure proofs and proofs of\nknowledge are insecure in the quantum setting.\n  More specifically, sigma-protocols, the Fiat-Shamir construction, and\nFischlin's proof system are quantum insecure under assumptions that are\nsufficient for classical security. Additionally, we show that for similar\nreasons, computationally binding commitments provide almost no security\nguarantees in a quantum setting.\n  To show these results, we develop the \"pick-one trick\", a general technique\nthat allows an adversary to find one value satisfying a given predicate, but\nnot two.Comment: An extended abstract has appeared at FOCS 2014", "1404.7325": "Tight Bounds for Restricted Grid Scheduling,Boyar, JoanEllen, Faith,Computer Science - Data Structures and Algorithms,The following online bin packing problem is considered: Items with integer\nsizes are given and variable sized bins arrive online. A bin must be used if\nthere is still an item remaining which fits in it when the bin arrives. The\ngoal is to minimize the total size of all the bins used. Previously, a lower\nbound of 5/4 on the competitive ratio of this problem was achieved using jobs\nof size S and 2S-1. For these item sizes and maximum bin size 4S-3, we obtain\nasymptotically matching upper and lower bounds, which vary depending on the\nratio of the number of small jobs to the number of large jobs.Comment: IMADA-preprint-cs", "1405.0149": "Coding Theoretic Construction of Quantum Ramp Secret Sharing,Matsumoto, Ryutaroh,Computer Science - Information TheoryMathematics - Algebraic GeometryMathematics - CombinatoricsQuantum Physics81P94 (Primary) 94A62, 94B27 (Secondary)E.3,We show a construction of a quantum ramp secret sharing scheme from a nested\npair of linear codes. Necessary and sufficient conditions for qualified sets\nand forbidden sets are given in terms of combinatorial properties of nested\nlinear codes. An algebraic geometric construction for quantum secret sharing is\nalso given.Comment: svjour3.cls, 12 pages, no figure. Version 5 added citations to\n  relevant prior papers that were missing in previous versions. Contents\n  unchanged", "1405.0637": "Crux: Locality-Preserving Distributed Services,Basescu, CristinaNowlan, Michael F.Nikitin, KirillFaleiro, Jose M.Ford, Bryan,Computer Science - Distributed, Parallel, and Cluster Computing,Distributed systems achieve scalability by distributing load across many\nmachines, but wide-area deployments can introduce worst-case response latencies\nproportional to the network's diameter. Crux is a general framework to build\nlocality-preserving distributed systems, by transforming an existing scalable\ndistributed algorithm A into a new locality-preserving algorithm ALP, which\nguarantees for any two clients u and v interacting via ALP that their\ninteractions exhibit worst-case response latencies proportional to the network\nlatency between u and v. Crux builds on compact-routing theory, but generalizes\nthese techniques beyond routing applications. Crux provides weak and strong\nconsistency flavors, and shows latency improvements for localized interactions\nin both cases, specifically up to several orders of magnitude for\nweakly-consistent Crux (from roughly 900ms to 1ms). We deployed on PlanetLab\nlocality-preserving versions of a Memcached distributed cache, a Bamboo\ndistributed hash table, and a Redis publish/subscribe. Our results indicate\nthat Crux is effective and applicable to a variety of existing distributed\nalgorithms.Comment: 11 figures", "1405.0713": "Further result on acyclic chromatic index of planar graphs,Wang, TaoZhang, Yaqiong,Mathematics - CombinatoricsComputer Science - Discrete Mathematics05C15,An acyclic edge coloring of a graph $G$ is a proper edge coloring such that\nevery cycle is colored with at least three colors. The acyclic chromatic index\n$\\chiup_{a}'(G)$ of a graph $G$ is the least number of colors in an acyclic\nedge coloring of $G$. It was conjectured that $\\chiup'_{a}(G)\\leq \\Delta(G) +\n2$ for any simple graph $G$ with maximum degree $\\Delta(G)$. In this paper, we\nprove that every planar graph $G$ admits an acyclic edge coloring with\n$\\Delta(G) + 6$ colors.Comment: 23 pages, 20 figures, mainly revised Lemma 8 in Discrete Applied\n  Mathematics, 2015. arXiv admin note: text overlap with arXiv:1302.2405", "1405.0718": "Generalized Signal Alignment: On the Achievable DoF for Multi-User MIMO\n  Two-Way Relay Channels,Liu, KangqiTao, Meixia,Computer Science - Information Theory,This paper studies the achievable degrees of freedom for multi-user MIMO\ntwo-way relay channels, where there are $K$ source nodes, each equipped with\n$M$ antennas, one relay node, equipped with $N$ antennas, and each source node\nexchanges independent messages with an arbitrary set of other source nodes via\nthe relay. By allowing an arbitrary information exchange pattern, the\nconsidered channel model is a unified one. It includes several existing channel\nmodels as special cases: $K$-user MIMO Y channel, multi-pair MIMO two-way relay\nchannel, generalized MIMO two-way X relay channel, and $L$-cluster MIMO\nmultiway relay channel. Previous studies mainly considered the achievability of\nthe DoF cut-set bound $2N$ at the antenna configuration $N < 2M$ by applying\nsignal alignment. This work aims to investigate the achievability of the DoF\ncut-set bound $KM$ for the case $N\\geq 2M$. To this end, we first derive\ntighter DoF upper bounds for three special cases of the considered channel\nmodel. Then, we propose a new transmission framework, generalized signal\nalignment, to approach these bounds. The notion of GSA is to form network-coded\nsymbols by aligning every pair of signals to be exchanged in a compressed\nsubspace at the relay. A necessary and sufficient condition to construct the\nrelay compression matrix is given. We show that using GSA, the new DoF upper\nbound is achievable when i) $\\frac{N}{M} \\in \\big(0, 2+\\frac{4}{K(K-1)}\\big]\n\\cup \\big[K-2, +\\infty\\big)$ for the $K$-user MIMO Y channel; ii) $\\frac{N}{M}\n\\in \\big(0, 2+\\frac{4}{K}\\big] \\cup \\big[K-2, +\\infty\\big)$ for the multi-pair\nMIMO two-way relay channel; iii) $\\frac{N}{M} \\in \\big(0, 2+\\frac{8}{K^2}\\big]\n\\cup \\big[K-2, +\\infty\\big)$ for the generalized MIMO two-way X relay channel.\nWe also provide the antenna configuration regions for the general multi-user\nMIMO two-way relay channel to achieve the total DoF $KM$.Comment: 22 pages, 15 figures. To be appeared in IEEE Transactions on\n  Information Theory", "1405.0854": "Unguarded Recursion on Coinductive Resumptions,Goncharov, SergeySchr\u00f6der, LutzRauch, ChristophJakob, Julian,Computer Science - Logic in Computer ScienceF.3.2F.3.3D.3.3,We study a model of side-effecting processes obtained by starting from a\nmonad modelling base effects and adjoining free operations using a cofree\ncoalgebra construction; one thus arrives at what one may think of as types of\nnon-wellfounded side-effecting trees, generalizing the infinite resumption\nmonad. Correspondingly, the arising monad transformer has been termed the\ncoinductive generalized resumption transformer. Monads of this kind have\nreceived some attention in the recent literature; in particular, it has been\nshown that they admit guarded iteration. Here, we show that they also admit\nunguarded iteration, i.e. form complete Elgot monads, provided that the\nunderlying base effect supports unguarded iteration. Moreover, we provide a\nuniversal characterization of the coinductive resumption monad transformer in\nterms of coproducts of complete Elgot monads.Comment: 47 pages, extended version of\n  http://www.sciencedirect.com/science/article/pii/S1571066115000791", "1405.0982": "Some undecidability results for asynchronous transducers and the\n  Brin-Thompson group 2V,Belk, JamesBleak, Collin,Mathematics - Group TheoryComputer Science - Formal Languages and Automata TheoryMathematics - Dynamical SystemsMathematics - Logic20F10 (Primary) 68Q45, 37B99, 03B25 (Secondary),Using a result of Kari and Ollinger, we prove that the torsion problem for\nelements of the Brin-Thompson group 2V is undecidable. As a result, we show\nthat there does not exist an algorithm to determine whether an element of the\nrational group R of Grigorchuk, Nekrashevich, and Sushchanskii has finite\norder. A modification of the construction gives other undecidability results\nabout the dynamics of the action of elements of 2V on Cantor Space.\nArzhantseva, Lafont, and Minasyanin prove in 2012 that there exists a finitely\npresented group with solvable word problem and unsolvable torsion problem. To\nour knowledge, 2V furnishes the first concrete example of such a group, and\ngives an example of a direct undecidability result in the extended family of R.\nThompson type groups.Comment: 16 pages, 3 figures", "1405.1481": "Graphical potential games,Babichenko, YakovTamuz, Omer,Mathematics - ProbabilityComputer Science - Computer Science and Game TheoryEconomics - Theoretical Economics,We study the class of potential games that are also graphical games with\nrespect to a given graph $G$ of connections between the players. We show that,\nup to strategic equivalence, this class of games can be identified with the set\nof Markov random fields on $G$.\n  From this characterization, and from the Hammersley-Clifford theorem, it\nfollows that the potentials of such games can be decomposed to local\npotentials. We use this decomposition to strongly bound the number of strategy\nchanges of a single player along a better response path. This result extends to\ngeneralized graphical potential games, which are played on infinite graphs.Comment: Accepted to the Journal of Economic Theory", "1405.1906": "Leader-following Consensus of Multi-agent Systems over Finite Fields,Xu, XiangruHong, Yiguang,Mathematics - Optimization and ControlComputer Science - Systems and Control,The leader-following consensus problem of multi-agent systems over finite\nfields ${\\mathbb F}_p$ is considered in this paper. Dynamics of each agent is\ngoverned by a linear equation over ${\\mathbb F}_p$, where a distributed control\nprotocol is utilized by the followers.Sufficient and/or necessary conditions on\nsystem matrices and graph weights in ${\\mathbb F}_p$ are provided for the\nfollowers to track the leader.", "1405.2690": "Policy Gradients for CVaR-Constrained MDPs,A., Prashanth L.,Statistics - Machine LearningComputer Science - Machine LearningMathematics - Optimization and Control,We study a risk-constrained version of the stochastic shortest path (SSP)\nproblem, where the risk measure considered is Conditional Value-at-Risk (CVaR).\nWe propose two algorithms that obtain a locally risk-optimal policy by\nemploying four tools: stochastic approximation, mini batches, policy gradients\nand importance sampling. Both the algorithms incorporate a CVaR estimation\nprocedure, along the lines of Bardou et al. [2009], which in turn is based on\nRockafellar-Uryasev's representation for CVaR and utilize the likelihood ratio\nprinciple for estimating the gradient of the sum of one cost function\n(objective of the SSP) and the gradient of the CVaR of the sum of another cost\nfunction (in the constraint of SSP). The algorithms differ in the manner in\nwhich they approximate the CVaR estimates/necessary gradients - the first\nalgorithm uses stochastic approximation, while the second employ mini-batches\nin the spirit of Monte Carlo methods. We establish asymptotic convergence of\nboth the algorithms. Further, since estimating CVaR is related to rare-event\nsimulation, we incorporate an importance sampling based variance reduction\nscheme into our proposed algorithms.", "1405.4472": "AND-compression of NP-complete problems: Streamlined proof and minor\n  observations,Dell, Holger,Computer Science - Computational ComplexityComputer Science - Data Structures and Algorithms,Drucker (2012) proved the following result: Unless the unlikely\ncomplexity-theoretic collapse coNP is in NP/poly occurs, there is no\nAND-compression for SAT. The result has implications for the compressibility\nand kernelizability of a whole range of NP-complete parameterized problems. We\npresent a streamlined proof of Drucker's theorem.\n  An AND-compression is a deterministic polynomial-time algorithm that maps a\nset of SAT-instances $x_1,\\dots,x_t$ to a single SAT-instance $y$ of size\npoly(max $|x_i|$) such that $y$ is satisfiable if and only if all $x_i$ are\nsatisfiable. The \"AND\" in the name stems from the fact that the predicate \"$y$\nis satisfiable\" can be written as the AND of all predicates \"$x_i$ is\nsatisfiable\". Drucker's result complements the result by Bodlaender et al.\n(2009) and Fortnow and Santhanam (2010), who proved the analogous statement for\nOR-compressions, and Drucker's proof not only subsumes that result but also\nextends it to randomized compression algorithms that are allowed to have a\ncertain probability of failure.\n  Drucker (2012) presented two proofs: The first uses information theory and\nthe minimax theorem from game theory, and the second is an elementary,\niterative proof that is not as general. In our proof, we realize the iterative\nstructure as a generalization of the arguments of Ko (1983) for P-selective\nsets, which use the fact that tournaments have dominating sets of logarithmic\nsize. We generalize this fact to hypergraph tournaments. Our proof achieves the\nfull generality of Drucker's theorem, avoids the minimax theorem, and restricts\nthe use of information theory to a single, intuitive lemma about the average\nnoise sensitivity of compressive maps. To prove this lemma, we use the same\ninformation-theoretic inequalities as Drucker.Comment: extended abstract appears in the Proceedings of the 9th International\n  Symposium on Parameterized and Exact Computation (IPEC 2014)", "1405.4713": "Signal-noise search RMT estimator with adaptive decision criterion for\n  estimating the number of signals based on random matrix theory,Yi, Huiyue,Computer Science - Information TheoryStatistics - Methodology,Estimating the number of signals embedded in noise is a fundamental problem\nin signal processing. As a classic estimator based on random matrix theory\n(RMT), the RMT estimator estimates the number of signals via sequentially\ntesting the likelihood of an eigenvalue as arising from a signal or noise for a\ngiven over-detection probability. However, it tends to down-estimate the number\nof signals as weak signal eigenvalues may be immersed in the bias term among\neigenvalues. In order to solve this problem, in this paper we focus on\ndeveloping novel RMT-based estimators by incorporating this bias term into RMT\nestimator. Firstly, we derive a novel decision statistics for signal detection\nby incorporating the bias term into the RMT estimator, and propose a\nsignal-test RMT estimator for signal number estimation for a given\nmiss-detection probability. Secondly, we analyze the effect of the bias term on\nthe detection performance of the signal-test RMT estimator and the RMT\nestimator. It shows that the signal-test RMT estimator has lower\ndown-estimation probability than the RMT estimator when weak signal eigenvalues\nare immersed in the bias term, but has higher over-estimation probability than\nthe RMT estimator when all signals are strong enough to be detected by the RMT\nestimator. Thirdly, we derive analytical formulas for the increased\nover-estimation probability of the signal-test RMT estimator and the increased\ndown-estimation probability of the RMT estimator incurred by this bias term,\nand then propose a signal-noise-test RMT estimator which can adaptively select\nits decision criterion between the RMT estimator and the signal-test RMT\nestimator to make benefits of these two estimators while avoiding their\nindividual drawbacks. Finally, simulation results are presented to show that\nthe proposed signal-noise-test RMT estimator significantly outperforms the\nexisting estimators in all cases.Comment: 17 pages, 9 figures", "1405.6397": "Efficient Evaluation of the Probability Density Function of a Wrapped\n  Normal Distribution,Kurz, GerhardGilitschenski, IgorHanebeck, Uwe D.,Statistics - ComputationComputer Science - Systems and ControlMathematics - Numerical Analysis,The wrapped normal distribution arises when a the density of a\none-dimensional normal distribution is wrapped around the circle infinitely\nmany times. At first look, evaluation of its probability density function\nappears tedious as an infinite series is involved. In this paper, we\ninvestigate the evaluation of two truncated series representations. As one\nrepresentation performs well for small uncertainties whereas the other performs\nwell for large uncertainties, we show that in all cases a small number of\nsummands is sufficient to achieve high accuracy.", "1405.7264": "A Datalog-based Computational Model for Coordination-free, Data-Parallel\n  Systems,Interlandi, MatteoTanca, Letizia,Computer Science - Databases,Cloud computing refers to maximizing efficiency by sharing computational and\nstorage resources, while data-parallel systems exploit the resources available\nin the cloud to perform parallel transformations over large amounts of data. In\nthe same line, considerable emphasis has been recently given to two apparently\ndisjoint research topics: data-parallel, and eventually consistent, distributed\nsystems. Declarative networking has been recently proposed to ease the task of\nprogramming in the cloud, by allowing the programmer to express only the\ndesired result and leave the implementation details to the responsibility of\nthe run-time system. In this context, we propose a study on a\nlogic-programming-based computational model for eventually consistent,\ndata-parallel systems, the keystone of which is provided by the recent finding\nthat the class of programs that can be computed in an eventually consistent,\ncoordination-free way is that of monotonic programs. This principle is called\nCALM and has been proven by Ameloot et al. for distributed, asynchronous\nsettings. We advocate that CALM should be employed as a basic theoretical tool\nalso for data-parallel systems, wherein computation usually proceeds\nsynchronously in rounds and where communication is assumed to be reliable. It\nis general opinion that coordination-freedom can be seen as a major\ndiscriminant factor. In this work we make the case that the current form of\nCALM does not hold in general for data-parallel systems, and show how, using\nnovel techniques, the satisfiability of the CALM principle can still be\nobtained although just for the subclass of programs called connected monotonic\nqueries. We complete the study with considerations on the relationships between\nour model and the one employed by Ameloot et al., showing that our techniques\nsubsume the latter when the synchronization constraints imposed on the system\nare loosened.Comment: Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "1405.7709": "A Stable Marriage Requires Communication,Gonczarowski, Yannai A.Nisan, NoamOstrovsky, RafailRosenbaum, Will,Computer Science - Computer Science and Game TheoryComputer Science - Computational Complexity,The Gale-Shapley algorithm for the Stable Marriage Problem is known to take\n$\\Theta(n^2)$ steps to find a stable marriage in the worst case, but only\n$\\Theta(n \\log n)$ steps in the average case (with $n$ women and $n$ men). In\n1976, Knuth asked whether the worst-case running time can be improved in a\nmodel of computation that does not require sequential access to the whole\ninput. A partial negative answer was given by Ng and Hirschberg, who showed\nthat $\\Theta(n^2)$ queries are required in a model that allows certain natural\nrandom-access queries to the participants' preferences. A significantly more\ngeneral - albeit slightly weaker - lower bound follows from Segal's general\nanalysis of communication complexity, namely that $\\Omega(n^2)$ Boolean queries\nare required in order to find a stable marriage, regardless of the set of\nallowed Boolean queries.\n  Using a reduction to the communication complexity of the disjointness\nproblem, we give a far simpler, yet significantly more powerful argument\nshowing that $\\Omega(n^2)$ Boolean queries of any type are indeed required for\nfinding a stable - or even an approximately stable - marriage. Notably, unlike\nSegal's lower bound, our lower bound generalizes also to (A) randomized\nalgorithms, (B) allowing arbitrary separate preprocessing of the women's\npreferences profile and of the men's preferences profile, (C) several variants\nof the basic problem, such as whether a given pair is married in every/some\nstable marriage, and (D) determining whether a proposed marriage is stable or\nfar from stable. In order to analyze \"approximately stable\" marriages, we\nintroduce the notion of \"distance to stability\" and provide an efficient\nalgorithm for its computation.", "1406.0263": "The \"Runs\" Theorem,Bannai, HideoI, TomohiroInenaga, ShunsukeNakashima, YutoTakeda, MasayukiTsuruta, Kazuya,Computer Science - Discrete MathematicsComputer Science - Data Structures and Algorithms,We give a new characterization of maximal repetitions (or runs) in strings\nbased on Lyndon words. The characterization leads to a proof of what was known\nas the \"runs\" conjecture (Kolpakov \\& Kucherov (FOCS '99)), which states that\nthe maximum number of runs $\\rho(n)$ in a string of length $n$ is less than\n$n$. The proof is remarkably simple, considering the numerous endeavors to\ntackle this problem in the last 15 years, and significantly improves our\nunderstanding of how runs can occur in strings. In addition, we obtain an upper\nbound of $3n$ for the maximum sum of exponents $\\sigma(n)$ of runs in a string\nof length $n$, improving on the best known bound of $4.1n$ by Crochemore et al.\n(JDA 2012), as well as other improved bounds on related problems. The\ncharacterization also gives rise to a new, conceptually simple linear-time\nalgorithm for computing all the runs in a string. A notable characteristic of\nour algorithm is that, unlike all existing linear-time algorithms, it does not\nutilize the Lempel-Ziv factorization of the string. We also establish a\nrelationship between runs and nodes of the Lyndon tree, which gives a simple\noptimal solution to the 2-Period Query problem that was recently solved by\nKociumaka et al. (SODA 2015).Comment: simple proof with some more bounds", "1406.0342": "A faster method for computing Gama-Nguyen-Regev's extreme pruning\n  coefficients,Aono, Yoshinori,Computer Science - Cryptography and Security,This paper considers Gama-Nguyen-Regev's strategy [GNR10] for optimizing\npruning coefficients for lattice vector enumeration. We give a table of\noptimized coefficients and proposes a faster method for computing\nnear-optimized coefficients for any parameters by interpolation.\n  From the first version published in 2014, we inserted new Section 3.3 to\nintroduce our recent technique to compute approximations of enumeration cost\nand success probability; both are completed in O(n^2) floating point operations\nwhere n is the lattice dimension.\n  For readers who are interested in this topic, we keep the descriptions of our\nheuristic optimization method in Section 4 although they are outdated now.", "1406.0641": "Extensions of Configuration Structures,Prisacariu, Cristian,Computer Science - Distributed, Parallel, and Cluster ComputingComputer Science - Logic in Computer Science,The present paper defines ST-structures (and an extension of these, called\nSTC-structures). The main purpose is to provide concrete relationships between\nhighly expressive concurrency models coming from two different schools of\nthought: the higher dimensional automata, a \\textit{state-based} approach of\nPratt and van Glabbeek; and the configuration structures and (in)pure event\nstructures, an \\textit{event-based} approach of van Glabbeek and Plotkin. In\nthis respect we make comparative studies of the expressive power of\nST-structures relative to the above models. Moreover, standard notions from\nother concurrency models are defined for ST(C)-structures, like steps and\npaths, bisimilarities, and action refinement, and related results are given.\nThese investigations of ST(C)-structures are intended to provide a better\nunderstanding of the \\textit{state-event duality} described by Pratt, and also\nof the (a)cyclic structures of higher dimensional automata.", "1406.1758": "Scaling limits and influence of the seed graph in preferential\n  attachment trees,Curien, NicolasDuquesne, ThomasKortchemski, IgorManolescu, Ioan,Mathematics - ProbabilityComputer Science - Discrete MathematicsMathematics - Statistics Theory,We are interested in the asymptotics of random trees built by linear\npreferential attachment, also known in the literature as Barab\\'asi-Albert\ntrees or plane-oriented recursive trees. We first prove a conjecture of Bubeck,\nMossel \\& R\\'acz concerning the influence of the seed graph on the asymptotic\nbehavior of such trees. Separately we study the geometric structure of nodes of\nlarge degrees in a plane version of Barab\\'asi-Albert trees via their\nassociated looptrees. As the number of nodes grows, we show that these\nlooptrees, appropriately rescaled, converge in the Gromov-Hausdorff sense\ntowards a random compact metric space which we call the Brownian looptree. The\nlatter is constructed as a quotient space of Aldous' Brownian Continuum Random\nTree and is shown to have almost sure Hausdorff dimension $2$.Comment: 32 pages, 11 figures", "1406.1949": "Distinct Distances: Open Problems and Current Bounds,Sheffer, Adam,Mathematics - CombinatoricsComputer Science - Computational Geometry,We survey the variants of Erd\\H{o}s' distinct distances problem and the\ncurrent best bounds for each of those.Comment: Many recent results were added, a few fixes, and two new sections\n  (bipartite problems and connections to Additive Combinatorics)", "1406.2534": "Load Hiding of Household's Power Demand,Egarter, DominikProkop, ChristophElmenreich, Wilfried,Computer Science - Other Computer Science,With the development and introduction of smart metering, the energy\ninformation for costumers will change from infrequent manual meter readings to\nfine-grained energy consumption data. On the one hand these fine-grained\nmeasurements will lead to an improvement in costumers' energy habits, but on\nthe other hand the fined-grained data produces information about a household\nand also households' inhabitants, which are the basis for many future privacy\nissues. To ensure household privacy and smart meter information owned by the\nhousehold inhabitants, load hiding techniques were introduced to obfuscate the\nload demand visible at the household energy meter. In this work, a\nstate-of-the-art battery-based load hiding (BLH) technique, which uses a\ncontrollable battery to disguise the power consumption and a novel load hiding\ntechnique called load-based load hiding (LLH) are presented. An LLH system uses\nan controllable household appliance to obfuscate the household's power demand.\nWe evaluate and compare both load hiding techniques on real household data and\nshow that both techniques can strengthen household privacy but only LLH can\nincrease appliance level privacy.", "1406.2587": "Structural Sparsity of Complex Networks: Bounded Expansion in Random\n  Models and Real-World Graphs,Demaine, Erik D.Reidl, FelixRossmanith, PeterVillaamil, Fernando SanchezSikdar, SomnathSullivan, Blair D.,Computer Science - Social and Information NetworksComputer Science - Discrete MathematicsComputer Science - Data Structures and AlgorithmsPhysics - Physics and Society,This research establishes that many real-world networks exhibit bounded\nexpansion, a strong notion of structural sparsity, and demonstrates that it can\nbe leveraged to design efficient algorithms for network analysis. We analyze\nseveral common network models regarding their structural sparsity. We show\nthat, with high probability, (1) graphs sampled with a prescribed s parse\ndegree sequence; (2) perturbed bounded-degree graphs; (3) stochastic block\nmodels with small probabilities; result in graphs of bounded expansion.\n  In contrast, we show that the Kleinberg and the Barabasi-Albert model have\nunbounded expansion. We support our findings with empirical measurements on a\ncorpus of real-world networks.", "1406.3065": "Lower Bounds for Tropical Circuits and Dynamic Programs,Jukna, Stasys,Computer Science - Computational Complexity,Tropical circuits are circuits with Min and Plus, or Max and Plus operations\nas gates. Their importance stems from their intimate relation to dynamic\nprogramming algorithms. The power of tropical circuits lies somewhere between\nthat of monotone boolean circuits and monotone arithmetic circuits. In this\npaper we present some lower bounds arguments for tropical circuits, and hence,\nfor dynamic programs.Comment: Corrected reduction to arithmetic circuits (holds only for\n  multilinear polynomials, now Sect. 4). Solved Open Problem 3 about Min/Max\n  gaps (now Lemma 10). Added lower bounds for the depth of tropical circuits\n  (Sect. 15)", "1406.4060": "Consistency of Quine's New Foundations using nominal techniques,Gabbay, Murdoch J.,Mathematics - LogicComputer Science - Logic in Computer Science03E35 (Primary), 03B70 (Secondary)F.4.1,We build a model in nominal sets for TST+; typed set theory with typical\nambiguity. It is known that this is equivalent to the consistency of Quine's\nNew Foundations.\n  Nominal techniques are used to constrain the size of powersets and thus model\ntypical ambiguity.", "1406.4426": "The number system hidden inside the Boolean satisfiability problem,Cho, Keum-Bae,Computer Science - Computational ComplexityMathematics - Logic,This paper gives a novel approach to analyze SAT problem more deeply. First,\nI define new elements of Boolean formula such as dominant variable, decision\nchain, and chain coupler. Through the analysis of the SAT problem using the\nelements, I prove that we can construct a k-SAT (k>2) instance where the\ncoefficients of cutting planes take exponentially large values in the input\nsize. This exponential property is caused by the number system formed from the\ncalculation of coefficients. In addition, I show that 2-SAT does not form the\nnumber system and Horn-SAT partially forms the number system according to the\nfeasible value of the dominant variable. Whether or not the coefficients of\ncutting planes in cutting plane proof are polynomially bounded was open\nproblem. Many researchers believed that cutting plane proofs with large\ncoefficients are highly non-intuitive20. However, we can construct a k-SAT\n(k>2) instance in which cutting planes take exponentially large coefficients by\nthe number system. In addition, this exponential property is so strong that it\ngives definite answers for several questions: why Horn-SAT has the intermediate\nproperty between 2-SAT and 3-SAT; why random-SAT is so easy; and why k-SAT\n(k>2) cannot be solved with the linear programming technique. As we know, 2-SAT\nis NL-complete, Horn-SAT is P-complete, and k-SAT (k>2) is NP-complete. In\nterms of computational complexity, this paper gives a clear mathematical\nproperty by which SAT problems in three different classes are distinguished.Comment: 15 pages, 9 figures", "1406.5688": "Information, Meaning, and Intellectual Organization in Networks of\n  Inter-Human Communication,Leydesdorff, Loet,Computer Science - Digital LibrariesComputer Science - Computers and Society,The Shannon-Weaver model of linear information transmission is extended with\ntwo loops potentially generating redundancies: (i) meaning is provided locally\nto the information from the perspective of hindsight, and (ii) meanings can be\ncodified differently and then refer to other horizons of meaning. Thus, three\nlayers are distinguished: variations in the communications, historical\norganization at each moment of time, and evolutionary self-organization of the\ncodes of communication over time. Furthermore, the codes of communication can\nfunctionally be different and then the system is both horizontally and\nvertically differentiated. All these subdynamics operate in parallel and\nnecessarily generate uncertainty. However, meaningful information can be\nconsidered as the specific selection of a signal from the noise; the codes of\ncommunication are social constructs that can generate redundancy by giving\ndifferent meanings to the same information. Reflexively, one can translate\namong codes in more elaborate discourses. The second (instantiating) layer can\nbe operationalized in terms of semantic maps using the vector space model; the\nthird in terms of mutual redundancy among the latent dimensions of the vector\nspace. Using Blaise Cronin's {\\oe}uvre, the different operations of the three\nlayers are demonstrated empirically.Comment: Pp. 280-303 in: Cassidy R. Sugimoto (Ed.), Theories of Informetrics\n  and Scholarly Communication, Berlin/Boston MA: De Gruyter, 2016", "1406.5943": "The Moser-Tardos Framework with Partial Resampling,Harris, David G.Srinivasan, Aravind,Mathematics - CombinatoricsComputer Science - Data Structures and Algorithms,The resampling algorithm of Moser \\& Tardos is a powerful approach to develop\nconstructive versions of the Lov\\'{a}sz Local Lemma (LLL). We generalize this\nto partial resampling: when a bad event holds, we resample an\nappropriately-random subset of the variables that define this event, rather\nthan the entire set as in Moser & Tardos. This is particularly useful when the\nbad events are determined by sums of random variables. This leads to several\nimproved algorithmic applications in scheduling, graph transversals, packet\nrouting etc. For instance, we settle a conjecture of Szab\\'{o} & Tardos (2006)\non graph transversals asymptotically, and obtain improved approximation ratios\nfor a packet routing problem of Leighton, Maggs, & Rao (1994).", "1406.6145": "Fast, Robust and Non-convex Subspace Recovery,Lerman, GiladMaunu, Tyler,Computer Science - Machine LearningComputer Science - Computer Vision and Pattern RecognitionStatistics - ApplicationsStatistics - Machine Learning,This work presents a fast and non-convex algorithm for robust subspace\nrecovery. The data sets considered include inliers drawn around a\nlow-dimensional subspace of a higher dimensional ambient space, and a possibly\nlarge portion of outliers that do not lie nearby this subspace. The proposed\nalgorithm, which we refer to as Fast Median Subspace (FMS), is designed to\nrobustly determine the underlying subspace of such data sets, while having\nlower computational complexity than existing methods. We prove convergence of\nthe FMS iterates to a stationary point. Further, under a special model of data,\nFMS converges to a point which is near to the global minimum with overwhelming\nprobability. Under this model, we show that the iteration complexity is\nglobally bounded and locally $r$-linear. The latter theorem holds for any fixed\nfraction of outliers (less than 1) and any fixed positive distance between the\nlimit point and the global minimum. Numerical experiments on synthetic and real\ndata demonstrate its competitive speed and accuracy.", "1406.6924": "Strongly stable ideals and Hilbert polynomials,Alberelli, DavideLella, Paolo,Computer Science - Symbolic ComputationComputer Science - Mathematical SoftwareMathematics - Commutative AlgebraMathematics - Algebraic GeometryMathematics - Combinatorics13P10, 13P99,The \\texttt{StronglyStableIdeals} package for \\textit{Macaulay2} provides a\nmethod to compute all saturated strongly stable ideals in a given polynomial\nring with a fixed Hilbert polynomial. A description of the main method and\nauxiliary tools is given.Comment: Source code available as an ancillary file. Final version", "1406.7373": "How to Achieve the Capacity of Asymmetric Channels,Mondelli, MarcoHassani, S. HamedUrbanke, R\u00fcdiger,Computer Science - Information Theory,We survey coding techniques that enable reliable transmission at rates that\napproach the capacity of an arbitrary discrete memoryless channel. In\nparticular, we take the point of view of modern coding theory and discuss how\nrecent advances in coding for symmetric channels help provide more efficient\nsolutions for the asymmetric case. We consider, in more detail, three basic\ncoding paradigms.\n  The first one is Gallager's scheme that consists of concatenating a linear\ncode with a non-linear mapping so that the input distribution can be\nappropriately shaped. We explicitly show that both polar codes and spatially\ncoupled codes can be employed in this scenario. Furthermore, we derive a\nscaling law between the gap to capacity, the cardinality of the input and\noutput alphabets, and the required size of the mapper.\n  The second one is an integrated scheme in which the code is used both for\nsource coding, in order to create codewords distributed according to the\ncapacity-achieving input distribution, and for channel coding, in order to\nprovide error protection. Such a technique has been recently introduced by\nHonda and Yamamoto in the context of polar codes, and we show how to apply it\nalso to the design of sparse graph codes.\n  The third paradigm is based on an idea of B\\\"ocherer and Mathar, and\nseparates the two tasks of source coding and channel coding by a chaining\nconstruction that binds together several codewords. We present conditions for\nthe source code and the channel code, and we describe how to combine any source\ncode with any channel code that fulfill those conditions, in order to provide\ncapacity-achieving schemes for asymmetric channels. In particular, we show that\npolar codes, spatially coupled codes, and homophonic codes are suitable as\nbasic building blocks of the proposed coding strategy.Comment: 32 pages, 4 figures, presented in part at Allerton'14 and published\n  in IEEE Trans. Inform. Theory", "1407.0208": "A Bayes consistent 1-NN classifier,Kontorovich, AryehWeiss, Roi,Computer Science - Machine LearningStatistics - Machine Learning,We show that a simple modification of the 1-nearest neighbor classifier\nyields a strongly Bayes consistent learner. Prior to this work, the only\nstrongly Bayes consistent proximity-based method was the k-nearest neighbor\nclassifier, for k growing appropriately with sample size. We will argue that a\nmargin-regularized 1-NN enjoys considerable statistical and algorithmic\nadvantages over the k-NN classifier. These include user-friendly finite-sample\nerror bounds, as well as time- and memory-efficient learning and test-point\nevaluation algorithms with a principled speed-accuracy tradeoff. Encouraging\nempirical results are reported.", "1407.0756": "Geometrical Localization Algorithm for 3-D Wireless Sensor Networks,Kumar, RajeshKumar, SushilShukla, DikshaRaw, Ram Shringar,Computer Science - Networking and Internet Architecture,In this paper, we propose an efficient range free localization scheme for\nlarge scale three dimensional wireless sensor networks. Our system environment\nconsists of two type of sensors, randomly deployed static sensors and global\npositioning system equipped moving sensors. These moving anchors travels across\nthe network field and broadcast their current locations on specified intervals.\nAs soon as the sensors which are deployed in random fashion receives three\nbeacon messages (known locations broadcasted by anchors), they computes their\nlocations automatically by using our proposed algorithm. One of our significant\ncontributions is, we use only three different beacon messages to localize one\nsensor, while in the best of our knowledge, all previously proposed methods use\nat least four different known locations. The ability of our method to localize\nby using only three known locations not only saves computation, time, energy,\nbut also reduces the number of anchors needed to be deployed and more\nimportantly reduces the communication overheads. Experimental results\ndemonstrate that our proposed scheme improves the overall efficiency of\nlocalization process significantly.\n  Important Note: Final version of this paper is accepted and published by\nJournal of Wireless Personal Communication, Springer : June, 2014 The final\nversion of publication is available at link.springer.com Link:\nhttp://link.springer.com/article/10.1007\\%2Fs11277-014-1852-6Comment: Journal of Wireless Personal Communication, Springer : June, 2014,\n  The final version of publication is available at link.springer.com Link:\n  http://link.springer.com/article/10.1007%2Fs11277-014-1852-6", "1407.1103": "Synchronization of finite-state pulse-coupled oscillators,Lyu, Hanbaek,Computer Science - Systems and ControlMathematics - CombinatoricsMathematics - Dynamical SystemsMathematics - Optimization and ControlNonlinear Sciences - Cellular Automata and Lattice Gases,We propose a novel generalized cellular automaton(GCA) model for\ndiscrete-time pulse-coupled oscillators and study the emergence of synchrony.\nGiven a finite simple graph and an integer $n\\ge 3$, each vertex is an\nidentical oscillator of period $n$ with the following weak coupling along the\nedges: each oscillator inhibits its phase update if it has at least one\nneighboring oscillator at a particular \"blinking\" state and if its state is\nahead of this blinking state. We obtain conditions on initial configurations\nand on network topologies for which states of all vertices eventually\nsynchronize. We show that our GCA model synchronizes arbitrary initial\nconfigurations on paths, trees, and with random perturbation, any connected\ngraph. In particular, our main result is the following local-global principle\nfor tree networks: for $n\\in \\{3,4,5,6\\}$, any $n$-periodic network on a tree\nsynchronizes arbitrary initial configuration if and only if the maximum degree\nof the tree is less than the period $n$.Comment: 23 pages, 17 figures, To appear in Physica D: Nonlinear Phenomena", "1407.2109": "Planar Graphs: Random Walks and Bipartiteness Testing,Czumaj, ArturMonemizadeh, MortezaOnak, KrzysztofSohler, Christian,Computer Science - Data Structures and Algorithms,We initiate the study of property testing in arbitrary planar graphs. We\nprove that bipartiteness can be tested in constant time, improving on the\nprevious bound of $\\tilde{O}(\\sqrt{n})$ for graphs on $n$ vertices. The\nconstant-time testability was only known for planar graphs with bounded degree.\n  Our algorithm is based on random walks. Since planar graphs have good\nseparators, i.e., bad expansion, our analysis diverges from standard techniques\nthat involve the fast convergence of random walks on expanders. We reduce the\nproblem to the task of detecting an odd-parity cycle in a multigraph induced by\nconstant-length cycles. We iteratively reduce the length of cycles while\npreserving the detection probability, until the multigraph collapses to a\ncollection of easily discoverable self-loops.\n  Our approach extends to arbitrary minor-free graphs. We also believe that our\ntechniques will find applications to testing other properties in arbitrary\nminor-free graphs.", "1407.2506": "Discovery of Important Crossroads in Road Network using Massive Taxi\n  Trajectories,Xu, MingWu, JianpingDu, YimanWang, HaohanQi, GeqiHu, KezhenXiao, Yunpeng,Computer Science - Artificial IntelligenceComputer Science - Social and Information NetworksPhysics - Physics and Society,A major problem in road network analysis is discovery of important\ncrossroads, which can provide useful information for transport planning.\nHowever, none of existing approaches addresses the problem of identifying\nnetwork-wide important crossroads in real road network. In this paper, we\npropose a novel data-driven based approach named CRRank to rank important\ncrossroads. Our key innovation is that we model the trip network reflecting\nreal travel demands with a tripartite graph, instead of solely analysis on the\ntopology of road network. To compute the importance scores of crossroads\naccurately, we propose a HITS-like ranking algorithm, in which a procedure of\nscore propagation on our tripartite graph is performed. We conduct experiments\non CRRank using a real-world dataset of taxi trajectories. Experiments verify\nthe utility of CRRank.", "1407.2524": "An improved analysis of the M\\\"omke-Svensson algorithm for graph-TSP on\n  subquartic graphs,Newman, Alantha,Computer Science - Data Structures and Algorithms,M\\\"omke and Svensson presented a beautiful new approach for the traveling\nsalesman problem on a graph metric (graph-TSP), which yields a\n$4/3$-approximation guarantee on subcubic graphs as well as a substantial\nimprovement over the $3/2$-approximation guarantee of Christofides' algorithm\non general graphs. The crux of their approach is to compute an upper bound on\nthe minimum cost of a circulation in a particular network, $C(G,T)$, where $G$\nis the input graph and $T$ is a carefully chosen spanning tree. The cost of\nthis circulation is directly related to the number of edges in a tour output by\ntheir algorithm. Mucha subsequently improved the analysis of the circulation\ncost, proving that M\\\"omke and Svensson's algorithm for graph-TSP has an\napproximation ratio of at most $13/9$ on general graphs.\n  This analysis of the circulation is local, and vertices with degree four and\nfive can contribute the most to its cost. Thus, hypothetically, there could\nexist a subquartic graph (a graph with degree at most four at each vertex) for\nwhich Mucha's analysis of the M\\\"omke-Svensson algorithm is tight. We show that\nthis is not the case and that M\\\"omke and Svensson's algorithm for graph-TSP\nhas an approximation guarantee of at most $25/18$ on subquartic graphs. To\nprove this, we present different methods to upper bound the minimum cost of a\ncirculation on the network $C(G,T)$. Our approximation guarantee holds for all\ngraphs that have an optimal solution to a standard linear programming\nrelaxation of graph-TSP with subquartic support.Comment: Journal version", "1407.2988": "Proving differential privacy in Hoare logic,Barthe, GillesGaboardi, MarcoArias, Emilio Jes\u00fas GallegoHsu, JustinKunz, C\u00e9sarStrub, Pierre-Yves,Computer Science - Logic in Computer ScienceComputer Science - Cryptography and Security,Differential privacy is a rigorous, worst-case notion of privacy-preserving\ncomputation. Informally, a probabilistic program is differentially private if\nthe participation of a single individual in the input database has a limited\neffect on the program's distribution on outputs. More technically, differential\nprivacy is a quantitative 2-safety property that bounds the distance between\nthe output distributions of a probabilistic program on adjacent inputs. Like\nmany 2-safety properties, differential privacy lies outside the scope of\ntraditional verification techniques. Existing approaches to enforce privacy are\nbased on intricate, non-conventional type systems, or customized relational\nlogics. These approaches are difficult to implement and often cumbersome to\nuse.\n  We present an alternative approach that verifies differential privacy by\nstandard, non-relational reasoning on non-probabilistic programs. Our approach\ntransforms a probabilistic program into a non-probabilistic program which\nsimulates two executions of the original program. We prove that if the target\nprogram is correct with respect to a Hoare specification, then the original\nprobabilistic program is differentially private. We provide a variety of\nexamples from the differential privacy literature to demonstrate the utility of\nour approach. Finally, we compare our approach with existing verification\ntechniques for privacy.Comment: Published at the Computer Security Foundations Symposium (CSF), 2014", "1407.3556": "Optimal Spectrum Management in Two-User Interference Channels,Hamedazimi, NavidGupta, Himanshu,Computer Science - Information Theory,In this work, we address the problem of optimal spectrum management in\ncontinuous frequency domain in multiuser interference channels. The objective\nis to maximize the weighted sum of user capacities. Our main results are as\nfollows: (i) For frequency-selective channels, we prove that in an optimal\nsolution, each user uses maximum power; this result also generalizes to the\ncases where the objective is to maximize the weighted product (i.e.,\nproportional fairness) of user capacities. (ii) For the special case of two\nusers in flat channels, we solve the problem optimally.", "1407.3764": "Perfect sampling algorithm for Schur processes,Betea, DanBoutillier, C\u00e9dricBouttier, J\u00e9r\u00e9mieChapuy, GuillaumeCorteel, SylvieVuleti\u0107, Mirjana,Mathematics - ProbabilityCondensed Matter - Statistical MechanicsComputer Science - Discrete MathematicsMathematics - Combinatorics05A17, 05E10, 60C05, 60J10, 68U20, 82B20,We describe random generation algorithms for a large class of random\ncombinatorial objects called Schur processes, which are sequences of random\n(integer) partitions subject to certain interlacing conditions. This class\ncontains several fundamental combinatorial objects as special cases, such as\nplane partitions, tilings of Aztec diamonds, pyramid partitions and more\ngenerally steep domino tilings of the plane. Our algorithm, which is of\npolynomial complexity, is both exact (i.e. the output follows exactly the\ntarget probability law, which is either Boltzmann or uniform in our case), and\nentropy optimal (i.e. it reads a minimal number of random bits as an input).\n  The algorithm encompasses previous growth procedures for special Schur\nprocesses related to the primal and dual RSK algorithm, as well as the famous\ndomino shuffling algorithm for domino tilings of the Aztec diamond. It can be\neasily adapted to deal with symmetric Schur processes and general Schur\nprocesses involving infinitely many parameters. It is more concrete and easier\nto implement than Borodin's algorithm, and it is entropy optimal.\n  At a technical level, it relies on unified bijective proofs of the different\ntypes of Cauchy and Littlewood identities for Schur functions, and on an\nadaptation of Fomin's growth diagram description of the RSK algorithm to that\nsetting. Simulations performed with this algorithm suggest interesting limit\nshape phenomena for the corresponding tiling models, some of which are new.Comment: 26 pages, 19 figures (v3: final version, corrected a few misprints\n  present in v2)", "1407.3975": "A Generalized Write Channel Model for Bit-Patterned Media Recording,Naseri, SimaYazdani, SomaieRazeghi, BehroozHodtani, Ghosheh Abed,Computer Science - Information Theory,In this paper, we propose a generalized write channel model for bit-patterned\nmedia recording by considering all sources of errors causing some extra\ndisturbances during write process, in addition to data dependent write\nsynchronization errors. We investigate information-theoretic bounds for this\nnew model according to various input distributions and also compare it\nnumerically to the last proposed model.Comment: Accepted for publication in the IEEE International Symposium on\n  Information Theory and its Applications (ISITA 2014), Melbourne, Australia,\n  Oct. 2014", "1407.4066": "Minors and dimension,Walczak, Bartosz,Mathematics - CombinatoricsComputer Science - Discrete Mathematics06A07, 05C35,It has been known for 30 years that posets with bounded height and with cover\ngraphs of bounded maximum degree have bounded dimension. Recently, Streib and\nTrotter proved that dimension is bounded for posets with bounded height and\nplanar cover graphs, and Joret et al. proved that dimension is bounded for\nposets with bounded height and with cover graphs of bounded tree-width. In this\npaper, it is proved that posets of bounded height whose cover graphs exclude a\nfixed topological minor have bounded dimension. This generalizes all the\naforementioned results and verifies a conjecture of Joret et al. The proof\nrelies on the Robertson-Seymour and Grohe-Marx graph structure theorems.Comment: Updated references", "1407.4723": "Toward Selectivity Based Keyword Extraction for Croatian News,Beliga, SlobodanMe\u0161trovi\u0107, AnaMartin\u010di\u0107-Ip\u0161i\u0107, Sanda,Computer Science - Computation and LanguageComputer Science - Information RetrievalComputer Science - Social and Information Networks,Preliminary report on network based keyword extraction for Croatian is an\nunsupervised method for keyword extraction from the complex network. We build\nour approach with a new network measure the node selectivity, motivated by the\nresearch of the graph based centrality approaches. The node selectivity is\ndefined as the average weight distribution on the links of the single node. We\nextract nodes (keyword candidates) based on the selectivity value. Furthermore,\nwe expand extracted nodes to word-tuples ranked with the highest in/out\nselectivity values. Selectivity based extraction does not require linguistic\nknowledge while it is purely derived from statistical and structural\ninformation en-compassed in the source text which is reflected into the\nstructure of the network. Obtained sets are evaluated on a manually annotated\nkeywords: for the set of extracted keyword candidates average F1 score is\n24,63%, and average F2 score is 21,19%; for the exacted words-tuples candidates\naverage F1 score is 25,9% and average F2 score is 24,47%.", "1407.4729": "Sparse Partially Linear Additive Models,Lou, YinBien, JacobCaruana, RichGehrke, Johannes,Statistics - MethodologyComputer Science - Machine LearningStatistics - Machine Learning,The generalized partially linear additive model (GPLAM) is a flexible and\ninterpretable approach to building predictive models. It combines features in\nan additive manner, allowing each to have either a linear or nonlinear effect\non the response. However, the choice of which features to treat as linear or\nnonlinear is typically assumed known. Thus, to make a GPLAM a viable approach\nin situations in which little is known $a~priori$ about the features, one must\novercome two primary model selection challenges: deciding which features to\ninclude in the model and determining which of these features to treat\nnonlinearly. We introduce the sparse partially linear additive model (SPLAM),\nwhich combines model fitting and $both$ of these model selection challenges\ninto a single convex optimization problem. SPLAM provides a bridge between the\nlasso and sparse additive models. Through a statistical oracle inequality and\nthorough simulation, we demonstrate that SPLAM can outperform other methods\nacross a broad spectrum of statistical regimes, including the high-dimensional\n($p\\gg N$) setting. We develop efficient algorithms that are applied to real\ndata sets with half a million samples and over 45,000 features with excellent\npredictive performance.Comment: Corrected typos", "1407.4908": "Integrating R and Hadoop for Big Data Analysis,Oancea, BogdanDragoescu, Raluca Mariana,Computer Science - Distributed, Parallel, and Cluster Computing,Analyzing and working with big data could be very diffi cult using classical\nmeans like relational database management systems or desktop software packages\nfor statistics and visualization. Instead, big data requires large clusters\nwith hundreds or even thousands of computing nodes. Offi cial statistics is\nincreasingly considering big data for deriving new statistics because big data\nsources could produce more relevant and timely statistics than traditional\nsources. One of the software tools successfully and wide spread used for\nstorage and processing of big data sets on clusters of commodity hardware is\nHadoop. Hadoop framework contains libraries, a distributed fi le-system (HDFS),\na resource-management platform and implements a version of the MapReduce\nprogramming model for large scale data processing. In this paper we investigate\nthe possibilities of integrating Hadoop with R which is a popular software used\nfor statistical computing and data visualization. We present three ways of\nintegrating them: R with Streaming, Rhipe and RHadoop and we emphasize the\nadvantages and disadvantages of each solution.Comment: Romanian Statistical Review no. 2 / 2014", "1407.5117": "Implementing Transitive Credit with JSON-LD,Katz, Daniel S.Smith, Arfon M.,Computer Science - Computers and SocietyComputer Science - Digital Libraries,Science and engineering research increasingly relies on activities that\nfacilitate research but are not currently rewarded or recognized, such as: data\nsharing; developing common data resources, software and methodologies; and\nannotating data and publications. To promote and advance these activities, we\nmust develop mechanisms for assigning credit, facilitate the appropriate\nattribution of research outcomes, devise incentives for activities that\nfacilitate research, and allocate funds to maximize return on investment. In\nthis article, we focus on addressing the issue of assigning credit for both\ndirect and indirect contributions, specifically by using JSON-LD to implement a\nprototype transitive credit system.Comment: accepted by WSSSPE2 - http://wssspe.researchcomputing.org.uk/wssspe2/", "1407.5218": "Abstractions, Algorithms and Data Structures for Structural\n  Bioinformatics in PyCogent,Cieslik, MarcinDerewenda, ZygmuntMura, Cameron,Quantitative Biology - BiomoleculesComputer Science - Data Structures and AlgorithmsComputer Science - Software Engineering,To facilitate flexible and efficient structural bioinformatics analyses, new\nfunctionality for three-dimensional structure processing and analysis has been\nintroduced into PyCogent -- a popular feature-rich framework for sequence-based\nbioinformatics, but one which has lacked equally powerful tools for handling\nstuctural/coordinate-based data. Extensible Python modules have been developed,\nwhich provide object-oriented abstractions (based on a hierarchical\nrepresentation of macromolecules), efficient data structures (e.g. kD-trees),\nfast implementations of common algorithms (e.g. surface-area calculations),\nread/write support for Protein Data Bank-related file formats and wrappers for\nexternal command-line applications (e.g. Stride). Integration of this code into\nPyCogent is symbiotic, allowing sequence-based work to benefit from\nstructure-derived data and, reciprocally, enabling structural studies to\nleverage PyCogent's versatile tools for phylogenetic and evolutionary analyses.Comment: 36 pages, 4 figures (including supplemental information)", "1407.5374": "Acyclic Edge Coloring through the Lov\\'asz Local Lemma,Giotis, IoannisKirousis, LefterisPsaromiligkos, Kostas I.Thilikos, Dimitrios M.,Computer Science - Discrete MathematicsComputer Science - Data Structures and AlgorithmsMathematics - CombinatoricsMathematics - Probability,We give a probabilistic analysis of a Moser-type algorithm for the Lov\\'{a}sz\nLocal Lemma (LLL), adjusted to search for acyclic edge colorings of a graph. We\nthus improve the best known upper bound to acyclic chromatic index, also\nobtained by analyzing a similar algorithm, but through the entropic method\n(basically counting argument). Specifically we show that a graph with maximum\ndegree $\\Delta$ has an acyclic proper edge coloring with at most $\\lceil\n3.74(\\Delta-1)\\rceil+1 $ colors, whereas, previously, the best bound was\n$4(\\Delta-1)$. The main contribution of this work is that it comprises a\nprobabilistic analysis of a Moser-type algorithm applied to events pertaining\nto dependent variables.Comment: The proof of Lemma 5 has been corrected", "1407.5536": "Multichannel Compressive Sensing MRI Using Noiselet Encoding,Pawar, KamleshEgan, Gary F.Zhang, Jingxin,Physics - Medical PhysicsComputer Science - Computer Vision and Pattern Recognition,The incoherence between measurement and sparsifying transform matrices and\nthe restricted isometry property (RIP) of measurement matrix are two of the key\nfactors in determining the performance of compressive sensing (CS). In CS-MRI,\nthe randomly under-sampled Fourier matrix is used as the measurement matrix and\nthe wavelet transform is usually used as sparsifying transform matrix. However,\nthe incoherence between the randomly under-sampled Fourier matrix and the\nwavelet matrix is not optimal, which can deteriorate the performance of CS-MRI.\nUsing the mathematical result that noiselets are maximally incoherent with\nwavelets, this paper introduces the noiselet unitary bases as the measurement\nmatrix to improve the incoherence and RIP in CS-MRI, and presents a method to\ndesign the pulse sequence for the noiselet encoding. This novel encoding scheme\nis combined with the multichannel compressive sensing (MCS) framework to take\nthe advantage of multichannel data acquisition used in MRI scanners. An\nempirical RIP analysis is presented to compare the multichannel noiselet and\nmultichannel Fourier measurement matrices in MCS. Simulations are presented in\nthe MCS framework to compare the performance of noiselet encoding\nreconstructions and Fourier encoding reconstructions at different acceleration\nfactors. The comparisons indicate that multichannel noiselet measurement matrix\nhas better RIP than that of its Fourier counterpart, and that noiselet encoded\nMCS-MRI outperforms Fourier encoded MCS-MRI in preserving image resolution and\ncan achieve higher acceleration factors. To demonstrate the feasibility of the\nproposed noiselet encoding scheme, two pulse sequences with tailored spatially\nselective RF excitation pulses was designed and implemented on a 3T scanner to\nacquire the data in the noiselet domain from a phantom and a human brain.", "1407.5965": "Optimization Techniques on Riemannian Manifolds,Smith, Steven Thomas,Mathematics - Optimization and ControlComputer Science - Computational GeometryComputer Science - Numerical AnalysisMathematics - Differential GeometryMathematics - Dynamical Systems,The techniques and analysis presented in this paper provide new methods to\nsolve optimization problems posed on Riemannian manifolds. A new point of view\nis offered for the solution of constrained optimization problems. Some\nclassical optimization techniques on Euclidean space are generalized to\nRiemannian manifolds. Several algorithms are presented and their convergence\nproperties are analyzed employing the Riemannian structure of the manifold.\nSpecifically, two apparently new algorithms, which can be thought of as\nNewton's method and the conjugate gradient method on Riemannian manifolds, are\npresented and shown to possess, respectively, quadratic and superlinear\nconvergence. Examples of each method on certain Riemannian manifolds are given\nwith the results of numerical experiments. Rayleigh's quotient defined on the\nsphere is one example. It is shown that Newton's method applied to this\nfunction converges cubically, and that the Rayleigh quotient iteration is an\nefficient approximation of Newton's method. The Riemannian version of the\nconjugate gradient method applied to this function gives a new algorithm for\nfinding the eigenvectors corresponding to the extreme eigenvalues of a\nsymmetric matrix. Another example arises from extremizing the function\n$\\mathop{\\rm tr} {\\Theta}^{\\scriptscriptstyle\\rm T}Q{\\Theta}N$ on the special\northogonal group. In a similar example, it is shown that Newton's method\napplied to the sum of the squares of the off-diagonal entries of a symmetric\nmatrix converges cubically.Comment: Hamiltonian and Gradient Flows, Algorithms, and Control, Fields\n  Institute Communications, Volume 3, AMS (1994)", "1407.6116": "A Genetic Algorithm for Software Design Migration from Structured to\n  Object Oriented Paradigm,Selim, Md.Siddik, SaeedGias, Alim UlAbdullah-Al-Wadud, M.Khaled, Shah Mostafa,Computer Science - Software EngineeringComputer Science - Neural and Evolutionary Computing,The potential benefit of migrating software design from Structured to Object\nOriented Paradigm is manifolded including modularity, manageability and\nextendability. This design migration should be automated as it will reduce the\ntime required in manual process. Our previous work has addressed this issue in\nterms of optimal graph clustering problem formulated by a quadratic Integer\nProgram (IP). However, it has been realized that solution to the IP is\ncomputationally hard and thus heuristic based methods are required to get a\nnear optimal solution. This paper presents a Genetic Algorithm (GA) for optimal\nclustering with an objective of maximizing intra-cluster edges whereas\nminimizing the inter-cluster ones. The proposed algorithm relies on fitness\nbased parent selection and cross-overing cluster elements to reach an optimal\nsolution step by step. The scheme was implemented and tested against a set of\nreal and synthetic data. The experimental results show that GA outperforms our\nprevious works based on Greedy and Monte Carlo approaches by 40% and 49.5%.", "1407.6169": "Multiplicative Complexity of Vector Valued Boolean Functions,Find, Magnus GausdalBoyar, Joan,Computer Science - Computational Complexity,We consider the multiplicative complexity of Boolean functions with multiple\nbits of output, studying how large a multiplicative complexity is necessary and\nsufficient to provide a desired nonlinearity. For so-called $\\Sigma\\Pi\\Sigma$\ncircuits, we show that there is a tight connection between error correcting\ncodes and circuits computing functions with high nonlinearity. Combining this\nwith known coding theory results, we show that functions with $n$ inputs and\n$n$ outputs with the highest possible nonlinearity must have at least $2.32n$\nAND gates. We further show that one cannot prove stronger lower bounds by only\nappealing to the nonlinearity of a function; we show a bilinear circuit\ncomputing a function with almost optimal nonlinearity with the number of AND\ngates being exactly the length of such a shortest code.\n  Additionally we provide a function which, for general circuits, has\nmultiplicative complexity at least $2n-3$.\n  Finally we study the multiplicative complexity of \"almost all\" functions. We\nshow that every function with $n$ bits of input and $m$ bits of output can be\ncomputed using at most $2.5(1+o(1))\\sqrt{m2^n}$ AND gates.Comment: Extended version of the paper \"The Relationship Between\n  Multiplicative Complexity and Nonlinearity\", MFCS2014", "1407.6845": "Higher-Order Approximate Relational Refinement Types for Mechanism\n  Design and Differential Privacy,Barthe, GillesGaboardi, MarcoArias, Emilio Jes\u00fas GallegoHsu, JustinRoth, AaronStrub, Pierre-Yves,Computer Science - Programming LanguagesComputer Science - Computer Science and Game Theory,Mechanism design is the study of algorithm design in which the inputs to the\nalgorithm are controlled by strategic agents, who must be incentivized to\nfaithfully report them. Unlike typical programmatic properties, it is not\nsufficient for algorithms to merely satisfy the property---incentive properties\nare only useful if the strategic agents also believe this fact.\n  Verification is an attractive way to convince agents that the incentive\nproperties actually hold, but mechanism design poses several unique challenges:\ninteresting properties can be sophisticated relational properties of\nprobabilistic computations involving expected values, and mechanisms may rely\non other probabilistic properties, like differential privacy, to achieve their\ngoals.\n  We introduce a relational refinement type system, called $\\mathsf{HOARe}^2$,\nfor verifying mechanism design and differential privacy. We show that\n$\\mathsf{HOARe}^2$ is sound w.r.t. a denotational semantics, and correctly\nmodels $(\\epsilon,\\delta)$-differential privacy; moreover, we show that it\nsubsumes DFuzz, an existing linear dependent type system for differential\nprivacy. Finally, we develop an SMT-based implementation of $\\mathsf{HOARe}^2$\nand use it to verify challenging examples of mechanism design, including\nauctions and aggregative games, and new proposed examples from differential\nprivacy.", "1407.7274": "Isomorphism within Naive Type Theory,McAllester, David,Computer Science - Logic in Computer Science,We provide a treatment of isomorphism within a set-theoretic formulation of\ndependent type theory. Type expressions are assigned their natural\nset-theoretic compositional meaning. Types are divided into small and large\ntypes --- sets and proper classes respectively. Each proper class, such as\n\"group\" or \"topological space\", has an associated notion of isomorphism in\ncorrespondence with standard definitions. Isomorphism is handled by definging a\ngroupoid structure on the space of all definable values. The values are\nsimultaneously objects (oids) and morphism --- they are \"morphoids\". Soundness\ncan then be proved for simple and natural inference rules deriving isomorphisms\nand for the substitution of isomorphics.", "1407.7459": "A note on multipivot Quicksort,Iliopoulos, Vasileios,Computer Science - Data Structures and AlgorithmsMathematics - Combinatorics68P10, 68W20,We analyse a generalisation of the Quicksort algorithm, where k uniformly at\nrandom chosen pivots are used for partitioning an array of n distinct keys.\nSpecifically, the expected cost of this scheme is obtained, under the\nassumption of linearity of the cost needed for the partition process. The\nintegration constants of the expected cost are computed using Vandermonde\nmatrices.Comment: Author's accepted manuscript, 7 pages", "1408.0135": "New data, new possibilities: Exploring the insides of Altmetric.com,Robinson-Garc\u00eda, Nicol\u00e1sTorres-Salinas, DanielZahedi, ZohrehCostas, Rodrigo,Computer Science - Digital Libraries,This paper analyzes Altmetric.com, one of the most important altmetric data\nproviders currently used. We have analyzed a set of publications with DOI\nnumber indexed in the Web of Science during the period 2011-2013 and collected\ntheir data with the Altmetric API. 19% of the original set of papers was\nretrieved from Altmetric.com including some altmetric data. We identified 16\ndifferent social media sources from which Altmetric.com retrieves data. However\nfive of them cover 95.5% of the total set. Twitter (87.1%) and Mendeley (64.8%)\nhave the highest coverage. We conclude that Altmetric.com is a transparent,\nrich and accurate tool for altmetric data. Nevertheless, there are still\npotential limitations on its exhaustiveness as well as on the selection of\nsocial media sources that need further research.", "1408.0652": "Precision of Pulse-Coupled Oscillator Synchronization on FPGA-Based\n  Radios,Brandner, G\u00fcntherKlinglmayr, JohannesSchilcher, UdoEgarter, DominikBettstetter, Christian,Computer Science - Other Computer Science,The precision of synchronization algorithms based on the theory of\npulse-coupled oscillators is evaluated on FPGA-based radios for the first time.\nMeasurements show that such algorithms can reach precision in the low\nmicrosecond range when being implemented in the physical layer. Furthermore, we\npropose an algorithm extension accounting for phase rate deviations of the\nhardware and show that an improved precision below one microsecond is possible\nwith this extension in the given setup. The resulting algorithm can thus be\napplied in ad hoc wireless systems for fully distributed synchronization of\ntransmission slots or sleep cycles, in particular, if centralized\nsynchronization is impossible.", "1408.0807": "Polynomial size linear programs for problems in P,Avis, DavidBremner, DavidTiwary, Hans RajWatanabe, Osamu,Computer Science - Discrete Mathematics,A perfect matching in an undirected graph $G=(V,E)$ is a set of vertex\ndisjoint edges from $E$ that include all vertices in $V$. The perfect matching\nproblem is to decide if $G$ has such a matching. Recently Rothvo{\\ss} proved\nthe striking result that the Edmonds' matching polytope has exponential\nextension complexity. Here for each $n=|V|$ we describe a perfect matching\npolytope that is different from Edmonds' polytope and define a weaker notion of\nextended formulation. We show that the new polytope has a weak extended\nformulation (WEF) $Q$ of polynomial size. For each graph $G$ with $n$ vertices\nwe can readily construct an objective function so that solving the resulting\nlinear program over $Q$ decides whether or not $G$ has a perfect matching. The\nconstruction is uniform in the sense that, for each $n$, a single polytope is\ndefined for the class of all graphs with $n$ nodes. The method extends to solve\npoly time optimization problems, such as the weighted matching problem. In this\ncase a logarithmic (in the weight of the optimum solution) number of\noptimizations are made over the constructed WEF.\n  The method described in the paper involves construction of a compiler that\nconverts an algorithm given in a prescribed pseudocode into a polytope. It can\ntherefore be used to construct a polytope for any decision problem in {\\bf P}\nwhich can be solved by a given algorithm. Compared with earlier results of\nDobkin-Lipton-Reiss and Valiant our method allows the construction of explicit\nlinear programs directly from algorithms written for a standard register model,\nwithout intermediate transformations. We apply our results to obtain polynomial\nupper bounds on the non-negative rank of certain slack matrices related to\nmembership testing of languages in {\\bf P/Poly}.Comment: 21 pages, 1 figure; This version comprises of a major revision of the\n  earlier version, with several errors corrected and parts rewritten", "1408.0848": "Multilayer bootstrap networks,Zhang, Xiao-Lei,Computer Science - Machine LearningComputer Science - Neural and Evolutionary ComputingStatistics - Machine Learning,Multilayer bootstrap network builds a gradually narrowed multilayer nonlinear\nnetwork from bottom up for unsupervised nonlinear dimensionality reduction.\nEach layer of the network is a nonparametric density estimator. It consists of\na group of k-centroids clusterings. Each clustering randomly selects data\npoints with randomly selected features as its centroids, and learns a one-hot\nencoder by one-nearest-neighbor optimization. Geometrically, the nonparametric\ndensity estimator at each layer projects the input data space to a\nuniformly-distributed discrete feature space, where the similarity of two data\npoints in the discrete feature space is measured by the number of the nearest\ncentroids they share in common. The multilayer network gradually reduces the\nnonlinear variations of data from bottom up by building a vast number of\nhierarchical trees implicitly on the original data space. Theoretically, the\nestimation error caused by the nonparametric density estimator is proportional\nto the correlation between the clusterings, both of which are reduced by the\nrandomization steps.Comment: accepted for publication by Neural Networks", "1408.0948": "A special role of Boolean quadratic polytopes among other combinatorial\n  polytopes,Maksimenko, Aleksandr,Computer Science - Computational ComplexityMathematics - Combinatorics,We consider several families of combinatorial polytopes associated with the\nfollowing NP-complete problems: maximum cut, Boolean quadratic programming,\nquadratic linear ordering, quadratic assignment, set partition, set packing,\nstable set, 3-assignment. For comparing two families of polytopes we use the\nfollowing method. We say that a family $P$ is affinely reduced to a family $Q$\nif for every polytope $p\\in P$ there exists $q\\in Q$ such that $p$ is affinely\nequivalent to $q$ or to a face of $q$, where $\\dim q = O((\\dim p)^k)$ for some\nconstant $k$. Under this comparison the above-mentioned families are splitted\ninto two equivalence classes. We show also that these two classes are simpler\n(in the above sence) than the families of poytopes of the following problems:\nset covering, traveling salesman, 0-1 knapsack problem, 3-satisfiability, cubic\nsubgraph, partial ordering. In particular, Boolean quadratic polytopes appear\nas faces of polytopes in every of the mentioned families.Comment: 16 pages", "1408.1025": "Stable Throughput Region of Cognitive-Relay Networks with Imperfect\n  Sensing and Finite Relaying Buffer,Alaa, Ahmed M.,Computer Science - Networking and Internet Architecture,In this letter, we obtain the stable throughput region for a cognitive\nrelaying scheme with a finite relaying buffer and imperfect sensing. The\nanalysis investigates the effect of the secondary user's finite relaying\ncapabilities under different scenarios of primary, secondary and relaying links\noutages. Furthermore, we demonstrate the effect of miss detection and false\nalarm probabilities on the achievable throughput for the primary and secondary\nusers.", "1408.1118": "Spoke-Darts for High-Dimensional Blue-Noise Sampling,Mitchell, Scott A.Ebeida, Mohamed S.Awad, Muhammad A.Park, ChonhyonPatney, AnjulRushdi, Ahmad A.Swiler, Laura P.Manocha, DineshWei, Li-Yi,Computer Science - Graphics,Blue noise sampling has proved useful for many graphics applications, but\nremains underexplored in high-dimensional spaces due to the difficulty of\ngenerating distributions and proving properties about them. We present a blue\nnoise sampling method with good quality and performance across different\ndimensions. The method, spoke-dart sampling, shoots rays from prior samples and\nselects samples from these rays. It combines the advantages of two major\nhigh-dimensional sampling methods: the locality of advancing front with the\ndimensionality-reduction of hyperplanes, specifically line sampling. We prove\nthat the output sampling is saturated with high probability, with bounds on\ndistances between pairs of samples and between any domain point and its nearest\nsample. We demonstrate spoke-dart applications for approximate Delaunay graph\nconstruction, global optimization, and robotic motion planning. Both the\nblue-noise quality of the output distribution and the adaptability of the\nintermediate processes of our method are useful in these applications.Comment: 19 pages, 22 figures", "1408.1390": "On optimal approximability results for computing the strong metric\n  dimension,DasGupta, BhaskarMobasheri, Nasim,Computer Science - Computational ComplexityComputer Science - Discrete Mathematics68Q17, 68Q25, 68R10G.2.2F.2.2,The strong metric dimension of a graph was first introduced by Seb\\\"{o} and\nTannier (Mathematics of Operations Research, 29(2), 383-393, 2004) as an\nalternative to the (weak) metric dimension of graphs previously introduced\nindependently by Slater (Proc. 6th Southeastern Conference on Combinatorics,\nGraph Theory, and Computing, 549-559, 1975) and by Harary and Melter (Ars\nCombinatoria, 2, 191-195, 1976), and has since been investigated in several\nresearch papers. However, the exact worst-case computational complexity of\ncomputing the strong metric dimension has remained open beyond being\nNP-complete. In this communication, we show that the problem of computing the\nstrong metric dimension of a graph of $n$ nodes admits a polynomial-time\n$2$-approximation, admits a $O^\\ast\\big(2^{\\,0.287\\,n}\\big)$-time exact\ncomputation algorithm, admits a $O\\big(1.2738^k+n\\,k\\big)$-time exact\ncomputation algorithm if the strong metric dimension is at most $k$, does not\nadmit a polynomial time $(2-\\varepsilon)$-approximation algorithm assuming the\nunique games conjecture is true, does not admit a polynomial time\n$(10\\sqrt{5}-21-\\varepsilon)$-approximation algorithm assuming P$\\neq$NP, does\nnot admit a $O^\\ast\\big(2^{o(n)}\\big)$-time exact computation algorithm\nassuming the exponential time hypothesis is true, and does not admit a\n$O^\\ast\\big(n^{o(k)}\\big)$-time exact computation algorithm if the strong\nmetric dimension is at most $k$ assuming the exponential time hypothesis is\ntrue.Comment: revised version based on reviewer comments; to appear in Discrete\n  Applied Mathematics", "1408.1868": "On the structure of classical realizability models of ZF,Krivine, Jean-Louis,Computer Science - Logic in Computer ScienceMathematics - Logic03E40F.4.1,The technique of \"classical realizability\" is an extension of the method of\n\"forcing\"; it permits to extend the Curry-Howard correspondence between proofs\nand programs, to Zermelo-Fraenkel set theory and to build new models of ZF,\ncalled \"realizability models\". The structure of these models is, in general,\nmuch more complicated than that of the particular case of \"forcing models\". We\nshow here that the class of constructible sets of any realizability model is an\nelementary extension of the constructibles of the ground model (a trivial fact\nin the case of forcing, since these classes are identical). It follows that\nShoenfield absoluteness theorem applies to realizability models.Comment: 17 pages", "1408.2071": "Near-Constant-Time Distributed Algorithms on a Congested Clique,Hegeman, James W.Pemmaraju, Sriram V.Sardeshmukh, Vivek B.,Computer Science - Distributed, Parallel, and Cluster Computing,This paper presents constant-time and near-constant-time distributed\nalgorithms for a variety of problems in the congested clique model. We show how\nto compute a 3-ruling set in expected $O(\\log \\log \\log n)$ rounds and using\nthis, we obtain a constant-approximation to metric facility location, also in\nexpected $O(\\log \\log \\log n)$ rounds. In addition, assuming an input metric\nspace of constant doubling dimension, we obtain constant-round algorithms to\ncompute constant-factor approximations to the minimum spanning tree and the\nmetric facility location problems. These results significantly improve on the\nrunning time of the fastest known algorithms for these problems in the\ncongested clique setting.Comment: Full version of DISC 2014 paper. Updated Sep 2018 to reflect the fact\n  that using the Ghaffari et al. congested clique MIS algorithm from PODC 2018,\n  it is possible to compute a 2-ruling set in the congested clique in\n  O(logloglog n) rounds with high probability", "1408.2467": "Matrix Completion under Interval Uncertainty,Marecek, JakubRichtarik, PeterTakac, Martin,Mathematics - Optimization and ControlComputer Science - Artificial IntelligenceComputer Science - Information Retrieval,Matrix completion under interval uncertainty can be cast as matrix completion\nwith element-wise box constraints. We present an efficient\nalternating-direction parallel coordinate-descent method for the problem. We\nshow that the method outperforms any other known method on a benchmark in image\nin-painting in terms of signal-to-noise ratio, and that it provides\nhigh-quality solutions for an instance of collaborative filtering with\n100,198,805 recommendations within 5 minutes.", "1408.3030": "Distributed Graph Automata and Verification of Distributed Algorithms,Reiter, Fabian,Computer Science - Formal Languages and Automata TheoryComputer Science - Distributed, Parallel, and Cluster ComputingComputer Science - Logic in Computer Science,Combining ideas from distributed algorithms and alternating automata, we\nintroduce a new class of finite graph automata that recognize precisely the\nlanguages of finite graphs definable in monadic second-order logic. By\nrestricting transitions to be nondeterministic or deterministic, we also obtain\ntwo strictly weaker variants of our automata for which the emptiness problem is\ndecidable. As an application, we suggest how suitable graph automata might be\nuseful in formal verification of distributed algorithms, using Floyd-Hoare\nlogic.Comment: 26 pages, 6 figures, includes a condensed version of the author's\n  Master's thesis arXiv:1404.6503. (This version of the article (v2) is\n  identical to the previous one (v1), except for minor changes in phrasing.)", "1408.3190": "On the neighbour sum distinguishing index of planar graphs,Bonamy, MarthePrzyby\u0142o, Jakub,Computer Science - Discrete MathematicsMathematics - Combinatorics05C78, 05C15,Let $c$ be a proper edge colouring of a graph $G=(V,E)$ with integers\n$1,2,\\ldots,k$. Then $k\\geq \\Delta(G)$, while by Vizing's theorem, no more than\n$k=\\Delta(G)+1$ is necessary for constructing such $c$. On the course of\ninvestigating irregularities in graphs, it has been moreover conjectured that\nonly slightly larger $k$, i.e., $k=\\Delta(G)+2$ enables enforcing additional\nstrong feature of $c$, namely that it attributes distinct sums of incident\ncolours to adjacent vertices in $G$ if only this graph has no isolated edges\nand is not isomorphic to $C_5$. We prove the conjecture is valid for planar\ngraphs of sufficiently large maximum degree. In fact even stronger statement\nholds, as the necessary number of colours stemming from the result of Vizing is\nproved to be sufficient for this family of graphs. Specifically, our main\nresult states that every planar graph $G$ of maximum degree at least $28$ which\ncontains no isolated edges admits a proper edge colouring\n$c:E\\to\\{1,2,\\ldots,\\Delta(G)+1\\}$ such that $\\sum_{e\\ni u}c(e)\\neq \\sum_{e\\ni\nv}c(e)$ for every edge $uv$ of $G$.Comment: 22 pages", "1408.3310": "An algorithm for canonical forms of finite subsets of $\\mathbb{Z}^d$ up\n  to affinities,Paolini, Giovanni,Computer Science - Data Structures and AlgorithmsComputer Science - Discrete MathematicsMathematics - Group Theory52C07,In this paper we describe an algorithm for the computation of canonical forms\nof finite subsets of $\\mathbb{Z}^d$, up to affinities over $\\mathbb{Z}$. For\nfixed dimension $d$, this algorithm has worst-case asymptotic complexity $O(n\n\\log^2 n \\, s\\,\\mu(s))$, where $n$ is the number of points in the given subset,\n$s$ is an upper bound to the size of the binary representation of any of the\n$n$ points, and $\\mu(s)$ is an upper bound to the number of operations required\nto multiply two $s$-bit numbers. In particular, the problem is fixed-parameter\ntractable with respect to the dimension $d$. This problem arises e.g. in the\ncontext of computation of invariants of finitely presented groups with\nabelianized group isomorphic to $\\mathbb{Z}^d$. In that context one needs to\ndecide whether two Laurent polynomials in $d$ indeterminates, considered as\nelements of the group ring over the abelianized group, are equivalent with\nrespect to a change of basis.", "1408.3743": "Parallel generator of $q$-valued pseudorandom sequences based on\n  arithmetic polynomials,Finko, OlegSamoylenko, DmitriyDichenko, SergeyEliseev, Nikolay,Computer Science - Cryptography and Security94A55, 68W10, 03B50, 11A07, 11B50, 94A60,A new method for parallel generation of $q$-valued pseudorandom sequence\nbased on the presentation of systems generating logical formulae by means of\narithmetic polynomials is proposed. Fragment consisting of $k$-elements of\n$q$-valued pseudorandom sequence may be obtained by means of single calculation\nof a single recursion numerical formula. It is mentioned that the method of the\n\"arithmetization\" of generation may be used and further developed in order to\nprotect the encryption gears from cryptographic onset, resulting in the\ninitiating of mass hardware failures. The achieved results may be widely\napplied to the realization of perspective high-performance cryptographic\nfacilities for information protection.Comment: 8 pages, 3 figures", "1408.3869": "Treewidth of graphs with balanced separations,Dvorak, ZdenekNorin, Sergey,Mathematics - CombinatoricsComputer Science - Discrete Mathematics,We prove that if every subgraph of a graph $G$ has a balanced separation of\norder at most $a$ then $G$ has treewidth at most $15a$. This establishes a\nlinear dependence between the treewidth and the separation number.Comment: Final version accepted for publication in J. Comb. Theory B", "1408.3877": "FESTUNG: A MATLAB / GNU Octave toolbox for the discontinuous Galerkin\n  method. Part I: Diffusion operator,Frank, FlorianReuter, BalthasarAizinger, VadymKnabner, Peter,Mathematics - Numerical AnalysisComputer Science - Computational Engineering, Finance, and ScienceComputer Science - Numerical Analysis,This is the first in a series of papers on implementing a discontinuous\nGalerkin method as a MATLAB / GNU Octave toolbox. The main goal is the\ndevelopment of techniques that deliver optimized computational performance\ncombined with a compact, user-friendly interface. Our implementation relies on\nfully vectorized matrix / vector operations and is carefully documented; in\naddition, a direct mapping between discretization terms and code routines is\nmaintained throughout. The present work focuses on a two-dimensional\ntime-dependent diffusion equation with space / time-varying coefficients. The\nspatial discretization is based on the local discontinuous Galerkin formulation\nand is locally mass conservative. Approximations of orders zero through four\nbased on orthogonal polynomials have been implemented; more spaces of arbitrary\ntype and order can be easily accommodated by the code structure. Time\ndiscretization is performed using an implicit Euler method.Comment: Updated with published manuscript. Substantial changes were applied\n  to the naming scheme of the included Matlab/GNU Octave codes", "1408.3976": "Static Analysis for Extracting Permission Checks of a Large Scale\n  Framework: The Challenges And Solutions for Analyzing Android,Bartel, AlexandreKlein, JacquesMonperrus, MartinTraon, Yves Le,Computer Science - Software Engineering,A common security architecture is based on the protection of certain\nresources by permission checks (used e.g., in Android and Blackberry). It has\nsome limitations, for instance, when applications are granted more permissions\nthan they actually need, which facilitates all kinds of malicious usage (e.g.,\nthrough code injection). The analysis of permission-based framework requires a\nprecise mapping between API methods of the framework and the permissions they\nrequire. In this paper, we show that naive static analysis fails miserably when\napplied with off-the-shelf components on the Android framework. We then present\nan advanced class-hierarchy and field-sensitive set of analyses to extract this\nmapping. Those static analyses are capable of analyzing the Android framework.\nThey use novel domain specific optimizations dedicated to Android.Comment: IEEE Transactions on Software Engineering (2014). arXiv admin note:\n  substantial text overlap with arXiv:1206.5829", "1408.4528": "Laplace Functional Ordering of Point Processes in Large-scale Wireless\n  Networks,Lee, JunghoonTepedelenlioglu, Cihan,Computer Science - Information TheoryComputer Science - Networking and Internet Architecture,Stochastic orders on point processes are partial orders which capture notions\nlike being larger or more variable. Laplace functional ordering of point\nprocesses is a useful stochastic order for comparing spatial deployments of\nwireless networks. It is shown that the ordering of point processes is\npreserved under independent operations such as marking, thinning, clustering,\nsuperposition, and random translation. Laplace functional ordering can be used\nto establish comparisons of several performance metrics such as coverage\nprobability, achievable rate, and resource allocation even when closed form\nexpressions of such metrics are unavailable. Applications in several network\nscenarios are also provided where tradeoffs between coverage and interference\nas well as fairness and peakyness are studied. Monte-Carlo simulations are used\nto supplement our analytical results.Comment: 30 pages, 5 figures, Submitted to Hindawi Wireless Communications and\n  Mobile Computing", "1408.6321": "Crossing Minimization for 1-page and 2-page Drawings of Graphs with\n  Bounded Treewidth,Bannister, Michael J.Eppstein, David,Computer Science - Data Structures and AlgorithmsComputer Science - Discrete MathematicsMathematics - Combinatorics,We investigate crossing minimization for 1-page and 2-page book drawings. We\nshow that computing the 1-page crossing number is fixed-parameter tractable\nwith respect to the number of crossings, that testing 2-page planarity is\nfixed-parameter tractable with respect to treewidth, and that computing the\n2-page crossing number is fixed-parameter tractable with respect to the sum of\nthe number of crossings and the treewidth of the input graph. We prove these\nresults via Courcelle's theorem on the fixed-parameter tractability of\nproperties expressible in monadic second order logic for graphs of bounded\ntreewidth.Comment: Graph Drawing 2014", "1408.6771": "Flat Foldings of Plane Graphs with Prescribed Angles and Edge Lengths,Abel, ZacharyDemaine, Erik D.Demaine, Martin L.Eppstein, DavidLubiw, AnnaUehara, Ryuhei,Computer Science - Computational GeometryComputer Science - Data Structures and AlgorithmsF.2.2,When can a plane graph with prescribed edge lengths and prescribed angles\n(from among $\\{0,180^\\circ, 360^\\circ$\\}) be folded flat to lie in an\ninfinitesimally thin line, without crossings? This problem generalizes the\nclassic theory of single-vertex flat origami with prescribed mountain-valley\nassignment, which corresponds to the case of a cycle graph. We characterize\nsuch flat-foldable plane graphs by two obviously necessary but also sufficient\nconditions, proving a conjecture made in 2001: the angles at each vertex should\nsum to $360^\\circ$, and every face of the graph must itself be flat foldable.\nThis characterization leads to a linear-time algorithm for testing flat\nfoldability of plane graphs with prescribed edge lengths and angles, and a\npolynomial-time algorithm for counting the number of distinct folded states.Comment: 21 pages, 10 figures", "1408.6923": "GPGPU Computing,Oancea, BogdanAndrei, TudorelDragoescu, Raluca Mariana,Computer Science - Distributed, Parallel, and Cluster Computing,Since the first idea of using GPU to general purpose computing, things have\nevolved over the years and now there are several approaches to GPU programming.\nGPU computing practically began with the introduction of CUDA (Compute Unified\nDevice Architecture) by NVIDIA and Stream by AMD. These are APIs designed by\nthe GPU vendors to be used together with the hardware that they provide. A new\nemerging standard, OpenCL (Open Computing Language) tries to unify different\nGPU general computing API implementations and provides a framework for writing\nprograms executed across heterogeneous platforms consisting of both CPUs and\nGPUs. OpenCL provides parallel computing using task-based and data-based\nparallelism. In this paper we will focus on the CUDA parallel computing\narchitecture and programming model introduced by NVIDIA. We will present the\nbenefits of the CUDA programming model. We will also compare the two main\napproaches, CUDA and AMD APP (STREAM) and the new framwork, OpenCL that tries\nto unify the GPGPU computing models.", "1409.0264": "Nash Equilbria for Quadratic Voting,Lalley, Steven P.Weyl, E. Glen,Computer Science - Computer Science and Game TheoryMathematics - Probability91B12 (Primary), 91B52, 60F99 (Secondary),Voters making a binary decision purchase votes from a centralized clearing\nhouse, paying the square of the number of votes purchased. The net payoff to an\nagent with utility $u$ who purchases $v$ votes is $\\Psi (S_{n+1})u-v^{2}$,\nwhere $\\Psi$ is a monotone function taking values between -1 and +1 and\n$S_{n+1}$ is the sum of all votes purchased by the $n+1$ voters participating\nin the election. The utilities of the voters are assumed to arise by random\nsampling from a probability distribution $F_{U}$ with compact support; each\nvoter knows her own utility, but not those of the other voters, although she\ndoes know the sampling distribution $F_{U}$. Nash equilibria for this game are\ndescribed. These results imply that the expected inefficiency of any Nash\nequilibrium decays like $1/n$.Comment: Revision of our earlier article \"Nash Equilibria for a Quadratic\n  Voting Game\"", "1409.0375": "Polynomial solvability of $NP$-complete problems,Panyukov, Anatoly,Computer Science - Computational Complexity05C85,${ NP}$-complete problem \"Hamiltonian cycle\"\\ for graph $G=(V,E)$ is extended\nto the \"Hamiltonian Complement of the Graph\"\\ problem of finding the minimal\ncardinality set $H$ containing additional edges so that graph $G=(V,E\\cup H)$\nis Hamiltonian. The solving of \"Hamiltonian Complement of a Graph\"\\ problem is\nreduced to the linear programming problem {\\bf P}, which has an optimal integer\nsolution. The optimal integer solution of {\\bf P} is found for any its optimal\nsolution by solving the linear assignment problem {\\bf L}. The existence of\npolynomial algorithms for problems {\\bf P} and {\\bf L} proves the polynomial\nsolvability of ${ NP}$-complete problems.Comment: 5 pages", "1409.1467": "Evaluation of Position-related Information in Multipath Components for\n  Indoor Positioning,Leitinger, ErikMeissner, PaulR\u00fcdisser, ChristophDumphart, GregorWitrisal, Klaus,Computer Science - Information Theory,Location awareness is a key factor for a wealth of wireless indoor\napplications. Its provision requires the careful fusion of diverse information\nsources. For agents that use radio signals for localization, this information\nmay either come from signal transmissions with respect to fixed anchors, from\ncooperative transmissions inbetween agents, or from radar-like monostatic\ntransmissions. Using a-priori knowledge of a floor plan of the environment,\nspecular multipath components can be exploited, based on a geometric-stochastic\nchannel model. In this paper, a unified framework is presented for the\nquantification of this type of position-related information, using the concept\nof equivalent Fisher information. We derive analytical results for the\nCram\\'er-Rao lower bound of multipath-assisted positioning, considering\nbistatic transmissions between agents and fixed anchors, monostatic\ntransmissions from agents, cooperative measurements inbetween agents, and\ncombinations thereof, including the effect of clock offsets. Awareness of this\ninformation enables highly accurate and robust indoor positioning.\nComputational results show the applicability of the framework for the\ncharacterization of the localization capabilities of a given environment,\nquantifying the influence of different system setups, signal parameters, and\nthe impact of path overlap.Comment: 14 pages, 10 figures, submitted to the IEEE Journal on Selected Areas\n  in Communications: Localization-Awareness for Radios and Networks", "1409.1714": "A level set based method for fixing overhangs in 3D printing,Cacace, SimoneCristiani, EmilianoRocchi, Leonardo,Mathematics - Numerical AnalysisComputer Science - Graphics65D17, 35F21,3D printers based on the Fused Decomposition Modeling create objects\nlayer-by-layer dropping fused material. As a consequence, strong overhangs\ncannot be printed because the new-come material does not find a suitable\nsupport over the last deposed layer. In these cases, one can add some support\nstructures (scaffolds) which make the object printable, to be removed at the\nend. In this paper we propose a level set method to create object-dependent\nsupport structures, specifically conceived to reduce both the amount of\nadditional material and the printing time. We also review some open problems\nabout 3D printing which can be of interests for the mathematical community.", "1409.2193": "An Epistemic Strategy Logic,Huang, Xiaoweivan der Meyden, Ron,Computer Science - Logic in Computer Science,This paper presents an extension of temporal epistemic logic with operators\nthat quantify over agent strategies. Unlike previous work on alternating\ntemporal epistemic logic, the semantics works with systems whose states\nexplicitly encode the strategy being used by each of the agents. This provides\na natural way to express what agents would know were they to be aware of some\nof the strategies being used by other agents. A number of examples that rely\nupon the ability to express an agent's knowledge about the strategies being\nused by other agents are presented to motivate the framework, including\nreasoning about game theoretic equilibria, knowledge-based programs, and\ninformation theoretic computer security policies. Relationships to several\nvariants of alternating temporal epistemic logic are discussed. The\ncomputational complexity of model checking the logic and several of its\nfragments are also characterized.", "1409.2248": "Secure pseudo-random linear binary sequences generators based on\n  arithmetic polynoms,Finko, OlegDichenko, Sergey,Computer Science - Cryptography and Security94C10, 94A60, 11K45, 11A07,We present a new approach to constructing of pseudo-random binary sequences\n(PRS) generators for the purpose of cryptographic data protection, secured from\nthe perpetrator's attacks, caused by generation of masses of hardware errors\nand faults. The new method is based on use of linear polynomial arithmetic for\nthe realization of systems of boolean characteristic functions of PRS'\ngenerators. \"Arithmetizatio\" of systems of logic formulas has allowed to apply\nmathematical apparatus of residue systems for multisequencing of the process of\nPRS generation and organizing control of computing errors, caused by hardware\nfaults. This has guaranteed high security of PRS generator's functioning and,\nconsequently, security of tools for cryptographic data protection based on\nthose PRSs.", "1409.2612": "A simple proof of the completeness of APAL,Balbiani, Philippevan Ditmarsch, Hans,Computer Science - Logic in Computer Science,We provide a simple proof of the completeness of arbitrary public\nannouncement logic APAL. The proof is an improvement over the proof found in\nthe publication Knowable as Known after an Announcement.", "1409.2908": "A Framework for Practical Parallel Fast Matrix Multiplication,Benson, Austin R.Ballard, Grey,Computer Science - Distributed, Parallel, and Cluster ComputingComputer Science - Mathematical SoftwareComputer Science - Numerical AnalysisG.4,Matrix multiplication is a fundamental computation in many scientific\ndisciplines. In this paper, we show that novel fast matrix multiplication\nalgorithms can significantly outperform vendor implementations of the classical\nalgorithm and Strassen's fast algorithm on modest problem sizes and shapes.\nFurthermore, we show that the best choice of fast algorithm depends not only on\nthe size of the matrices but also the shape. We develop a code generation tool\nto automatically implement multiple sequential and shared-memory parallel\nvariants of each fast algorithm, including our novel parallelization scheme.\nThis allows us to rapidly benchmark over 20 fast algorithms on several problem\nsizes. Furthermore, we discuss a number of practical implementation issues for\nthese algorithms on shared-memory machines that can direct further research on\nmaking fast algorithms practical.", "1409.3176": "Test Case Purification for Improving Fault Localization,Xuan, JifengMonperrus, Martin,Computer Science - Software Engineering,Finding and fixing bugs are time-consuming activities in software\ndevelopment. Spectrum-based fault localization aims to identify the faulty\nposition in source code based on the execution trace of test cases. Failing\ntest cases and their assertions form test oracles for the failing behavior of\nthe system under analysis. In this paper, we propose a novel concept of\nspectrum driven test case purification for improving fault localization. The\ngoal of test case purification is to separate existing test cases into small\nfractions (called purified test cases) and to enhance the test oracles to\nfurther localize faults. Combining with an original fault localization\ntechnique (e.g., Tarantula), test case purification results in better ranking\nthe program statements. Our experiments on 1800 faults in six open-source Java\nprograms show that test case purification can effectively improve existing\nfault localization techniques.", "1409.3562": "Strong converse exponent for classical-quantum channel coding,Mosonyi, MilanOgawa, Tomohiro,Quantum PhysicsComputer Science - Information TheoryMathematical Physics,We determine the exact strong converse exponent of classical-quantum channel\ncoding, for every rate above the Holevo capacity. Our form of the exponent is\nan exact analogue of Arimoto's, given as a transform of the Renyi capacities\nwith parameters alpha>1. It is important to note that, unlike in the classical\ncase, there are many inequivalent ways to define the Renyi divergence of\nstates, and hence the R\\'enyi capacities of channels. Our exponent is in terms\nof the Renyi capacities corresponding to a version of the Renyi divergences\nthat has been introduced recently in [M\\\"uller-Lennert, Dupuis, Szehr, Fehr and\nTomamichel, J. Math. Phys. 54, 122203, (2013)], and [Wilde, Winter, Yang,\nCommun. Math. Phys. 331, (2014)]. Our result adds to the growing body of\nevidence that this new version is the natural definition for the purposes of\nstrong converse problems.Comment: v6: New section on entanglement breaking, and covariant channels. v7:\n  Added Appendix B on the concavity of various versions of the auxiliary\n  function. v8: Updated references", "1409.3600": "Select with Small Groups,Chen, KeDumitrescu, Adrian,Computer Science - Data Structures and AlgorithmsMathematics - Combinatorics,We revisit the selection problem, namely that of computing the $i$th order\nstatistic of $n$ given elements, in particular the classical deterministic\nalgorithm by grouping and partition due to Blum, Floyd, Pratt, Rivest, and\nTarjan (1973). While the original algorithm uses groups of odd size at least\n$5$ and runs in linear time, it has been perpetuated in the literature that\nusing smaller group sizes will force the worst-case running time to become\nsuperlinear, namely $\\Omega(n \\log{n})$. We first point out that the arguments\nexistent in the literature justifying the superlinear worst-case running time\nfall short of proving this claim. We further prove that it is possible to use\ngroup size smaller than $5$ while maintaining the worst case linear running\ntime. To this end we introduce three simple variants of the classical\nalgorithm, the repeated step algorithm, the shifting target algorithm, and the\nhyperpair algorithm, all running in linear time.Comment: 12 pages, 5 figures, 1 table; a new section has been added", "1409.3954": "MIMO-MC Radar: A MIMO Radar Approach Based on Matrix Completion,Sun, ShunqiaoBajwa, Waheed U.Petropulu, Athina P.,Computer Science - Information TheoryStatistics - Applications,In a typical MIMO radar scenario, transmit nodes transmit orthogonal\nwaveforms, while each receive node performs matched filtering with the known\nset of transmit waveforms, and forwards the results to the fusion center. Based\non the data it receives from multiple antennas, the fusion center formulates a\nmatrix, which, in conjunction with standard array processing schemes, such as\nMUSIC, leads to target detection and parameter estimation. In MIMO radars with\ncompressive sensing (MIMO-CS), the data matrix is formulated by each receive\nnode forwarding a small number of compressively obtained samples. In this\npaper, it is shown that under certain conditions, in both sampling cases, the\ndata matrix at the fusion center is low-rank, and thus can be recovered based\non knowledge of a small subset of its entries via matrix completion (MC)\ntechniques. Leveraging the low-rank property of that matrix, we propose a new\nMIMO radar approach, termed, MIMO-MC radar, in which each receive node either\nperforms matched filtering with a small number of randomly selected dictionary\nwaveforms or obtains sub-Nyquist samples of the received signal at random\nsampling instants, and forwards the results to a fusion center. Based on the\nreceived samples, and with knowledge of the sampling scheme, the fusion center\npartially fills the data matrix and subsequently applies MC techniques to\nestimate the full matrix. MIMO-MC radars share the advantages of the recently\nproposed MIMO-CS radars, i.e., high resolution with reduced amounts of data,\nbut unlike MIMO-CS radars do not require grid discretization. The MIMO-MC radar\nconcept is illustrated through a linear uniform array configuration, and its\ntarget estimation performance is demonstrated via simulations.Comment: 29 pages, 13 figures, IEEE Trans. on Aerospace and Electronic Systems", "1409.4575": "Stable Cosparse Recovery via \\ell_p-analysis Optimization,Zhang, ShubaoQian, HuiGong, XiaojinZhou, Jianying,Computer Science - Information Theory,In this paper we study the $\\ell_p$-analysis optimization ($0<p\\leq1$)\nproblem for cosparse signal recovery. We establish a bound for recovery error\nvia the restricted $p$-isometry property over any subspace. We further prove\nthat the nonconvex $\\ell_q$-analysis optimization can do recovery with a lower\nsample complexity and in a wider range of cosparsity than its convex\ncounterpart. In addition, we develop an iteratively reweighted method to solve\nthe optimization problem under a variational framework. Empirical results of\npreliminary computational experiments illustrate that the nonconvex method\noutperforms its convex counterpart.", "1409.4711": "Doing-it-All with Bounded Work and Communication,Chlebus, Bogdan S.G\u0105sieniec, LeszekKowalski, Dariusz R.Schwarzmann, Alexander A.,Computer Science - Distributed, Parallel, and Cluster Computing,We consider the Do-All problem, where $p$ cooperating processors need to\ncomplete $t$ similar and independent tasks in an adversarial setting. Here we\ndeal with a synchronous message passing system with processors that are subject\nto crash failures. Efficiency of algorithms in this setting is measured in\nterms of work complexity (also known as total available processor steps) and\ncommunication complexity (total number of point-to-point messages). When work\nand communication are considered to be comparable resources, then the overall\nefficiency is meaningfully expressed in terms of effort defined as work +\ncommunication. We develop and analyze a constructive algorithm that has work\n$O( t + p \\log p\\, (\\sqrt{p\\log p}+\\sqrt{t\\log t}\\, ) )$ and a nonconstructive\nalgorithm that has work $O(t +p \\log^2 p)$. The latter result is close to the\nlower bound $\\Omega(t + p \\log p/ \\log \\log p)$ on work. The effort of each of\nthese algorithms is proportional to its work when the number of crashes is\nbounded above by $c\\,p$, for some positive constant $c < 1$. We also present a\nnonconstructive algorithm that has effort $O(t + p ^{1.77})$.", "1409.6182": "A Benchmark Suite for Template Detection and Content Extraction,Alarte, Juli\u00e1nInsa, DavidSilva, JosepTamarit, Salvador,Computer Science - Information Retrieval,Template detection and content extraction are two of the main areas of\ninformation retrieval applied to the Web. They perform different analyses over\nthe structure and content of webpages to extract some part of the document.\nHowever, their objective is different. While template detection identifies the\ntemplate of a webpage (usually comparing with other webpages of the same\nwebsite), content extraction identifies the main content of the webpage\ndiscarding the other part. Therefore, they are somehow complementary, because\nthe main content is not part of the template. It has been measured that\ntemplates represent between 40% and 50% of data on the Web. Therefore,\nidentifying templates is essential for indexing tasks because templates usually\ncontain irrelevant information such as advertisements, menus and banners.\nProcessing and storing this information is likely to lead to a waste of\nresources (storage space, bandwidth, etc.). Similarly, identifying the main\ncontent is essential for many information retrieval tasks. In this paper, we\npresent a benchmark suite to test different approaches for template detection\nand content extraction. The suite is public, and it contains real heterogeneous\nwebpages that have been labelled so that different techniques can be suitable\n(and automatically) compared.Comment: 13 pages, 3 tables", "1409.6193": "Estimating topological properties of weighted networks from limited\n  information,Cimini, GiulioSquartini, TizianoGabrielli, AndreaGarlaschelli, Diego,Physics - Physics and SocietyCondensed Matter - Statistical MechanicsComputer Science - Social and Information NetworksQuantitative Finance - Statistical Finance,A fundamental problem in studying and modeling economic and financial systems\nis represented by privacy issues, which put severe limitations on the amount of\naccessible information. Here we introduce a novel, highly nontrivial method to\nreconstruct the structural properties of complex weighted networks of this kind\nusing only partial information: the total number of nodes and links, and the\nvalues of the strength for all nodes. The latter are used as fitness to\nestimate the unknown node degrees through a standard configuration model. Then,\nthese estimated degrees and the strengths are used to calibrate an enhanced\nconfiguration model in order to generate ensembles of networks intended to\nrepresent the real system. The method, which is tested on real economic and\nfinancial networks, while drastically reducing the amount of information needed\nto infer network properties, turns out to be remarkably effective$-$thus\nrepresenting a valuable tool for gaining insights on privacy-protected\nsocioeconomic systems.", "1409.6777": "Impossibility of Classically Simulating One-Clean-Qubit Computation,Fujii, KeisukeKobayashi, HirotadaMorimae, TomoyukiNishimura, HarumichiTamate, ShuheiTani, Seiichiro,Quantum PhysicsComputer Science - Computational Complexity,Deterministic quantum computation with one quantum bit (DQC1) is a restricted\nmodel of quantum computing where the input state is the completely mixed state\nexcept for a single clean qubit, and only a single output qubit is measured at\nthe end of the computing. It is proved that the restriction of quantum\ncomputation to the DQC1 model does not change the complexity classes NQP and\nSBQP. As a main consequence, it follows that the DQC1 model cannot be\nefficiently simulated by classical computers unless the polynomial-time\nhierarchy collapses to the second level (more precisely, to AM), which answers\nthe long-standing open problem posed by Knill and Laflamme under the very\nplausible complexity assumption. The argument developed in this paper also\nweakens the complexity assumption necessary for the existing impossibility\nresults on classical simulation of various sub-universal quantum computing\nmodels, such as the IQP model and the Boson sampling.Comment: 13 pages, 1 figure. New results and new authors have been added.\n  (DQC1_2 is improved to DQC1_1, and collapse of PH is improved from 3rd to 2nd\n  level.) Title is also changed", "1409.7579": "Field evidence of social influence in the expression of political\n  preferences: the case of secessionist flags in Barcelona,Parravano, AntonioNoguera, Jos\u00e9 A.Tena, JordiHermida, Paula,Physics - Physics and SocietyComputer Science - Social and Information Networks,Different models of social influence have explored the dynamics of social\ncontagion, imitation, and diffusion of different types of traits, opinions, and\nconducts. However, few behavioral data indicating social influence dynamics\nhave been obtained from direct observation in `natural' social contexts. The\npresent research provides that kind of evidence in the case of the public\nexpression of political preferences in the city of Barcelona, where thousands\nof citizens supporting the secession of Catalonia from Spain have placed a\nCatalan flag in their balconies. We present two different studies. 1) In July\n2013 we registered the number of flags in 26% of the the city. We find that\nthere is a large dispersion in the density of flags in districts with similar\ndensity of pro-independence voters. However, we find that the density of flags\ntends to be fostered in those electoral district where there is a clear\nmajority of pro-independence vote, while it is inhibited in the opposite cases.\n2) During 17 days around Catalonia's 2013 National Holiday we observed the\nposition at balcony resolution of the flags displayed in the facades of 82\nblocks. We compare the clustering of flags on the facades observed each day to\nequivalent random distributions and find that successive hangings of flags are\nnot independent events but that a local influence mechanism is favoring their\nclustering. We also find that except for the National Holiday day the density\nof flags tends to be fostered in those facades where there is a clear majority\nof pro-independence vote.Comment: 27 pages, 13 figures, 2 tables", "1409.8061": "A New DoF Upper Bound and Its Achievability for $K$-User MIMO Y Channels,Liu, KangqiTao, Meixia,Computer Science - Information Theory,This work is to study the degrees of freedom (DoF) for the $K$-user MIMO Y\nchannel. Previously, two transmission frameworks have been proposed for the DoF\nanalysis when $N \\geq 2M$, where $M$ and $N$ denote the number of antennas at\neach source node and the relay node respectively. The first method is named as\nsignal group based alignment proposed by Hua et al. in [1]. The second is named\nas signal pattern approach introduced by Wang et al. in [2]. But both of them\nonly studied certain antenna configurations. The maximum achievable DoF in the\ngeneral case still remains unknown. In this work, we first derive a new upper\nbound of the DoF using the genie-aided approach. Then, we propose a more\ngeneral transmission framework, generalized signal alignment (GSA), and show\nthat the previous two methods are both special cases of GSA. With GSA, we prove\nthat the new DoF upper bound is achievable when $\\frac{N}{M} \\in\n\\left(0,2+\\frac{4}{K(K-1)}\\right] \\cup \\left[K-2, +\\infty\\right)$. The DoF\nanalysis in this paper provides a major step forward towards the fundamental\ncapacity limit of the $K$-user MIMO Y channel. It also offers a new approach of\nintegrating interference alignment with physical layer network coding.Comment: 6 pages, 3 figures, submitted to IEEE ICC 2015. arXiv admin note:\n  text overlap with arXiv:1405.0718", "1409.8230": "RENOIR - A Dataset for Real Low-Light Image Noise Reduction,Anaya, JosueBarbu, Adrian,Computer Science - Computer Vision and Pattern Recognition,Image denoising algorithms are evaluated using images corrupted by artificial\nnoise, which may lead to incorrect conclusions about their performances on real\nnoise. In this paper we introduce a dataset of color images corrupted by\nnatural noise due to low-light conditions, together with spatially and\nintensity-aligned low noise images of the same scenes. We also introduce a\nmethod for estimating the true noise level in our images, since even the low\nnoise images contain small amounts of noise. We evaluate the accuracy of our\nnoise estimation method on real and artificial noise, and investigate the\nPoisson-Gaussian noise model. Finally, we use our dataset to evaluate six\ndenoising algorithms: Active Random Field, BM3D, Bilevel-MRF, Multi-Layer\nPerceptron, and two versions of NL-means. We show that while the Multi-Layer\nPerceptron, Bilevel-MRF, and NL-means with soft threshold outperform BM3D on\ngray images with synthetic noise, they lag behind on our dataset.Comment: 27 pages, 11 figures", "1409.8498": "Non-myopic learning in repeated stochastic games,Crandall, Jacob W.,Computer Science - Computer Science and Game TheoryComputer Science - Artificial IntelligenceComputer Science - Machine Learning,In repeated stochastic games (RSGs), an agent must quickly adapt to the\nbehavior of previously unknown associates, who may themselves be learning. This\nmachine-learning problem is particularly challenging due, in part, to the\npresence of multiple (even infinite) equilibria and inherently large strategy\nspaces. In this paper, we introduce a method to reduce the strategy space of\ntwo-player general-sum RSGs to a handful of expert strategies. This process,\ncalled Mega, effectually reduces an RSG to a bandit problem. We show that the\nresulting strategy space preserves several important properties of the original\nRSG, thus enabling a learner to produce robust strategies within a reasonably\nsmall number of interactions. To better establish strengths and weaknesses of\nthis approach, we empirically evaluate the resulting learning system against\nother algorithms in three different RSGs.", "1409.8580": "Interference Functionals in Poisson Networks,Schilcher, UdoToumpis, StavrosHaenggi, MartinCrismani, AlessandroBrandner, G\u00fcntherBettstetter, Christian,Computer Science - Information Theory,We propose and prove a theorem that allows the calculation of a class of\nfunctionals on Poisson point processes that have the form of expected values of\nsum-products of functions. In proving the theorem, we present a variant of the\nCampbell-Mecke theorem from stochastic geometry. We proceed to apply our result\nin the calculation of expected values involving interference in wireless\nPoisson networks. Based on this, we derive outage probabilities for\ntransmissions in a Poisson network with Nakagami fading. Our results extend the\nstochastic geometry toolbox used for the mathematical analysis of\ninterference-limited wireless networks.", "1410.0446": "Identification of Dynamic functional brain network states Through Tensor\n  Decomposition,Mahyari, Arash GolibaghAviyente, Selin,Computer Science - Neural and Evolutionary ComputingComputer Science - Machine LearningQuantitative Biology - Neurons and Cognition,With the advances in high resolution neuroimaging, there has been a growing\ninterest in the detection of functional brain connectivity. Complex network\ntheory has been proposed as an attractive mathematical representation of\nfunctional brain networks. However, most of the current studies of functional\nbrain networks have focused on the computation of graph theoretic indices for\nstatic networks, i.e. long-time averages of connectivity networks. It is\nwell-known that functional connectivity is a dynamic process and the\nconstruction and reorganization of the networks is key to understanding human\ncognition. Therefore, there is a growing need to track dynamic functional brain\nnetworks and identify time intervals over which the network is\nquasi-stationary. In this paper, we present a tensor decomposition based method\nto identify temporally invariant 'network states' and find a common topographic\nrepresentation for each state. The proposed methods are applied to\nelectroencephalogram (EEG) data during the study of error-related negativity\n(ERN).Comment: 2014 IEEE International Conference on Acoustics, Speech and Signal\n  Processing (ICASSP)", "1410.0736": "HD-CNN: Hierarchical Deep Convolutional Neural Network for Large Scale\n  Visual Recognition,Yan, ZhichengZhang, HaoPiramuthu, RobinsonJagadeesh, VigneshDeCoste, DennisDi, WeiYu, Yizhou,Computer Science - Computer Vision and Pattern RecognitionComputer Science - Artificial IntelligenceComputer Science - Machine LearningComputer Science - Neural and Evolutionary ComputingStatistics - Machine Learning,In image classification, visual separability between different object\ncategories is highly uneven, and some categories are more difficult to\ndistinguish than others. Such difficult categories demand more dedicated\nclassifiers. However, existing deep convolutional neural networks (CNN) are\ntrained as flat N-way classifiers, and few efforts have been made to leverage\nthe hierarchical structure of categories. In this paper, we introduce\nhierarchical deep CNNs (HD-CNNs) by embedding deep CNNs into a category\nhierarchy. An HD-CNN separates easy classes using a coarse category classifier\nwhile distinguishing difficult classes using fine category classifiers. During\nHD-CNN training, component-wise pretraining is followed by global finetuning\nwith a multinomial logistic loss regularized by a coarse category consistency\nterm. In addition, conditional executions of fine category classifiers and\nlayer parameter compression make HD-CNNs scalable for large-scale visual\nrecognition. We achieve state-of-the-art results on both CIFAR100 and\nlarge-scale ImageNet 1000-class benchmark datasets. In our experiments, we\nbuild up three different HD-CNNs and they lower the top-1 error of the standard\nCNNs by 2.65%, 3.1% and 1.1%, respectively.Comment: Add new results on ImageNet using VGG-16-layer building block net", "1410.2670": "Entropy NAND: Early Functional Completeness in Entropy Networks,Jesse, Forrest Fabian,Computer Science - Information Theory37A35, 81P15F.1.1F.1.2,An observer increases in relative entropy as it receives information from\nwhat it is observing. In a system of only an observer and the observed, an\nincrease in the relative entropy of the observer is a decrease in the relative\nentropy of the observed. Linking together these directional entropy\ndisequilibriums we show that NAND and NOR functionality arise in such networks\nat very low levels of complexity.Comment: 12 pages, 3 figures", "1410.2752": "Spatial Straight Line Linkages by Factorization of Motion Polynomials,Li, ZijiaSchicho, JosefSchr\u00f6cker, Hans-Peter,Mathematics - Metric GeometryComputer Science - RoboticsMathematics - Rings and Algebras70B10,We use the recently introduced factorization of motion polynomials for\nconstructing overconstrained spatial linkages with a straight line trajectory.\nUnlike previous examples, the end-effector motion is not translational and the\nlink graph is a cycle. In particular, we obtain a number of linkages with four\nrevolute and two prismatic joints and a remarkable linkage with seven revolute\njoints one of whose joints performs a Darboux motion.Comment: Corrected author name", "1410.3247": "An easy subexponential bound for online chain partitioning,Bosek, Bart\u0142omiejKierstead, Hal A.Krawczyk, TomaszMatecki, GrzegorzSmith, Matthew E.,Computer Science - Data Structures and AlgorithmsMathematics - Combinatorics68W27,Bosek and Krawczyk exhibited an online algorithm for partitioning an online\nposet of width $w$ into $w^{14\\lg w}$ chains. We improve this to $w^{6.5 \\lg w\n+ 7}$ with a simpler and shorter proof by combining the work of Bosek &\nKrawczyk with work of Kierstead & Smith on First-Fit chain partitioning of\nladder-free posets. We also provide examples illustrating the limits of our\napproach.Comment: 23 pages, 11 figures", "1410.3351": "Ricci Curvature and the Manifold Learning Problem,Ache, Antonio G.Warren, Micah W.,Mathematics - Differential GeometryComputer Science - Machine LearningMathematics - Metric GeometryStatistics - Machine Learning68T05, 58J35,Consider a sample of $n$ points taken i.i.d from a submanifold $\\Sigma$ of\nEuclidean space. We show that there is a way to estimate the Ricci curvature of\n$\\Sigma$ with respect to the induced metric from the sample. Our method is\ngrounded in the notions of Carr\\'e du Champ for diffusion semi-groups, the\ntheory of Empirical processes and local Principal Component Analysis.Comment: 47 pages", "1410.3764": "A lazy approach to on-line bipartite matching,Kozik, JakubMatecki, Grzegorz,Computer Science - Data Structures and AlgorithmsComputer Science - Discrete Mathematics,We present a new approach, called a lazy matching, to the problem of on-line\nmatching on bipartite graphs. Imagine that one side of a graph is given and the\nvertices of the other side are arriving on-line. Originally, incoming vertex is\neither irrevocably matched to an another element or stays forever unmatched. A\nlazy algorithm is allowed to match a new vertex to a group of elements\n(possibly empty) and afterwords, forced against next vertices, may give up\nparts of the group. The restriction is that all the time each element is in at\nmost one group. We present an optimal lazy algorithm (deterministic) and prove\nthat its competitive ratio equals $1-\\pi/\\cosh(\\frac{\\sqrt{3}}{2}\\pi)\\approx\n0.588$. The lazy approach allows us to break the barrier of $1/2$, which is the\nbest competitive ratio that can be guaranteed by any deterministic algorithm in\nthe classical on-line matching.", "1410.3877": "Selection-based Approach to Cooperative Interval Games,Bok, JanHlad\u00edk, Milan,Mathematics - Optimization and ControlComputer Science - Computer Science and Game Theory65G99, 91A12,Cooperative interval games are a generalized model of cooperative games in\nwhich the worth of every coalition corresponds to a closed interval\nrepresenting the possible outcomes of its cooperation. Selections are all\npossible outcomes of the interval game with no additional uncertainty.\n  We introduce new selection-based classes of interval games and prove their\ncharacterization theorems and relations to existing classes based on the\ninterval weakly better operator. We show new results regarding the core and\nimputations and examine a problem of equivalence for two different versions of\nthe core, the main stability solution of cooperative games. Finally, we\nintroduce the definition of strong imputation and strong core as universal\nsolution concepts of interval games.Comment: slightly more appropriate wording about the results of Section 4", "1410.4060": "Decoupling Multivariate Polynomials Using First-Order Information,Dreesen, PhilippeIshteva, MariyaSchoukens, Johan,Mathematics - Numerical AnalysisComputer Science - Numerical Analysis,We present a method to decompose a set of multivariate real polynomials into\nlinear combinations of univariate polynomials in linear forms of the input\nvariables. The method proceeds by collecting the first-order information of the\npolynomials in a set of operating points, which is captured by the Jacobian\nmatrix evaluated at the operating points. The polyadic canonical decomposition\nof the three-way tensor of Jacobian matrices directly returns the unknown\nlinear relations, as well as the necessary information to reconstruct the\nunivariate polynomials. The conditions under which this decoupling procedure\nworks are discussed, and the method is illustrated on several numerical\nexamples.", "1410.4536": "Numerical Optimization for Symmetric Tensor Decomposition,Kolda, Tamara G.,Mathematics - Numerical AnalysisComputer Science - Numerical Analysis,We consider the problem of decomposing a real-valued symmetric tensor as the\nsum of outer products of real-valued vectors. Algebraic methods exist for\ncomputing complex-valued decompositions of symmetric tensors, but here we focus\non real-valued decompositions, both unconstrained and nonnegative, for problems\nwith low-rank structure. We discuss when solutions exist and how to formulate\nthe mathematical program. Numerical results show the properties of the proposed\nformulations (including one that ignores symmetry) on a set of test problems\nand illustrate that these straightforward formulations can be effective even\nthough the problem is nonconvex.", "1410.4617": "A Cut Principle for Information Flow,Guttman, Joshua D.Rowe, Paul D.,Computer Science - Cryptography and Security,We view a distributed system as a graph of active locations with\nunidirectional channels between them, through which they pass messages. In this\ncontext, the graph structure of a system constrains the propagation of\ninformation through it.\n  Suppose a set of channels is a cut set between an information source and a\npotential sink. We prove that, if there is no disclosure from the source to the\ncut set, then there can be no disclosure to the sink. We introduce a new\nformalization of partial disclosure, called *blur operators*, and show that the\nsame cut property is preserved for disclosure to within a blur operator. This\ncut-blur property also implies a compositional principle, which ensures limited\ndisclosure for a class of systems that differ only beyond the cut.Comment: 31 pages", "1410.5131": "An Algebra of Reversible Computation,Wang, Yong,Computer Science - Logic in Computer Science,Process algebra ACP based on the interleaving semantics can not be reversed.\nWe design a reversible version of APTC called RAPTC. It has algebraic laws of\nreversible choice, sequence, parallelism, communication, silent step and\nabstraction, and also the soundness and completeness modulo strongly\nforward-reverse truly concurrent bisimulations and weakly forward-reverse truly\nconcurrent bisimulations.Comment: 74 pages", "1410.5920": "Active Regression by Stratification,Sabato, SivanMunos, Remi,Statistics - Machine LearningComputer Science - Machine Learning,We propose a new active learning algorithm for parametric linear regression\nwith random design. We provide finite sample convergence guarantees for general\ndistributions in the misspecified model. This is the first active learner for\nthis setting that provably can improve over passive learning. Unlike other\nlearning settings (such as classification), in regression the passive learning\nrate of $O(1/\\epsilon)$ cannot in general be improved upon. Nonetheless, the\nso-called `constant' in the rate of convergence, which is characterized by a\ndistribution-dependent risk, can be improved in many cases. For a given\ndistribution, achieving the optimal risk requires prior knowledge of the\ndistribution. Following the stratification technique advocated in Monte-Carlo\nfunction integration, our active learner approaches the optimal risk using\npiecewise constant approximations.", "1410.6516": "Coalition Structure Generation on Graphs,Rahwan, TalalMichalak, Tomasz P.,Computer Science - Multiagent Systems,Two fundamental algorithm-design paradigms are Tree Search and Dynamic\nProgramming. The techniques used therein have been shown to complement one\nanother when solving the complete set partitioning problem, also known as the\ncoalition structure generation problem [5]. Inspired by this observation, we\ndevelop in this paper an algorithm to solve the coalition structure generation\nproblem on graphs, where the goal is to identifying an optimal partition of a\ngraph into connected subgraphs. More specifically, we develop a new depth-first\nsearch algorithm, and combine it with an existing dynamic programming algorithm\ndue to Vinyals et al. [9]. The resulting hybrid algorithm is empirically shown\nto significantly outperform both its constituent parts when the\nsubset-evaluation function happens to have certain intuitive properties.", "1410.7082": "Complexity of LP in Terms of the Face Lattice,Maksimenko, Aleksandr,Computer Science - Computational ComplexityMathematics - Combinatorics,Let $X$ be a finite set in $Z^d$. We consider the problem of optimizing\nlinear function $f(x) = c^T x$ on $X$, where $c\\in Z^d$ is an input vector. We\ncall it a problem $X$. A problem $X$ is related with linear program\n$\\max\\limits_{x \\in P} f(x)$, where polytope $P$ is a convex hull of $X$. The\nkey parameters for evaluating the complexity of a problem $X$ are the dimension\n$d$, the cardinality $|X|$, and the encoding size $S(X) = \\log_2\n\\left(\\max\\limits_{x\\in X} \\|x\\|_{\\infty}\\right)$. We show that if the (time\nand space) complexity of some algorithm $A$ for solving a problem $X$ is\ndefined only in terms of combinatorial structure of $P$ and the size $S(X)$,\nthen for every $d$ and $n$ there exists polynomially (in $d$, $\\log n$, and\n$S$) solvable problem $Y$ with $\\dim Y = d$, $|Y| = n$, such that the algorithm\n$A$ requires exponential time or space for solving $Y$.Comment: 11 pages", "1410.7694": "Dynamic Analysis of Digital Chaotic Maps via State-Mapping Networks,Li, ChengqingFeng, BingbingLi, ShujunKurths, JuergenChen, Guanrong,Computer Science - Cryptography and SecurityNonlinear Sciences - Chaotic Dynamics37D45, 05C82,Chaotic dynamics is widely used to design pseudo-random number generators and\nfor other applications such as secure communications and encryption. This paper\naims to study the dynamics of discrete-time chaotic maps in the digital (i.e.,\nfinite-precision) domain. Differing from the traditional approaches treating a\ndigital chaotic map as a black box with different explanations according to the\ntest results of the output, the dynamical properties of such chaotic maps are\nfirst explored with a fixed-point arithmetic, using the Logistic map and the\nTent map as two representative examples, from a new perspective with the\ncorresponding state-mapping networks (SMNs). In an SMN, every possible value in\nthe digital domain is considered as a node and the mapping relationship between\nany pair of nodes is a directed edge. The scale-free properties of the Logistic\nmap's SMN are proved. The analytic results are further extended to the scenario\nof floating-point arithmetic and for other chaotic maps. Understanding the\nnetwork structure of a chaotic map's SMN in digital computers can facilitate\ncounteracting the undesirable degeneration of chaotic dynamics in\nfinite-precision domains, helping also classify and improve the randomness of\npseudo-random number sequences generated by iterating chaotic maps.Comment: 14 pages, 20 figures", "1410.8663": "On the Inequalities of Projected Volumes and the Constructible Region,Tan, ZihanZeng, Liwei,Computer Science - Discrete Mathematics,We study the following geometry problem: given a $2^n-1$ dimensional vector\n$\\pi=\\{\\pi_S\\}_{S\\subseteq [n], S\\ne \\emptyset}$, is there an object\n$T\\subseteq\\mathbb{R}^n$ such that $\\log(\\mathsf{vol}(T_S))= \\pi_S$, for all\n$S\\subseteq [n]$, where $T_S$ is the projection of $T$ to the subspace spanned\nby the axes in $S$? If $\\pi$ does correspond to an object in $\\mathbb{R}^n$, we\nsay that $\\pi$ is {\\em constructible}. We use $\\Psi_n$ to denote the\nconstructible region, i.e., the set of all constructible vectors in\n$\\mathbb{R}^{2^n-1}$. In 1995, Bollob\\'{a}s and Thomason showed that $\\Psi_n$\nis contained in a polyhedral cone, defined a class of so called uniform cover\ninequalities. We propose a new set of natural inequalities, called\nnonuniform-cover inequalities, which generalize the BT inequalities. We show\nthat any linear inequality that all points in $\\Psi_n$ satisfy must be a\nnonuniform-cover inequality. Based on this result and an example by\nBollob\\'{a}s and Thomason, we show that constructible region $\\Psi_n$ is not\neven convex, and thus cannot be fully characterized by linear inequalities. We\nfurther show that some subclasses of the nonuniform-cover inequalities are not\ncorrect by various combinatorial constructions, which refutes a previous\nconjecture about $\\Psi_n$. Finally, we conclude with an interesting conjecture\nregarding the convex hull of $\\Psi_n$.", "1411.0187": "Construction of Capacity-Achieving Lattice Codes: Polar Lattices,Liu, LingYan, YanfeiLing, CongWu, Xiaofu,Computer Science - Information Theory,In this paper, we propose a new class of lattices constructed from polar\ncodes, namely polar lattices, to achieve the capacity $\\frac{1}{2}\\log(1+\\SNR)$\nof the additive white Gaussian-noise (AWGN) channel. Our construction follows\nthe multilevel approach of Forney \\textit{et al.}, where we construct a\ncapacity-achieving polar code on each level. The component polar codes are\nshown to be naturally nested, thereby fulfilling the requirement of the\nmultilevel lattice construction. We prove that polar lattices are\n\\emph{AWGN-good}. Furthermore, using the technique of source polarization, we\npropose discrete Gaussian shaping over the polar lattice to satisfy the power\nconstraint. Both the construction and shaping are explicit, and the overall\ncomplexity of encoding and decoding is $O(N\\log N)$ for any fixed target error\nprobability.Comment: full version of the paper to appear in IEEE Trans. Communications", "1411.0440": "Modelling serendipity in a computational context,Corneli, JosephJordanous, AnnaGuckelsberger, ChristianPease, AlisonColton, Simon,Computer Science - Artificial IntelligenceI.2.11D.2.2,We understand the term serendipity to describe a creative process that\ndevelops, in context, with the active participation of a creative agent, but\nnot entirely within that agent's control. While a system cannot be made to\nperform serendipitously on demand, nevertheless, we argue that its\n\\emph{serendipity potential} can be increased by means of a suitable system\narchitecture and other design choices. We distil a unified description of\nserendipitous occurrences from historical theorisations of serendipity and\ncreativity. This takes the form of a framework with six phases:\n\\emph{perception}, \\emph{attention}, \\emph{interest}, \\emph{explanation},\n\\emph{bridge}, and \\emph{valuation}. We then use this framework to organise a\nsurvey of literature in cognitive science, philosophy, and computing, which\nyields practical definitions of the six phases, along with heuristics for\nimplementation. We use the resulting model to evaluate the serendipity\npotential of four existing systems developed by others, and two systems\npreviously developed by two of us. Whereas most existing research that\nconsiders serendipity in a computing context deals with serendipity as a\nservice, we relate theories of serendipity to artificial intelligence practice\nand the development of autonomous systems. We outline representative directions\nfor future applications of our model in the domains of automated programming,\nrecommender systems, and computational creativity. We conclude that it is\nfeasible to equip computational systems with the potential for serendipity, and\nthat this could be beneficial in varied artificial intelligence applications,\nparticularly those designed to operate responsively in real-world contexts.Comment: 55pp, working version to be submitted end 2018/early 2019", "1411.0998": "Jointly Private Convex Programming,Hsu, JustinHuang, ZhiyiRoth, AaronWu, Zhiwei Steven,Computer Science - Data Structures and AlgorithmsComputer Science - Computer Science and Game Theory,In this paper we present an extremely general method for approximately\nsolving a large family of convex programs where the solution can be divided\nbetween different agents, subject to joint differential privacy. This class\nincludes multi-commodity flow problems, general allocation problems, and\nmulti-dimensional knapsack problems, among other examples. The accuracy of our\nalgorithm depends on the \\emph{number} of constraints that bind between\nindividuals, but crucially, is \\emph{nearly independent} of the number of\nprimal variables and hence the number of agents who make up the problem. As the\nnumber of agents in a problem grows, the error we introduce often becomes\nnegligible.\n  We also consider the setting where agents are strategic and have preferences\nover their part of the solution. For any convex program in this class that\nmaximizes \\emph{social welfare}, there is a generic reduction that makes the\ncorresponding optimization \\emph{approximately dominant strategy truthful} by\ncharging agents prices for resources as a function of the approximately optimal\ndual variables, which are themselves computed under differential privacy. Our\nresults substantially expand the class of problems that are known to be\nsolvable under both privacy and incentive constraints.", "1411.1124": "Nearly Linear-Time Packing and Covering LP Solvers,Allen-Zhu, ZeyuanOrecchia, Lorenzo,Computer Science - Data Structures and AlgorithmsComputer Science - Numerical AnalysisMathematics - Numerical AnalysisMathematics - Optimization and Control,Packing and covering linear programs (PC-LPs) form an important class of\nlinear programs (LPs) across computer science, operations research, and\noptimization. In 1993, Luby and Nisan constructed an iterative algorithm for\napproximately solving PC-LPs in nearly linear time, where the time complexity\nscales nearly linearly in $N$, the number of nonzero entries of the matrix, and\npolynomially in $\\varepsilon$, the (multiplicative) approximation error.\nUnfortunately, all existing nearly linear-time algorithms for solving PC-LPs\nrequire time at least proportional to $\\varepsilon^{-2}$.\n  In this paper, we break this longstanding barrier by designing a packing\nsolver that runs in time $\\tilde{O}(N \\varepsilon^{-1})$ and covering LP solver\nthat runs in time $\\tilde{O}(N \\varepsilon^{-1.5})$. Our packing solver can be\nextended to run in time $\\tilde{O}(N \\varepsilon^{-1})$ for a class of\nwell-behaved covering programs. In a follow-up work, Wang et al. showed that\nall covering LPs can be converted into well-behaved ones by a reduction that\nblows up the problem size only logarithmically.\n  At high level, these two algorithms can be described as linear couplings of\nseveral first-order descent steps. This is an application of our linear\ncoupling technique to problems that are not amenable to blackbox applications\nknown iterative algorithms in convex optimization.Comment: journal version (to appear in Mathematical Programming)", "1411.1420": "Eigenvectors of Orthogonally Decomposable Functions,Belkin, MikhailRademacher, LuisVoss, James,Computer Science - Machine Learning,The Eigendecomposition of quadratic forms (symmetric matrices) guaranteed by\nthe spectral theorem is a foundational result in applied mathematics. Motivated\nby a shared structure found in inferential problems of recent interest---namely\northogonal tensor decompositions, Independent Component Analysis (ICA), topic\nmodels, spectral clustering, and Gaussian mixture learning---we generalize the\neigendecomposition from quadratic forms to a broad class of \"orthogonally\ndecomposable\" functions. We identify a key role of convexity in our extension,\nand we generalize two traditional characterizations of eigenvectors: First, the\neigenvectors of a quadratic form arise from the optima structure of the\nquadratic form on the sphere. Second, the eigenvectors are the fixed points of\nthe power iteration.\n  In our setting, we consider a simple first order generalization of the power\nmethod which we call gradient iteration. It leads to efficient and easily\nimplementable methods for basis recovery. It includes influential Machine\nLearning methods such as cumulant-based FastICA and the tensor power iteration\nfor orthogonally decomposable tensors as special cases.\n  We provide a complete theoretical analysis of gradient iteration using the\nstructure theory of discrete dynamical systems to show almost sure convergence\nand fast (super-linear) convergence rates. The analysis also extends to the\ncase when the observed function is only approximately orthogonally\ndecomposable, with bounds that are polynomial in dimension and other relevant\nparameters, such as perturbation size. Our perturbation results can be\nconsidered as a non-linear version of the classical Davis-Kahan theorem for\nperturbations of eigenvectors of symmetric matrices.Comment: 69 pages", "1411.1751": "Playing the Wrong Game: Bounding Externalities in Diverse Populations of\n  Agents,Meir, ReshefParkes, David,Computer Science - Computer Science and Game TheoryComputer Science - Multiagent Systems,The robustness of multiagent systems can be affected by mistakes or\nbehavioral biases (e.g., risk-aversion, altruism, toll-sensitivity), with some\nagents playing the \"wrong game.\" This can change the set of equilibria, and may\nin turn harm or improve the social welfare of agents in the system. We are\ninterested in bounding what we call the biased price of anarchy (BPoA) in\npopulations with diverse agent behaviors, which is the ratio between welfare in\nthe \"wrong\" equilibrium and optimal welfare.\n  We study nonatomic routing games, and derive an externality bound that\ndepends on a key topological parameter of the underlying network.\n  We then prove two general BPoA bounds for games with diverse populations: one\nthat relies on the network structure and the average bias of all agents in the\npopulation, and one that is independent of the structure but depends on the\nmaximal bias. Both types of bounds can be combined with known results to derive\nconcrete BPoA bounds for a variety of specific behaviors (e.g., varied levels\nof risk-aversion).Comment: full version of a paper accepted to AAMAS 2018", "1411.2419": "Beta-expansions of rational numbers in quadratic Pisot bases,Hejda, Tom\u00e1\u0161Steiner, Wolfgang,Mathematics - Dynamical SystemsComputer Science - Discrete MathematicsMathematics - CombinatoricsMathematics - Number Theory11A63 (11R06 37B10),We study rational numbers with purely periodic R\\'enyi $\\beta$-expansions.\nFor bases $\\beta$ satisfying $\\beta^2=a\\beta+b$ with $b$ dividing $a$, we give\na necessary and sufficient condition for $\\gamma(\\beta)=1$, i.e., that all\nrational numbers $p/q\\in[0,1)$ with $\\gcd(q,b)=1$ have a purely periodic\n$\\beta$-expansion. A simple algorithm for determining the value of\n$\\gamma(\\beta)$ for all quadratic Pisot numbers $\\beta$ is described.Comment: 12 pages, 3 figures, 2 tables", "1411.3010": "Computational Complexity of Functions,Levin, Leonid A.,Computer Science - Computational Complexity,Below is a translation from my Russian paper. I added references, unavailable\nto me in Moscow. Similar results have been also given in [Schnorr Stumpf 75]\n(see also [Lynch 75]). Earlier relevant work (classical theorems like\nCompression, Speed-up, etc.) was done in [Tseitin 56, Rabin 59, Hartmanis\nStearns 65, Blum 67, Trakhtenbrot 67, Meyer Fischer 72].\n  I translated only the part with the statement of the results. Instead of the\nproof part I appended a later (1979, unpublished) proof sketch of a slightly\ntighter version. The improvement is based on the results of [Meyer Winklmann\n78, Sipser 78]. Meyer and Winklmann extended earlier versions to machines with\na separate input and working tape, thus allowing complexities smaller than the\ninput length (down to its log). Sipser showed the space-bounded Halting Problem\nto require only additive constant overhead. The proof in the appendix below\nemploys both advances to extend the original proofs to machines with a fixed\nalphabet and a separate input and working space. The extension has no (even\nlogarithmic) restrictions on complexity and no overhead (beyond an additive\nconstant). The sketch is very brief and a more detailed exposition is expected\nlater: [Seiferas Meyer].Comment: Partial translation from [Levin 74]; preliminary version is in [Levin\n  73]", "1411.3140": "Social media fingerprints of unemployment,Llorente, AlejandroGarcia-Herranz, ManuelCebrian, ManuelMoro, Esteban,Physics - Physics and SocietyComputer Science - Social and Information NetworksPhysics - Data Analysis, Statistics and Probability,Recent wide-spread adoption of electronic and pervasive technologies has\nenabled the study of human behavior at an unprecedented level, uncovering\nuniversal patterns underlying human activity, mobility, and inter-personal\ncommunication. In the present work, we investigate whether deviations from\nthese universal patterns may reveal information about the socio-economical\nstatus of geographical regions. We quantify the extent to which deviations in\ndiurnal rhythm, mobility patterns, and communication styles across regions\nrelate to their unemployment incidence. For this we examine a country-scale\npublicly articulated social media dataset, where we quantify individual\nbehavioral features from over 145 million geo-located messages distributed\namong more than 340 different Spanish economic regions, inferred by computing\ncommunities of cohesive mobility fluxes. We find that regions exhibiting more\ndiverse mobility fluxes, earlier diurnal rhythms, and more correct grammatical\nstyles display lower unemployment rates. As a result, we provide a simple model\nable to produce accurate, easily interpretable reconstruction of regional\nunemployment incidence from their social-media digital fingerprints alone. Our\nresults show that cost-effective economical indicators can be built based on\npublicly-available social media datasets.Comment: 19 pages (8 main article, 11 Supplementary Information)", "1411.3444": "Growing Scale-free Networks by a Mediation-Driven Attachment Rule,Hassan, KamrulIslam, Liana,Physics - Physics and SocietyCondensed Matter - Statistical MechanicsComputer Science - Social and Information Networks,We propose a model that generates a new class of networks exhibiting\npower-law degree distribution with a spectrum of exponents depending on the\nnumber of links ($m$) with which incoming nodes join the existing network.\nUnlike the Barab\\'{a}si-Albert (BA) model, each new node first picks an\nexisting node at random, and connects not with this but with $m$ of its\nneighbors also picked at random. Counterintuitively enough, such a\nmediation-driven attachment rule results not only in preferential but\nsuper-preferential attachment, albeit in disguise. We show that for small $m$,\nthe dynamics of our model is governed by winners take all phenomenon, and for\nhigher $m$ it is governed by winners take some. Besides, we show that the mean\nof the inverse harmonic mean of degrees of the neighborhood of all existing\nnodes is a measure that can well qualify how straight the degree distribution\nis.Comment: 4 pages, 6 figures", "1411.3517": "Derandomized Graph Product Results using the Low Degree Long Code,Dinur, IritHarsha, PrahladhSrinivasan, SrikanthVarma, Girish,Computer Science - Computational Complexity,In this paper, we address the question of whether the recent derandomization\nresults obtained by the use of the low-degree long code can be extended to\nother product settings. We consider two settings: (1) the graph product results\nof Alon, Dinur, Friedgut and Sudakov [GAFA, 2004] and (2) the \"majority is\nstablest\" type of result obtained by Dinur, Mossel and Regev [SICOMP, 2009] and\nDinur and Shinkar [In Proc. APPROX, 2010] while studying the hardness of\napproximate graph coloring.\n  In our first result, we show that there exists a considerably smaller\nsubgraph of $K_3^{\\otimes R}$ which exhibits the following property (shown for\n$K_3^{\\otimes R}$ by Alon et al.): independent sets close in size to the\nmaximum independent set are well approximated by dictators.\n  The \"majority is stablest\" type of result of Dinur et al. and Dinur and\nShinkar shows that if there exist two sets of vertices $A$ and $B$ in\n$K_3^{\\otimes R}$ with very few edges with one endpoint in $A$ and another in\n$B$, then it must be the case that the two sets $A$ and $B$ share a single\ninfluential coordinate. In our second result, we show that a similar \"majority\nis stablest\" statement holds good for a considerably smaller subgraph of\n$K_3^{\\otimes R}$. Furthermore using this result, we give a more efficient\nreduction from Unique Games to the graph coloring problem, leading to improved\nhardness of approximation results for coloring.", "1411.4097": "A Game Theoretic Model for the Formation of Navigable Small-World\n  Networks --- the Tradeoff between Distance and Reciprocity,Yang, ZhiChen, Wei,Computer Science - Social and Information NetworksPhysics - Physics and Society,Kleinberg proposed a family of small-world networks to explain the\nnavigability of large-scale real-world social networks. However, the underlying\nmechanism that drives real networks to be navigable is not yet well understood.\nIn this paper, we present a game theoretic model for the formation of navigable\nsmall world networks. We model the network formation as a Distance-Reciprocity\nBalanced (DRB) game in which people seek for both high reciprocity and\nlong-distance relationships. We show that the game has only two Nash\nequilibria: One is the navigable small-world network, and the other is the\nrandom network in which each node connects with each other node with equal\nprobability. We further show that the navigable small world is very stable ---\n(a) no collusion of any size would benefit from deviating from it; and (b)\nafter an arbitrary deviations of a large random set of nodes, the network would\nreturn to the navigable small world as soon as every node takes one\nbest-response step. In contrast, for the random network, a small group\ncollusion or random perturbations is guaranteed to move the network to the\nnavigable network as soon as every node takes one best-response step. Moreover,\nwe show that navigable small world has much better social welfare than the\nrandom network, and provide the price-of-anarchy and price-of-stability results\nof the game. Our empirical evaluation demonstrates that the system always\nconverges to the navigable network even when limited or no information about\nother players' strategies is available, and the DRB game simulated on the\nreal-world network leads to navigability characteristic that is very close to\nthat of the real network. Our theoretical and empirical analyses provide\nimportant new insight on the connection between distance, reciprocity and\nnavigability in social networks.", "1411.4498": "Scalable Wake-up of Multi-Channel Single-Hop Radio Networks,Chlebus, Bogdan S.De Marco, GianlucaKowalski, Dariusz R.,Computer Science - Data Structures and Algorithms,We consider single-hop radio networks with multiple channels as a model of\nwireless networks. There are $n$ stations connected to $b$ radio channels that\ndo not provide collision detection. A station uses all the channels\nconcurrently and independently. Some $k$ stations may become active\nspontaneously at arbitrary times. The goal is to wake up the network, which\noccurs when all the stations hear a successful transmission on some channel.\nDuration of a waking-up execution is measured starting from the first\nspontaneous activation. We present a deterministic algorithm for the general\nproblem that wakes up the network in $O(k\\log^{1/b} k\\log n)$ time, where $k$\nis unknown. We give a deterministic scalable algorithm for the special case\nwhen $b>d \\log \\log n$, for some constant $d>1$, which wakes up the network in\n$O(\\frac{k}{b}\\log n\\log(b\\log n))$ time, with $k$ unknown. This algorithm\nmisses time optimality by at most a factor of $O(\\log n(\\log b +\\log\\log n))$,\nbecause any deterministic algorithm requires $\\Omega(\\frac{k}{b}\\log\n\\frac{n}{k})$ time. We give a randomized algorithm that wakes up the network\nwithin $O(k^{1/b}\\ln \\frac{1}{\\epsilon})$ rounds with a probability that is at\nleast $1-\\epsilon$, for any $0<\\epsilon<1$, where $k$ is known. We also\nconsider a model of jamming, in which each channel in any round may be jammed\nto prevent a successful transmission, which happens with some known parameter\nprobability $p$, independently across all channels and rounds. For this model,\nwe give two deterministic algorithms for unknown~$k$: one wakes up the network\nin time $O(\\log^{-1}(\\frac{1}{p})\\, k\\log n\\log^{1/b} k)$, and the other in\ntime $O(\\log^{-1}(\\frac{1}{p}) \\, \\frac{k}{b} \\log n\\log(b\\log n))$ but\nassuming the inequality $b>\\log(128b\\log n)$, both with a probability that is\nat least $1-1/\\mbox{poly}(n)$.", "1411.4696": "Security Analysis of the Unrestricted Identity-Based Aggregate Signature\n  Scheme,Lee, KwangsuLee, Dong Hoon,Computer Science - Cryptography and Security,Aggregate signatures allow anyone to combine different signatures signed by\ndifferent signers on different messages into a single short signature. An ideal\naggregate signature scheme is an identity-based aggregate signature (IBAS)\nscheme that supports full aggregation since it can reduce the total transmitted\ndata by using an identity string as a public key and anyone can freely\naggregate different signatures. Constructing a secure IBAS scheme that supports\nfull aggregation in bilinear maps is an important open problem. Recently, Yuan\n{\\it et al.} proposed an IBAS scheme with full aggregation in bilinear maps and\nclaimed its security in the random oracle model under the computational\nDiffie-Hellman assumption. In this paper, we show that there exists an\nefficient forgery attacker on their IBAS scheme and their security proof has a\nserious flaw.Comment: 9 pages", "1411.4823": "Automated Reasoning in Deontic Logic,Furbach, UlrichSchon, ClaudiaStolzenburg, Frieder,Computer Science - Artificial Intelligence,Deontic logic is a very well researched branch of mathematical logic and\nphilosophy. Various kinds of deontic logics are discussed for different\napplication domains like argumentation theory, legal reasoning, and acts in\nmulti-agent systems. In this paper, we show how standard deontic logic can be\nstepwise transformed into description logic and DL- clauses, such that it can\nbe processed by Hyper, a high performance theorem prover which uses a\nhypertableau calculus. Two use cases, one from multi-agent research and one\nfrom the development of normative system are investigated.", "1411.4840": "Dual-induced multifractality in online viewing activity,Qin, Yu-HaoZhao, Zhi-DanCai, Shi-MinGao, LiangStanley, H. Eugene,Physics - Physics and SocietyComputer Science - Social and Information NetworksPhysics - Data Analysis, Statistics and Probability,Although recent studies have found that the long-term correlations relating\nto the fat-tailed distribution of inter-event times exist in human activity,\nand that these correlations indicate the presence of fractality, the property\nof fractality and its origin have not been analyzed. We use both DFA and MFDFA\nto analyze the time series in online viewing activity separating from Movielens\nand Netflix. We find long-term correlations at both the individual and communal\nlevel, and that the extent of correlation at the individual level is determined\nby the activity level. These long-term correlations also indicate that there is\nfractality in the pattern of online viewing. And, we firstly find a\nmultifractality that results from the combined effect of the fat-tailed\ndistribution of inter-event times (i.e., the times between successive viewing\nactions of individual) and the long-term correlations in online viewing\nactivity and verify this finding using three synthesized series. Therefore, it\ncan be concluded that the multifractality in online viewing activity is caused\nby both the fat-tailed distribution of inter-event times and the long-term\ncorrelations, and that this enlarges the generic property of human activity to\ninclude not just physical space, but also cyberspace.Comment: 10 pages, 13 figures", "1411.5123": "Deterministic Edge Connectivity in Near-Linear Time,Kawarabayashi, Ken-ichiThorup, Mikkel,Computer Science - Data Structures and AlgorithmsComputer Science - Discrete Mathematics,We present a deterministic near-linear time algorithm that computes the\nedge-connectivity and finds a minimum cut for a simple undirected unweighted\ngraph G with n vertices and m edges. This is the first o(mn) time deterministic\nalgorithm for the problem. In near-linear time we can also construct the\nclassic cactus representation of all minimum cuts.\n  The previous fastest deterministic algorithm by Gabow from STOC'91 took\n~O(m+k^2 n), where k is the edge connectivity, but k could be Omega(n).\n  At STOC'96 Karger presented a randomized near linear time Monte Carlo\nalgorithm for the minimum cut problem. As he points out, there is no better way\nof certifying the minimality of the returned cut than to use Gabow's slower\ndeterministic algorithm and compare sizes.\n  Our main technical contribution is a near-linear time algorithm that contract\nvertex sets of a simple input graph G with minimum degree d, producing a\nmultigraph with ~O(m/d) edges which preserves all minimum cuts of G with at\nleast 2 vertices on each side.\n  In our deterministic near-linear time algorithm, we will decompose the\nproblem via low-conductance cuts found using PageRank a la Brin and Page\n(1998), as analyzed by Andersson, Chung, and Lang at FOCS'06. Normally such\nalgorithms for low-conductance cuts are randomized Monte Carlo algorithms,\nbecause they rely on guessing a good start vertex. However, in our case, we\nhave so much structure that no guessing is needed.Comment: This is the full journal version. Has been accepted for J.ACM", "1411.5166": "Subtyping in Java is a Fractal,AbdelGawad, Moez A.,Computer Science - Programming LanguagesMathematics - Geometric Topology,While developing their software, professional object-oriented (OO) software\ndevelopers keep in their minds an image of the subtyping relation between types\nin their software. The goal of this paper is to present an observation about\nthe graph of the subtyping relation in Java, namely the observation that, after\nthe addition of generics---and of wildcards, in particular---to Java, the graph\nof the subtyping relation is no longer a simple directed-acyclic graph (DAG),\nas in pre-generics Java, but is rather a fractal. Further, this observation\nequally applies to other mainstream nominally-typed OO languages (such as C#,\nC++ and Scala) where generics and wildcards (or some other form of 'variance\nannotations') are standard features. Accordingly, the shape of the subtyping\nrelation in these OO languages is more complex than a tree or a simple DAG, and\nindeed is also a fractal. Given the popularity of fractals, the fractal\nobservation may help OO software developers keep a useful and intuitive mental\nimage of their software's subtyping relation, even if it is a little more\nfrightening, and more amazing one than before. With proper support from IDEs,\nthe fractal observation can help OO developers in resolving type errors they\nmay find in their code in lesser time, and with more confidence.Comment: 18 pages", "1411.5735": "Minimization of Transformed $L_1$ Penalty: Theory, Difference of Convex\n  Function Algorithm, and Robust Application in Compressed Sensing,Zhang, ShuaiXin, Jack,Computer Science - Information Theory,We study the minimization problem of a non-convex sparsity promoting penalty\nfunction, the transformed $l_1$ (TL1), and its application in compressed\nsensing (CS). The TL1 penalty interpolates $l_0$ and $l_1$ norms through a\nnonnegative parameter $a \\in (0,+\\infty)$, similar to $l_p$ with $p \\in (0,1]$,\nand is known to satisfy unbiasedness, sparsity and Lipschitz continuity\nproperties. We first consider the constrained minimization problem and discuss\nthe exact recovery of $l_0$ norm minimal solution based on the null space\nproperty (NSP). We then prove the stable recovery of $l_0$ norm minimal\nsolution if the sensing matrix $A$ satisfies a restricted isometry property\n(RIP). Next, we present difference of convex algorithms for TL1 (DCATL1) in\ncomputing TL1-regularized constrained and unconstrained problems in CS. The\ninner loop concerns an $l_1$ minimization problem on which we employ the\nAlternating Direction Method of Multipliers (ADMM). For the unconstrained\nproblem, we prove convergence of DCATL1 to a stationary point satisfying the\nfirst order optimality condition. In numerical experiments, we identify the\noptimal value $a=1$, and compare DCATL1 with other CS algorithms on two classes\nof sensing matrices: Gaussian random matrices and over-sampled discrete cosine\ntransform matrices (DCT). We find that for both classes of sensing matrices,\nthe performance of DCATL1 algorithm (initiated with $l_1$ minimization) always\nranks near the top (if not the top), and is the most robust choice insensitive\nto the conditioning of the sensing matrix $A$. DCATL1 is also competitive in\ncomparison with DCA on other non-convex penalty functions commonly used in\nstatistics with two hyperparameters.Comment: to appear in Mathematical Programming, Series B", "1411.5878": "Salient Object Detection: A Survey,Borji, AliCheng, Ming-MingHou, QibinJiang, HuaizuLi, Jia,Computer Science - Computer Vision and Pattern RecognitionComputer Science - Artificial IntelligenceQuantitative Biology - Neurons and Cognition,Detecting and segmenting salient objects in natural scenes, often referred to\nas salient object detection, has attracted a lot of interest in computer\nvision. While many models have been proposed and several applications have\nemerged, yet a deep understanding of achievements and issues is lacking. We aim\nto provide a comprehensive review of the recent progress in salient object\ndetection and situate this field among other closely related areas such as\ngeneric scene segmentation, object proposal generation, and saliency for\nfixation prediction. Covering 228 publications, we survey i) roots, key\nconcepts, and tasks, ii) core techniques and main modeling trends, and iii)\ndatasets and evaluation metrics in salient object detection. We also discuss\nopen problems such as evaluation metrics and dataset bias in model performance\nand suggest future research directions.Comment: 21 pages, 12 figures", "1411.6057": "Mesoscopic analysis of online social networks - The role of negative\n  ties,Esmailian, PouyaAbtahi, Seyed EbrahimJalili, Mahdi,Physics - Physics and SocietyComputer Science - Social and Information NetworksPhysics - Data Analysis, Statistics and Probability,A class of networks are those with both positive and negative links. In this\nmanuscript, we studied the interplay between positive and negative ties on\nmesoscopic level of these networks, i.e., their community structure. A\ncommunity is considered as a tightly interconnected group of actors; therefore,\nit does not borrow any assumption from balance theory and merely uses the\nwell-known assumption in the community detection literature. We found that if\none detects the communities based on only positive relations (by ignoring the\nnegative ones), the majority of negative relations are already placed between\nthe communities. In other words, negative ties do not have a major role in\ndetecting communities of studied signed networks. Moreover, regarding the\ninternal negative ties, we proved that most unbalanced communities are\nmaximally balanced, and hence they cannot be partitioned into k nonempty\nsub-clusters with higher balancedness (k >= 2). Furthermore, we showed that\nalthough the mediator triad ++- (hostile-mediator-hostile) is underrepresented,\nit constitutes a considerable portion of triadic relations among communities.\nHence, mediator triads should not be ignored by community detection and\nclustering algorithms. As a result, if one uses a clustering algorithm that\noperates merely based on social balance, mesoscopic structure of signed\nnetworks significantly remains hidden.Comment: 13 pages, 8 figures", "1411.6538": "Efficient storage of Pareto points in biobjective mixed integer\n  programming,Adelgren, NathanBelotti, PietroGupte, Akshay,Computer Science - Data Structures and AlgorithmsMathematics - Optimization and Control90C29, 68P05, 90C11,E.1.7,In biobjective mixed integer linear programs (BOMILPs), two linear objectives\nare minimized over a polyhedron while restricting some of the variables to be\ninteger. Since many of the techniques for finding or approximating the Pareto\nset of a BOMILP use and update a subset of nondominated solutions, it is highly\ndesirable to efficiently store this subset. We present a new data structure, a\nvariant of a binary tree that takes as input points and line segments in $\\R^2$\nand stores the nondominated subset of this input. When used within an exact\nsolution procedure, such as branch-and-bound (BB), at termination this\nstructure contains the set of Pareto optimal solutions.\n  We compare the efficiency of our structure in storing solutions to that of a\ndynamic list which updates via pairwise comparison. Then we use our data\nstructure in two biobjective BB techniques available in the literature and\nsolve three classes of instances of BOMILP, one of which is generated by us.\nThe first experiment shows that our data structure handles up to $10^7$ points\nor segments much more efficiently than a dynamic list. The second experiment\nshows that our data structure handles points and segments much more efficiently\nthan a list when used in a BB.", "1411.6907": "Spatiotemporal Modeling of a Pervasive Game,Nevelsteen, Kim J. L.,Computer Science - Other Computer Science,Given pervasive games that maintain a virtual spatiotemporal model of the\nphysical world, game designers must contend with space and time in the virtual\nand physical, but an integrated conceptual model is lacking. Because the\nproblem domains of GIS and Pervasive Games overlap, Peuquet's Triad\nRepresentational Framework is exapted, from the domain of GIS, and applied to\nPervasive Games. Using Dix et al.'s three types of space and Langran's notion\nof time, virtual time and space are then be mapped to the physical world and\nvice versa. The approach is evaluated using the pervasive game called Codename:\nHeroes, as case study.Comment: 11 pages, 1 figure", "1411.7086": "Discrete Sampling: A graph theoretic approach to Orthogonal\n  Interpolation,Siripuram, AdityaWu, WilliamOsgood, Brad,Computer Science - Information Theory,We study the problem of finding unitary submatrices of the $N \\times N$\ndiscrete Fourier transform matrix, in the context of interpolating a discrete\nbandlimited signal using an orthogonal basis. This problem is related to a\ndiverse set of questions on idempotents on $\\mathbb{Z}_N$ and tiling\n$\\mathbb{Z}_N$. In this work, we establish a graph-theoretic approach and\nconnections to the problem of finding maximum cliques. We identify the key\nproperties of these graphs that make the interpolation problem tractable when\n$N$ is a prime power, and we identify the challenges in generalizing to\narbitrary $N$. Finally, we investigate some connections between graph\nproperties and the spectral-tile direction of the Fuglede conjecture.Comment: Submitted to IEEE Transactions on Information Theory", "1411.7087": "Consistency proof of a fragment of PV with substitution in bounded\n  arithmetic,Yamagata, Yoriyuki,Mathematics - LogicComputer Science - Logic in Computer Science03F03, 03D15F.4.1,This paper presents proof that Buss's $S^2_2$ can prove the consistency of a\nfragment of Cook and Urquhart's $\\mathrm{PV}$ from which induction has been\nremoved but substitution has been retained.\n  This result improves Beckmann's result, which proves the consistency of such\na system without substitution in bounded arithmetic $S^1_2$.\n  Our proof relies on the notion of \"computation\" of the terms of\n$\\mathrm{PV}$.\n  In our work, we first prove that, in the system under consideration, if an\nequation is proved and either its left- or right-hand side is computed, then\nthere is a corresponding computation for its right- or left-hand side,\nrespectively.\n  By carefully computing the bound of the size of the computation, the proof of\nthis theorem inside a bounded arithmetic is obtained, from which the\nconsistency of the system is readily proven.\n  This result apparently implies the separation of bounded arithmetic because\nBuss and Ignjatovi\\'c stated that it is not possible to prove the consistency\nof a fragment of $\\mathrm{PV}$ without induction but with substitution in\nBuss's $S^1_2$.\n  However, their proof actually shows that it is not possible to prove the\nconsistency of the system, which is obtained by the addition of propositional\nlogic and other axioms to a system such as ours.\n  On the other hand, the system that we have considered is strictly equational,\nwhich is a property on which our proof relies.Comment: Submitted version", "1411.7346": "A Chasm Between Identity and Equivalence Testing with Conditional\n  Queries,Acharya, JayadevCanonne, Cl\u00e9ment L.Kamath, Gautam,Computer Science - Data Structures and AlgorithmsComputer Science - Computational ComplexityComputer Science - Machine LearningMathematics - ProbabilityMathematics - Statistics Theory,A recent model for property testing of probability distributions (Chakraborty\net al., ITCS 2013, Canonne et al., SICOMP 2015) enables tremendous savings in\nthe sample complexity of testing algorithms, by allowing them to condition the\nsampling on subsets of the domain. In particular, Canonne, Ron, and Servedio\n(SICOMP 2015) showed that, in this setting, testing identity of an unknown\ndistribution $D$ (whether $D=D^\\ast$ for an explicitly known $D^\\ast$) can be\ndone with a constant number of queries, independent of the support size $n$ --\nin contrast to the required $\\Omega(\\sqrt{n})$ in the standard sampling model.\nIt was unclear whether the same stark contrast exists for the case of testing\nequivalence, where both distributions are unknown. While Canonne et al.\nestablished a $\\mathrm{poly}(\\log n)$-query upper bound for equivalence\ntesting, very recently brought down to $\\tilde O(\\log\\log n)$ by Falahatgar et\nal. (COLT 2015), whether a dependence on the domain size $n$ is necessary was\nstill open, and explicitly posed by Fischer at the Bertinoro Workshop on\nSublinear Algorithms (2014). We show that any testing algorithm for equivalence\nmust make $\\Omega(\\sqrt{\\log\\log n})$ queries in the conditional sampling\nmodel. This demonstrates a gap between identity and equivalence testing, absent\nin the standard sampling model (where both problems have sampling complexity\n$n^{\\Theta(1)}$).\n  We also obtain results on the query complexity of uniformity testing and\nsupport-size estimation with conditional samples. We answer a question of\nChakraborty et al. (ITCS 2013) showing that non-adaptive uniformity testing\nindeed requires $\\Omega(\\log n)$ queries in the conditional model. For the\nrelated problem of support-size estimation, we provide both adaptive and\nnon-adaptive algorithms, with query complexities $\\mathrm{poly}(\\log\\log n)$\nand $\\mathrm{poly}(\\log n)$, respectively.Comment: 39 pages. To appear in Theory of Computing. Preliminary version\n  appeared in RANDOM 2015", "1411.7632": "Semidefinite Programming Approach to Gaussian Sequential Rate-Distortion\n  Trade-offs,Tanaka, TakashiKim, Kwang-Ki K.Parrilo, Pablo A.Mitter, Sanjoy K.,Mathematics - Optimization and ControlComputer Science - Information Theory,Sequential rate-distortion (SRD) theory provides a framework for studying the\nfundamental trade-off between data-rate and data-quality in real-time\ncommunication systems. In this paper, we consider the SRD problem for\nmulti-dimensional time-varying Gauss-Markov processes under mean-square\ndistortion criteria. We first revisit the sensor-estimator separation\nprinciple, which asserts that considered SRD problem is equivalent to a joint\nsensor and estimator design problem in which data-rate of the sensor output is\nminimized while the estimator's performance satisfies the distortion criteria.\nWe then show that the optimal joint design can be performed by semidefinite\nprogramming. A semidefinite representation of the corresponding SRD function is\nobtained. Implications of the obtained result in the context of zero-delay\nsource coding theory and applications to networked control theory are also\ndiscussed.", "1411.7895": "Influence of sociodemographic characteristics on human mobility,Lenormand, MaximeLouail, ThomasCantu-Ros, Oliva G.Picornell, MiguelHerranz, RicardoArias, Juan MurilloBarthelemy, MarcMiguel, Maxi SanRamasco, Jose J.,Physics - Physics and SocietyComputer Science - Social and Information Networks,Human mobility has been traditionally studied using surveys that deliver\nsnapshots of population displacement patterns. The growing accessibility to ICT\ninformation from portable digital media has recently opened the possibility of\nexploring human behavior at high spatio-temporal resolutions. Mobile phone\nrecords, geolocated tweets, check-ins from Foursquare or geotagged photos, have\ncontributed to this purpose at different scales, from cities to countries, in\ndifferent world areas. Many previous works lacked, however, details on the\nindividuals' attributes such as age or gender. In this work, we analyze\ncredit-card records from Barcelona and Madrid and by examining the geolocated\ncredit-card transactions of individuals living in the two provinces, we find\nthat the mobility patterns vary according to gender, age and occupation.\nDifferences in distance traveled and travel purpose are observed between\nyounger and older people, but, curiously, either between males and females of\nsimilar age. While mobility displays some generic features, here we show that\nsociodemographic characteristics play a relevant role and must be taken into\naccount for mobility and epidemiological modelization.Comment: 13 pages, 11 figures + Supplementary information", "1412.0291": "Bits from Biology for Computational Intelligence,Wibral, MichaelLizier, Joseph T.Priesemann, Viola,Quantitative Biology - Neurons and CognitionComputer Science - Information TheoryPhysics - Data Analysis, Statistics and Probability,Computational intelligence is broadly defined as biologically-inspired\ncomputing. Usually, inspiration is drawn from neural systems. This article\nshows how to analyze neural systems using information theory to obtain\nconstraints that help identify the algorithms run by such systems and the\ninformation they represent. Algorithms and representations identified\ninformation-theoretically may then guide the design of biologically inspired\ncomputing systems (BICS). The material covered includes the necessary\nintroduction to information theory and the estimation of information theoretic\nquantities from neural data. We then show how to analyze the information\nencoded in a system about its environment, and also discuss recent\nmethodological developments on the question of how much information each agent\ncarries about the environment either uniquely, or redundantly or\nsynergistically together with others. Last, we introduce the framework of local\ninformation dynamics, where information processing is decomposed into component\nprocesses of information storage, transfer, and modification -- locally in\nspace and time. We close by discussing example applications of these measures\nto neural data and other complex systems.", "1412.0340": "Approximate MAP Estimation for Pairwise Potentials via Baker's Technique,Wang, Yi-Kai,Computer Science - Data Structures and Algorithms,The theoretical models providing mathematical abstractions for several\nsignificant optimization problems in machine learning, combinatorial\noptimization, computer vision and statistical physics have intrinsic\nsimilarities. We propose a unified framework to model these computation tasks\nwhere the structures of these optimization problems are encoded by functions\nattached on the vertices and edges of a graph. We show that computing MAX 2-CSP\nadmits polynomial-time approximation scheme (PTAS) on planar graphs, graphs\nwith bounded local treewidth, $H$-minor-free graphs, geometric graphs with\nbounded density and graphs embeddable with bounded number of crossings per\nedge. This implies computing MAX-CUT, MAX-DICUT and MAX $k$-CUT admits PTASs on\nall these classes of graphs. Our method also gives the first PTAS for computing\nthe ground state of ferromagnetic Edwards-Anderson model without external\nmagnetic field on $d$-dimensional lattice graphs. These results are widely\napplicable in vision, graphics and machine learning.", "1412.1538": "Krylov Subspace Methods in Dynamical Sampling,Aldroubi, AkramKrishtal, Ilya,Computer Science - Information Theory94A20, 94A12, 42C15, 15A29,Let $B$ be an unknown linear evolution process on $\\mathbb C^d\\simeq\nl^2(\\mathbb Z_d)$ driving an unknown initial state $x$ and producing the states\n$\\{B^\\ell x, \\ell = 0,1,\\ldots\\}$ at different time levels. The problem under\nconsideration in this paper is to find as much information as possible about\n$B$ and $x$ from the measurements $Y=\\{x(i)$, $Bx(i)$, $\\dots$,\n$B^{\\ell_i}x(i): i \\in \\Omega\\subset \\mathbb Z^d\\}$. If $B$ is a \"low-pass\"\nconvolution operator, we show that we can recover both $B$ and $x$, almost\nsurely, as long as we double the amount of temporal samples needed in\n\\cite{ADK13} to recover the signal propagated by a known operator $B$. For a\ngeneral operator $B$, we can recover parts or even all of its spectrum from\n$Y$. As a special case of our method, we derive the centuries old Prony's\nmethod \\cite{BDVMC08, P795, PP13} which recovers a vector with an $s$-sparse\nFourier transform from $2s$ of its consecutive components.Comment: 12 pages, 2 figures", "1412.1547": "Efficient algorithms to decide tightness,Bagchi, BhaskarBurton, Benjamin A.Datta, BasudebSingh, NitinSpreer, Jonathan,Computer Science - Computational GeometryMathematics - CombinatoricsF.2.2G.2.1,Tightness is a generalisation of the notion of convexity: a space is tight if\nand only if it is \"as convex as possible\", given its topological constraints.\nFor a simplicial complex, deciding tightness has a straightforward exponential\ntime algorithm, but efficient methods to decide tightness are only known in the\ntrivial setting of triangulated surfaces.\n  In this article, we present a new polynomial time procedure to decide\ntightness for triangulations of $3$-manifolds -- a problem which previously was\nthought to be hard. Furthermore, we describe an algorithm to decide general\ntightness in the case of $4$-dimensional combinatorial manifolds which is fixed\nparameter tractable in the treewidth of the $1$-skeletons of their vertex\nlinks, and we present an algorithm to decide $\\mathbb{F}_2$-tightness for weak\npseudomanifolds $M$ of arbitrary but fixed dimension which is fixed parameter\ntractable in the treewidth of the dual graph of $M$.Comment: 18 pages, 3 figures", "1412.1695": "Convolutional codes from unit schemes,Hurley, Ted,Mathematics - Rings and AlgebrasComputer Science - Discrete MathematicsComputer Science - Information Theory94B10, 11T71, 16S99,Convolutional codes are constructed, designed and analysed using row and/or\nblock structures of unit algebraic schemes. Infinite series of such codes and\nof codes with specific properties are derived. Properties are shown\nalgebraically and algebraic decoding methods are derived. For a given rate and\ngiven error-correction capability at each component, convolutional codes with\nthese specifications and with efficient decoding algorithms are constructed.\nExplicit prototype examples are given but in general large lengths and large\nerror capability are achievable. Convolutional codes with efficient decoding\nalgorithms at or near the maximum free distances attainable for the parameters\nare constructible. Unit memory convolutional codes of maximum possible free\ndistance are designed with practical algebraic decoding algorithms.\n  LDPC (low density parity check) convolutional codes with efficient decoding\nschemes are constructed and analysed by the methods. Self-dual and\ndual-containing convolutional codes may also be designed by the methods;\ndual-containing codes enables the construction of quantum codes.Comment: This version has substantive changes from previous versions", "1412.1866": "Integer-Programming Ensemble of Temporal-Relations Classifiers,Kerr, CatherineHoare, TerriCarroll, PaulaMarecek, Jakub,Computer Science - Computation and LanguageComputer Science - Machine LearningMathematics - Optimization and Control,The extraction and understanding of temporal events and their relations are\nmajor challenges in natural language processing. Processing text on a\nsentence-by-sentence or expression-by-expression basis often fails, in part due\nto the challenge of capturing the global consistency of the text. We present an\nensemble method, which reconciles the outputs of multiple classifiers of\ntemporal expressions across the text using integer programming. Computational\nexperiments show that the ensemble improves upon the best individual results\nfrom two recent challenges, SemEval-2013 TempEval-3 (Temporal Annotation) and\nSemEval-2016 Task 12 (Clinical TempEval).", "1412.2114": "Chases and Escapes, and Optimization Problems,Ohira, Toru,Computer Science - Artificial Intelligence,We propose a new approach for solving combinatorial optimization problem by\nutilizing the mechanism of chases and escapes, which has a long history in\nmathematics. In addition to the well-used steepest descent and neighboring\nsearch, we perform a chase and escape game on the \"landscape\" of the cost\nfunction. We have created a concrete algorithm for the Traveling Salesman\nProblem. Our preliminary test indicates a possibility that this new fusion of\nchases and escapes problem into combinatorial optimization search is fruitful.Comment: 3 pages, 4 figures. To appear in the Proceedings of the International\n  Symposium on Artificial Life and Robotics (AROB20th), Beppu, Oita Japan,\n  January 21-23, 2015", "1412.2231": "Generalized Singular Value Thresholding,Lu, CanyiZhu, ChangboXu, ChunyanYan, ShuichengLin, Zhouchen,Computer Science - Computer Vision and Pattern RecognitionComputer Science - Machine LearningComputer Science - Numerical AnalysisMathematics - Numerical Analysis,This work studies the Generalized Singular Value Thresholding (GSVT) operator\n${\\text{Prox}}_{g}^{{\\sigma}}(\\cdot)$, \\begin{equation*}\n  {\\text{Prox}}_{g}^{{\\sigma}}(B)=\\arg\\min\\limits_{X}\\sum_{i=1}^{m}g(\\sigma_{i}(X))\n+ \\frac{1}{2}||X-B||_{F}^{2}, \\end{equation*} associated with a nonconvex\nfunction $g$ defined on the singular values of $X$. We prove that GSVT can be\nobtained by performing the proximal operator of $g$ (denoted as\n$\\text{Prox}_g(\\cdot)$) on the singular values since $\\text{Prox}_g(\\cdot)$ is\nmonotone when $g$ is lower bounded. If the nonconvex $g$ satisfies some\nconditions (many popular nonconvex surrogate functions, e.g., $\\ell_p$-norm,\n$0<p<1$, of $\\ell_0$-norm are special cases), a general solver to find\n$\\text{Prox}_g(b)$ is proposed for any $b\\geq0$. GSVT greatly generalizes the\nknown Singular Value Thresholding (SVT) which is a basic subroutine in many\nconvex low rank minimization methods. We are able to solve the nonconvex low\nrank minimization problem by using GSVT in place of SVT.Comment: Proceedings of the AAAI Conference on Artificial Intelligence (AAAI),\n  2015", "1412.2526": "Exploiting Packing Components in General-Purpose Integer Programming\n  Solvers,Marecek, Jakub,Mathematics - Optimization and ControlComputer Science - Data Structures and Algorithms,The problem of packing boxes into a large box is often a part of a larger\nproblem. For example in furniture supply chain applications, one needs to\ndecide what trucks to use to transport furniture between production sites and\ndistribution centers and stores, such that the furniture fits inside. Such\nproblems are often formulated and sometimes solved using general-purpose\ninteger programming solvers.\n  This chapter studies the problem of identifying a compact formulation of the\nmulti-dimensional packing component in a general instance of integer linear\nprogramming, reformulating it using the discretisation of\nAllen--Burke--Marecek, and and solving the extended reformulation. Results on\ninstances of up to 10000000 boxes are reported.", "1412.2684": "HyperSpectral classification with adaptively weighted L1-norm\n  regularization and spatial postprocessing,Aldea, Victor Stefan,Mathematics - Optimization and ControlComputer Science - Computer Vision and Pattern Recognition,Sparse regression methods have been proven effective in a wide range of\nsignal processing problems such as image compression, speech coding, channel\nequalization, linear regression and classification. In this paper a new convex\nmethod of hyperspectral image classification is developed based on the sparse\nunmixing algorithm SUnSAL for which a pixel adaptive L1-norm regularization\nterm is introduced. To further enhance class separability, the algorithm is\nkernelized using an RBF kernel and the final results are improved by a\ncombination of spatial pre and post-processing operations. It is shown that the\nproposed method is competitive with state of the art algorithms such as SVM-CK,\nKSOMP-CK and KSSP-CK.Comment: v3: 11 pages, 2 Figures, 10 Tables. Updated the results for the\n  Indian Pines image; added the results for the Pavia University image", "1412.2877": "Autonomous Load Disaggregation Approach based on Active Power\n  Measurements,Egarter, DominikElmenreich, Wilfried,Computer Science - Other Computer Science,With the help of smart metering valuable information of the appliance usage\ncan be retrieved. In detail, non-intrusive load monitoring (NILM), also called\nload disaggregation, tries to identify appliances in the power draw of an\nhousehold. In this paper an unsupervised load disaggregation approach is\nproposed that works without a priori knowledge about appliances. The proposed\nalgorithm works autonomously in real time. The number of used appliances and\nthe corresponding appliance models are learned in operation and are\nprogressively updated. The proposed algorithm is considering each useful and\nsuitable detected power state. The algorithm tries to detect power states\ncorresponding to on/off appliances as well as to multi-state appliances based\non active power measurements in 1s resolution. We evaluated the novel\nintroduced load disaggregation approach on real world data by testing the\npossibility to disaggregate energy demand on appliance level.", "1412.3347": "Computational Aspects of the Colorful Carath\\'eodory Theorem,Mulzer, WolfgangStein, Yannik,Computer Science - Computational Geometry,Let $C_1,\\dots,C_{d+1}\\subset \\mathbb{R}^d$ be $d+1$ point sets, each\ncontaining the origin in its convex hull. We call these sets color classes, and\nwe call a sequence $p_1, \\dots, p_{d+1}$ with $p_i \\in C_i$, for $i = 1, \\dots,\nd+1$, a colorful choice. The colorful Carath\\'eodory theorem guarantees the\nexistence of a colorful choice that also contains the origin in its convex\nhull. The computational complexity of finding such a colorful choice (CCP) is\nunknown. This is particularly interesting in the light of polynomial-time\nreductions from several related problems, such as computing centerpoints, to\nCCP.\n  We define a novel notion of approximation that is compatible with the\npolynomial-time reductions to CCP: a sequence that contains at most $k$ points\nfrom each color class is called a $k$-colorful choice. We present an algorithm\nthat for any fixed $\\varepsilon > 0$, outputs an $\\lceil \\epsilon\nd\\rceil$-colorful choice containing the origin in its convex hull in polynomial\ntime.\n  Furthermore, we consider a related problem of CCP: in the nearest colorful\npolytope problem (NCP), we are given sets $C_1,\\dots,C_n\\subset\\mathbb{R}^d$\nthat do not necessarily contain the origin in their convex hulls. The goal is\nto find a colorful choice whose convex hull minimizes the distance to the\norigin. We show that computing a local optimum for NCP is PLS-complete, while\ncomputing a global optimum is NP-hard.Comment: 28 pages, 7 figures. A preliminary version appeared at SoCG 2015", "1412.3701": "How Much Lookahead is Needed to Win Infinite Games?,Klein, FelixZimmermann, Martin,Computer Science - Computer Science and Game TheoryComputer Science - Formal Languages and Automata Theory,Delay games are two-player games of infinite duration in which one player may\ndelay her moves to obtain a lookahead on her opponent's moves. For\n$\\omega$-regular winning conditions it is known that such games can be solved\nin doubly-exponential time and that doubly-exponential lookahead is sufficient.\n  We improve upon both results by giving an exponential time algorithm and an\nexponential upper bound on the necessary lookahead. This is complemented by\nshowing EXPTIME-hardness of the solution problem and tight exponential lower\nbounds on the lookahead. Both lower bounds already hold for safety conditions.\nFurthermore, solving delay games with reachability conditions is shown to be\nPSPACE-complete.\n  This is a corrected version of the paper https://arxiv.org/abs/1412.3701v4\npublished originally on August 26, 2016.", "1412.4171": "Dynamics of Information Diffusion and Social Sensing,Krishnamurthy, VikramHoiles, William,Computer Science - Social and Information NetworksPhysics - Physics and Society,Statistical inference using social sensors is an area that has witnessed\nremarkable progress and is relevant in applications including localizing events\nfor targeted advertising, marketing, localization of natural disasters and\npredicting sentiment of investors in financial markets. This chapter presents a\ntutorial description of four important aspects of sensing-based information\ndiffusion in social networks from a communications/signal processing\nperspective. First, diffusion models for information exchange in large scale\nsocial networks together with social sensing via social media networks such as\nTwitter is considered. Second, Bayesian social learning models and risk averse\nsocial learning is considered with applications in finance and online\nreputation systems. Third, the principle of revealed preferences arising in\nmicro-economics theory is used to parse datasets to determine if social sensors\nare utility maximizers and then determine their utility functions. Finally, the\ninteraction of social sensors with YouTube channel owners is studied using time\nseries analysis methods. All four topics are explained in the context of actual\nexperimental datasets from health networks, social media and psychological\nexperiments. Also, algorithms are given that exploit the above models to infer\nunderlying events based on social sensing. The overview, insights, models and\nalgorithms presented in this chapter stem from recent developments in network\nscience, economics and signal processing. At a deeper level, this chapter\nconsiders mean field dynamics of networks, risk averse Bayesian social learning\nfiltering and quickest change detection, data incest in decision making over a\ndirected acyclic graph of social sensors, inverse optimization problems for\nutility function estimation (revealed preferences) and statistical modeling of\ninteracting social sensors in YouTube social networks.Comment: arXiv admin note: text overlap with arXiv:1405.1129", "1412.4198": "An Ordinal Minimax Theorem,Brandt, FelixBrill, MarkusSuksompong, Warut,Computer Science - Computer Science and Game Theory,In the early 1950s Lloyd Shapley proposed an ordinal and set-valued solution\nconcept for zero-sum games called \\emph{weak saddle}. We show that all weak\nsaddles of a given zero-sum game are interchangeable and equivalent. As a\nconsequence, every such game possesses a unique set-based value.Comment: 10 pages, 2 figures", "1412.4586": "Generalized Vietoris Bisimulations,Enqvist, SebastianSourabh, Sumit,Computer Science - Logic in Computer ScienceMathematics - Logic,We introduce and study bisimulations for coalgebras on Stone spaces [14]. Our\nnotion of bisimulation is sound and complete for behavioural equivalence, and\ngeneralizes Vietoris bisimulations [4]. The main result of our paper is that\nbisimulation for a $\\mathbf{Stone}$ coalgebra is the topological closure of\nbisimulation for the underlying $\\mathbf{Set}$ coalgebra.", "1412.5204": "How many queries are needed to distinguish a truncated random\n  permutation from a random function?,Gilboa, ShoniGueron, ShayMorris, Ben,Computer Science - Cryptography and Security,An oracle chooses a function $f$ from the set of $n$ bits strings to itself,\nwhich is either a randomly chosen permutation or a randomly chosen function.\nWhen queried by an $n$-bit string $w$, the oracle computes $f(w)$, truncates\nthe $m$ last bits, and returns only the first $n-m$ bits of $f(w)$. How many\nqueries does a querying adversary need to submit in order to distinguish the\ntruncated permutation from the (truncated) function?\n  In 1998, Hall et al. showed an algorithm for determining (with high\nprobability) whether or not $f$ is a permutation, using $O(2^{\\frac{m+n}{2}})$\nqueries. They also showed that if $m < n/7$, a smaller number of queries will\nnot suffice. For $m > n/7$, their method gives a weaker bound. In this note, we\nfirst show how a modification of the approximation method used by Hall et al.\ncan solve the problem completely. It extends the result to practically any $m$,\nshowing that $\\Omega(2^{\\frac{m+n}{2}})$ queries are needed to get a\nnon-negligible distinguishing advantage. However, more surprisingly, a better\nbound for the distinguishing advantage can be obtained from a result of Stam\npublished, in a different context, already in 1978. We also show that, at least\nin some cases, Stam's bound is tight.", "1412.5374": "Maximal Correlation Secrecy,Li, Cheuk TingGamal, Abbas El,Computer Science - Information TheoryComputer Science - Cryptography and Security,This paper shows that the Hirschfeld-Gebelein-R\\'enyi maximal correlation\nbetween the message and the ciphertext provides good secrecy guarantees for\ncryptosystems that use short keys. We first establish a bound on the\neavesdropper's advantage in guessing functions of the message in terms of\nmaximal correlation and the R\\'enyi entropy of the message. This result implies\nthat maximal correlation is stronger than the notion of entropic security\nintroduced by Russell and Wang. We then show that a small maximal correlation\n$\\rho$ can be achieved via a randomly generated cipher with key length\n$\\approx2\\log(1/\\rho)$, independent of the message length, and by a stream\ncipher with key length $2\\log(1/\\rho)+\\log n+2$ for a message of length $n$. We\nestablish a converse showing that these ciphers are close to optimal. This is\nin contrast to entropic security for which there is a gap between the lower and\nupper bounds. Finally, we show that a small maximal correlation implies secrecy\nwith respect to several mutual information based criteria but is not\nnecessarily implied by them. Hence, maximal correlation is a stronger and more\npractically relevant measure of secrecy than mutual information.Comment: 15 pages, 2 figure, presented in part at IEEE International Symposium\n  on Information Theory 2015", "1412.5466": "Enumerative Coding for Line Polar Grassmannians with applications to\n  codes,Cardinali, IlariaGiuzzi, Luca,Computer Science - Information TheoryMathematics - Combinatorics14M15, 94B27, 94B05,A $k$-polar Grassmannian is the geometry having as pointset the set of all\n$k$-dimensional subspaces of a vector space $V$ which are totally isotropic for\na given non-degenerate bilinear form $\\mu$ defined on $V.$ Hence it can be\nregarded as a subgeometry of the ordinary $k$-Grassmannian. In this paper we\ndeal with orthogonal line Grassmannians and with symplectic line Grassmannians,\ni.e. we assume $k=2$ and $\\mu$ a non-degenerate symmetric or alternating form.\nWe will provide a method to efficiently enumerate the pointsets of both\northogonal and symplectic line Grassmannians. This has several nice\napplications; among them, we shall discuss an efficient encoding/decoding/error\ncorrection strategy for line polar Grassmann codes of both types.Comment: 27 pages; revised version after review", "1412.5669": "The Timestamp of Timed Automata,Rosenmann, Amnon,Computer Science - Formal Languages and Automata TheoryF.1.1D.2.4,Given a member A of the class of non-deterministic timed automata with silent\ntransitions (eNTA), we show how one can effectively compute its timestamp: the\nset of all pairs of time values and the corresponding actions of all observable\ntimed traces of A, and also a deterministic timed automaton with the same\ntimestamp as that of A. The timestamp is eventually periodic and is constructed\nvia a finite periodic augmented region automaton. A consequence of this\nconstruction is the periodicity of the language of timed automata with respect\nto suffixes. Applications include the decidability of the 1-bounded language\ninclusion problem for the class eNTA, and a partial method, not bounded by time\nor number of steps, for the general language non-inclusion problem for eNTA.Comment: 31 pages, 7 figures", "1412.5718": "Revisiting Non-Progressive Influence Models: Scalable Influence\n  Maximization,Golnari, GolshanAsiaee, AmirBanerjee, ArindamZhang, Zhi-Li,Computer Science - Social and Information NetworksPhysics - Physics and Society,While influence maximization in social networks has been studied extensively\nin computer science community for the last decade the focus has been on the\nprogressive influence models, such as independent cascade (IC) and Linear\nthreshold (LT) models, which cannot capture the reversibility of choices. In\nthis paper, we present the Heat Conduction (HC) model which is a\nnon-progressive influence model with real-world interpretations. We show that\nHC unifies, generalizes, and extends the existing nonprogressive models, such\nas the Voter model [1] and non-progressive LT [2]. We then prove that selecting\nthe optimal seed set of influential nodes is NP-hard for HC but by establishing\nthe submodularity of influence spread, we can tackle the influence maximization\nproblem with a scalable and provably near-optimal greedy algorithm. We are the\nfirst to present a scalable solution for influence maximization under\nnonprogressive LT model, as a special case of the HC model. In sharp contrast\nto the other greedy influence maximization methods, our fast and efficient\nC2GREEDY algorithm benefits from two analytically computable steps: closed-form\ncomputation for finding the influence spread as well as the greedy seed\nselection. Through extensive experiments on several large real and synthetic\nnetworks, we show that C2GREEDY outperforms the state-of-the-art methods, in\nterms of both influence spread and scalability.Comment: G. Golnari and A. Asiaee contributed equally to this work. Published\n  in 31st Conference on Uncertainty in Artificial Intelligence (UAI) proceeding", "1412.5831": "Deducing Truth from Correlation,N\u00f6tzel, JanisSwetly, Walter,Computer Science - Information Theory,This work is motivated by a question at the heart of unsupervised learning\napproaches: Assume we are collecting a number K of (subjective) opinions about\nsome event E from K different agents. Can we infer E from them? Prima facie\nthis seems impossible, since the agents may be lying. We model this task by\nletting the events be distributed according to some distribution p and the task\nis to estimate p under unknown noise. Again, this is impossible without\nadditional assumptions. We report here the finding of very natural such\nassumptions - the availability of multiple copies of the true data, each under\nindependent and invertible (in the sense of matrices) noise, is already\nsufficient: If the true distribution and the observations are modeled on the\nsame finite alphabet, then the number of such copies needed to determine p to\nthe highest possible precision is exactly three! This result can be seen as a\ncounterpart to independent component analysis. Therefore, we call our approach\n'dependent component analysis'. In addition, we present generalizations of the\nmodel to different alphabet sizes at in- and output. A second result is found:\nthe 'activation' of invertibility through multiple parallel uses.Comment: 13 pages, 3 figures. Published in IEEE Transactions on Information\n  Theory. Typo in Theorem 4 and Conjecture 1 corrected in this version", "1412.5902": "Nearest Descent, In-Tree, and Clustering,Qiu, TengYang, KaifuLi, ChaoyiLi, Yongjie,Computer Science - Machine LearningComputer Science - Computer Vision and Pattern Recognition,In this paper, we propose a physically inspired graph-theoretical clustering\nmethod, which first makes the data points organized into an attractive graph,\ncalled In-Tree, via a physically inspired rule, called Nearest Descent (ND). In\nparticular, the rule of ND works to select the nearest node in the descending\ndirection of potential as the parent node of each node, which is in essence\ndifferent from the classical Gradient Descent or Steepest Descent. The\nconstructed In-Tree proves a very good candidate for clustering due to its\nparticular features and properties. In the In-Tree, the original clustering\nproblem is reduced to a problem of removing a very few of undesired edges from\nthis graph. Pleasingly, the undesired edges in In-Tree are so distinguishable\nthat they can be easily determined in either automatic or interactive way,\nwhich is in stark contrast to the cases in the widely used Minimal Spanning\nTree and k-nearest-neighbor graph. The cluster number in the proposed method\ncan be easily determined based on some intermediate plots, and the cluster\nassignment for each node is easily made by quickly searching its root node in\neach sub-graph (also an In-Tree). The proposed method is extensively evaluated\non both synthetic and real-world datasets. Overall, the proposed clustering\nmethod is a density-based one, but shows significant differences and advantages\nin comparison to the traditional ones. The proposed method is simple yet\nefficient and reliable, and is applicable to various datasets with diverse\nshapes, attributes and any high dimensionalityComment: 28 pages: text part(1-14), supplementary material(15-28)", "1412.6466": "Finding 2-Edge and 2-Vertex Strongly Connected Components in Quadratic\n  Time,Henzinger, MonikaKrinninger, SebastianLoitzenbauer, Veronika,Computer Science - Data Structures and Algorithms,We present faster algorithms for computing the 2-edge and 2-vertex strongly\nconnected components of a directed graph, which are straightforward\ngeneralizations of strongly connected components. While in undirected graphs\nthe 2-edge and 2-vertex connected components can be found in linear time, in\ndirected graphs only rather simple $O(m n)$-time algorithms were known. We use\na hierarchical sparsification technique to obtain algorithms that run in time\n$O(n^2)$. For 2-edge strongly connected components our algorithm gives the\nfirst running time improvement in 20 years. Additionally we present an $O(m^2 /\n\\log{n})$-time algorithm for 2-edge strongly connected components, and thus\nimprove over the $O(m n)$ running time also when $m = O(n)$. Our approach\nextends to k-edge and k-vertex strongly connected components for any constant k\nwith a running time of $O(n^2 \\log^2 n)$ for edges and $O(n^3)$ for vertices.", "1412.6622": "Deep metric learning using Triplet network,Hoffer, EladAilon, Nir,Computer Science - Machine LearningComputer Science - Computer Vision and Pattern RecognitionStatistics - Machine Learning,Deep learning has proven itself as a successful set of models for learning\nuseful semantic representations of data. These, however, are mostly implicitly\nlearned as part of a classification task. In this paper we propose the triplet\nnetwork model, which aims to learn useful representations by distance\ncomparisons. A similar model was defined by Wang et al. (2014), tailor made for\nlearning a ranking for image information retrieval. Here we demonstrate using\nvarious datasets that our model learns a better representation than that of its\nimmediate competitor, the Siamese network. We also discuss future possible\nusage as a framework for unsupervised learning.", "1412.6761": "New results on classical and quantum counter automata,Nakanishi, MasakiYakary\u0131lmaz, AbuzerGainutdinova, Aida,Computer Science - Formal Languages and Automata TheoryComputer Science - Computational ComplexityQuantum Physics,We show that one-way quantum one-counter automaton with zero-error is more\npowerful than its probabilistic counterpart on promise problems. Then, we\nobtain a similar separation result between Las Vegas one-way probabilistic\none-counter automaton and one-way deterministic one-counter automaton.\n  We also obtain new results on classical counter automata regarding language\nrecognition. It was conjectured that one-way probabilistic one blind-counter\nautomata cannot recognize Kleene closure of equality language [A. Yakaryilmaz:\nSuperiority of one-way and realtime quantum machines. RAIRO - Theor. Inf. and\nApplic. 46(4): 615-641 (2012)]. We show that this conjecture is false, and also\nshow several separation results for blind/non-blind counter automata.Comment: 21 pages. Title was changed. Introduction was revised", "1412.6808": "Learning the nonlinear geometry of high-dimensional data: Models and\n  algorithms,Wu, TongBajwa, Waheed U.,Statistics - Machine LearningComputer Science - Computer Vision and Pattern RecognitionComputer Science - Machine Learning,Modern information processing relies on the axiom that high-dimensional data\nlie near low-dimensional geometric structures. This paper revisits the problem\nof data-driven learning of these geometric structures and puts forth two new\nnonlinear geometric models for data describing \"related\" objects/phenomena. The\nfirst one of these models straddles the two extremes of the subspace model and\nthe union-of-subspaces model, and is termed the metric-constrained\nunion-of-subspaces (MC-UoS) model. The second one of these models---suited for\ndata drawn from a mixture of nonlinear manifolds---generalizes the kernel\nsubspace model, and is termed the metric-constrained kernel union-of-subspaces\n(MC-KUoS) model. The main contributions of this paper in this regard include\nthe following. First, it motivates and formalizes the problems of MC-UoS and\nMC-KUoS learning. Second, it presents algorithms that efficiently learn an\nMC-UoS or an MC-KUoS underlying data of interest. Third, it extends these\nalgorithms to the case when parts of the data are missing. Last, but not least,\nit reports the outcomes of a series of numerical experiments involving both\nsynthetic and real data that demonstrate the superiority of the proposed\ngeometric models and learning algorithms over existing approaches in the\nliterature. These experiments also help clarify the connections between this\nwork and the literature on (subspace and kernel k-means) clustering.Comment: Extended version of the journal paper accepted for publication in\n  IEEE Trans. Signal Processing (20 pages, 7 figures, 4 tables)", "1412.7172": "Rational Groupthink,Harel, MatanMossel, ElchananStrack, PhilippTamuz, Omer,Computer Science - Computer Science and Game TheoryEconomics - Theoretical EconomicsMathematics - Probability,We study how long-lived rational agents learn from repeatedly observing each\nothers' actions. We find that in the long run, information aggregation fails,\nand the fraction of private information transmitted goes to zero as the number\nof agents gets large. With Normal signals, in the long-run, agents learn less\nfrom observing the actions of any number of other agents than they learn from\nseeing three other agents' signals. We identify rational groupthink---in which\nagents ignore their private signals and choose the same action for long periods\nof time---as the cause of this failure of information aggregation.", "1412.7646": "Sub-linear Time Support Recovery for Compressed Sensing using\n  Sparse-Graph Codes,Li, XiaoYin, DongPawar, SameerPedarsani, RamtinRamchandran, Kannan,Computer Science - Information Theory,We study the support recovery problem for compressed sensing, where the goal\nis to reconstruct the a high-dimensional $K$-sparse signal\n$\\mathbf{x}\\in\\mathbb{R}^N$, from low-dimensional linear measurements with and\nwithout noise. Our key contribution is a new compressed sensing framework\nthrough a new family of carefully designed sparse measurement matrices\nassociated with minimal measurement costs and a low-complexity recovery\nalgorithm. The measurement matrix in our framework is designed based on the\nwell-crafted sparsification through capacity-approaching sparse-graph codes,\nwhere the sparse coefficients can be recovered efficiently in a few iterations\nby performing simple error decoding over the observations. We formally connect\nthis general recovery problem with sparse-graph decoding in packet\ncommunication systems, and analyze our framework in terms of the measurement\ncost, time complexity and recovery performance. In the noiseless setting, our\nframework can recover any arbitrary $K$-sparse signal in $O(K)$ time using $2K$\nmeasurements asymptotically with high probability. In the noisy setting, when\nthe sparse coefficients take values in a finite and quantized alphabet, our\nframework can achieve the same goal in time $O(K\\log(N/K))$ using\n$O(K\\log(N/K))$ measurements obtained from measurement matrix with elements\n$\\{-1,0,1\\}$. When the sparsity $K$ is sub-linear in the signal dimension\n$K=O(N^\\delta)$ for some $0<\\delta<1$, our results are order-optimal in terms\nof measurement costs and run-time, both of which are sub-linear in the signal\ndimension $N$. The sub-linear measurement cost and run-time can also be\nachieved with continuous-valued sparse coefficients, with a slight increment in\nthe logarithmic factors. This offers the desired scalability of our framework\nthat can potentially enable real-time or near-real-time processing for massive\ndatasets featuring sparsity.", "1412.7725": "Automatic Photo Adjustment Using Deep Neural Networks,Yan, ZhichengZhang, HaoWang, BaoyuanParis, SylvainYu, Yizhou,Computer Science - Computer Vision and Pattern RecognitionComputer Science - GraphicsComputer Science - Machine LearningElectrical Engineering and Systems Science - Image and Video Processing,Photo retouching enables photographers to invoke dramatic visual impressions\nby artistically enhancing their photos through stylistic color and tone\nadjustments. However, it is also a time-consuming and challenging task that\nrequires advanced skills beyond the abilities of casual photographers. Using an\nautomated algorithm is an appealing alternative to manual work but such an\nalgorithm faces many hurdles. Many photographic styles rely on subtle\nadjustments that depend on the image content and even its semantics. Further,\nthese adjustments are often spatially varying. Because of these\ncharacteristics, existing automatic algorithms are still limited and cover only\na subset of these challenges. Recently, deep machine learning has shown unique\nabilities to address hard problems that resisted machine algorithms for long.\nThis motivated us to explore the use of deep learning in the context of photo\nediting. In this paper, we explain how to formulate the automatic photo\nadjustment problem in a way suitable for this approach. We also introduce an\nimage descriptor that accounts for the local semantics of an image. Our\nexperiments demonstrate that our deep learning formulation applied using these\ndescriptors successfully capture sophisticated photographic styles. In\nparticular and unlike previous techniques, it can model local adjustments that\ndepend on the image semantics. We show on several examples that this yields\nresults that are qualitatively and quantitatively better than previous work.Comment: TOG minor revision", "1412.7839": "Cloud K-SVD: A Collaborative Dictionary Learning Algorithm for Big,\n  Distributed Data,Raja, HaroonBajwa, Waheed U.,Computer Science - Machine LearningComputer Science - Information TheoryStatistics - Machine Learning,This paper studies the problem of data-adaptive representations for big,\ndistributed data. It is assumed that a number of geographically-distributed,\ninterconnected sites have massive local data and they are interested in\ncollaboratively learning a low-dimensional geometric structure underlying these\ndata. In contrast to previous works on subspace-based data representations,\nthis paper focuses on the geometric structure of a union of subspaces (UoS). In\nthis regard, it proposes a distributed algorithm---termed cloud K-SVD---for\ncollaborative learning of a UoS structure underlying distributed data of\ninterest. The goal of cloud K-SVD is to learn a common overcomplete dictionary\nat each individual site such that every sample in the distributed data can be\nrepresented through a small number of atoms of the learned dictionary. Cloud\nK-SVD accomplishes this goal without requiring exchange of individual samples\nbetween sites. This makes it suitable for applications where sharing of raw\ndata is discouraged due to either privacy concerns or large volumes of data.\nThis paper also provides an analysis of cloud K-SVD that gives insights into\nits properties as well as deviations of the dictionaries learned at individual\nsites from a centralized solution in terms of different measures of\nlocal/global data and topology of interconnections. Finally, the paper\nnumerically illustrates the efficacy of cloud K-SVD on real and synthetic\ndistributed data.Comment: Accepted for Publication in IEEE Trans. Signal Processing (2015); 16\n  pages, 3 figures", "1412.7998": "Propositional Logics of Dependence,Yang, FanV\u00e4\u00e4n\u00e4nen, Jouko,Mathematics - LogicComputer Science - Logic in Computer Science03B60,In this paper, we study logics of dependence on the propositional level. We\nprove that several interesting propositional logics of dependence, including\npropositional dependence logic, propositional intuitionistic dependence logic\nas well as propositional inquisitive logic, are expressively complete and have\ndisjunctive or conjunctive normal forms. We provide deduction systems and prove\nthe completeness theorems for these logics.", "1412.8324": "A Constructive Proof on the Compositionality of Linearizability,Lin, Haoxiang,Computer Science - Distributed, Parallel, and Cluster Computing,Linearizability is the strongest correctness property for both shared memory\nand message passing systems. One of its useful features is the\ncompositionality: a history (execution) is linearizable if and only if each\nobject (component) subhistory is linearizable. In this paper, we propose a new\nhierarchical system model to address challenges in modular development of cloud\nsystems. Object are defined by induction from the most fundamental atomic\nBoolean registers, and histories are represented as countable well-ordered\nstructures of events to deal with both finite and infinite executions. Then, we\npresent a new constructive proof on the compositionality theorem of\nlinearizability inspired by Multiway Merge. This proof deduces a theoretically\nefficient algorithm which generates linearization in O(N*logP) running time\nwith O(N) space, where P and N are process/event numbers respectively.", "1412.8358": "Odd graph and its applications to the strong edge coloring,Wang, TaoZhao, Xiaodan,Mathematics - CombinatoricsComputer Science - Discrete Mathematics05C15,A strong edge coloring of a graph is a proper edge coloring in which every\ncolor class is an induced matching. The strong chromatic index $\\chi_s'(G)$ of\na graph $G$ is the minimum number of colors in a strong edge coloring of $G$.\nLet $\\Delta \\geq 4$ be an integer. In this note, we study the odd graphs and\nshow the existence of some special walks. By using these results and Chang's\nideas in [Discuss. Math. Graph Theory 34 (4) (2014) 723--733], we show that\nevery planar graph with maximum degree at most $\\Delta$ and girth at least $10\n\\Delta - 4$ has a strong edge coloring with $2\\Delta - 1$ colors. In addition,\nwe prove that if $G$ is a graph with girth at least $2\\Delta - 1$ and mad$(G) <\n2 + \\frac{1}{3\\Delta - 2}$, where $\\Delta$ is the maximum degree and $\\Delta\n\\geq 4$, then $\\chi_s'(G) \\leq 2\\Delta - 1$, if $G$ is a subcubic graph with\ngirth at least $8$ and mad$(G) < 2 + \\frac{2}{23}$, then $\\chi_s'(G) \\leq 5$.Comment: 7 pages", "1412.8591": "Maze Solving Automatons for Self-Healing of Open Interconnects: Modular\n  Add-on for Circuit Boards,Nair, AswathiRaghunandan, KarthikYaswanth, VaddiShridharan, SreelalSambandan, Sanjiv,Computer Science - Emerging TechnologiesCondensed Matter - Soft Condensed Matter,We present the circuit board integration of a self-healing mechanism to\nrepair open faults. The electric field driven mechanism physically restores\nfractured interconnects in electronic circuits and has the ability to solve\nmazes. The repair is performed by conductive particles dispersed in an\ninsulating fluid. We demonstrate the integration of the healing module onto\nprinted circuit boards and the ability of maze solving. We model and perform\nexperiments on the influence of the geometry of the conductive particles as\nwell as the terminal impedances of the route on the healing efficiency. The\ntypical heal rate is 10 $\\mu$m/s with healed route having resistance of 100\n$\\Omega$ to 20 k$\\Omega$ depending on the materials and concentrations used.", "1501.00433": "On the Uniform Computational Content of Computability Theory,Brattka, VascoHendtlass, MatthewKreuzer, Alexander P.,Mathematics - LogicComputer Science - Logic in Computer Science,We demonstrate that the Weihrauch lattice can be used to classify the uniform\ncomputational content of computability-theoretic properties as well as the\ncomputational content of theorems in one common setting. The properties that we\nstudy include diagonal non-computability, hyperimmunity, complete consistent\nextensions of Peano arithmetic, 1-genericity, Martin-L\\\"of randomness, and\ncohesiveness. The theorems that we include in our case study are the low basis\ntheorem of Jockusch and Soare, the Kleene-Post theorem, and Friedberg's jump\ninversion theorem. It turns out that all the aforementioned properties and many\ntheorems in computability theory, including all theorems that claim the\nexistence of some Turing degree, have very little uniform computational\ncontent: they are located outside of the upper cone of binary choice (also\nknown as LLPO); we call problems with this property indiscriminative. Since\npractically all theorems from classical analysis whose computational content\nhas been classified are discriminative, our observation could yield an\nexplanation for why theorems and results in computability theory typically have\nvery few direct consequences in other disciplines such as analysis. A notable\nexception in our case study is the low basis theorem which is discriminative.\nThis is perhaps why it is considered to be one of the most applicable theorems\nin computability theory. In some cases a bridge between the indiscriminative\nworld and the discriminative world of classical mathematics can be established\nvia a suitable residual operation and we demonstrate this in the case of the\ncohesiveness problem and the problem of consistent complete extensions of Peano\narithmetic. Both turn out to be the quotient of two discriminative problems.Comment: 42 pages", "1501.00960": "Characterizing the Google Books corpus: Strong limits to inferences of\n  socio-cultural and linguistic evolution,Pechenick, Eitan AdamDanforth, Christopher M.Dodds, Peter Sheridan,Physics - Physics and SocietyCondensed Matter - Statistical MechanicsComputer Science - Computation and LanguageStatistics - Applications,It is tempting to treat frequency trends from the Google Books data sets as\nindicators of the \"true\" popularity of various words and phrases. Doing so\nallows us to draw quantitatively strong conclusions about the evolution of\ncultural perception of a given topic, such as time or gender. However, the\nGoogle Books corpus suffers from a number of limitations which make it an\nobscure mask of cultural popularity. A primary issue is that the corpus is in\neffect a library, containing one of each book. A single, prolific author is\nthereby able to noticeably insert new phrases into the Google Books lexicon,\nwhether the author is widely read or not. With this understood, the Google\nBooks corpus remains an important data set to be considered more lexicon-like\nthan text-like. Here, we show that a distinct problematic feature arises from\nthe inclusion of scientific texts, which have become an increasingly\nsubstantive portion of the corpus throughout the 1900s. The result is a surge\nof phrases typical to academic articles but less common in general, such as\nreferences to time in the form of citations. We highlight these dynamics by\nexamining and comparing major contributions to the statistical divergence of\nEnglish data sets between decades in the period 1800--2000. We find that only\nthe English Fiction data set from the second version of the corpus is not\nheavily affected by professional texts, in clear contrast to the first version\nof the fiction data set and both unfiltered English data sets. Our findings\nemphasize the need to fully characterize the dynamics of the Google Books\ncorpus before using these data sets to draw broad conclusions about cultural\nand linguistic evolution.Comment: 13 pages, 16 figures", "1501.01042": "Augur: a decentralized oracle and prediction market platform,Peterson, JackKrug, JosephZoltu, MicahWilliams, Austin K.Alexander, Stephanie,Computer Science - Cryptography and Security,Augur is a trustless, decentralized oracle and platform for prediction\nmarkets. The outcomes of Augur's prediction markets are chosen by users that\nhold Augur's native Reputation token, who stake their tokens on the actual\nobserved outcome and, in return, receive settlement fees from the markets.\nAugur's incentive structure is designed to ensure that honest, accurate\nreporting of outcomes is always the most profitable option for Reputation token\nholders. Token holders can post progressively-larger Reputation bonds to\ndispute proposed market outcomes. If the size of these bonds reaches a certain\nthreshold, Reputation splits into multiple versions, one for each possible\noutcome of the disputed market; token holders must then exchange their\nReputation tokens for one of these versions. Versions of Reputation which do\nnot correspond to the real-world outcome will become worthless, as no one will\nparticipate in prediction markets unless they are confident that the markets\nwill resolve correctly. Therefore, token holders will select the only version\nof Reputation which they know will continue to have value: the version that\ncorresponds to reality.Comment: 19 pages, 2 figures", "1501.02741": "Salient Object Detection: A Benchmark,Borji, AliCheng, Ming-MingJiang, HuaizuLi, Jia,Computer Science - Computer Vision and Pattern Recognition,We extensively compare, qualitatively and quantitatively, 40 state-of-the-art\nmodels (28 salient object detection, 10 fixation prediction, 1 objectness, and\n1 baseline) over 6 challenging datasets for the purpose of benchmarking salient\nobject detection and segmentation methods. From the results obtained so far,\nour evaluation shows a consistent rapid progress over the last few years in\nterms of both accuracy and running time. The top contenders in this benchmark\nsignificantly outperform the models identified as the best in the previous\nbenchmark conducted just two years ago. We find that the models designed\nspecifically for salient object detection generally work better than models in\nclosely related areas, which in turn provides a precise definition and suggests\nan appropriate treatment of this problem that distinguishes it from other\nproblems. In particular, we analyze the influences of center bias and scene\ncomplexity in model performance, which, along with the hard cases for\nstate-of-the-art models, provide useful hints towards constructing more\nchallenging large scale datasets and better saliency models. Finally, we\npropose probable solutions for tackling several open problems such as\nevaluation scores and dataset bias, which also suggest future research\ndirections in the rapidly-growing field of salient object detection.", "1501.03043": "Functionals and hardware,Ambroszkiewicz, Stanislaw,Mathematics - LogicComputer Science - Logic in Computer Science03DF.4.1,Functionals are an important research subject in Mathematics and Computer\nScience as well as a challenge in Information Technologies where the current\nprogramming paradigm states that only symbolic computations are possible on\nhigher order objects, i.e. functionals are terms, and computation is term\nrewriting. The idea explored in the paper is that functionals correspond to\ngeneric mechanisms for management of connections in arrays consisting of first\norder functional units. Functionals are higher order abstractions that are\nuseful for the management of such large arrays. Computations on higher order\nobjects comprise dynamic configuration of connections between first order\nelementary functions in the arrays. Once the functionals are considered as the\ngeneric mechanisms, they have a grounding in hardware. A conceptual framework\nfor constructing such mechanisms is presented, and their hardware realization\nis discussed.Comment: minor changes - September 12, 2018", "1501.03347": "Dirichlet Process Parsimonious Mixtures for clustering,Chamroukhi, FaicelBartcus, MariusGlotin, Herv\u00e9,Statistics - Machine LearningComputer Science - Machine LearningStatistics - Methodology,The parsimonious Gaussian mixture models, which exploit an eigenvalue\ndecomposition of the group covariance matrices of the Gaussian mixture, have\nshown their success in particular in cluster analysis. Their estimation is in\ngeneral performed by maximum likelihood estimation and has also been considered\nfrom a parametric Bayesian prospective. We propose new Dirichlet Process\nParsimonious mixtures (DPPM) which represent a Bayesian nonparametric\nformulation of these parsimonious Gaussian mixture models. The proposed DPPM\nmodels are Bayesian nonparametric parsimonious mixture models that allow to\nsimultaneously infer the model parameters, the optimal number of mixture\ncomponents and the optimal parsimonious mixture structure from the data. We\ndevelop a Gibbs sampling technique for maximum a posteriori (MAP) estimation of\nthe developed DPMM models and provide a Bayesian model selection framework by\nusing Bayes factors. We apply them to cluster simulated data and real data\nsets, and compare them to the standard parsimonious mixture models. The\nobtained results highlight the effectiveness of the proposed nonparametric\nparsimonious mixture models as a good nonparametric alternative for the\nparametric parsimonious models.", "1501.03872": "The Dead Cryptographers Society Problem,Barbosa, Andr\u00e9 Luiz,Computer Science - Computational ComplexityComputer Science - Cryptography and Security94A60 (Primary), 94A62 (Secondary),This paper defines The Dead Cryptographers Society Problem - DCS (where\nseveral great cryptographers created many polynomial-time Deterministic Turing\nMachines (DTMs) of a specific type, ran them on their proper descriptions\nconcatenated with some arbitrary strings, deleted them and left only the\nresults from those running, after they died: if those DTMs only permute and\nsometimes invert the bits on input, is it possible to decide the language\nformed by such resulting strings within polynomial time?), proves some facts\nabout its computational complexity, and discusses some possible uses on\nCryptography, such as into distance keys distribution, online reverse auction\nand secure communication.Comment: 7 pages, 2 tables, 1 JavaScript code and some great new ideas on\n  Cryptography!", "1501.04147": "Categorified Reeb Graphs,de Silva, VinMunch, ElizabethPatel, Amit,Computer Science - Computational Geometry,The Reeb graph is a construction which originated in Morse theory to study a\nreal valued function defined on a topological space. More recently, it has been\nused in various applications to study noisy data which creates a desire to\ndefine a measure of similarity between these structures. Here, we exploit the\nfact that the category of Reeb graphs is equivalent to the category of a\nparticular class of cosheaf. Using this equivalency, we can define an\n`interleaving' distance between Reeb graphs which is stable under the\nperturbation of a function. Along the way, we obtain a natural construction for\nsmoothing a Reeb graph to reduce its topological complexity. The smoothed Reeb\ngraph can be constructed in polynomial time.", "1501.04318": "Clustering based on the In-tree Graph Structure and Affinity Propagation,Qiu, TengLi, Yongjie,Computer Science - Machine LearningComputer Science - Computer Vision and Pattern RecognitionStatistics - Machine Learning,A recently proposed clustering method, called the Nearest Descent (ND), can\norganize the whole dataset into a sparsely connected graph, called the In-tree.\nThis ND-based Intree structure proves able to reveal the clustering structure\nunderlying the dataset, except one imperfect place, that is, there are some\nundesired edges in this In-tree which require to be removed. Here, we propose\nan effective way to automatically remove the undesired edges in In-tree via an\neffective combination of the In-tree structure with affinity propagation (AP).\nThe key for the combination is to add edges between the reachable nodes in\nIn-tree before using AP to remove the undesired edges. The experiments on both\nsynthetic and real datasets demonstrate the effectiveness of the proposed\nmethod.", "1501.04343": "Algorithms for Scheduling Malleable Cloud Tasks,Wu, XiaohuLoiseau, Patrick,Computer Science - Distributed, Parallel, and Cluster ComputingComputer Science - Data Structures and Algorithms,Due to the ubiquity of batch data processing in cloud computing, the related\nproblem of scheduling malleable batch tasks and its extensions have received\nsignificant attention recently. In this paper, we consider a fundamental model\nwhere a set of n tasks is to be processed on C identical machines and each task\nis specified by a value, a workload, a deadline and a parallelism bound. Within\nthe parallelism bound, the number of machines assigned to a task can vary over\ntime without affecting its workload. For this model, we obtain two core\nresults: a sufficient and necessary condition such that a set of tasks can be\nfinished by their deadlines on C machines, and an algorithm to produce such a\nschedule. These core results provide a conceptual tool and an optimal\nscheduling algorithm that enable proposing new algorithmic analysis and design\nand improving existing algorithms under various objectives.Comment: The conference version of this manuscript appeared at the 53rd Annual\n  Allerton Conference on Communication, Control, and Computing, 2015", "1501.04706": "A Novel Implementation of QuickHull Algorithm on the GPU,Zhang, JiayinMei, GangXu, NengxiongZhao, Kunyang,Computer Science - Computational GeometryComputer Science - Graphics,We present a novel GPU-accelerated implementation of the QuickHull algorihtm\nfor calculating convex hulls of planar point sets. We also describe a practical\nsolution to demonstrate how to efficiently implement a typical\nDivide-and-Conquer algorithm on the GPU. We highly utilize the parallel\nprimitives provided by the library Thrust such as the parallel segmented scan\nfor better efficiency and simplicity. To evaluate the performance of our\nimplementation, we carry out four groups of experimental tests using two groups\nof point sets in two modes on the GPU K20c. Experimental results indicate that:\nour implementation can achieve the speedups of up to 10.98x over the\nstate-of-art CPU-based convex hull implementation Qhull [16]. In addition, our\nimplementation can find the convex hull of 20M points in about 0.2 seconds.Comment: 10 pages, 5 figures", "1501.04836": "Subtropical Real Root Finding,Sturm, Thomas,Computer Science - Symbolic Computation,We describe a new incomplete but terminating method for real root finding for\nlarge multivariate polynomials. We take an abstract view of the polynomial as\nthe set of exponent vectors associated with sign information on the\ncoefficients. Then we employ linear programming to heuristically find roots.\nThere is a specialized variant for roots with exclusively positive coordinates,\nwhich is of considerable interest for applications in chemistry and systems\nbiology. An implementation of our method combining the computer algebra system\nReduce with the linear programming solver Gurobi has been successfully applied\nto input data originating from established mathematical models used in these\nareas. We have solved several hundred problems with up to more than 800000\nmonomials in up to 10 variables with degrees up to 12. Our method has failed\ndue to its incompleteness in less than 8 percent of the cases.", "1501.05098": "Better Answers to Real Questions,Kosta, MarekSturm, ThomasDolzmann, Andreas,Computer Science - Symbolic ComputationComputer Science - Logic in Computer Science,We consider existential problems over the reals. Extended quantifier\nelimination generalizes the concept of regular quantifier elimination by\nproviding in addition answers, which are descriptions of possible assignments\nfor the quantified variables. Implementations of extended quantifier\nelimination via virtual substitution have been successfully applied to various\nproblems in science and engineering. So far, the answers produced by these\nimplementations included infinitesimal and infinite numbers, which are hard to\ninterpret in practice. We introduce here a post-processing procedure to\nconvert, for fixed parameters, all answers into standard real numbers. The\nrelevance of our procedure is demonstrated by application of our implementation\nto various examples from the literature, where it significantly improves the\nquality of the results.", "1501.05151": "Recursive Bayesian Filtering in Circular State Spaces,Kurz, GerhardGilitschenski, IgorHanebeck, Uwe D.,Computer Science - Systems and ControlComputer Science - Robotics,For recursive circular filtering based on circular statistics, we introduce a\ngeneral framework for estimation of a circular state based on different\ncircular distributions, specifically the wrapped normal distribution and the\nvon Mises distribution. We propose an estimation method for circular systems\nwith nonlinear system and measurement functions. This is achieved by relying on\nefficient deterministic sampling techniques. Furthermore, we show how the\ncalculations can be simplified in a variety of important special cases, such as\nsystems with additive noise as well as identity system or measurement\nfunctions. We introduce several novel key components, particularly a\ndistribution-free prediction algorithm, a new and superior formula for the\nmultiplication of wrapped normal densities, and the ability to deal with\nnon-additive system noise. All proposed methods are thoroughly evaluated and\ncompared to several state-of-the-art solutions.", "1501.05260": "An Algebra of Reversible Quantum Computing,Wang, Yong,Computer Science - Logic in Computer Science,We extend the algebra of reversible computation to support quantum computing.\nSince the algebra is based on true concurrency, it is reversible for quantum\ncomputing and it has a sound and complete theory.", "1501.05354": "A speed and departure time optimization algorithm for the\n  Pollution-Routing Problem,Kramer, RaphaelMaculan, NelsonSubramanian, AnandVidal, Thibaut,Computer Science - Data Structures and Algorithms,We propose a new speed and departure time optimization algorithm for the\nPollution-Routing Problem (PRP), which runs in quadratic time and returns a\ncertified optimal schedule. This algorithm is embedded into an iterated local\nsearch-based metaheuristic to achieve a combined speed, scheduling and routing\noptimization. The start of the working day is set as a decision variable for\nindividual routes, thus enabling a better assignment of human resources to\nrequired demands. Some routes that were evaluated as unprofitable can now\nappear as viable candidates later in the day, leading to a larger search space\nand further opportunities of distance optimization via better service\nconsolidation. Extensive computational experiments on available PRP benchmark\ninstances demonstrate the good performance of the algorithms. The flexible\ndeparture times from the depot contribute to reduce the operational costs by\n8.36% on the considered instances.Comment: 12 pages", "1501.06076": "Fourier Analysis of MAC Polarization,Nasser, RajaiTelatar, Emre,Computer Science - Information Theory,One problem with MAC polar codes that are based on MAC polarization is that\nthey may not achieve the entire capacity region. The reason behind this problem\nis that MAC polarization sometimes induces a loss in the capacity region. This\npaper provides a single letter necessary and sufficient condition which\ncharacterizes all the MACs that do not lose any part of their capacity region\nby polarization.Comment: 33 pages, accepted to IEEE Trans. Inform. Theory and presented in\n  part in ISIT2015", "1501.06297": "Geodesic convolutional neural networks on Riemannian manifolds,Masci, JonathanBoscaini, DavideBronstein, Michael M.Vandergheynst, Pierre,Computer Science - Computer Vision and Pattern Recognition,Feature descriptors play a crucial role in a wide range of geometry analysis\nand processing applications, including shape correspondence, retrieval, and\nsegmentation. In this paper, we introduce Geodesic Convolutional Neural\nNetworks (GCNN), a generalization of the convolutional networks (CNN) paradigm\nto non-Euclidean manifolds. Our construction is based on a local geodesic\nsystem of polar coordinates to extract \"patches\", which are then passed through\na cascade of filters and linear and non-linear operators. The coefficients of\nthe filters and linear combination weights are optimization variables that are\nlearned to minimize a task-specific cost function. We use GCNN to learn\ninvariant shape features, allowing to achieve state-of-the-art performance in\nproblems such as shape description, retrieval, and correspondence.", "1501.06654": "Compressive Sampling of Ensembles of Correlated Signals,Ahmed, AliRomberg, Justin,Computer Science - Information Theory,We propose several sampling architectures for the efficient acquisition of an\nensemble of correlated signals. We show that without prior knowledge of the\ncorrelation structure, each of our architectures (under different sets of\nassumptions) can acquire the ensemble at a sub-Nyquist rate. Prior to sampling,\nthe analog signals are diversified using simple, implementable components. The\ndiversification is achieved by injecting types of \"structured randomness\" into\nthe ensemble, the result of which is subsampled. For reconstruction, the\nensemble is modeled as a low-rank matrix that we have observed through an\n(undetermined) set of linear equations. Our main results show that this matrix\ncan be recovered using standard convex programming techniques when the total\nnumber of samples is on the order of the intrinsic degree of freedom of the\nensemble --- the more heavily correlated the ensemble, the fewer samples are\nneeded.\n  To motivate this study, we discuss how such ensembles arise in the context of\narray processing.Comment: 40 pages, 10 figures, journal. arXiv admin note: substantial text\n  overlap with arXiv:1308.5146", "1501.07496": "Implementation of an Automatic Syllabic Division Algorithm from Speech\n  Files in Portuguese Language,Da Silva, E. L. F.de Oliveira, H. M.,Computer Science - SoundComputer Science - Computation and LanguageComputer Science - Data Structures and AlgorithmsElectrical Engineering and Systems Science - Audio and Speech Processing,A new algorithm for voice automatic syllabic splitting in the Portuguese\nlanguage is proposed, which is based on the envelope of the speech signal of\nthe input audio file. A computational implementation in MatlabTM is presented\nand made available at the URL\nhttp://www2.ee.ufpe.br/codec/divisao_silabica.html. Due to its\nstraightforwardness, the proposed method is very attractive for embedded\nsystems (e.g. i-phones). It can also be used as a screen to assist more\nsophisticated methods. Voice excerpts containing more than one syllable and\nidentified by the same envelope are named as super-syllables and they are\nsubsequently separated. The results indicate which samples corresponds to the\nbeginning and end of each detected syllable. Preliminary tests were performed\nto fifty words at an identification rate circa 70% (further improvements may be\nincorporated to treat particular phonemes). This algorithm is also useful in\nvoice command systems, as a tool in the teaching of Portuguese language or even\nfor patients with speech pathology.Comment: 9 pages, 7 figures, 4 tables, conference: XIX Congresso Brasileiro de\n  Automatica CBA, Campina Grande, Setembro, 2012", "1501.07584": "Efficient Divide-And-Conquer Classification Based on Feature-Space\n  Decomposition,Guo, QiChen, Bo-WeiJiang, FengJi, XiangyangKung, Sun-Yuan,Computer Science - Machine Learning,This study presents a divide-and-conquer (DC) approach based on feature space\ndecomposition for classification. When large-scale datasets are present,\ntypical approaches usually employed truncated kernel methods on the feature\nspace or DC approaches on the sample space. However, this did not guarantee\nseparability between classes, owing to overfitting. To overcome such problems,\nthis work proposes a novel DC approach on feature spaces consisting of three\nsteps. Firstly, we divide the feature space into several subspaces using the\ndecomposition method proposed in this paper. Subsequently, these feature\nsubspaces are sent into individual local classifiers for training. Finally, the\noutcomes of local classifiers are fused together to generate the final\nclassification results. Experiments on large-scale datasets are carried out for\nperformance evaluation. The results show that the error rates of the proposed\nDC method decreased comparing with the state-of-the-art fast SVM solvers, e.g.,\nreducing error rates by 10.53% and 7.53% on RCV1 and covtype datasets\nrespectively.Comment: 5 pages", "1501.07637": "Simple Mechanisms for a Subadditive Buyer and Applications to Revenue\n  Monotonicity,Rubinstein, AviadWeinberg, S. Matthew,Computer Science - Computer Science and Game Theory,We study the revenue maximization problem of a seller with n heterogeneous\nitems for sale to a single buyer whose valuation function for sets of items is\nunknown and drawn from some distribution D. We show that if D is a distribution\nover subadditive valuations with independent items, then the better of pricing\neach item separately or pricing only the grand bundle achieves a\nconstant-factor approximation to the revenue of the optimal mechanism. This\nincludes buyers who are k-demand, additive up to a matroid constraint, or\nadditive up to constraints of any downwards-closed set system (and whose values\nfor the individual items are sampled independently), as well as buyers who are\nfractionally subadditive with item multipliers drawn independently. Our proof\nmakes use of the core-tail decomposition framework developed in prior work\nshowing similar results for the significantly simpler class of additive buyers\n[LY13, BILW14].\n  In the second part of the paper, we develop a connection between\napproximately optimal simple mechanisms and approximate revenue monotonicity\nwith respect to buyers' valuations. Revenue non-monotonicity is the phenomenon\nthat sometimes strictly increasing buyers' values for every set can strictly\ndecrease the revenue of the optimal mechanism [HR12]. Using our main result, we\nderive a bound on how bad this degradation can be (and dub such a bound a proof\nof approximate revenue monotonicity); we further show that better bounds on\napproximate monotonicity imply a better analysis of our simple mechanisms.Comment: Updated title and body to version included in TEAC. Adapted Theorem\n  5.2 to accommodate \\eta-BIC auctions (versus exactly BIC)", "1502.00112": "Bar recursion in classical realisability : dependent choice and\n  continuum hypothesis,Krivine, Jean-Louis,Computer Science - Logic in Computer ScienceMathematics - Logic03E40F.4.1,This paper is about the bar recursion operator in the context of classical\nrealizability. After the pioneering work of Berardi, Bezem & Coquand [1], T.\nStreicher has shown [10], by means of their bar recursion operator, that the\nrealizability models of ZF, obtained from usual models of $\\lambda$-calculus\n(Scott domains, coherent spaces, . . .), satisfy the axiom of dependent choice.\nWe give a proof of this result, using the tools of classical realizability.\nMoreover, we show that these realizability models satisfy the well ordering of\n$\\mathbb{R}$ and the continuum hypothesis These formulas are therefore realized\nby closed $\\lambda_c$-terms. This allows to obtain programs from proofs of\narithmetical formulas using all these axioms.Comment: 11 pages", "1502.01187": "Reversibility of d-State Finite Cellular Automata,Bhattacharjee, KamalikaDas, Sukanta,Computer Science - Formal Languages and Automata Theory,This paper investigates reversibility properties of 1-dimensional\n3-neighborhood d-state finite cellular automata (CAs) of length n under\nperiodic boundary condition. A tool named reachability tree has been developed\nfrom de Bruijn graph which represents all possible reachable configurations of\nan n-cell CA. This tool has been used to test reversibility of CAs. We have\nidentified a large set of reversible CAs using this tool by following some\ngreedy strategies.Comment: Copyright of Old City Publishing", "1502.01410": "On the Lexical Distinguishability of Source Code,Velez, MartinQiu, DongZhou, YouBarr, Earl T.Su, Zhendong,Computer Science - Software Engineering,Natural language is robust against noise. The meaning of many sentences\nsurvives the loss of words, sometimes many of them. Some words in a sentence,\nhowever, cannot be lost without changing the meaning of the sentence. We call\nthese words \"wheat\" and the rest \"chaff\". The word \"not\" in the sentence \"I do\nnot like rain\" is wheat and \"do\" is chaff. For human understanding of the\npurpose and behavior of source code, we hypothesize that the same holds. To\nquantify the extent to which we can separate code into \"wheat\" and \"chaff\", we\nstudy a large (100M LOC), diverse corpus of real-world projects in Java. Since\nmethods represent natural, likely distinct units of code, we use the ~9M Java\nmethods in the corpus to approximate a universe of \"sentences.\" We extract\ntheir wheat by computing the function's minimal distinguishing subset (Minset).\nOur results confirm that functions contain work offers the first quantitative\nevidence for recent promising work on keyword-based programming and insight\ninto how to develop a powerful, alternative programming model.Comment: 14 pages, 10 figures, Under Submission", "1502.01494": "Code generator matrices as RNG conditioners,Tomasi, AlessandroMeneghetti, AlessioSala, Massimiliano,Computer Science - Information Theory65C10, 60B99, 11T71, 94B99E.4G.3,We quantify precisely the distribution of the output of a binary random\nnumber generator (RNG) after conditioning with a binary linear code generator\nmatrix by showing the connection between the Walsh spectrum of the resulting\nrandom variable and the weight distribution of the code. Previously known\nbounds on the performance of linear binary codes as entropy extractors can be\nderived by considering generator matrices as a selector of a subset of that\nspectrum. We also extend this framework to the case of non-binary codes.", "1502.01566": "A Matrix Laurent Series-based Fast Fourier Transform for Blocklengths\n  N=4 (mod 8),de Oliveira, H. M.de Souza, R. M. Campellode Oliveira, R. C.,Computer Science - Data Structures and AlgorithmsComputer Science - Discrete MathematicsElectrical Engineering and Systems Science - Signal Processing,General guidelines for a new fast computation of blocklength 8m+4 DFTs are\npresented, which is based on a Laurent series involving matrices. Results of\nnon-trivial real multiplicative complexity are presented for blocklengths N=64,\nachieving lower multiplication counts than previously published FFTs. A\ndetailed description for the cases m=1 and m=2 is presented.Comment: 6 pages, 2 figures, 2 tables. Conference: XXVII Simposio Brasileiro\n  de Telecomunicacoes - SBrT'09, 2009, Blumenau, SC, Brazil", "1502.01865": "Lower Bounds for Monotone Counting Circuits,Jukna, Stasys,Computer Science - Computational Complexity,A {+,x}-circuit counts a given multivariate polynomial f, if its values on\n0-1 inputs are the same as those of f; on other inputs the circuit may output\narbitrary values. Such a circuit counts the number of monomials of f evaluated\nto 1 by a given 0-1 input vector (with multiplicities given by their\ncoefficients). A circuit decides $f$ if it has the same 0-1 roots as f. We\nfirst show that some multilinear polynomials can be exponentially easier to\ncount than to compute them, and can be exponentially easier to decide than to\ncount them. Then we give general lower bounds on the size of counting circuits.Comment: 20 pages", "1502.02253": "Data Bits in Karnaugh Map and Increasing Map Capability in Error\n  Correcting,Pezeshkpour, PouyaTabandeh, Mahmoud,Computer Science - Information Theory,To provide reliable communication in data transmission, ability of correcting\nerrors is of prime importance. This paper intends to suggest an easy algorithm\nto detect and correct errors in transmission codes using the well-known\nKarnaugh map. Referring to past research done and proving new theorems and also\nusing a suggested simple technique taking advantage of the easy concept of\nKarnaugh map, we offer an algorithm to reduce the number of occupied squares in\nthe map and therefore, reduce substantially the execution time for placing data\nbits in Karnaugh map. Based on earlier papers, we first propose an algorithm\nfor correction of two simultaneous errors in a code. Then, defining\nspecifications for empty squares of the map, we limit the choices for selection\nof new squares. In addition, burst errors in sending codes is discussed, and\nsystematically code words for correcting them will be made.Comment: 8 pages, 4 figures, 1 table", "1502.02272": "Rigorous Deductive Argumentation for Socially Relevant Issues,Wehr, Robert Dustin,Computer Science - Logic in Computer ScienceMathematics - Logic03Bxx, 03B52, 03B10, 03AxxI.2.3F.4.mI.2.4F.4.0,The most important problems for society are describable only in vague terms,\ndependent on subjective positions, and missing highly relevant data. This\nthesis is intended to revive and further develop the view that giving\nnon-trivial, rigorous deductive arguments concerning such problems -without\neliminating the complications of vagueness, subjectivity, and uncertainty- is,\nthough very difficult, not problematic in principle, does not require the\ninvention of new logics -classical first-order logic will do- and is something\nthat more mathematically-inclined people should be pursuing. The framework of\ninterpreted formal proofs is presented for formalizing and criticizing rigorous\ndeductive arguments about vague, subjective, and uncertain issues, and its\nadequacy is supported largely by a number of major examples. This thesis also\ndocuments progress towards a web system for collaboratively authoring and\ncriticizing such arguments, which is the ultimate goal of this project.Comment: PhD Thesis. 130 pages", "1502.02348": "MATLAB based language for generating randomized multiple choice\n  questions,Azamov, Nurulla,Computer Science - Computers and Society,In this work we describe a simple MATLAB based language which allows to\ncreate randomized multiple choice questions with minimal effort. This language\nhas been successfully tested at Flinders University by the author in a number\nof mathematics topics including Numerical Analysis, Abstract Algebra and\nPartial Differential Equations.Comment: 38 pages", "1502.02481": "Dynamic DFS Tree in Undirected Graphs: breaking the $O(m)$ barrier,Baswana, SurenderChaudhury, Shreejit RayChoudhary, KeertiKhan, Shahbaz,Computer Science - Data Structures and Algorithms,Depth first search (DFS) tree is a fundamental data structure for solving\nvarious problems in graphs. It is well known that it takes $O(m+n)$ time to\nbuild a DFS tree for a given undirected graph $G=(V,E)$ on $n$ vertices and $m$\nedges. We address the problem of maintaining a DFS tree when the graph is\nundergoing {\\em updates} (insertion and deletion of vertices or edges). We\npresent the following results for this problem.\n  (a) Fault tolerant DFS tree: There exists a data structure of size ${O}(m\n~polylog~ n)$ such that given any set ${\\cal F}$ of failed vertices or edges, a\nDFS tree of the graph $G\\setminus {\\cal F}$ can be reported in ${O}(n|{\\cal F}|\n~polylog~ n)$ time.\n  (b) Fully dynamic DFS tree: There exists a fully dynamic algorithm for\nmaintaining a DFS tree that takes worst case ${O}(\\sqrt{mn} ~polylog~ n)$ time\nper update for any arbitrary online sequence of updates.\n  (c) Incremental DFS tree: Given any arbitrary online sequence of edge\ninsertions, we can maintain a DFS tree in ${O}(n ~polylog~ n)$ worst case time\nper edge insertion.\n  These are the first $o(m)$ worst case time results for maintaining a DFS tree\nin a dynamic environment. Moreover, our fully dynamic algorithm provides, in a\nseamless manner, the first deterministic algorithm with $O(1)$ query time and\n$o(m)$ worst case update time for the dynamic subgraph connectivity,\nbiconnectivity, and 2-edge connectivity.Comment: 27 pages, SODA 2016", "1502.02511": "Measurement Scale Effect on Prediction of Soil Water Retention Curve and\n  Saturated Hydraulic Conductivity,Ghanbarian, BehzadTaslimitehrani, VahidDong, GuozhuPachepsky, Yakov A.,Computer Science - Computational Engineering, Finance, and ScienceComputer Science - Databases,Soil water retention curve (SWRC) and saturated hydraulic conductivity (SHC)\nare key hydraulic properties for unsaturated zone hydrology and groundwater. In\nparticular, SWRC provides useful information on entry pore-size distribution,\nand SHC is required for flow and transport modeling in the hydrologic cycle.\nNot only the SWRC and SHC measurements are time-consuming, but also scale\ndependent. This means as soil column volume increases, variability of the SWRC\nand SHC decreases. Although prediction of the SWRC and SHC from available\nparameters, such as textural data, organic matter, and bulk density have been\nunder investigation for decades, up to now no research has focused on the\neffect of measurement scale on the soil hydraulic properties pedotransfer\nfunctions development. In the literature, several data mining approaches have\nbeen applied, such as multiple linear regression, artificial neural networks,\ngroup method of data handling. However, in this study we develop pedotransfer\nfunctions using a novel approach called contrast pattern aided regression\n(CPXR) and compare it with the multiple linear regression method. For this\npurpose, two databases including 210 and 213 soil samples are collected to\ndevelop and evaluate pedotransfer functions for the SWRC and SHC, respectively,\nfrom the UNSODA database. The 10-fold cross-validation method is applied to\nevaluate the accuracy and reliability of the proposed regression-based models.\nOur results show that including measurement scale parameters, such as sample\ninternal diameter and length could substantially improve the accuracy of the\nSWRC and SHC pedotransfer functions developed using the CPXR method, while this\nis not the case when MLR is used. Moreover, the CPXR method yields remarkably\nmore accurate soil water retention curve and saturated hydraulic conductivity\npredictions than the MLR approach.", "1502.02800": "Fast integer multiplication using generalized Fermat primes,Covanov, SvyatoslavThom\u00e9, Emmanuel,Computer Science - Symbolic ComputationComputer Science - Computational ComplexityComputer Science - Discrete MathematicsComputer Science - Data Structures and Algorithms,For almost 35 years, Sch{\\\"o}nhage-Strassen's algorithm has been the fastest\nalgorithm known for multiplying integers, with a time complexity O(n $\\times$\nlog n $\\times$ log log n) for multiplying n-bit inputs. In 2007, F{\\\"u}rer\nproved that there exists K > 1 and an algorithm performing this operation in\nO(n $\\times$ log n $\\times$ K log n). Recent work by Harvey, van der Hoeven,\nand Lecerf showed that this complexity estimate can be improved in order to get\nK = 8, and conjecturally K = 4. Using an alternative algorithm, which relies on\narithmetic modulo generalized Fermat primes, we obtain conjecturally the same\nresult K = 4 via a careful complexity analysis in the deterministic multitape\nTuring model.", "1502.02908": "Fast event-based epidemiological simulations on national scales,Bauer, PavolEngblom, StefanWidgren, Stefan,Quantitative Biology - Populations and EvolutionComputer Science - Distributed, Parallel, and Cluster Computing,We present a computational modeling framework for data-driven simulations and\nanalysis of infectious disease spread in large populations. For the purpose of\nefficient simulations, we devise a parallel solution algorithm targeting\nmulti-socket shared memory architectures. The model integrates infectious\ndynamics as continuous-time Markov chains and available data such as animal\nmovements or aging are incorporated as externally defined events. To bring out\nparallelism and accelerate the computations, we decompose the spatial domain\nand optimize cross-boundary communication using dependency-aware task\nscheduling. Using registered livestock data at a high spatio-temporal\nresolution, we demonstrate that our approach not only is resilient to varying\nmodel configurations, but also scales on all physical cores at realistic work\nloads. Finally, we show that these very features enable the solution of inverse\nproblems on national scales.Comment: 27 pages, 5 figures", "1502.03097": "Contextuality, Cohomology and Paradox,Abramsky, SamsonBarbosa, Rui SoaresKishida, KoheiLal, RaymondMansfield, Shane,Quantum PhysicsComputer Science - Logic in Computer ScienceMathematics - Algebraic Topology,Contextuality is a key feature of quantum mechanics that provides an\nimportant non-classical resource for quantum information and computation.\nAbramsky and Brandenburger used sheaf theory to give a general treatment of\ncontextuality in quantum theory [New Journal of Physics 13 (2011) 113036].\nHowever, contextual phenomena are found in other fields as well, for example\ndatabase theory. In this paper, we shall develop this unified view of\ncontextuality. We provide two main contributions: firstly, we expose a\nremarkable connection between contexuality and logical paradoxes; secondly, we\nshow that an important class of contextuality arguments has a topological\norigin. More specifically, we show that \"All-vs-Nothing\" proofs of\ncontextuality are witnessed by cohomological obstructions.Comment: 18 pages, 4 figures", "1502.03371": "The Z Transform over Finite Fields,de Souza, R. M. Campellode Oliveira, H. M.Silva, D.,Mathematics - Number TheoryComputer Science - Numerical AnalysisElectrical Engineering and Systems Science - Signal Processing,Finite field transforms have many applications and, in many cases, can be\nimplemented with a low computational complexity. In this paper, the Z Transform\nover a finite field is introduced and some of its properties are presented.Comment: 6 pages, 5 figures, Proc. IEEE/SBrT Int. Telecomm. Symp., 2002.\n  pp.362-367", "1502.03387": "A Full Frequency Masking Vocoder for Legal Eavesdropping Conversation\n  Recording,Filho, R. F. B. Soterode Oliveira, H. M.de Souza, R. M. Campello,Computer Science - SoundElectrical Engineering and Systems Science - Audio and Speech Processing,This paper presents a new approach for a vocoder design based on full\nfrequency masking by octaves in addition to a technique for spectral filling\nvia beta probability distribution. Some psycho-acoustic characteristics of\nhuman hearing - inaudibility masking in frequency and phase - are used as a\nbasis for the proposed algorithm. The results confirm that this technique may\nbe useful to save bandwidth in applications requiring intelligibility. It is\nrecommended for the legal eavesdropping of long voice conversations.Comment: 7 pages, 3 figures, 3 tables, XXXV Cong. Nac. de Matematica Aplicada\n  e Computacional, Natal, RN, Brazil 2014", "1502.03951": "Varieties,Straubing, HowardWeil, Pascal,Computer Science - Formal Languages and Automata Theory68Q70, 20M07F.4.3,This text is devoted to the theory of varieties, which provides an important\ntool, based in universal algebra, for the classification of regular languages.\nIn the introductory section, we present a number of examples that illustrate\nand motivate the fundamental concepts. We do this for the most part without\nproofs, and often without precise definitions, leaving these to the formal\ndevelopment of the theory that begins in Section 2. Our presentation of the\ntheory draws heavily on the work of Gehrke, Grigorieff and Pin (2008) on the\nequational theory of lattices of regular languages. In the subsequent sections\nwe consider in more detail aspects of varieties that were only briefly evoked\nin the introduction: Decidability, operations on languages, and\ncharacterizations in formal logic.Comment: This is a chapter in an upcoming Handbook of Automata Theory", "1502.04052": "Computer-aided verification in mechanism design,Barthe, GillesGaboardi, MarcoArias, Emilio Jes\u00fas GallegoHsu, JustinRoth, AaronStrub, Pierre-Yves,Computer Science - Computer Science and Game TheoryComputer Science - Logic in Computer Science,In mechanism design, the gold standard solution concepts are dominant\nstrategy incentive compatibility and Bayesian incentive compatibility. These\nsolution concepts relieve the (possibly unsophisticated) bidders from the need\nto engage in complicated strategizing. While incentive properties are simple to\nstate, their proofs are specific to the mechanism and can be quite complex.\nThis raises two concerns. From a practical perspective, checking a complex\nproof can be a tedious process, often requiring experts knowledgeable in\nmechanism design. Furthermore, from a modeling perspective, if unsophisticated\nagents are unconvinced of incentive properties, they may strategize in\nunpredictable ways.\n  To address both concerns, we explore techniques from computer-aided\nverification to construct formal proofs of incentive properties. Because formal\nproofs can be automatically checked, agents do not need to manually check the\nproperties, or even understand the proof. To demonstrate, we present the\nverification of a sophisticated mechanism: the generic reduction from Bayesian\nincentive compatible mechanism design to algorithm design given by Hartline,\nKleinberg, and Malekian. This mechanism presents new challenges for formal\nverification, including essential use of randomness from both the execution of\nthe mechanism and from the prior type distributions. As an immediate\nconsequence, our work also formalizes Bayesian incentive compatibility for the\nentire family of mechanisms derived via this reduction. Finally, as an\nintermediate step in our formalization, we provide the first formal\nverification of incentive compatibility for the celebrated\nVickrey-Clarke-Groves mechanism.", "1502.04147": "Bayesian Incentive-Compatible Bandit Exploration,Mansour, YishaySlivkins, AleksandrsSyrgkanis, Vasilis,Computer Science - Computer Science and Game Theory,Individual decision-makers consume information revealed by the previous\ndecision makers, and produce information that may help in future decisions.\nThis phenomenon is common in a wide range of scenarios in the Internet economy,\nas well as in other domains such as medical decisions. Each decision-maker\nwould individually prefer to \"exploit\": select an action with the highest\nexpected reward given her current information. At the same time, each\ndecision-maker would prefer previous decision-makers to \"explore\", producing\ninformation about the rewards of various actions. A social planner, by means of\ncarefully designed information disclosure, can incentivize the agents to\nbalance the exploration and exploitation so as to maximize social welfare.\n  We formulate this problem as a multi-armed bandit problem (and various\ngeneralizations thereof) under incentive-compatibility constraints induced by\nthe agents' Bayesian priors. We design an incentive-compatible bandit algorithm\nfor the social planner whose regret is asymptotically optimal among all bandit\nalgorithms (incentive-compatible or not). Further, we provide a black-box\nreduction from an arbitrary multi-arm bandit algorithm to an\nincentive-compatible one, with only a constant multiplicative increase in\nregret. This reduction works for very general bandit setting that incorporate\ncontexts and arbitrary auxiliary feedback.Comment: An extended abstract of this paper has been published in ACM EC 2015.\n  This version contains complete proofs, revamped introductory sections (incl.\n  a discussion of potential applications to medical trials), and thoroughly\n  revised and streamlined presentation of the technical material. Two major\n  extensions are fleshed out, whereas they were only informally described in\n  the conference version", "1502.04382": "Temporal Network Optimization Subject to Connectivity Constraints,Mertzios, George B.Michail, OthonSpirakis, Paul G.,Computer Science - Discrete Mathematics68R10, 68Q17, 68Q25,In this work we consider \\emph{temporal networks}, i.e. networks defined by a\n\\emph{labeling} $\\lambda$ assigning to each edge of an \\emph{underlying graph}\n$G$ a set of \\emph{discrete} time-labels. The labels of an edge, which are\nnatural numbers, indicate the discrete time moments at which the edge is\navailable. We focus on \\emph{path problems} of temporal networks. In\nparticular, we consider \\emph{time-respecting} paths, i.e. paths whose edges\nare assigned by $\\lambda$ a strictly increasing sequence of labels. We begin by\ngiving two efficient algorithms for computing shortest time-respecting paths on\na temporal network. We then prove that there is a \\emph{natural analogue of\nMenger's theorem} holding for arbitrary temporal networks. Finally, we propose\ntwo \\emph{cost minimization parameters} for temporal network design. One is the\n\\emph{temporality} of $G$, in which the goal is to minimize the maximum number\nof labels of an edge, and the other is the \\emph{temporal cost} of $G$, in\nwhich the goal is to minimize the total number of labels used. Optimization of\nthese parameters is performed subject to some \\emph{connectivity constraint}.\nWe prove several lower and upper bounds for the temporality and the temporal\ncost of some very basic graph families such as rings, directed acyclic graphs,\nand trees.", "1502.04634": "The exp-log normal form of types,Ilik, Danko,Computer Science - Logic in Computer ScienceComputer Science - Programming LanguagesMathematics - Logic,Lambda calculi with algebraic data types lie at the core of functional\nprogramming languages and proof assistants, but conceal at least two\nfundamental theoretical problems already in the presence of the simplest\nnon-trivial data type, the sum type. First, we do not know of an explicit and\nimplemented algorithm for deciding the beta-eta-equality of terms---and this in\nspite of the first decidability results proven two decades ago. Second, it is\nnot clear how to decide when two types are essentially the same, i.e.\nisomorphic, in spite of the meta-theoretic results on decidability of the\nisomorphism.\n  In this paper, we present the exp-log normal form of types---derived from the\nrepresentation of exponential polynomials via the unary exponential and\nlogarithmic functions---that any type built from arrows, products, and sums,\ncan be isomorphically mapped to. The type normal form can be used as a simple\nheuristic for deciding type isomorphism, thanks to the fact that it is a\nsystematic application of the high-school identities.\n  We then show that the type normal form allows to reduce the standard beta-eta\nequational theory of the lambda calculus to a specialized version of itself,\nwhile preserving the completeness of equality on terms. We end by describing an\nalternative representation of normal terms of the lambda calculus with sums,\ntogether with a Coq-implemented converter into/from our new term calculus. The\ndifference with the only other previously implemented heuristic for deciding\ninteresting instances of eta-equality by Balat, Di Cosmo, and Fiore, is that we\nexploit the type information of terms substantially and this often allows us to\nobtain a canonical representation of terms without performing sophisticated\nterm analyses.", "1502.05058": "Tensor Spectral Clustering for Partitioning Higher-order Network\n  Structures,Benson, Austin R.Gleich, David F.Leskovec, Jure,Computer Science - Social and Information NetworksPhysics - Physics and Society,Spectral graph theory-based methods represent an important class of tools for\nstudying the structure of networks. Spectral methods are based on a first-order\nMarkov chain derived from a random walk on the graph and thus they cannot take\nadvantage of important higher-order network substructures such as triangles,\ncycles, and feed-forward loops. Here we propose a Tensor Spectral Clustering\n(TSC) algorithm that allows for modeling higher-order network structures in a\ngraph partitioning framework. Our TSC algorithm allows the user to specify\nwhich higher-order network structures (cycles, feed-forward loops, etc.) should\nbe preserved by the network clustering. Higher-order network structures of\ninterest are represented using a tensor, which we then partition by developing\na multilinear spectral method. Our framework can be applied to discovering\nlayered flows in networks as well as graph anomaly detection, which we\nillustrate on synthetic networks. In directed networks, a higher-order\nstructure of particular interest is the directed 3-cycle, which captures\nfeedback loops in networks. We demonstrate that our TSC algorithm produces\nlarge partitions that cut fewer directed 3-cycles than standard spectral\nclustering algorithms.Comment: SDM 2015", "1502.05183": "Practically-Self-Stabilizing Virtual Synchrony,Dolev, ShlomiGeorgiou, ChryssisMarcoullis, IoannisSchiller, Elad Michael,Computer Science - Distributed, Parallel, and Cluster Computing,Virtual synchrony is an important abstraction that is proven to be extremely\nuseful when implemented over asynchronous, typically large, message-passing\ndistributed systems. Fault tolerant design is a key criterion for the success\nof such implementations. This is because large distributed systems can be\nhighly available as long as they do not depend on the full operational status\nof every system participant. Namely, they employ redundancy in numbers to\novercome non-optimal behavior of participants and to gain global robustness and\nhigh availability.\n  Self-stabilizing systems can tolerate transient faults that drive the system\nto an arbitrary unpredicted configuration. Such systems automatically regain\nconsistency from any such arbitrary configuration, and then produce the desired\nsystem behavior. Practically self-stabilizing systems ensure the desired system\nbehavior for practically infinite number of successive steps e.g., $2^{64}$\nsteps.\n  We present the first practically self-stabilizing virtual synchrony\nalgorithm. The algorithm is a combination of several new techniques that may be\nof independent interest. In particular, we present a new counter algorithm that\nestablishes an efficient practically unbounded counter, that in turn can be\ndirectly used to implement a self-stabilizing Multiple-Writer Multiple-Reader\n(MWMR) register emulation. Other components include self-stabilizing group\nmembership, self-stabilizing multicast, and self-stabilizing emulation of\nreplicated state machine. As we base the replicated state machine\nimplementation on virtual synchrony, rather than consensus, the system\nprogresses in more extreme asynchronous executions in relation to\nconsensus-based replicated state machine.", "1502.05472": "On the Effects of Low-Quality Training Data on Information Extraction\n  from Clinical Reports,Marcheggiani, DiegoSebastiani, Fabrizio,Computer Science - Machine LearningComputer Science - Computation and LanguageComputer Science - Information Retrieval,In the last five years there has been a flurry of work on information\nextraction from clinical documents, i.e., on algorithms capable of extracting,\nfrom the informal and unstructured texts that are generated during everyday\nclinical practice, mentions of concepts relevant to such practice. Most of this\nliterature is about methods based on supervised learning, i.e., methods for\ntraining an information extraction system from manually annotated examples.\nWhile a lot of work has been devoted to devising learning methods that generate\nmore and more accurate information extractors, no work has been devoted to\ninvestigating the effect of the quality of training data on the learning\nprocess. Low quality in training data often derives from the fact that the\nperson who has annotated the data is different from the one against whose\njudgment the automatically annotated data must be evaluated. In this paper we\ntest the impact of such data quality issues on the accuracy of information\nextraction systems as applied to the clinical domain. We do this by comparing\nthe accuracy deriving from training data annotated by the authoritative coder\n(i.e., the one who has also annotated the test data, and by whose judgment we\nmust abide), with the accuracy deriving from training data annotated by a\ndifferent coder. The results indicate that, although the disagreement between\nthe two coders (as measured on the training set) is substantial, the difference\nis (surprisingly enough) not always statistically significant.Comment: Submitted for publication", "1502.05491": "Optimizing Text Quantifiers for Multivariate Loss Functions,Esuli, AndreaSebastiani, Fabrizio,Computer Science - Machine LearningComputer Science - Information Retrieval,We address the problem of \\emph{quantification}, a supervised learning task\nwhose goal is, given a class, to estimate the relative frequency (or\n\\emph{prevalence}) of the class in a dataset of unlabelled items.\nQuantification has several applications in data and text mining, such as\nestimating the prevalence of positive reviews in a set of reviews of a given\nproduct, or estimating the prevalence of a given support issue in a dataset of\ntranscripts of phone calls to tech support. So far, quantification has been\naddressed by learning a general-purpose classifier, counting the unlabelled\nitems which have been assigned the class, and tuning the obtained counts\naccording to some heuristics. In this paper we depart from the tradition of\nusing general-purpose classifiers, and use instead a supervised learning model\nfor \\emph{structured prediction}, capable of generating classifiers directly\noptimized for the (multivariate and non-linear) function used for evaluating\nquantification accuracy. The experiments that we have run on 5500 binary\nhigh-dimensional datasets (averaging more than 14,000 documents each) show that\nthis method is more accurate, more stable, and more efficient than existing,\nstate-of-the-art quantification methods.Comment: In press in ACM Transactions on Knowledge Discovery from Data, 2015", "1502.05507": "On asymptotically good ramp secret sharing schemes,Geil, OlavMartin, StefanoMart\u00ednez-Pe\u00f1as, UmbertoMatsumoto, RyutarohRuano, Diego,Computer Science - Information Theory94A62, 94B27, 94B65,Asymptotically good sequences of linear ramp secret sharing schemes have been\nintensively studied by Cramer et al. in terms of sequences of pairs of nested\nalgebraic geometric codes. In those works the focus is on full privacy and full\nreconstruction. In this paper we analyze additional parameters describing the\nasymptotic behavior of partial information leakage and possibly also partial\nreconstruction giving a more complete picture of the access structure for\nsequences of linear ramp secret sharing schemes. Our study involves a detailed\ntreatment of the (relative) generalized Hamming weights of the considered\ncodes.", "1502.05632": "Capturing k-ary Existential Second Order Logic with k-ary\n  Inclusion-Exclusion Logic,R\u00f6nnholm, Raine,Mathematics - LogicComputer Science - Logic in Computer ScienceF.4.1,In this paper we analyze k-ary inclusion-exclusion logic, INEX[k], which is\nobtained by extending first order logic with k-ary inclusion and exclusion\natoms. We show that every formula of INEX[k] can be expressed with a formula of\nk-ary existential second order logic, ESO[k]. Conversely, every formula of\nESO[k] with at most k-ary free relation variables can be expressed with a\nformula of INEX[k]. From this it follows that, on the level of sentences,\nINEX[k] captures the expressive power of ESO[k].\n  We also introduce several useful operators that can be expressed in INEX[k].\nIn particular, we define inclusion and exclusion quantifiers and so-called term\nvalue preserving disjunction which is essential for the proofs of the main\nresults in this paper. Furthermore, we present a novel method of relativization\nfor team semantics and analyze the duality of inclusion and exclusion atoms.Comment: Extended version of a paper published in Annals of Pure and Applied\n  Logic 169 (3), 177-215", "1502.05767": "Automatic differentiation in machine learning: a survey,Baydin, Atilim GunesPearlmutter, Barak A.Radul, Alexey AndreyevichSiskind, Jeffrey Mark,Computer Science - Symbolic ComputationComputer Science - Machine LearningStatistics - Machine Learning68W30, 65D25, 68T05G.1.4I.2.6,Derivatives, mostly in the form of gradients and Hessians, are ubiquitous in\nmachine learning. Automatic differentiation (AD), also called algorithmic\ndifferentiation or simply \"autodiff\", is a family of techniques similar to but\nmore general than backpropagation for efficiently and accurately evaluating\nderivatives of numeric functions expressed as computer programs. AD is a small\nbut established field with applications in areas including computational fluid\ndynamics, atmospheric sciences, and engineering design optimization. Until very\nrecently, the fields of machine learning and AD have largely been unaware of\neach other and, in some cases, have independently discovered each other's\nresults. Despite its relevance, general-purpose AD has been missing from the\nmachine learning toolbox, a situation slowly changing with its ongoing adoption\nunder the names \"dynamic computational graphs\" and \"differentiable\nprogramming\". We survey the intersection of AD and machine learning, cover\napplications where AD has direct relevance, and address the main implementation\ntechniques. By precisely defining the main differentiation techniques and their\ninterrelationships, we aim to bring clarity to the usage of the terms\n\"autodiff\", \"automatic differentiation\", and \"symbolic differentiation\" as\nthese are encountered more and more in machine learning settings.Comment: 43 pages, 5 figures", "1502.05880": "A Flexible Implementation of a Matrix Laurent Series-Based 16-Point Fast\n  Fourier and Hartley Transforms,de Oliveira, R. C.de Oliveira, H. M.de Souza, R. M. CampelloSantos, E. J. P.,Computer Science - Numerical AnalysisComputer Science - Discrete MathematicsElectrical Engineering and Systems Science - Signal Processing,This paper describes a flexible architecture for implementing a new fast\ncomputation of the discrete Fourier and Hartley transforms, which is based on a\nmatrix Laurent series. The device calculates the transforms based on a single\nbit selection operator. The hardware structure and synthesis are presented,\nwhich handled a 16-point fast transform in 65 nsec, with a Xilinx SPARTAN 3E\ndevice.Comment: 4 pages, 4 figures. IEEE VI Southern Programmable Logic Conference\n  2010", "1502.06464": "Rectified Factor Networks,Clevert, Djork-Arn\u00e9Mayr, AndreasUnterthiner, ThomasHochreiter, Sepp,Computer Science - Machine LearningComputer Science - Computer Vision and Pattern RecognitionComputer Science - Neural and Evolutionary ComputingStatistics - Machine Learning,We propose rectified factor networks (RFNs) to efficiently construct very\nsparse, non-linear, high-dimensional representations of the input. RFN models\nidentify rare and small events in the input, have a low interference between\ncode units, have a small reconstruction error, and explain the data covariance\nstructure. RFN learning is a generalized alternating minimization algorithm\nderived from the posterior regularization method which enforces non-negative\nand normalized posterior means. We proof convergence and correctness of the RFN\nlearning algorithm. On benchmarks, RFNs are compared to other unsupervised\nmethods like autoencoders, RBMs, factor analysis, ICA, and PCA. In contrast to\nprevious sparse coding methods, RFNs yield sparser codes, capture the data's\ncovariance structure more precisely, and have a significantly smaller\nreconstruction error. We test RFNs as pretraining technique for deep networks\non different vision datasets, where RFNs were superior to RBMs and\nautoencoders. On gene expression data from two pharmaceutical drug discovery\nstudies, RFNs detected small and rare gene modules that revealed highly\nrelevant new biological insights which were so far missed by other unsupervised\nmethods.Comment: 9 pages + 49 pages supplement", "1502.06761": "Minimal Distance of Propositional Models,Behrisch, MikeHermann, MikiMengel, StefanSalzer, Gernot,Computer Science - Computational Complexity,We investigate the complexity of three optimization problems in Boolean\npropositional logic related to information theory: Given a conjunctive formula\nover a set of relations, find a satisfying assignment with minimal Hamming\ndistance to a given assignment that satisfies the formula\n($\\mathsf{NeareastOtherSolution}$, $\\mathsf{NOSol}$) or that does not need to\nsatisfy it ($\\mathsf{NearestSolution}$, $\\mathsf{NSol}$). The third problem\nasks for two satisfying assignments with a minimal Hamming distance among all\nsuch assignments ($\\mathsf{MinSolutionDistance}$, $\\mathsf{MSD}$).\n  For all three problems we give complete classifications with respect to the\nrelations admitted in the formula. We give polynomial time algorithms for\nseveral classes of constraint languages. For all other cases we prove hardness\nor completeness regarding APX, APX, NPO, or equivalence to well-known hard\noptimization problems.", "1502.07209": "Exploiting Feature and Class Relationships in Video Categorization with\n  Regularized Deep Neural Networks,Jiang, Yu-GangWu, ZuxuanWang, JunXue, XiangyangChang, Shih-Fu,Computer Science - Computer Vision and Pattern RecognitionComputer Science - Multimedia,In this paper, we study the challenging problem of categorizing videos\naccording to high-level semantics such as the existence of a particular human\naction or a complex event. Although extensive efforts have been devoted in\nrecent years, most existing works combined multiple video features using simple\nfusion strategies and neglected the utilization of inter-class semantic\nrelationships. This paper proposes a novel unified framework that jointly\nexploits the feature relationships and the class relationships for improved\ncategorization performance. Specifically, these two types of relationships are\nestimated and utilized by rigorously imposing regularizations in the learning\nprocess of a deep neural network (DNN). Such a regularized DNN (rDNN) can be\nefficiently realized using a GPU-based implementation with an affordable\ntraining cost. Through arming the DNN with better capability of harnessing both\nthe feature and the class relationships, the proposed rDNN is more suitable for\nmodeling video semantics. With extensive experimental evaluations, we show that\nrDNN produces superior performance over several state-of-the-art approaches. On\nthe well-known Hollywood2 and Columbia Consumer Video benchmarks, we obtain\nvery competitive results: 66.9\\% and 73.5\\% respectively in terms of mean\naverage precision. In addition, to substantially evaluate our rDNN and\nstimulate future research on large scale video categorization, we collect and\nrelease a new benchmark dataset, called FCVID, which contains 91,223 Internet\nvideos and 239 manually annotated categories.Comment: Please cite the officially published IEEE TPAMI version if you find\n  this work helpful", "1502.07331": "Highly corrupted image inpainting through hypoelliptic diffusion,Boscain, UgoChertovskih, RomanGauthier, Jean-PaulPrandi, DarioRemizov, Alexey,Computer Science - Computer Vision and Pattern RecognitionMathematics - Analysis of PDEs,We present a new image inpainting algorithm, the Averaging and Hypoelliptic\nEvolution (AHE) algorithm, inspired by the one presented in [SIAM J. Imaging\nSci., vol. 7, no. 2, pp. 669--695, 2014] and based upon a semi-discrete\nvariation of the Citti-Petitot-Sarti model of the primary visual cortex V1. The\nAHE algorithm is based on a suitable combination of sub-Riemannian hypoelliptic\ndiffusion and ad-hoc local averaging techniques. In particular, we focus on\nreconstructing highly corrupted images (i.e. where more than the 80% of the\nimage is missing), for which we obtain reconstructions comparable with the\nstate-of-the-art.Comment: 15 pages, 10 figures", "1502.07481": "Cluster Synchronization of Coupled Systems with Nonidentical Linear\n  Dynamics,Liu, ZhongchangWong, Wing Shing,Computer Science - Systems and Control,This paper considers the cluster synchronization problem of generic linear\ndynamical systems whose system models are distinct in different clusters. These\nnonidentical linear models render control design and coupling conditions highly\ncorrelated if static couplings are used for all individual systems. In this\npaper, a dynamic coupling structure, which incorporates a global weighting\nfactor and a vanishing auxiliary control variable, is proposed for each agent\nand is shown to be a feasible solution. Lower bounds on the global and local\nweighting factors are derived under the condition that every interaction\nsubgraph associated with each cluster admits a directed spanning tree. The\nspanning tree requirement is further shown to be a necessary condition when the\nclusters connect acyclicly with each other. Simulations for two applications,\ncluster heading alignment of nonidentical ships and cluster phase\nsynchronization of nonidentical harmonic oscillators, illustrate essential\nparts of the derived theoretical results.Comment: 22 pages, 4 figures", "1502.07884": "Characterising Modal Definability of Team-Based Logics via the Universal\n  Modality,Sano, KatsuhikoVirtema, Jonni,Mathematics - LogicComputer Science - Logic in Computer Science,We study model and frame definability of various modal logics. Let ML(A+)\ndenote the fragment of modal logic extended with the universal modality in\nwhich the universal modality occurs only positively. We show that a class of\nKripke models is definable in ML(A+) if and only if the class is elementary and\nclosed under disjoint unions and surjective bisimulations. We also characterise\nthe definability of ML(A+) in the spirit of the well-known Goldblatt--Thomason\ntheorem. We show that an elementary class F of Kripke frames is definable in\nML(A+) if and only if F is closed under taking generated subframes and bounded\nmorphic images, and reflects ultrafilter extensions and finitely generated\nsubframes. In addition we study frame definability relative to finite\ntransitive frames and give an analogous characterisation of ML(A+)-definability\nrelative to finite transitive frames. Finally, we initiate the study of model\nand frame definability in team-based logics. We study (extended) modal\ndependence logic, (extended) modal inclusion logic, and modal team logic. We\nestablish strict linear hierarchies with respect to model definability and\nframe definability, respectively. We show that, with respect to model and frame\ndefinability, the before mentioned team-based logics, except modal dependence\nlogic, either coincide with ML(A+) or plain modal logic ML. Thus as a corollary\nwe obtain model theoretic characterisation of model and frame definability for\nthe team-based logics.Comment: 30 pages. This is a preprint of a journal article to appear in Annals\n  of Pure and Applied Logic. The preprint combines and extends two conference\n  papers arXiv:1502.07884v1 and arXiv:1606.05140. The title of this preprint is\n  changed to reflect this", "1502.08010": "Tropical differential equations,Grigoriev, Dima,Computer Science - Symbolic ComputationMathematics - Algebraic Geometry14T05I.1.2,Tropical differential equations are introduced and an algorithm is designed\nwhich tests solvability of a system of tropical linear differential equations\nwithin the complexity polynomial in the size of the system and in its\ncoefficients. Moreover, we show that there exists a minimal solution, and the\nalgorithm constructs it (in case of solvability). This extends a similar\ncomplexity bound established for tropical linear systems. In case of tropical\nlinear differential systems in one variable a polynomial complexity algorithm\nfor testing its solvability is designed.\n  We prove also that the problem of solvability of a system of tropical\nnon-linear differential equations in one variable is $NP$-hard, and this\nproblem for arbitrary number of variables belongs to $NP$. Similar to tropical\nalgebraic equations, a tropical differential equation expresses the (necessary)\ncondition on the dominant term in the issue of solvability of a differential\nequation in power series.", "1503.00207": "Knowledge-aided Two-dimensional Autofocus for Spotlight SAR Polar Format\n  Imagery,Mao, Xinhua,Computer Science - Information Theory,Conventional two-dimensional (2-D) autofocus algorithms blindly estimate the\nphase error in the sense that they do not exploit any a priori information on\nthe structure of the 2-D phase error. As such, they often suffer from low\ncomputational efficiency and lack of data redundancy to accurately estimate the\n2-D phase error. In this paper, a knowledge-aided (KA) 2-D autofocus algorithm\nwhich is based on exploiting a priori knowledge about the 2-D phase error\nstructure, is presented. First, as a prerequisite of the proposed KA method,\nthe analytical structure of residual 2-D phase error in SAR imagery is\ninvestigated in the polar format algorithm (PFA) framework. Then, by\nincorporating this a priori information, a novel 2-D autofocus approach is\nproposed. The new method only requires an estimate of azimuth phase error\nand/or residual range cell migration, while the 2-D phase error can then be\ncomputed directly from the estimated azimuth phase error or residual range cell\nmigration. This 2-D autofocus method can also be applied to refocus moving\ntargets in PFA imagery. Experimental results clearly demonstrate the\neffectiveness and robustness of the proposed method.", "1503.00244": "23-bit Metaknowledge Template Towards Big Data Knowledge Discovery and\n  Management,Bari, NimaVichr, RomanKowsari, KamranBerkovich, Simon Y.,Computer Science - DatabasesComputer Science - Artificial IntelligenceComputer Science - Information RetrievalComputer Science - Machine Learning,The global influence of Big Data is not only growing but seemingly endless.\nThe trend is leaning towards knowledge that is attained easily and quickly from\nmassive pools of Big Data. Today we are living in the technological world that\nDr. Usama Fayyad and his distinguished research fellows discussed in the\nintroductory explanations of Knowledge Discovery in Databases (KDD) predicted\nnearly two decades ago. Indeed, they were precise in their outlook on Big Data\nanalytics. In fact, the continued improvement of the interoperability of\nmachine learning, statistics, database building and querying fused to create\nthis increasingly popular science- Data Mining and Knowledge Discovery. The\nnext generation computational theories are geared towards helping to extract\ninsightful knowledge from even larger volumes of data at higher rates of speed.\nAs the trend increases in popularity, the need for a highly adaptive solution\nfor knowledge discovery will be necessary. In this research paper, we are\nintroducing the investigation and development of 23 bit-questions for a\nMetaknowledge template for Big Data Processing and clustering purposes. This\nresearch aims to demonstrate the construction of this methodology and proves\nthe validity and the beneficial utilization that brings Knowledge Discovery\nfrom Big Data.Comment: IEEE Data Science and Advanced Analytics (DSAA'2014)", "1503.00245": "Novel Metaknowledge-based Processing Technique for Multimedia Big Data\n  clustering challenges,Bari, NimaVichr, RomanKowsari, KamranBerkovich, Simon Y.,Computer Science - DatabasesComputer Science - Artificial IntelligenceComputer Science - Information RetrievalComputer Science - Multimedia,Past research has challenged us with the task of showing relational patterns\nbetween text-based data and then clustering for predictive analysis using Golay\nCode technique. We focus on a novel approach to extract metaknowledge in\nmultimedia datasets. Our collaboration has been an on-going task of studying\nthe relational patterns between datapoints based on metafeatures extracted from\nmetaknowledge in multimedia datasets. Those selected are significant to suit\nthe mining technique we applied, Golay Code algorithm. In this research paper\nwe summarize findings in optimization of metaknowledge representation for\n23-bit representation of structured and unstructured multimedia data in order\ntoComment: IEEE Multimedia Big Data (BigMM 2015)", "1503.00491": "Utility-Theoretic Ranking for Semi-Automated Text Classification,Berardi, GiacomoEsuli, AndreaSebastiani, Fabrizio,Computer Science - Machine Learning,\\emph{Semi-Automated Text Classification} (SATC) may be defined as the task\nof ranking a set $\\mathcal{D}$ of automatically labelled textual documents in\nsuch a way that, if a human annotator validates (i.e., inspects and corrects\nwhere appropriate) the documents in a top-ranked portion of $\\mathcal{D}$ with\nthe goal of increasing the overall labelling accuracy of $\\mathcal{D}$, the\nexpected increase is maximized. An obvious SATC strategy is to rank\n$\\mathcal{D}$ so that the documents that the classifier has labelled with the\nlowest confidence are top-ranked. In this work we show that this strategy is\nsuboptimal. We develop new utility-theoretic ranking methods based on the\nnotion of \\emph{validation gain}, defined as the improvement in classification\neffectiveness that would derive by validating a given automatically labelled\ndocument. We also propose a new effectiveness measure for SATC-oriented ranking\nmethods, based on the expected reduction in classification error brought about\nby partially validating a list generated by a given ranking method. We report\nthe results of experiments showing that, with respect to the baseline method\nabove, and according to the proposed measure, our utility-theoretic ranking\nmethods can achieve substantially higher expected reductions in classification\nerror.Comment: Forthcoming on ACM Transactions on Knowledge Discovery from Data", "1503.00941": "Approximation Algorithms for Computing Maximin Share Allocations,Amanatidis, GeorgiosMarkakis, EvangelosNikzad, AfshinSaberi, Amin,Computer Science - Computer Science and Game TheoryF.2.2G.2.1,We study the problem of computing maximin share guarantees, a recently\nintroduced fairness notion. Given a set of $n$ agents and a set of goods, the\nmaximin share of a single agent is the best that she can guarantee to herself,\nif she would be allowed to partition the goods in any way she prefers, into $n$\nbundles, and then receive her least desirable bundle. The objective then in our\nproblem is to find a partition, so that each agent is guaranteed her maximin\nshare. In settings with indivisible goods, such allocations are not guaranteed\nto exist, so we resort to approximation algorithms. Our main result is a\n$2/3$-approximation, that runs in polynomial time for any number of agents.\nThis improves upon the algorithm of Procaccia and Wang, which also produces a\n$2/3$-approximation but runs in polynomial time only for a constant number of\nagents. To achieve this, we redesign certain parts of their algorithm.\nFurthermore, motivated by the apparent difficulty, both theoretically and\nexperimentally, in finding lower bounds on the existence of approximate\nsolutions, we undertake a probabilistic analysis. We prove that in randomly\ngenerated instances, with high probability there exists a maximin share\nallocation. This can be seen as a justification of the experimental evidence\nreported in relevant works. Finally, we provide further positive results for\ntwo special cases that arise from previous works. The first one is the\nintriguing case of $3$ agents, for which it is already known that exact maximin\nshare allocations do not always exist (contrary to the case of $2$ agents). We\nprovide a $7/8$-approximation algorithm, improving the previously known result\nof $3/4$. The second case is when all item values belong to $\\{0, 1, 2\\}$,\nextending the $\\{0, 1\\}$ setting studied in Bouveret and Lema\\^itre. We obtain\nan exact algorithm for any number of agents in this case.", "1503.01239": "Joint Active Learning with Feature Selection via CUR Matrix\n  Decomposition,Li, ChangshengWang, XiangfengDong, WeishanYan, JunchiLiu, QingshanZha, Hongyuan,Computer Science - Machine Learning,This paper presents an unsupervised learning approach for simultaneous sample\nand feature selection, which is in contrast to existing works which mainly\ntackle these two problems separately. In fact the two tasks are often\ninterleaved with each other: noisy and high-dimensional features will bring\nadverse effect on sample selection, while informative or representative samples\nwill be beneficial to feature selection. Specifically, we propose a framework\nto jointly conduct active learning and feature selection based on the CUR\nmatrix decomposition. From the data reconstruction perspective, both the\nselected samples and features can best approximate the original dataset\nrespectively, such that the selected samples characterized by the features are\nhighly representative. In particular, our method runs in one-shot without the\nprocedure of iterative sample selection for progressive labeling. Thus, our\nmodel is especially suitable when there are few labeled samples or even in the\nabsence of supervision, which is a particular challenge for existing methods.\nAs the joint learning problem is NP-hard, the proposed formulation involves a\nconvex but non-smooth optimization problem. We solve it efficiently by an\niterative algorithm, and prove its global convergence. Experimental results on\npublicly available datasets corroborate the efficacy of our method compared\nwith the state-of-the-art.Comment: Accepted by T-PAMI", "1503.01334": "Faster quantum mixing for slowly evolving sequences of Markov chains,Orsucci, DavideBriegel, Hans J.Dunjko, Vedran,Quantum PhysicsComputer Science - Artificial IntelligenceComputer Science - Data Structures and Algorithms,Markov chain methods are remarkably successful in computational physics,\nmachine learning, and combinatorial optimization. The cost of such methods\noften reduces to the mixing time, i.e., the time required to reach the steady\nstate of the Markov chain, which scales as $\\delta^{-1}$, the inverse of the\nspectral gap. It has long been conjectured that quantum computers offer nearly\ngeneric quadratic improvements for mixing problems. However, except in special\ncases, quantum algorithms achieve a run-time of $\\mathcal{O}(\\sqrt{\\delta^{-1}}\n\\sqrt{N})$, which introduces a costly dependence on the Markov chain size $N,$\nnot present in the classical case. Here, we re-address the problem of mixing of\nMarkov chains when these form a slowly evolving sequence. This setting is akin\nto the simulated annealing setting and is commonly encountered in physics,\nmaterial sciences and machine learning. We provide a quantum memory-efficient\nalgorithm with a run-time of $\\mathcal{O}(\\sqrt{\\delta^{-1}} \\sqrt[4]{N})$,\nneglecting logarithmic terms, which is an important improvement for large state\nspaces. Moreover, our algorithms output quantum encodings of distributions,\nwhich has advantages over classical outputs. Finally, we discuss the run-time\nbounds of mixing algorithms and show that, under certain assumptions, our\nalgorithms are optimal.Comment: 20 pages, 2 figures", "1503.01404": "Complete intersection vanishing ideals on sets of clutter type over\n  finite fields,Tochimani, AzucenaVillarreal, Rafael H.,Mathematics - Commutative AlgebraComputer Science - Information TheoryMathematics - Algebraic GeometryMathematics - Combinatorics14M10, 14G15, 13P25, 13P10, 11T71, 94B27, 94B05,In this paper we give a classification of complete intersection vanishing\nideals on parameterized sets of clutter type over finite fields.", "1503.01628": "Minimal classes of graphs of unbounded clique-width defined by finitely\n  many forbidden induced subgraphs,Atminas, A.Brignall, R.Lozin, V.Stacho, J.,Mathematics - CombinatoricsComputer Science - Discrete Mathematics,We discover new hereditary classes of graphs that are minimal (with respect\nto set inclusion) of unbounded clique-width. The new examples include split\npermutation graphs and bichain graphs. Each of these classes is characterised\nby a finite list of minimal forbidden induced subgraphs. These, therefore,\ndisprove a conjecture due to Daligault, Rao and Thomasse from 2010 claiming\nthat all such minimal classes must be defined by infinitely many forbidden\ninduced subgraphs.\n  In the same paper, Daligault, Rao and Thomasse make another conjecture that\nevery hereditary class of unbounded clique-width must contain a labelled\ninfinite antichain. We show that the two example classes we consider here\nsatisfy this conjecture. Indeed, they each contain a canonical labelled\ninfinite antichain, which leads us to propose a stronger conjecture: that every\nhereditary class of graphs that is minimal of unbounded clique-width contains a\ncanonical labelled infinite antichain.Comment: 17 pages, 7 figures", "1503.02196": "Higher Weights of Affine Grassmann Codes and Their Duals,Datta, MrinmoyGhorpade, Sudhir R.,Computer Science - Information TheoryMathematics - CombinatoricsPrimary 15A03, 11T06 05E99 Secondary 11T71,We consider the question of determining the higher weights or the generalized\nHamming weights of affine Grassmann codes and their duals. Several initial as\nwell as terminal higher weights of affine Grassmann codes of an arbitrary level\nare determined explicitly. In the case of duals of these codes, we give a\nformula for many initial as well as terminal higher weights. As a special case,\nwe obtain an alternative simpler proof of the formula of Beelen et al for the\nminimum distance of the dual of an affine Grasmann code.Comment: 13 pages; to appear in the Proceedings of AGCT (Luminy, France, June\n  2013)", "1503.02577": "New Algorithms for Computing a Single Component of the Discrete Fourier\n  Transform,Silva Jr., G. Jer\u00f4nimo dade Souza, R. M. Campellode Oliveira, H. M.,Computer Science - Discrete MathematicsComputer Science - Data Structures and AlgorithmsElectrical Engineering and Systems Science - Signal ProcessingStatistics - Methodology,This paper introduces the theory and hardware implementation of two new\nalgorithms for computing a single component of the discrete Fourier transform.\nIn terms of multiplicative complexity, both algorithms are more efficient, in\ngeneral, than the well known Goertzel Algorithm.Comment: 4 pages, 3 figures, 1 table. In: 10th International Symposium on\n  Communication Theory and Applications, Ambleside, UK", "1503.02951": "Mean Field Games in Nudge Systems for Societal Networks,Li, JianXia, BainanGeng, XinboMing, HaoShakkottai, SrinivasSubramanian, VijayXie, Le,Computer Science - Computer Science and Game Theory,We consider the general problem of resource sharing in societal networks,\nconsisting of interconnected communication, transportation, energy and other\nnetworks important to the functioning of society. Participants in such network\nneed to take decisions daily, both on the quantity of resources to use as well\nas the periods of usage. With this in mind, we discuss the problem of\nincentivizing users to behave in such a way that society as a whole benefits.\nIn order to perceive societal level impact, such incentives may take the form\nof rewarding users with lottery tickets based on good behavior, and\nperiodically conducting a lottery to translate these tickets into real rewards.\nWe will pose the user decision problem as a mean field game (MFG), and the\nincentives question as one of trying to select a good mean field equilibrium\n(MFE). In such a framework, each agent (a participant in the societal network)\ntakes a decision based on an assumed distribution of actions of his/her\ncompetitors, and the incentives provided by the social planner. The system is\nsaid to be at MFE if the agent's action is a sample drawn from the assumed\ndistribution. We will show the existence of such an MFE under different\nsettings, and also illustrate how to choose an attractive equilibrium using as\nan example demand-response in energy networks.Comment: An extended abstract titled \"Energy Coupon: A Mean Field Game\n  perspective on Demand Response in Smart Grids\" appeared in ACM Sigmetrics,\n  2015", "1503.02985": "SybilFrame: A Defense-in-Depth Framework for Structure-Based Sybil\n  Detection,Gao, PengGong, Neil ZhenqiangKulkarni, SanjeevThomas, KurtMittal, Prateek,Computer Science - Social and Information NetworksComputer Science - Cryptography and Security,Sybil attacks are becoming increasingly widespread, and pose a significant\nthreat to online social systems; a single adversary can inject multiple\ncolluding identities in the system to compromise security and privacy. Recent\nworks have leveraged the use of social network-based trust relationships to\ndefend against Sybil attacks. However, existing defenses are based on\noversimplified assumptions, which do not hold in real world social graphs. In\nthis work, we propose SybilFrame, a defense-in-depth framework for mitigating\nthe problem of Sybil attacks when the oversimplified assumptions are relaxed.\nOur framework is able to incorporate prior information about users and edges in\nthe social graph. We validate our framework on synthetic and real world network\ntopologies, including a large-scale Twitter dataset with 20M nodes and 265M\nedges, and demonstrate that our scheme performs an order of magnitude better\nthan previous structure-based approaches.Comment: 17 pages, 18 figures", "1503.03169": "Dynamic Partitioning of Physical Memory Among Virtual Machines,\n  ASMI:Architectural Support for Memory Isolation,R, JithinChandran, Priya,Computer Science - Hardware Architecture,Cloud computing relies on secure and efficient virtualization. Software level\nsecurity solutions compromise the performance of virtual machines (VMs), as a\nlarge amount of computational power would be utilized for running the security\nmodules. Moreover, software solutions are only as secure as the level that they\nwork on. For example a security module on a hypervisor cannot provide security\nin the presence of an infected hypervisor. It is a challenge for virtualization\ntechnology architects to enhance the security of VMs without degrading their\nperformance. Currently available server machines are not fully equipped to\nsupport a secure VM environment without compromising on performance. A few\nhardware modifications have been introduced by manufactures like Intel and AMD\nto provide a secure VM environment with low performance degradation. In this\npaper we propose a novel memory architecture model named \\textit{ Architectural\nSupport for Memory Isolation(ASMI)}, that can achieve a true isolated physical\nmemory region to each VM without degrading performance. Along with true memory\nisolation, ASMI is designed to provide lower memory access times, better\nutilization of available memory, support for DMA isolation and support for\nplatform independence for users of VMs.Comment: Rejected this short paper by the VEE 2015 Conference conducted by ACM\n  due to the lack of implementation details", "1503.03185": "Testing Randomness by Matching Pennies,Pavlovic, DuskoSeidel, Peter-MichaelYahia, Muzamil,Computer Science - Computer Science and Game Theory91A26, 68Q32I.2.6,In the game of Matching Pennies, Alice and Bob each hold a penny, and at\nevery tick of the clock they simultaneously display the head or the tail sides\nof their coins. If they both display the same side, then Alice wins Bob's\npenny; if they display different sides, then Bob wins Alice's penny. To avoid\ngiving the opponent a chance to win, both players seem to have nothing else to\ndo but to randomly play heads and tails with equal frequencies. However, while\nnot losing in this game is easy, not missing an opportunity to win is not.\nRandomizing your own moves can be made easy. Recognizing when the opponent's\nmoves are not random can be arbitrarily hard.\n  The notion of randomness is central in game theory, but it is usually taken\nfor granted. The notion of outsmarting is not central in game theory, but it is\ncentral in the practice of gaming. We pursue the idea that these two notions\ncan be usefully viewed as two sides of the same coin.Comment: 19 pages, 1 table; in this version: added proofs and explanations", "1503.03605": "An improved return-mapping scheme for nonsmooth yield surfaces: PART I -\n  the Haigh-Westergaard coordinates,Sysala, StanislavCermak, MartinKoudelka, TomasKruis, JaroslavZeman, JanBlaheta, Radim,Computer Science - Computational Engineering, Finance, and Science,The paper is devoted to the numerical solution of elastoplastic constitutive\ninitial value problems. An improved form of the implicit return-mapping scheme\nfor nonsmooth yield surfaces is proposed that systematically builds on a\nsubdifferential formulation of the flow rule. The main advantage of this\napproach is that the treatment of singular points, such as apices or edges at\nwhich the flow direction is multivalued involves only a uniquely defined set of\nnon-linear equations, similarly to smooth yield surfaces. This paper (PART I)\nis focused on isotropic models containing: $a)$ yield surfaces with one or two\napices (singular points) laying on the hydrostatic axis; $b)$ plastic\npseudo-potentials that are independent of the Lode angle; $c)$ nonlinear\nisotropic hardening (optionally). It is shown that for some models the improved\nintegration scheme also enables to a priori decide about a type of the return\nand investigate existence, uniqueness and semismoothness of discretized\nconstitutive operators in implicit form. Further, the semismooth Newton method\nis introduced to solve incremental boundary-value problems. The paper also\ncontains numerical examples related to slope stability with available Matlab\nimplementation.Comment: 25 pages, 10 figures", "1503.04099": "Algorithms and complexity for Turaev-Viro invariants,Burton, Benjamin A.Maria, Cl\u00e9mentSpreer, Jonathan,Mathematics - Geometric TopologyComputer Science - Computational ComplexityComputer Science - Data Structures and AlgorithmsComputer Science - Mathematical Software57M27, 57Q15, 68Q17F.2.2G.2.1G.4,The Turaev-Viro invariants are a powerful family of topological invariants\nfor distinguishing between different 3-manifolds. They are invaluable for\nmathematical software, but current algorithms to compute them require\nexponential time.\n  The invariants are parameterised by an integer $r \\geq 3$. We resolve the\nquestion of complexity for $r=3$ and $r=4$, giving simple proofs that computing\nTuraev-Viro invariants for $r=3$ is polynomial time, but for $r=4$ is \\#P-hard.\nMoreover, we give an explicit fixed-parameter tractable algorithm for arbitrary\n$r$, and show through concrete implementation and experimentation that this\nalgorithm is practical---and indeed preferable---to the prior state of the art\nfor real computation.Comment: 17 pages, 5 figures", "1503.04424": "Bridging Social Media via Distant Supervision,Magdy, WalidSajjad, HassanEl-Ganainy, TarekSebastiani, Fabrizio,Computer Science - Information Retrieval,Microblog classification has received a lot of attention in recent years.\nDifferent classification tasks have been investigated, most of them focusing on\nclassifying microblogs into a small number of classes (five or less) using a\ntraining set of manually annotated tweets. Unfortunately, labelling data is\ntedious and expensive, and finding tweets that cover all the classes of\ninterest is not always straightforward, especially when some of the classes do\nnot frequently arise in practice. In this paper we study an approach to tweet\nclassification based on distant supervision, whereby we automatically transfer\nlabels from one social medium to another for a single-label multi-class\nclassification task. In particular, we apply YouTube video classes to tweets\nlinking to these videos. This provides for free a virtually unlimited number of\nlabelled instances that can be used as training data. The classification\nexperiments we have run show that training a tweet classifier via these\nautomatically labelled data achieves substantially better performance than\ntraining the same classifier with a limited amount of manually labelled data;\nthis is advantageous, given that the automatically labelled data come at no\ncost. Further investigation of our approach shows its robustness when applied\nwith different numbers of classes and across different languages.", "1503.04500": "A Residual Based Sparse Approximate Inverse Preconditioning Procedure\n  for Large Sparse Linear Systems,Jia, ZhongxiaoKang, Wenjie,Mathematics - Numerical AnalysisComputer Science - Numerical Analysis65F10,The SPAI algorithm, a sparse approximate inverse preconditioning technique\nfor large sparse linear systems, proposed by Grote and Huckle [SIAM J. Sci.\nComput., 18 (1997), pp.~838--853.], is based on the F-norm minimization and\ncomputes a sparse approximate inverse $M$ of a large sparse matrix $A$\nadaptively. However, SPAI may be costly to seek the most profitable indices at\neach loop and $M$ may be ineffective for preconditioning. In this paper, we\npropose a residual based sparse approximate inverse preconditioning procedure\n(RSAI), which, unlike SPAI, is based on only the {\\em dominant} rather than all\ninformation on the current residual and augments sparsity patterns adaptively\nduring the loops. RSAI is less costly to seek indices and is more effective to\ncapture a good approximate sparsity pattern of $A^{-1}$ than SPAI. To control\nthe sparsity of $M$ and reduce computational cost, we develop a practical\nRSAI($tol$) algorithm that drops small nonzero entries adaptively during the\nprocess. Numerical experiments are reported to demonstrate that RSAI($tol$) is\nat least competitive with SPAI and can be considerably more efficient and\neffective than SPAI. They also indicate that RSAI($tol$) is comparable to the\nPSAI($tol$) algorithm proposed by one of the authors in 2009.Comment: 18 pages, 1 figure", "1503.04522": "Really Natural Linear Indexed Type Checking,de Amorim, Arthur AzevedoArias, Emilio Jes\u00fas GallegoGaboardi, MarcoHsu, Justin,Computer Science - Logic in Computer Science,Recent works have shown the power of linear indexed type systems for\nenforcing complex program properties. These systems combine linear types with a\nlanguage of type-level indices, allowing more fine-grained analyses. Such\nsystems have been fruitfully applied in diverse domains, including implicit\ncomplexity and differential privacy. A natural way to enhance the\nexpressiveness of this approach is by allowing the indices to depend on runtime\ninformation, in the spirit of dependent types. This approach is used in DFuzz,\na language for differential privacy. The DFuzz type system relies on an index\nlanguage supporting real and natural number arithmetic over constants and\nvariables. Moreover, DFuzz uses a subtyping mechanism to make types more\nflexible. By themselves, linearity, dependency, and subtyping each require\ndelicate handling when performing type checking or type inference; their\ncombination increases this challenge substantially, as the features can\ninteract in non-trivial ways. In this paper, we study the type-checking problem\nfor DFuzz. We show how we can reduce type checking for (a simple extension of)\nDFuzz to constraint solving over a first-order theory of naturals and real\nnumbers which, although undecidable, can often be handled in practice by\nstandard numeric solvers.", "1503.05496": "IMP with exceptions over decorated logic,Ekici, Burak,Computer Science - Logic in Computer Science,In this paper, we facilitate the reasoning about impure programming\nlanguages, by annotating terms with `decorations' that describe what\ncomputational (side) effect evaluation of a term may involve. In a point-free\ncategorical language,called the `decorated logic', we formalize the mutable\nstate and the exception effects first separately, exploiting anice duality\nbetween them, and then combined. The combined decorated logic is used as the\ntarget language forthe denotational semantics of the IMP+Exc imperative\nprogramming language, and allows us to prove equivalencesbetween programs\nwritten in IMP+Exc. The combined logic is encoded in Coq, and this encoding is\nused to certifysome program equivalence proofs.", "1503.05656": "Cost-Effective Conceptual Design Using Taxonomies,Vakilian, AliChodpathumwan, YodsawalaiTermehchy, ArashNayyeri, Amir,Computer Science - Databases,It is known that annotating named entities in unstructured and\nsemi-structured data sets by their concepts improves the effectiveness of\nanswering queries over these data sets. As every enterprise has a limited\nbudget of time or computational resources, it has to annotate a subset of\nconcepts in a given domain whose costs of annotation do not exceed the budget.\nWe call such a subset of concepts a {\\it conceptual design} for the annotated\ndata set. We focus on finding a conceptual design that provides the most\neffective answers to queries over the annotated data set, i.e., a {\\it\ncost-effective conceptual design}. Since, it is often less time-consuming and\ncostly to annotate general concepts than specific concepts, we use information\non superclass/subclass relationships between concepts in taxonomies to find a\ncost-effective conceptual design. We quantify the amount by which a conceptual\ndesign with concepts from a taxonomy improves the effectiveness of answering\nqueries over an annotated data set. If the taxonomy is a tree, we prove that\nthe problem is NP-hard and propose an efficient approximation and\npseudo-polynomial time algorithms for the problem. We further prove that if the\ntaxonomy is a directed acyclic graph, given some generally accepted hypothesis,\nit is not possible to find any approximation algorithm with reasonably small\napproximation ratio for the problem. Our empirical study using real-world data\nsets, taxonomies, and query workloads shows that our framework effectively\nquantifies the amount by which a conceptual design improves the effectiveness\nof answering queries. It also indicates that our algorithms are efficient for a\ndesign-time task with pseudo-polynomial algorithm being generally more\neffective than the approximation algorithm.", "1503.06126": "Polynomial complexity recognizing a tropical linear variety,Grigoriev, Dima,Computer Science - Symbolic ComputationMathematics - Algebraic Geometry15T05I.1.2,A polynomial complexity algorithm is designed which tests whether a point\nbelongs to a given tropical linear variety.", "1503.06483": "Construction of FuzzyFind Dictionary using Golay Coding Transformation\n  for Searching Applications,Kowsari, KamranYammahi, MaryamBari, NimaVichr, RomanAlsaby, FaisalBerkovich, Simon Y.,Computer Science - DatabasesComputer Science - Artificial IntelligenceComputer Science - Data Structures and AlgorithmsComputer Science - Information RetrievalComputer Science - Machine Learning,Searching through a large volume of data is very critical for companies,\nscientists, and searching engines applications due to time complexity and\nmemory complexity. In this paper, a new technique of generating FuzzyFind\nDictionary for text mining was introduced. We simply mapped the 23 bits of the\nEnglish alphabet into a FuzzyFind Dictionary or more than 23 bits by using more\nFuzzyFind Dictionary, and reflecting the presence or absence of particular\nletters. This representation preserves closeness of word distortions in terms\nof closeness of the created binary vectors within Hamming distance of 2\ndeviations. This paper talks about the Golay Coding Transformation Hash Table\nand how it can be used on a FuzzyFind Dictionary as a new technology for using\nin searching through big data. This method is introduced by linear time\ncomplexity for generating the dictionary and constant time complexity to access\nthe data and update by new data sets, also updating for new data sets is linear\ntime depends on new data points. This technique is based on searching only for\nletters of English that each segment has 23 bits, and also we have more than\n23-bit and also it could work with more segments as reference table.", "1503.06822": "Tree spanners of bounded degree graphs,Papoutsakis, Ioannis,Computer Science - Discrete MathematicsComputer Science - Data Structures and Algorithms,A tree $t$-spanner of a graph $G$ is a spanning tree of $G$ such that the\ndistance between pairs of vertices in the tree is at most $t$ times their\ndistance in $G$. Deciding tree $t$-spanner admissible graphs has been proved to\nbe tractable for $t<3$ and NP-complete for $t>3$, while the complexity status\nof this problem is unresolved when $t=3$. For every $t>2$ and $b>0$, an\nefficient dynamic programming algorithm to decide tree $t$-spanner\nadmissibility of graphs with vertex degrees less than $b$ is presented. Only\nfor $t=3$, the algorithm remains efficient, when graphs $G$ with degrees less\nthan $b\\log |V(G)|$ are examined.", "1503.07759": "Large-scale Biological Meta-database Management,Pedersen, EdvardBongo, Lars Ailo,Computer Science - Distributed, Parallel, and Cluster ComputingComputer Science - Databases,Up-to-date meta-databases are vital for the analysis of biological data.\nHowever,the current exponential increase in biological data leads to\nexponentially increasing meta-database sizes. Large-scale meta-database\nmanagement is therefore an important challenge for production platforms\nproviding services for biological data analysis. In particular, there is often\na need either to run an analysis with a particular version of a meta-database,\nor to rerun an analysis with an updated meta-database. We present our GeStore\napproach for biological meta-database management. It provides efficient storage\nand runtime generation of specific meta-database versions, and efficient\nincremental updates for biological data analysis tools. The approach is\ntransparent to the tools, and we provide a framework that makes it easy to\nintegrate GeStore with biological data analysis frameworks. We present the\nGeStore system, an evaluation of the performance characteristics of the system,\nand an evaluation of the benefits for a biological data analysis workflow.Comment: 10 pages, 6 figures, 4 tables", "1503.08370": "Global Bandits,Atan, OnurTekin, Cemvan der Schaar, Mihaela,Computer Science - Machine Learning,Multi-armed bandits (MAB) model sequential decision making problems, in which\na learner sequentially chooses arms with unknown reward distributions in order\nto maximize its cumulative reward. Most of the prior work on MAB assumes that\nthe reward distributions of each arm are independent. But in a wide variety of\ndecision problems -- from drug dosage to dynamic pricing -- the expected\nrewards of different arms are correlated, so that selecting one arm provides\ninformation about the expected rewards of other arms as well. We propose and\nanalyze a class of models of such decision problems, which we call {\\em global\nbandits}. In the case in which rewards of all arms are deterministic functions\nof a single unknown parameter, we construct a greedy policy that achieves {\\em\nbounded regret}, with a bound that depends on the single true parameter of the\nproblem. Hence, this policy selects suboptimal arms only finitely many times\nwith probability one. For this case we also obtain a bound on regret that is\n{\\em independent of the true parameter}; this bound is sub-linear, with an\nexponent that depends on the informativeness of the arms. We also propose a\nvariant of the greedy policy that achieves $\\tilde{\\mathcal{O}}(\\sqrt{T})$\nworst-case and $\\mathcal{O}(1)$ parameter dependent regret. Finally, we perform\nexperiments on dynamic pricing and show that the proposed algorithms achieve\nsignificant gains with respect to the well-known benchmarks.Comment: arXiv admin note: substantial text overlap with arXiv:1410.7890", "1503.08381": "Towards Easier and Faster Sequence Labeling for Natural Language\n  Processing: A Search-based Probabilistic Online Learning Framework (SAPO),Sun, XuMa, ShumingZhang, YiRen, Xuancheng,Computer Science - Machine LearningComputer Science - Artificial Intelligence,There are two major approaches for sequence labeling. One is the\nprobabilistic gradient-based methods such as conditional random fields (CRF)\nand neural networks (e.g., RNN), which have high accuracy but drawbacks: slow\ntraining, and no support of search-based optimization (which is important in\nmany cases). The other is the search-based learning methods such as structured\nperceptron and margin infused relaxed algorithm (MIRA), which have fast\ntraining but also drawbacks: low accuracy, no probabilistic information, and\nnon-convergence in real-world tasks. We propose a novel and \"easy\" solution, a\nsearch-based probabilistic online learning method, to address most of those\nissues. The method is \"easy\", because the optimization algorithm at the\ntraining stage is as simple as the decoding algorithm at the test stage. This\nmethod searches the output candidates, derives probabilities, and conducts\nefficient online learning. We show that this method with fast training and\ntheoretical guarantee of convergence, which is easy to implement, can support\nsearch-based optimization and obtain top accuracy. Experiments on well-known\ntasks show that our method has better accuracy than CRF and BiLSTM\\footnote{The\nSAPO code is released at \\url{https://github.com/lancopku/SAPO}.}.", "1503.08925": "Geometry of Interaction for MALL via Hughes-vanGlabbeek Proof-Nets,Hamano, Masahiro,Computer Science - Logic in Computer ScienceMathematics - Logic,This paper presents, for the first time, a Geometry of Interaction (GoI)\ninterpretation inspired from Hughes-vanGlabbeek (HvG) proof-nets for\nmultiplicative additive linear logic (MALL). Our GoI dynamically captures HvG's\ngeometric correctness criterion-the toggling cycle condition-in terms of\nalgebraic operators. Our new ingredient is a scalar extension of the *-algebra\nin Girard's *-ring of partial isometries over a boolean polynomial ring with\nliterals of eigenweights as indeterminates. In order to capture feedback\narising from cuts, we construct a finer grained execution formula. The\nexpansion of this execution formula is longer than that for collections of\nslices for multiplicative GoI, hence it is harder to prove termination. Our GoI\ngives a dynamical, semantical account of boolean valuations (in particular,\npruning sub-proofs), conversion of weights (in particular, alpha-conversion),\nand additive (co)contraction, peculiar to additive proof-theory. Termination of\nour execution formula is shown to correspond to HvG's toggling criterion. The\nslice-wise restriction of our execution formula (by collapsing the boolean\nstructure) yields the well known correspondence, explicit or implicit in\nprevious works on multiplicative GoI, between the convergence of execution\nformulas and acyclicity of proof-nets. Feedback arising from the execution\nformula by restricting to the boolean polynomial structure yields autonomous\ndefinability of eigenweights among cuts from the rest of the eigenweights.Comment: 37 pages", "1504.00169": "Complete Simulation of Automata Networks,Bridoux, FlorianCastillo-Ramirez, AlonsoGadouleau, Maximilien,Computer Science - Formal Languages and Automata TheoryComputer Science - Computational ComplexityComputer Science - Discrete MathematicsMathematics - Group Theory,Consider a finite set $A$ and an integer $n \\geq 1$. This paper studies the\nconcept of complete simulation in the context of semigroups of transformations\nof $A^n$, also known as finite state-homogeneous automata networks. For $m \\geq\nn$, a transformation of $A^m$ is \\emph{$n$-complete of size $m$} if it may\nsimulate every transformation of $A^n$ by updating one coordinate (or register)\nat a time. Using tools from memoryless computation, it is established that\nthere is no $n$-complete transformation of size $n$, but there is such a\ntransformation of size $n+1$. By studying the the time of simulation of various\n$n$-complete transformations, it is conjectured that the maximal time of\nsimulation of any $n$-complete transformation is at least $2n$. A\ntransformation of $A^m$ is \\emph{sequentially $n$-complete of size $m$} if it\nmay sequentially simulate every finite sequence of transformations of $A^n$; in\nthis case, minimal examples and bounds for the size and time of simulation are\ndetermined. It is also shown that there is no $n$-complete transformation that\nupdates all the registers in parallel, but that there exists a sequentally\n$n$-complete transformation that updates all but one register in parallel. This\nillustrates the strengths and weaknesses of parallel models of computation,\nsuch as cellular automata.Comment: Vastly updated version of the paper previously known as \"Universal\n  simulation of automata networks.\" Florian Bridoux has joined the paper,\n  thanks to his significant contribution", "1504.00222": "On the Exact and Approximate Eigenvalue Distribution for Sum of Wishart\n  Matrices,Kumar, S.Pivaro, G. F.Fraidenraich, G.Dias, C. F.,Computer Science - Information Theory94A15, 94A17, 15A18, 15B52,The sum of Wishart matrices has an important role in multiuser communication\nemploying multiantenna elements, such as multiple-input multiple-output (MIMO)\nmultiple access channel (MAC), MIMO Relay channel, and other multiuser channels\nwhere the mathematical model is best described using random matrices. In this\npaper, the distribution of linear combination of complex Wishart distributed\nmatrices has been studied. We present a new closed form expression for the\nmarginal distribution of the eigenvalues of a weighted sum of K complex central\nWishart matrices having covariance matrices proportional to the identity\nmatrix. The expression is general and allows for any set of linear\ncoefficients. As an application example, we have used the marginal distribution\nexpression to obtain the ergodic sum-rate capacity for the MIMO-MAC network,\nand the cut-set upper bound for the MIMO-Relay case, both as closed form\nexpressions. We also present a very simple expression to approximate the sum of\nWishart matrices by one equivalent Wishart matrix. All of our results are\nvalidated by means of Monte Carlo simulations. As expected, the agreement\nbetween the exact eigenvalue distribution and simulations is perfect, whereas\nfor the approximate solution the difference is indistinguishable.Comment: 18 pages, 8 figures, 1 table", "1504.00495": "Exploring the complex pattern of information spreading in online blog\n  communities,Pei, SenMuchnik, LevTang, ShaotingZheng, ZhimingMakse, Hernan A.,Physics - Physics and SocietyComputer Science - Social and Information Networks,Information spreading in online social communities has attracted tremendous\nattention due to its utmost practical values in applications. Despite that\nseveral individual-level diffusion data have been investigated, we still lack\nthe detailed understanding of the spreading pattern of information. Here, by\ncomparing information flows and social links in a blog community, we find that\nthe diffusion processes are induced by three different spreading mechanisms:\nsocial spreading, self-promotion and broadcast. Although numerous previous\nstudies have employed epidemic spreading models to simulate information\ndiffusion, we observe that such models fail to reproduce the realistic\ndiffusion pattern. In respect to users behaviors, strikingly, we find that most\nusers would stick to one specific diffusion mechanism. Moreover, our\nobservations indicate that the social spreading is not only crucial for the\nstructure of diffusion trees, but also capable of inducing more subsequent\nindividuals to acquire the information. Our findings suggest new directions for\nmodeling of information diffusion in social systems and could inform design of\nefficient propagation strategies based on users behaviors.", "1504.01019": "On the Total-Power Capacity of Regular-LDPC Codes with Iterative\n  Message-Passing Decoders,Ganesan, KarthikGrover, PulkitRabaey, JanGoldsmith, Andrea,Computer Science - Information Theory,Motivated by recently derived fundamental limits on total (transmit +\ndecoding) power for coded communication with VLSI decoders, this paper\ninvestigates the scaling behavior of the minimum total power needed to\ncommunicate over AWGN channels as the target bit-error-probability tends to\nzero. We focus on regular-LDPC codes and iterative message-passing decoders. We\nanalyze scaling behavior under two VLSI complexity models of decoding. One\nmodel abstracts power consumed in processing elements (\"node model\"), and\nanother abstracts power consumed in wires which connect the processing elements\n(\"wire model\"). We prove that a coding strategy using regular-LDPC codes with\nGallager-B decoding achieves order-optimal scaling of total power under the\nnode model. However, we also prove that regular-LDPC codes and iterative\nmessage-passing decoders cannot meet existing fundamental limits on total power\nunder the wire model. Further, if the transmit energy-per-bit is bounded, total\npower grows at a rate that is worse than uncoded transmission. Complementing\nour theoretical results, we develop detailed physical models of decoding\nimplementations using post-layout circuit simulations. Our theoretical and\nnumerical results show that approaching fundamental limits on total power\nrequires increasing the complexity of both the code design and the\ncorresponding decoding algorithm as communication distance is increased or\nerror-probability is lowered.Comment: 21 pages, 6 figures. To appear in JSAC Recent Advances In Capacity\n  Approaching Codes", "1504.01442": "The Effect of Recency to Human Mobility,Barbosa, HugoNeto, Fernando Buarque de LimaEvsukoff, AlexandreMenezes, Ronaldo,Physics - Physics and SocietyComputer Science - Social and Information Networks,In recent years, we have seen scientists attempt to model and explain human\ndynamics and, in particular, human movement. Many aspects of our complex life\nare affected by human movements such as disease spread and epidemics modeling,\ncity planning, wireless network development, and disaster relief, to name a\nfew. Given the myriad of applications it is clear that a complete understanding\nof how people move in space can lead to huge benefits to our society. In most\nof the recent works, scientists have focused on the idea that people movements\nare biased towards frequently-visited locations. According to them, human\nmovement is based on an exploration/exploitation dichotomy in which individuals\nchoose new locations (exploration) or return to frequently-visited locations\n(exploitation). In this work, we focus on the concept of recency. We propose a\nmodel in which exploitation in human movement also considers recently-visited\nlocations and not solely frequently-visited locations. We test our hypothesis\nagainst different empirical data of human mobility and show that our proposed\nmodel is able to better explain the human trajectories in these datasets.", "1504.01708": "Reactive Synthesis Without Regret,Hunter, PaulP\u00e9rez, Guillermo A.Raskin, Jean-Fran\u00e7ois,Computer Science - Computer Science and Game TheoryComputer Science - Formal Languages and Automata TheoryComputer Science - Logic in Computer ScienceF.1.1,Two-player zero-sum games of infinite duration and their quantitative\nversions are used in verification to model the interaction between a controller\n(Eve) and its environment (Adam). The question usually addressed is that of the\nexistence (and computability) of a strategy for Eve that can maximize her\npayoff against any strategy of Adam. In this work, we are interested in\nstrategies of Eve that minimize her regret, i.e. strategies that minimize the\ndifference between her actual payoff and the payoff she could have achieved if\nshe had known the strategy of Adam in advance. We give algorithms to compute\nthe strategies of Eve that ensure minimal regret against an adversary whose\nchoice of strategy is (i) unrestricted, (ii) limited to positional strategies,\nor (iii) limited to word strategies. We also establish relations between the\nlatter version and other problems studied in the literature.Comment: Removed some text that was redundant", "1504.01709": "Copyless Cost-Register Automata: Structure, Expressiveness, and Closure\n  Properties,Mazowiecki, FilipRiveros, Cristian,Computer Science - Formal Languages and Automata Theory,Cost register automata (CRA) and its subclass, copyless CRA, were recently\nproposed by Alur et al. as a new model for computing functions over strings. We\nstudy some structural properties, expressiveness, and closure properties of\ncopyless CRA. We show that copyless CRA are strictly less expressive than\nweighted automata and are not closed under reverse operation. To find a better\nclass we impose restrictions on copyless CRA, which ends successfully with a\nnew robust computational model that is closed under reverse and other\nextensions.", "1504.01782": "Profit Maximization for Geographical Dispersed Green Data Centers,Kiani, AbbasAnsari, Nirwan,Computer Science - Networking and Internet Architecture,This paper aims at maximizing the profit associated with running\ngeographically dispersed green data centers, which offer multiple classes of\nservice. To this end, we formulate an optimization framework which relies on\nthe accuracy of the G/D/1 queue in characterizing the workload distribution,\nand taps on the merits of the workload decomposition into green and brown\nworkload served by green and brown energy resources. Moreover, we take into\naccount of not only the Service Level Agreements (SLAs) between the data\ncenters and clients but also different deregulated electricity markets of data\ncenters located at different regions. We prove the convexity of our\noptimization problem and the performance of the proposed workload distribution\nstrategy is evaluated via simulations.", "1504.02141": "Detecting Falls with X-Factor Hidden Markov Models,Khan, Shehroz S.Karg, Michelle E.Kulic, DanaHoey, Jesse,Computer Science - Machine LearningComputer Science - Artificial Intelligence,Identification of falls while performing normal activities of daily living\n(ADL) is important to ensure personal safety and well-being. However, falling\nis a short term activity that occurs infrequently. This poses a challenge to\ntraditional classification algorithms, because there may be very little\ntraining data for falls (or none at all). This paper proposes an approach for\nthe identification of falls using a wearable device in the absence of training\ndata for falls but with plentiful data for normal ADL. We propose three\n`X-Factor' Hidden Markov Model (XHMMs) approaches. The XHMMs model unseen falls\nusing \"inflated\" output covariances (observation models). To estimate the\ninflated covariances, we propose a novel cross validation method to remove\n\"outliers\" from the normal ADL that serve as proxies for the unseen falls and\nallow learning the XHMMs using only normal activities. We tested the proposed\nXHMM approaches on two activity recognition datasets and show high detection\nrates for falls in the absence of fall-specific training data. We show that the\ntraditional method of choosing a threshold based on maximum of negative of\nlog-likelihood to identify unseen falls is ill-posed for this problem. We also\nshow that supervised classification methods perform poorly when very limited\nfall data are available during the training phase.Comment: 27 pages, 4 figures, 3 tables, Applied Soft Computing, 2017", "1504.03342": "A Survey on Privacy and Security in Online Social Networks,Kayes, ImrulIamnitchi, Adriana,Computer Science - Social and Information NetworksComputer Science - Cryptography and Security,Online Social Networks (OSN) are a permanent presence in today's personal and\nprofessional lives of a huge segment of the population, with direct\nconsequences to offline activities. Built on a foundation of trust-users\nconnect to other users with common interests or overlapping personal\ntrajectories-online social networks and the associated applications extract an\nunprecedented volume of personal information. Unsurprisingly, serious privacy\nand security risks emerged, positioning themselves along two main types of\nattacks: attacks that exploit the implicit trust embedded in declared social\nrelationships; and attacks that harvest user's personal information for\nill-intended use. This article provides an overview of the privacy and security\nissues that emerged so far in OSNs. We introduce a taxonomy of privacy and\nsecurity attacks in OSNs, we overview existing solutions to mitigate those\nattacks, and outline challenges still to overcome.", "1504.03856": "Sparse multivariate polynomial interpolation in the basis of Schubert\n  polynomials,Mukhopadhyay, PriyankaQiao, Youming,Computer Science - Computational ComplexityComputer Science - Data Structures and AlgorithmsMathematics - Combinatorics,Schubert polynomials were discovered by A. Lascoux and M. Sch\\\"utzenberger in\nthe study of cohomology rings of flag manifolds in 1980's. These polynomials\ngeneralize Schur polynomials, and form a linear basis of multivariate\npolynomials. In 2003, Lenart and Sottile introduced skew Schubert polynomials,\nwhich generalize skew Schur polynomials, and expand in the Schubert basis with\nthe generalized Littlewood-Richardson coefficients.\n  In this paper we initiate the study of these two families of polynomials from\nthe perspective of computational complexity theory. We first observe that skew\nSchubert polynomials, and therefore Schubert polynomials, are in $\\CountP$\n(when evaluating on non-negative integral inputs) and $\\VNP$.\n  Our main result is a deterministic algorithm that computes the expansion of a\npolynomial $f$ of degree $d$ in $\\Z[x_1, \\dots, x_n]$ in the basis of Schubert\npolynomials, assuming an oracle computing Schubert polynomials. This algorithm\nruns in time polynomial in $n$, $d$, and the bit size of the expansion. This\ngeneralizes, and derandomizes, the sparse interpolation algorithm of symmetric\npolynomials in the Schur basis by Barvinok and Fomin (Advances in Applied\nMathematics, 18(3):271--285). In fact, our interpolation algorithm is general\nenough to accommodate any linear basis satisfying certain natural properties.\n  Applications of the above results include a new algorithm that computes the\ngeneralized Littlewood-Richardson coefficients.Comment: 20 pages; some typos corrected", "1504.03872": "Extended Formulations for Independence Polytopes of Regular Matroids,Kaibel, VolkerLee, JonWalter, MatthiasWeltge, Stefan,Computer Science - Discrete MathematicsMathematics - Combinatorics52Bxx,We show that the independence polytope of every regular matroid has an\nextended formulation of size quadratic in the size of its ground set. This\ngeneralizes a similar statement for (co-)graphic matroids, which is a simple\nconsequence of Martin's extended formulation for the spanning-tree polytope. In\nour construction, we make use of Seymour's decomposition theorem for regular\nmatroids. As a consequence, the extended formulations can be computed in\npolynomial time.Comment: Minor corrections in the paragraph after Theorem 1", "1504.03957": "Optimal Hierarchical Radio Resource Management for HetNets with Flexible\n  Backhaul,Omidvar, NaeimehLiu, AnLau, VincentZhang, FanTsang, Danny H. K.Pakravan, Mohammad Reza,Computer Science - Information Theory,Providing backhaul connectivity for macro and pico base stations (BSs)\nconstitutes a significant share of infrastructure costs in future heterogeneous\nnetworks (HetNets). To address this issue, the emerging idea of flexible\nbackhaul is proposed. Under this architecture, not all the pico BSs are\nconnected to the backhaul, resulting in a significant reduction in the\ninfrastructure costs. In this regard, pico BSs without backhaul connectivity\nneed to communicate with their nearby BSs in order to have indirect\naccessibility to the backhaul. This makes the radio resource management (RRM)\nin such networks more complex and challenging. In this paper, we address the\nproblem of cross-layer RRM in HetNets with flexible backhaul. We formulate this\nproblem as a two-timescale non-convex stochastic optimization which jointly\noptimizes flow control, routing, interference mitigation and link scheduling in\norder to maximize a generic network utility. By exploiting a hidden convexity\nof this non-convex problem, we propose an iterative algorithm which converges\nto the global optimal solution. The proposed algorithm benefits from low\ncomplexity and low signalling, which makes it scalable. Moreover, due to the\nproposed two-timescale design, it is robust to the backhaul signalling latency\nas well. Simulation results demonstrate the significant performance gain of the\nproposed solution over various baselines.", "1504.04073": "The Parametric Closure Problem,Eppstein, David,Computer Science - Data Structures and AlgorithmsF.2.2,We define the parametric closure problem, in which the input is a partially\nordered set whose elements have linearly varying weights and the goal is to\ncompute the sequence of minimum-weight lower sets of the partial order as the\nweights vary. We give polynomial time solutions to many important special cases\nof this problem including semiorders, reachability orders of bounded-treewidth\ngraphs, partial orders of bounded width, and series-parallel partial orders.\nOur result for series-parallel orders provides a significant generalization of\na previous result of Carlson and Eppstein on bicriterion subtree problems.Comment: 22 pages, 8 figures. A preliminary version of this paper appeared at\n  the 14th Algorithms and Data Structures Symposium (WADS), Victoria, BC,\n  August 2015, Springer, Lecture Notes in Comp. Sci. 9214 (2015), pp. 327-338", "1504.04217": "Quantum and classical coin-flipping protocols based on bit-commitment\n  and their point games,Nayak, AshwinSikora, JamieTun\u00e7el, Levent,Quantum PhysicsComputer Science - Cryptography and SecurityMathematics - Optimization and Control,We focus on a family of quantum coin-flipping protocols based on\nbit-commitment. We discuss how the semidefinite programming formulations of\ncheating strategies can be reduced to optimizing a linear combination of\nfidelity functions over a polytope. These turn out to be much simpler\nsemidefinite programs which can be modelled using second-order cone programming\nproblems. We then use these simplifications to construct their point games as\ndeveloped by Kitaev. We also study the classical version of these protocols and\nuse linear optimization to formulate optimal cheating strategies. We then\nconstruct the point games for the classical protocols as well using the\nanalysis for the quantum case.\n  We discuss the philosophical connections between the classical and quantum\nprotocols and their point games as viewed from optimization theory. In\nparticular, we observe an analogy between a spectrum of physical theories (from\nclassical to quantum) and a spectrum of convex optimization problems (from\nlinear programming to semidefinite programming, through second-order cone\nprogramming). In this analogy, classical systems correspond to linear\nprogramming problems and the level of quantum features in the system is\ncorrelated to the level of sophistication of the semidefinite programming\nmodels on the optimization side.\n  Concerning security analysis, we use the classical point games to prove that\nevery classical protocol of this type allows exactly one of the parties to\nentirely determine the coin-flip. Using the relationships between the quantum\nand classical protocols, we show that only \"classical\" protocols can saturate\nKitaev's lower bound for strong coin-flipping. Moreover, if the product of\nAlice and Bob's optimal cheating probabilities is 1/2, then one party can cheat\nwith probability 1. This rules out quantum protocols of this type from\nattaining the optimal level of security.Comment: 41 pages (plus a 17 page appendix). Comments welcome", "1504.04867": "Information Hiding as a Challenge for Malware Detection,Mazurczyk, WojciechCaviglione, Luca,Computer Science - Cryptography and Security,Information hiding techniques are increasingly utilized by the current\nmalware to hide its existence and communication attempts. In this paper we\nhighlight this new trend by reviewing the most notable examples of malicious\nsoftware that shows this capability.Comment: 9 pages, 1 table", "1504.04869": "Equitable total coloring of corona of cubic graphs,Furma\u0144czyk, HannaZuazua, Rita,Computer Science - Discrete MathematicsMathematics - Combinatorics05C15, 05C76,The minimum number of total independent partition sets of $V \\cup E$ of a\ngraph $G=(V,E)$ is called the \\emph{total chromatic number} of $G$, denoted by\n$\\chi''(G)$. If the difference between cardinalities of any two total\nindependent sets is at most one, then the minimum number of total independent\npartition sets of $V \\cup E$ is called the \\emph{equitable total chromatic\nnumber}, and is denoted by $\\chi''_=(G)$.\n  In this paper we consider equitable total coloring of coronas of cubic\ngraphs, $G \\circ H$. It turns out that, independly on the values of equitable\ntotal chromatic number of factors $G$ and $H$, equitable total chromatic number\nof corona $G \\circ H$ is equal to $\\Delta(G \\circ H) +1$. Thereby, we confirm\nTotal Coloring Conjecture (TCC), posed by Behzad in 1964, and Equitable Total\nColoring Conjecture (ETCC), posed by Wang in 2002, for coronas of cubic graphs.\nAs a direct consequence we get that all coronas of cubic graphs are of Type 1.Comment: 12 pages", "1504.05895": "Semantic Enrichment of Mobile Phone Data Records Using Background\n  Knowledge,Dashdorj, ZolzayaSobolevsky, StanislavSerafini, LucianoAntonelli, FabrizioRatti, Carlo,Computer Science - Artificial IntelligenceComputer Science - Information Theory68H.1.2H.2.8H.3.3I.2.3I.2.4G.3,Every day, billions of mobile network events (i.e. CDRs) are generated by\ncellular phone operator companies. Latent in this data are inspiring insights\nabout human actions and behaviors, the discovery of which is important because\ncontext-aware applications and services hold the key to user-driven,\nintelligent services, which can enhance our everyday lives such as social and\neconomic development, urban planning, and health prevention. The major\nchallenge in this area is that interpreting such a big stream of data requires\na deep understanding of mobile network events' context through available\nbackground knowledge. This article addresses the issues in context awareness\ngiven heterogeneous and uncertain data of mobile network events missing\nreliable information on the context of this activity. The contribution of this\nresearch is a model from a combination of logical and statistical reasoning\nstandpoints for enabling human activity inference in qualitative terms from\nopen geographical data that aimed at improving the quality of human behaviors\nrecognition tasks from CDRs. We use open geographical data, Openstreetmap\n(OSM), as a proxy for predicting the content of human activity in the area. The\nuser study performed in Trento shows that predicted human activities (top\nlevel) match the survey data with around 93% overall accuracy. The extensive\nvalidation for predicting a more specific economic type of human activity\nperformed in Barcelona, by employing credit card transaction data. The analysis\nidentifies that appropriately normalized data on points of interest (POI) is a\ngood proxy for predicting human economical activities, with 84% accuracy on\naverage. So the model is proven to be efficient for predicting the context of\nhuman activity, when its total level could be efficiently observed from cell\nphone data records, missing contextual information however.Comment: 40 pages, 34 figures", "1504.06043": "Stability of Stochastic Approximations with `Controlled Markov' Noise\n  and Temporal Difference Learning,Ramaswamy, ArunselvanBhatnagar, Shalabh,Computer Science - Systems and ControlStatistics - Machine Learning62L20, 93E03, 93E35, 34A60,We are interested in understanding stability (almost sure boundedness) of\nstochastic approximation algorithms (SAs) driven by a `controlled Markov'\nprocess. Analyzing this class of algorithms is important, since many\nreinforcement learning (RL) algorithms can be cast as SAs driven by a\n`controlled Markov' process. In this paper, we present easily verifiable\nsufficient conditions for stability and convergence of SAs driven by a\n`controlled Markov' process. Many RL applications involve continuous state\nspaces. While our analysis readily ensures stability for such continuous state\napplications, traditional analyses do not. As compared to literature, our\nanalysis presents a two-fold generalization (a) the Markov process may evolve\nin a continuous state space and (b) the process need not be ergodic under any\ngiven stationary policy. Temporal difference learning (TD) is an important\npolicy evaluation method in reinforcement learning. The theory developed\nherein, is used to analyze generalized $TD(0)$, an important variant of TD. Our\ntheory is also used to analyze a TD formulation of supervised learning for\nforecasting problems.Comment: 18 pages", "1504.06234": "Acyclic chromatic index of triangle-free 1-planar graphs,Chen, JijuanWang, TaoZhang, Huiqin,Mathematics - CombinatoricsComputer Science - Discrete Mathematics05C15,An acyclic edge coloring of a graph $G$ is a proper edge coloring such that\nevery cycle is colored with at least three colors. The acyclic chromatic index\n$\\chiup_{a}'(G)$ of a graph $G$ is the least number of colors in an acyclic\nedge coloring of $G$. It was conjectured that $\\chiup'_{a}(G)\\leq \\Delta(G) +\n2$ for any simple graph $G$ with maximum degree $\\Delta(G)$. A graph is {\\em\n$1$-planar} if it can be drawn on the plane such that every edge is crossed by\nat most one other edge. In this paper, we prove that every triangle-free\n$1$-planar graph $G$ has an acyclic edge coloring with $\\Delta(G) + 16$ colors.Comment: 7 pages. Lemma 6 was strengthened and the main result was slightly\n  improved", "1504.06320": "The Fallacy of Favoring Gradual Replacement Mind Uploading Over\n  Scan-and-Copy,Wiley, Keith B.Koene, Randal A.,Computer Science - Other Computer ScienceI.2.0,Mind uploading speculation and debate often concludes that a procedure\ndescribed as gradual in-place replacement preserves personal identity while a\nprocedure described as destructive scan-and-copy produces some other identity\nin the target substrate such that personal identity is lost along with the\nbiological brain. This paper demonstrates a chain of reasoning that establishes\nmetaphysical equivalence between these two methods in terms of preserving\npersonal identity.Comment: 14 pages, 0 figures", "1504.06544": "Sampling Correctors,Canonne, Cl\u00e9mentGouleakis, ThemisRubinfeld, Ronitt,Computer Science - Data Structures and AlgorithmsComputer Science - Machine LearningMathematics - Probability,In many situations, sample data is obtained from a noisy or imperfect source.\nIn order to address such corruptions, this paper introduces the concept of a\nsampling corrector. Such algorithms use structure that the distribution is\npurported to have, in order to allow one to make \"on-the-fly\" corrections to\nsamples drawn from probability distributions. These algorithms then act as\nfilters between the noisy data and the end user.\n  We show connections between sampling correctors, distribution learning\nalgorithms, and distribution property testing algorithms. We show that these\nconnections can be utilized to expand the applicability of known distribution\nlearning and property testing algorithms as well as to achieve improved\nalgorithms for those tasks.\n  As a first step, we show how to design sampling correctors using proper\nlearning algorithms. We then focus on the question of whether algorithms for\nsampling correctors can be more efficient in terms of sample complexity than\nlearning algorithms for the analogous families of distributions. When\ncorrecting monotonicity, we show that this is indeed the case when also granted\nquery access to the cumulative distribution function. We also obtain sampling\ncorrectors for monotonicity without this stronger type of access, provided that\nthe distribution be originally very close to monotone (namely, at a distance\n$O(1/\\log^2 n)$). In addition to that, we consider a restricted error model\nthat aims at capturing \"missing data\" corruptions. In this model, we show that\ndistributions that are close to monotone have sampling correctors that are\nsignificantly more efficient than achievable by the learning approach.\n  We also consider the question of whether an additional source of independent\nrandom bits is required by sampling correctors to implement the correction\nprocess.", "1504.06582": "Approximate Fitting of a Circular Arc When Two Points Are Known,Gribov, Alexander,Computer Science - Computational Geometry,The task of approximating points with circular arcs is performed in many\napplications, such as polyline compression, noise filtering, and feature\nrecognition. However, the development of algorithms that perform a significant\namount of circular arcs fitting requires an efficient way of fitting circular\narcs with complexity O(1). The elegant solution to this task based on an\neigenvector problem for a square nonsymmetrical matrix is described in [1]. For\nthe compression algorithm described in [2], it is necessary to solve this task\nwhen two points on the arc are known. This paper describes a different approach\nto efficiently fitting the arcs and solves the task when one or two points are\nknown.Comment: 15 pages, 4 figures, extended abstract published at the conference", "1504.06584": "Searching for a Compressed Polyline with a Minimum Number of Vertices,Gribov, Alexander,Computer Science - Computational Geometry,There are many practical applications that require simplification of\npolylines. Some of the goals are to reduce the amount of information necessary\nto store, improve processing time, or simplify editing. The simplification is\nusually done by removing some of the vertices, making the resultant polyline go\nthrough a subset of the source polyline vertices. However, such approaches do\nnot necessarily produce a new polyline with the minimum number of vertices. The\napproximate solution to find a polyline, within a specified tolerance, with the\nminimum number of vertices is described in this paper.", "1504.06804": "High Speed Hashing for Integers and Strings,Thorup, Mikkel,Computer Science - Data Structures and Algorithms,These notes describe the most efficient hash functions currently known for\nhashing integers and strings. These modern hash functions are often an order of\nmagnitude faster than those presented in standard text books. They are also\nsimpler to implement, and hence a clear win in practice, but their analysis is\nharder. Some of the most practical hash functions have only appeared in theory\npapers, and some of them requires combining results from different theory\npapers. The goal here is to combine the information in lecture-style notes that\ncan be used by theoreticians and practitioners alike, thus making these\npractical fruits of theory more widely accessible.Comment: Fixed a few typos from first version. Please send comments/typos to\n  me at mikkel2thorup@gmail.com", "1504.06979": "Obstructions for three-coloring graphs without induced paths on six\n  vertices,Chudnovsky, MariaGoedgebeur, JanSchaudt, OliverZhong, Mingxian,Mathematics - CombinatoricsComputer Science - Discrete Mathematics,We prove that there are 24 4-critical $P_6$-free graphs, and give the\ncomplete list. We remark that, if $H$ is connected and not a subgraph of $P_6$,\nthere are infinitely many 4-critical $H$-free graphs. Our result answers\nquestions of Golovach et al. and Seymour.Comment: 31 pages", "1504.07056": "A Deterministic Almost-Tight Distributed Algorithm for Approximating\n  Single-Source Shortest Paths,Henzinger, MonikaKrinninger, SebastianNanongkai, Danupon,Computer Science - Distributed, Parallel, and Cluster ComputingComputer Science - Data Structures and AlgorithmsC.2.4F.2.0G.2.2,We present a deterministic $(1+o(1))$-approximation\n$(n^{1/2+o(1)}+D^{1+o(1)})$-time algorithm for solving the single-source\nshortest paths problem on distributed weighted networks (the CONGEST model);\nhere $n$ is the number of nodes in the network and $D$ is its (hop) diameter.\nThis is the first non-trivial deterministic algorithm for this problem. It also\nimproves (i) the running time of the randomized $(1+o(1))$-approximation\n$\\tilde O(n^{1/2}D^{1/4}+D)$-time algorithm of Nanongkai [STOC 2014] by a\nfactor of as large as $n^{1/8}$, and (ii) the $O(\\epsilon^{-1}\\log\n\\epsilon^{-1})$-approximation factor of Lenzen and Patt-Shamir's $\\tilde\nO(n^{1/2+\\epsilon}+D)$-time algorithm [STOC 2013] within the same running time.\nOur running time matches the known time lower bound of $\\Omega(n^{1/2}/\\log n +\nD)$ [Elkin STOC 2004] up to subpolynomial factors, thus essentially settling\nthe status of this problem which was raised at least a decade ago [Elkin SIGACT\nNews 2004]. It also implies a $(2+o(1))$-approximation\n$(n^{1/2+o(1)}+D^{1+o(1)})$-time algorithm for approximating a network's\nweighted diameter which almost matches the lower bound by Holzer and Pinsker\n[OPODIS 2015]. In achieving this result, we develop two techniques which might\nbe of independent interest and useful in other settings: (i) a deterministic\nprocess that replaces the \"hitting set argument\" commonly used for shortest\npaths computation in various settings, and (ii) a simple, deterministic,\nconstruction of an $(n^{o(1)}, o(1))$-hop set of size $n^{1+o(1)}$. We combine\nthese techniques with many distributed algorithmic techniques, some of which\nfrom problems that are not directly related to shortest paths, e.g., ruling\nsets [Goldberg et al. STOC 1987], source detection [Lenzen and Peleg PODC\n2013], and partial distance estimation [Lenzen and Patt-Shamir PODC 2015].Comment: Accepted to SIAM Journal on Computing. A preliminary version of this\n  paper was presented at the 48th ACM Symposium on Theory of Computing (STOC\n  2016). Abstract shortened to respect the arXiv limit of 1920 characters", "1504.07766": "A multi-class approach for ranking graph nodes: models and experiments\n  with incomplete data,Del Corso, Gianna M.Romani, Francesco,Mathematics - Numerical AnalysisComputer Science - Information RetrievalPhysics - Physics and Society65F15G.2.2F.2.1,After the phenomenal success of the PageRank algorithm, many researchers have\nextended the PageRank approach to ranking graphs with richer structures beside\nthe simple linkage structure. In some scenarios we have to deal with\nmulti-parameters data where each node has additional features and there are\nrelationships between such features.\n  This paper stems from the need of a systematic approach when dealing with\nmulti-parameter data. We propose models and ranking algorithms which can be\nused with little adjustments for a large variety of networks (bibliographic\ndata, patent data, twitter and social data, healthcare data). In this paper we\nfocus on several aspects which have not been addressed in the literature: (1)\nwe propose different models for ranking multi-parameters data and a class of\nnumerical algorithms for efficiently computing the ranking score of such\nmodels, (2) by analyzing the stability and convergence properties of the\nnumerical schemes we tune a fast and stable technique for the ranking problem,\n(3) we consider the issue of the robustness of our models when data are\nincomplete. The comparison of the rank on the incomplete data with the rank on\nthe full structure shows that our models compute consistent rankings whose\ncorrelation is up to 60% when just 10% of the links of the attributes are\nmaintained suggesting the suitability of our model also when the data are\nincomplete.", "1504.07959": "Sublinear-Time Decremental Algorithms for Single-Source Reachability and\n  Shortest Paths on Directed Graphs,Henzinger, MonikaKrinninger, SebastianNanongkai, Danupon,Computer Science - Data Structures and Algorithms,We consider dynamic algorithms for maintaining Single-Source Reachability\n(SSR) and approximate Single-Source Shortest Paths (SSSP) on $n$-node $m$-edge\ndirected graphs under edge deletions (decremental algorithms). The previous\nfastest algorithm for SSR and SSSP goes back three decades to Even and Shiloach\n[JACM 1981]; it has $ O(1) $ query time and $ O (mn) $ total update time (i.e.,\nlinear amortized update time if all edges are deleted). This algorithm serves\nas a building block for several other dynamic algorithms. The question whether\nits total update time can be improved is a major, long standing, open problem.\n  In this paper, we answer this question affirmatively. We obtain a randomized\nalgorithm with an expected total update time of $ O(\\min (m^{7/6} n^{2/3 +\no(1)}, m^{3/4} n^{5/4 + o(1)}) ) = O (m n^{9/10 + o(1)}) $ for SSR and\n$(1+\\epsilon)$-approximate SSSP if the edge weights are integers from $ 1 $ to\n$ W \\leq 2^{\\log^c{n}} $ and $ \\epsilon \\geq 1 / \\log^c{n} $ for some constant\n$ c $. We also extend our algorithm to achieve roughly the same running time\nfor Strongly Connected Components (SCC), improving the algorithm of Roditty and\nZwick [FOCS 2002]. Our algorithm is most efficient for sparse and dense graphs.\nWhen $ m = \\Theta(n) $ its running time is $ O (n^{1 + 5/6 + o(1)}) $ and when\n$ m = \\Theta(n^2) $ its running time is $ O (n^{2 + 3/4 + o(1)}) $. For SSR we\nalso obtain an algorithm that is faster for dense graphs and has a total update\ntime of $ O ( m^{2/3} n^{4/3 + o(1)} + m^{3/7} n^{12/7 + o(1)}) $ which is $ O\n(n^{2 + 2/3}) $ when $ m = \\Theta(n^2) $. All our algorithms have constant\nquery time in the worst case and are correct with high probability against an\noblivious adversary.Comment: Preliminary versions of this paper were presented at the 46th ACM\n  Symposium on Theory of Computing (STOC 2014) and the 42nd International\n  Colloquium on Automata, Languages, and Programming (ICALP 2015)", "1504.08117": "Average Convergence Rate of Evolutionary Algorithms,He, JunLin, Guangming,Computer Science - Neural and Evolutionary Computing,In evolutionary optimization, it is important to understand how fast\nevolutionary algorithms converge to the optimum per generation, or their\nconvergence rate. This paper proposes a new measure of the convergence rate,\ncalled average convergence rate. It is a normalised geometric mean of the\nreduction ratio of the fitness difference per generation. The calculation of\nthe average convergence rate is very simple and it is applicable for most\nevolutionary algorithms on both continuous and discrete optimization. A\ntheoretical study of the average convergence rate is conducted for discrete\noptimization. Lower bounds on the average convergence rate are derived. The\nlimit of the average convergence rate is analysed and then the asymptotic\naverage convergence rate is proposed.", "1505.00199": "Theory of Optimizing Pseudolinear Performance Measures: Application to\n  F-measure,Parambath, Shameem A PuthiyaUsunier, NicolasGrandvalet, Yves,Computer Science - Machine Learning,Non-linear performance measures are widely used for the evaluation of\nlearning algorithms. For example, $F$-measure is a commonly used performance\nmeasure for classification problems in machine learning and information\nretrieval community. We study the theoretical properties of a subset of\nnon-linear performance measures called pseudo-linear performance measures which\nincludes $F$-measure, \\emph{Jaccard Index}, among many others. We establish\nthat many notions of $F$-measures and \\emph{Jaccard Index} are pseudo-linear\nfunctions of the per-class false negatives and false positives for binary,\nmulticlass and multilabel classification. Based on this observation, we present\na general reduction of such performance measure optimization problem to\ncost-sensitive classification problem with unknown costs. We then propose an\nalgorithm with provable guarantees to obtain an approximately optimal\nclassifier for the $F$-measure by solving a series of cost-sensitive\nclassification problems. The strength of our analysis is to be valid on any\ndataset and any class of classifiers, extending the existing theoretical\nresults on pseudo-linear measures, which are asymptotic in nature. We also\nestablish the multi-objective nature of the $F$-score maximization problem by\nlinking the algorithm with the weighted-sum approach used in multi-objective\noptimization. We present numerical experiments to illustrate the relative\nimportance of cost asymmetry and thresholding when learning linear classifiers\non various $F$-measure optimization tasks.Comment: Extended Version of the NIPS 2014 Paper", "1505.00398": "Block Basis Factorization for Scalable Kernel Matrix Evaluation,Wang, RuoxiLi, YingzhouMahoney, Michael W.Darve, Eric,Statistics - Machine LearningComputer Science - Machine LearningComputer Science - Numerical Analysis,Kernel methods are widespread in machine learning; however, they are limited\nby the quadratic complexity of the construction, application, and storage of\nkernel matrices. Low-rank matrix approximation algorithms are widely used to\naddress this problem and reduce the arithmetic and storage cost. However, we\nobserved that for some datasets with wide intra-class variability, the optimal\nkernel parameter for smaller classes yields a matrix that is less well\napproximated by low-rank methods. In this paper, we propose an efficient\nstructured low-rank approximation method---the Block Basis Factorization\n(BBF)---and its fast construction algorithm to approximate radial basis\nfunction (RBF) kernel matrices. Our approach has linear memory cost and\nfloating point operations. BBF works for a wide range of kernel bandwidth\nparameters and extends the domain of applicability of low-rank approximation\nmethods significantly. Our empirical results demonstrate the stability and\nsuperiority over the state-of-art kernel approximation algorithms.Comment: 16 pages, 5 figures", "1505.00947": "Colocated MIMO Radar Waveform Design for Transmit Beampattern Formation,Xu, HaishengBlum, Rick S.Wang, JianYuan, Jian,Computer Science - Information Theory,In this paper, colocated MIMO radar waveform design is considered by\nminimizing the integrated side-lobe level to obtain beam patterns with lower\nside-lobe levels than competing methods. First, a quadratic programming problem\nis formulated to design beam patterns by using the criteria for a minimal\nintegrated side-lobe level. A theorem is derived that provides a closed-form\nanalytical optimal solution that appears to be an extension of the Rayleigh\nquotient minimization for a possibly singular matrix in quadratic form. Such\nsingularities are shown to occur in the problem of interest, but proofs for the\noptimum solution in these singular matrix cases could not be found in the\nliterature. Next, an additional constraint is added to obtain beam patterns\nwith desired 3 dB beamwidths, resulting in a nonconvex quadratically\nconstrained quadratic program which is NP-hard. A semidefinite program and a\nGaussian randomized semidefinite relaxation are used to determine feasible\nsolutions arbitrarily close to the solution to the original problem.\nTheoretical and numerical analyses illustrate the impacts of changing the\nnumber of transmitters and orthogonal waveforms employed in the designs.\nNumerical comparisons are conducted to evaluate the proposed design approaches.Comment: 22 pages, 6 figures, Accepted by IEEE Transactions on Aerospace and\n  Electronic Systems", "1505.01189": "On the Rigidity of Sparse Random Graphs,Linial, NatiMosheiff, Jonathan,Mathematics - CombinatoricsComputer Science - Discrete MathematicsMathematics - Probability,A graph with a trivial automorphism group is said to be rigid. Wright proved\nthat for $\\frac{\\log n}{n}+\\omega(\\frac 1n)\\leq p\\leq \\frac 12$ a random graph\n$G\\in G(n,p)$ is rigid whp. It is not hard to see that this lower bound is\nsharp and for $p<\\frac{(1-\\epsilon)\\log n}{n}$ with positive probability\n$\\text{aut}(G)$ is nontrivial. We show that in the sparser case $\\omega(\\frac 1\nn)\\leq p\\leq \\frac{\\log n}{n}+\\omega(\\frac 1n)$, it holds whp that $G$'s\n$2$-core is rigid. We conclude that for all $p$, a graph in $G(n,p)$ is\nreconstrutible whp. In addition this yields for $\\omega(\\frac 1n)\\leq p\\leq\n\\frac 12$ a canonical labeling algorithm that almost surely runs in polynomial\ntime with $o(1)$ error rate. This extends the range for which such an algorithm\nis currently known.Comment: 17 pages", "1505.01668": "Multi-Target Tracking in Distributed Sensor Networks using Particle PHD\n  Filters,Leonard, Mark R.Zoubir, Abdelhak M.,Computer Science - Multiagent SystemsComputer Science - Systems and ControlStatistics - Applications68,Multi-target tracking is an important problem in civilian and military\napplications. This paper investigates multi-target tracking in distributed\nsensor networks. Data association, which arises particularly in multi-object\nscenarios, can be tackled by various solutions. We consider sequential Monte\nCarlo implementations of the Probability Hypothesis Density (PHD) filter based\non random finite sets. This approach circumvents the data association issue by\njointly estimating all targets in the region of interest. To this end, we\ndevelop the Diffusion Particle PHD Filter (D-PPHDF) as well as a centralized\nversion, called the Multi-Sensor Particle PHD Filter (MS-PPHDF). Their\nperformance is evaluated in terms of the Optimal Subpattern Assignment (OSPA)\nmetric, benchmarked against a distributed extension of the Posterior\nCram\\'er-Rao Lower Bound (PCRLB), and compared to the performance of an\nexisting distributed PHD Particle Filter. Furthermore, the robustness of the\nproposed tracking algorithms against outliers and their performance with\nrespect to different amounts of clutter is investigated.Comment: 27 pages, 6 figures", "1505.02091": "Weihrauch-completeness for layerwise computability,Pauly, ArnoFouch\u00e9, WillemDavie, George,Computer Science - Logic in Computer Science,We introduce the notion of being Weihrauch-complete for layerwise\ncomputability and provide several natural examples related to complex\noscillations, the law of the iterated logarithm and Birkhoff's theorem. We also\nconsider hitting time operators, which share the Weihrauch degree of the former\nexamples but fail to be layerwise computable.", "1505.02213": "Measuring dependence powerfully and equitably,Reshef, Yakir A.Reshef, David N.Finucane, Hilary K.Sabeti, Pardis C.Mitzenmacher, Michael M.,Statistics - MethodologyComputer Science - Information TheoryComputer Science - Machine LearningQuantitative Biology - Quantitative MethodsStatistics - Machine Learning,Given a high-dimensional data set we often wish to find the strongest\nrelationships within it. A common strategy is to evaluate a measure of\ndependence on every variable pair and retain the highest-scoring pairs for\nfollow-up. This strategy works well if the statistic used is equitable [Reshef\net al. 2015a], i.e., if, for some measure of noise, it assigns similar scores\nto equally noisy relationships regardless of relationship type (e.g., linear,\nexponential, periodic).\n  In this paper, we introduce and characterize a population measure of\ndependence called MIC*. We show three ways that MIC* can be viewed: as the\npopulation value of MIC, a highly equitable statistic from [Reshef et al.\n2011], as a canonical \"smoothing\" of mutual information, and as the supremum of\nan infinite sequence defined in terms of optimal one-dimensional partitions of\nthe marginals of the joint distribution. Based on this theory, we introduce an\nefficient approach for computing MIC* from the density of a pair of random\nvariables, and we define a new consistent estimator MICe for MIC* that is\nefficiently computable. In contrast, there is no known polynomial-time\nalgorithm for computing the original equitable statistic MIC. We show through\nsimulations that MICe has better bias-variance properties than MIC. We then\nintroduce and prove the consistency of a second statistic, TICe, that is a\ntrivial side-product of the computation of MICe and whose goal is powerful\nindependence testing rather than equitability.\n  We show in simulations that MICe and TICe have good equitability and power\nagainst independence respectively. The analyses here complement a more in-depth\nempirical evaluation of several leading measures of dependence [Reshef et al.\n2015b] that shows state-of-the-art performance for MICe and TICe.Comment: Yakir A. Reshef and David N. Reshef are co-first authors, Pardis C.\n  Sabeti and Michael M. Mitzenmacher are co-last authors. This paper, together\n  with arXiv:1505.02212, subsumes arXiv:1408.4908. v3 includes new analyses and\n  exposition", "1505.02214": "An Empirical Study of Leading Measures of Dependence,Reshef, David N.Reshef, Yakir A.Sabeti, Pardis C.Mitzenmacher, Michael M.,Statistics - MethodologyComputer Science - Information TheoryComputer Science - Machine LearningQuantitative Biology - Quantitative MethodsStatistics - Machine Learning,In exploratory data analysis, we are often interested in identifying\npromising pairwise associations for further analysis while filtering out\nweaker, less interesting ones. This can be accomplished by computing a measure\nof dependence on all variable pairs and examining the highest-scoring pairs,\nprovided the measure of dependence used assigns similar scores to equally noisy\nrelationships of different types. This property, called equitability, is\nformalized in Reshef et al. [2015b]. In addition to equitability, measures of\ndependence can also be assessed by the power of their corresponding\nindependence tests as well as their runtime.\n  Here we present extensive empirical evaluation of the equitability, power\nagainst independence, and runtime of several leading measures of dependence.\nThese include two statistics introduced in Reshef et al. [2015a]: MICe, which\nhas equitability as its primary goal, and TICe, which has power against\nindependence as its goal. Regarding equitability, our analysis finds that MICe\nis the most equitable method on functional relationships in most of the\nsettings we considered, although mutual information estimation proves the most\nequitable at large sample sizes in some specific settings. Regarding power\nagainst independence, we find that TICe, along with Heller and Gorfine's S^DDP,\nis the state of the art on the relationships we tested. Our analyses also show\na trade-off between power against independence and equitability consistent with\nthe theory in Reshef et al. [2015b]. In terms of runtime, MICe and TICe are\nsignificantly faster than many other measures of dependence tested, and\ncomputing either one makes computing the other trivial. This suggests that a\nfast and useful strategy for achieving a combination of power against\nindependence and equitability may be to filter relationships by TICe and then\nto examine the MICe of only the significant ones.Comment: David N. Reshef and Yakir A. Reshef are co-first authors, Pardis C.\n  Sabeti and Michael M. Mitzenmacher are co-last authors", "1505.02348": "The Topology of Biological Networks from a Complexity Perspective,Atiia, AliMajor, Fran\u00e7oisWaldisp\u00fchl, J\u00e9r\u00f4me,Computer Science - Social and Information NetworksPhysics - Physics and SocietyQuantitative Biology - Molecular Networks,A complexity-theoretic approach to studying biological networks is proposed.\nA simple graph representation is used where molecules (DNA, RNA, proteins and\nchemicals) are vertices and relations between them are directed and signed\n(promotional (+) or inhibitory (-)) edges. Based on this model, the problem of\nnetwork evolution (NE) is defined formally as an optimization problem and\nsubsequently proven to be fundamentally hard (NP-hard) by means of reduction\nfrom the Knapsack problem (KP). Second, for empirical validation, various\nbiological networks of experimentally-validated interactions are compared\nagainst randomly generated networks with varying degree distributions. An NE\ninstance is created using a given real or synthetic (random) network. After\nbeing reverse-reduced to a KP instance, each NE instance is fed to a KP solver\nand the average achieved knapsack value-to-weight ratio is recorded from\nmultiple rounds of simulated evolutionary pressure. The results show that\nbiological networks (and synthetic networks of similar degree distribution)\nachieve the highest ratios at maximal evolutionary pressure and minimal error\ntolerance conditions. The more distant (in degree distribution) a synthetic\nnetwork is from biological networks the lower its achieved ratio. The results\nshed light on how computational intractability has shaped the evolution of\nbiological networks into their current topology.Comment: 11 pages, 2 figures, 3 tables, 1 theorem", "1505.02921": "How Far Can You Get By Combining Change Detection Algorithms?,Bianco, SimoneCiocca, GianluigiSchettini, Raimondo,Computer Science - Computer Vision and Pattern RecognitionI.4.8G.1.6,Given the existence of many change detection algorithms, each with its own\npeculiarities and strengths, we propose a combination strategy, that we termed\nIUTIS (In Unity There Is Strength), based on a genetic Programming framework.\nThis combination strategy is aimed at leveraging the strengths of the\nalgorithms and compensate for their weakness. In this paper we show our\nfindings in applying the proposed strategy in two different scenarios. The\nfirst scenario is purely performance-based. The second scenario performance and\nefficiency must be balanced. Results demonstrate that starting from simple\nalgorithms we can achieve comparable results with respect to more complex\nstate-of-the-art change detection algorithms, while keeping the computational\ncomplexity affordable for real-time applications.", "1505.03001": "Detecting the large entries of a sparse covariance matrix in\n  sub-quadratic time,Shwartz, OferNadler, Boaz,Statistics - ComputationComputer Science - Machine LearningStatistics - Machine Learning,The covariance matrix of a $p$-dimensional random variable is a fundamental\nquantity in data analysis. Given $n$ i.i.d. observations, it is typically\nestimated by the sample covariance matrix, at a computational cost of\n$O(np^{2})$ operations. When $n,p$ are large, this computation may be\nprohibitively slow. Moreover, in several contemporary applications, the\npopulation matrix is approximately sparse, and only its few large entries are\nof interest. This raises the following question, at the focus of our work:\nAssuming approximate sparsity of the covariance matrix, can its large entries\nbe detected much faster, say in sub-quadratic time, without explicitly\ncomputing all its $p^{2}$ entries? In this paper, we present and theoretically\nanalyze two randomized algorithms that detect the large entries of an\napproximately sparse sample covariance matrix using only $O(np\\text{ poly log }\np)$ operations. Furthermore, assuming sparsity of the population matrix, we\nderive sufficient conditions on the underlying random variable and on the\nnumber of samples $n$, for the sample covariance matrix to satisfy our\napproximate sparsity requirements. Finally, we illustrate the performance of\nour algorithms via several simulations.", "1505.03653": "Timed Consistent Network Updates,Mizrahi, TalSaat, EfiMoses, Yoram,Computer Science - Networking and Internet Architecture,Network updates such as policy and routing changes occur frequently in\nSoftware Defined Networks (SDN). Updates should be performed consistently,\npreventing temporary disruptions, and should require as little overhead as\npossible. Scalability is increasingly becoming an essential requirement in SDN.\nIn this paper we propose to use time-triggered network updates to achieve\nconsistent updates. Our proposed solution requires lower overhead than existing\nupdate approaches, without compromising the consistency during the update. We\ndemonstrate that accurate time enables far more scalable consistent updates in\nSDN than previously available. In addition, it provides the SDN programmer with\nfine-grained control over the tradeoff between consistency and scalability.Comment: This technical report is an extended version of the paper \"Timed\n  Consistent Network Updates\", which was accepted to the ACM SIGCOMM Symposium\n  on SDN Research (SOSR) '15, Santa Clara, CA, US, June 2015", "1505.03898": "Pinball Loss Minimization for One-bit Compressive Sensing: Convex Models\n  and Algorithms,Huang, XiaolinShi, LeiYan, MingSuykens, Johan A. K.,Computer Science - Information TheoryMathematics - Numerical AnalysisMathematics - Optimization and ControlStatistics - Machine Learning,The one-bit quantization is implemented by one single comparator that\noperates at low power and a high rate. Hence one-bit compressive sensing\n(1bit-CS) becomes attractive in signal processing. When measurements are\ncorrupted by noise during signal acquisition and transmission, 1bit-CS is\nusually modeled as minimizing a loss function with a sparsity constraint. The\none-sided $\\ell_1$ loss and the linear loss are two popular loss functions for\n1bit-CS. To improve the decoding performance on noisy data, we consider the\npinball loss, which provides a bridge between the one-sided $\\ell_1$ loss and\nthe linear loss. Using the pinball loss, two convex models, an elastic-net\npinball model and its modification with the $\\ell_1$-norm constraint, are\nproposed. To efficiently solve them, the corresponding dual coordinate ascent\nalgorithms are designed and their convergence is proved. The numerical\nexperiments confirm the effectiveness of the proposed algorithms and the\nperformance of the pinball loss minimization for 1bit-CS.Comment: 11 pages", "1505.03931": "Robust Biomolecular Finite Automata,Klinge, Titus H.Lathrop, James I.Lutz, Jack H.,Computer Science - Computational ComplexityComputer Science - Emerging TechnologiesComputer Science - Formal Languages and Automata Theory,We present a uniform method for translating an arbitrary nondeterministic\nfinite automaton (NFA) into a deterministic mass action input/output chemical\nreaction network (I/O CRN) that simulates it. The I/O CRN receives its input as\na continuous time signal consisting of concentrations of chemical species that\nvary to represent the NFA's input string in a natural way. The I/O CRN exploits\nthe inherent parallelism of chemical kinetics to simulate the NFA in real time\nwith a number of chemical species that is linear in the size of the NFA. We\nprove that the simulation is correct and that it is robust with respect to\nperturbations of the input signal, the initial concentrations of species, the\noutput (decision), and the rate constants of the reactions of the I/O CRN.", "1505.04026": "Automatic Facial Expression Recognition Using Features of Salient Facial\n  Patches,Happy, S LRoutray, Aurobinda,Computer Science - Computer Vision and Pattern Recognition,Extraction of discriminative features from salient facial patches plays a\nvital role in effective facial expression recognition. The accurate detection\nof facial landmarks improves the localization of the salient patches on face\nimages. This paper proposes a novel framework for expression recognition by\nusing appearance features of selected facial patches. A few prominent facial\npatches, depending on the position of facial landmarks, are extracted which are\nactive during emotion elicitation. These active patches are further processed\nto obtain the salient patches which contain discriminative features for\nclassification of each pair of expressions, thereby selecting different facial\npatches as salient for different pair of expression classes. One-against-one\nclassification method is adopted using these features. In addition, an\nautomated learning-free facial landmark detection technique has been proposed,\nwhich achieves similar performances as that of other state-of-art landmark\ndetection methods, yet requires significantly less execution time. The proposed\nmethod is found to perform well consistently in different resolutions, hence,\nproviding a solution for expression recognition in low resolution images.\nExperiments on CK+ and JAFFE facial expression databases show the effectiveness\nof the proposed system.", "1505.04036": "Unified way for computing dynamics of Bose-Einstein condensates and\n  degenerate Fermi gases,Gawryluk, KrzysztofKarpiuk, TomaszGajda, MariuszRzazewski, KazimierzBrewczyk, Miroslaw,Computer Science - Computational Engineering, Finance, and ScienceCondensed Matter - Quantum Gases,In this work we present a very simple and efficient numerical scheme which\ncan be applied to study the dynamics of bosonic systems like, for instance,\nspinor Bose-Einstein condensates with nonlocal interactions but equally well\nworks for Fermi gases. The method we use is a modification of well known Split\nOperator Method (SOM). We carefully examine this algorithm in the case of $F=1$\nspinor Bose-Einstein condensate without and with dipolar interactions and for\nstrongly interacting two-component Fermi gas. Our extension of the SOM method\nhas many advantages: it is fast, stable, and keeps constant all the physical\nconstraints (constants of motion) at high level.Comment: 21 pages, 7 figures", "1505.04252": "Global Convergence of Unmodified 3-Block ADMM for a Class of Convex\n  Minimization Problems,Lin, TianyiMa, ShiqianZhang, Shuzhong,Mathematics - Optimization and ControlComputer Science - Machine LearningStatistics - Machine Learning,The alternating direction method of multipliers (ADMM) has been successfully\napplied to solve structured convex optimization problems due to its superior\npractical performance. The convergence properties of the 2-block ADMM have been\nstudied extensively in the literature. Specifically, it has been proven that\nthe 2-block ADMM globally converges for any penalty parameter $\\gamma>0$. In\nthis sense, the 2-block ADMM allows the parameter to be free, i.e., there is no\nneed to restrict the value for the parameter when implementing this algorithm\nin order to ensure convergence. However, for the 3-block ADMM, Chen \\etal\n\\cite{Chen-admm-failure-2013} recently constructed a counter-example showing\nthat it can diverge if no further condition is imposed. The existing results on\nstudying further sufficient conditions on guaranteeing the convergence of the\n3-block ADMM usually require $\\gamma$ to be smaller than a certain bound, which\nis usually either difficult to compute or too small to make it a practical\nalgorithm. In this paper, we show that the 3-block ADMM still globally\nconverges with any penalty parameter $\\gamma>0$ if the third function $f_3$ in\nthe objective is smooth and strongly convex, and its condition number is in\n$[1,1.0798)$, besides some other mild conditions. This requirement covers an\nimportant class of problems to be called regularized least squares\ndecomposition (RLSD) in this paper.", "1505.04343": "Provably Correct Algorithms for Matrix Column Subset Selection with\n  Selectively Sampled Data,Wang, YiningSingh, Aarti,Statistics - Machine LearningComputer Science - Machine Learning,We consider the problem of matrix column subset selection, which selects a\nsubset of columns from an input matrix such that the input can be well\napproximated by the span of the selected columns. Column subset selection has\nbeen applied to numerous real-world data applications such as population\ngenetics summarization, electronic circuits testing and recommendation systems.\nIn many applications the complete data matrix is unavailable and one needs to\nselect representative columns by inspecting only a small portion of the input\nmatrix. In this paper we propose the first provably correct column subset\nselection algorithms for partially observed data matrices. Our proposed\nalgorithms exhibit different merits and limitations in terms of statistical\naccuracy, computational efficiency, sample complexity and sampling schemes,\nwhich provides a nice exploration of the tradeoff between these desired\nproperties for column subset selection. The proposed methods employ the idea of\nfeedback driven sampling and are inspired by several sampling schemes\npreviously introduced for low-rank matrix approximation tasks (Drineas et al.,\n2008; Frieze et al., 2004; Deshpande and Vempala, 2006; Krishnamurthy and\nSingh, 2014). Our analysis shows that, under the assumption that the input data\nmatrix has incoherent rows but possibly coherent columns, all algorithms\nprovably converge to the best low-rank approximation of the original data as\nnumber of selected columns increases. Furthermore, two of the proposed\nalgorithms enjoy a relative error bound, which is preferred for column subset\nselection and matrix approximation purposes. We also demonstrate through both\ntheoretical and empirical analysis the power of feedback driven sampling\ncompared to uniform random sampling on input matrices with highly correlated\ncolumns.Comment: 42 pages. Accepted to Journal of Machine Learning Research", "1505.04911": "Read Mapping on de Bruijn graph,Limasset, AntoineCazaux, BastienRivals, EricPeterlongo, Pierre,Computer Science - Data Structures and AlgorithmsQuantitative Biology - Genomics,Background Next Generation Sequencing (NGS) has dramatically enhanced our\nability to sequence genomes, but not to assemble them. In practice, many\npublished genome sequences remain in the state of a large set of contigs. Each\ncontig describes the sequence found along some path of the assembly graph,\nhowever, the set of contigs does not record all the sequence information\ncontained in that graph. Although many subsequent analyses can be performed\nwith the set of contigs, one may ask whether mapping reads on the contigs is as\ninformative as mapping them on the paths of the assembly graph. Currently, one\nlacks practical tools to perform mapping on such graphs. Results Here, we\npropose a formal definition of mapping on a de Bruijn graph, analyse the\nproblem complexity which turns out to be NP-complete, and provide a practical\nsolution.We propose a pipeline called GGMAP (Greedy Graph MAPping). Its novelty\nis a procedure to map reads on branching paths of the graph, for which we\ndesigned a heuristic algorithm called BGREAT (de Bruijn Graph REAd mapping\nTool). For the sake of efficiency, BGREAT rewrites a read sequence as a\nsuccession of unitigs sequences. GGMAP can map millions of reads per CPU hour\non a de Bruijn graph built from a large set of human genomic reads.\nSurprisingly, results show that up to 22% more reads can be mapped on the graph\nbut not on the contig set. Conclusions Although mapping reads on a de Bruijn\ngraph is complex task, our proposal offers a practical solution combining\nefficiency with an improved mapping capacity compared to assembly-based mapping\neven for complex eukaryotic data. Availability: github.com/Malfoy/BGREAT\nKeywords: Read mapping; De bruijn graphs; NGS; NP-completenessComment: BMC Bioinformatics", "1505.04938": "Convective regularization for optical flow,Iglesias, Jos\u00e9 A.Kirisits, Clemens,Mathematics - Optimization and ControlComputer Science - Computer Vision and Pattern Recognition49N45, 68T45, 68U10,We argue that the time derivative in a fixed coordinate frame may not be the\nmost appropriate measure of time regularity of an optical flow field. Instead,\nfor a given velocity field $v$ we consider the convective acceleration $v_t +\n\\nabla v v$ which describes the acceleration of objects moving according to\n$v$. Consequently we investigate the suitability of the nonconvex functional\n$\\|v_t + \\nabla v v\\|^2_{L^2}$ as a regularization term for optical flow. We\ndemonstrate that this term acts as both a spatial and a temporal regularizer\nand has an intrinsic edge-preserving property. We incorporate it into a\ncontrast invariant and time-regularized variant of the Horn-Schunck functional,\nprove existence of minimizers and verify experimentally that it addresses some\nof the problems of basic quadratic models. For the minimization we use an\niterative scheme that approximates the original nonlinear problem with a\nsequence of linear ones. We believe that the convective acceleration may be\ngainfully introduced in a variety of optical flow models.", "1505.05193": "Synthesising Executable Gene Regulatory Networks from Single-cell Gene\n  Expression Data,Fisher, JasminK\u00f6ksal, Ali SinanPiterman, NirWoodhouse, Steven,Computer Science - Computational Engineering, Finance, and ScienceComputer Science - Logic in Computer ScienceQuantitative Biology - Molecular Networks,Recent experimental advances in biology allow researchers to obtain gene\nexpression profiles at single-cell resolution over hundreds, or even thousands\nof cells at once. These single-cell measurements provide snapshots of the\nstates of the cells that make up a tissue, instead of the population-level\naverages provided by conventional high-throughput experiments. This new data\ntherefore provides an exciting opportunity for computational modelling. In this\npaper we introduce the idea of viewing single-cell gene expression profiles as\nstates of an asynchronous Boolean network, and frame model inference as the\nproblem of reconstructing a Boolean network from its state space. We then give\na scalable algorithm to solve this synthesis problem. We apply our technique to\nboth simulated and real data. We first apply our technique to data simulated\nfrom a well established model of common myeloid progenitor differentiation. We\nshow that our technique is able to recover the original Boolean network rules.\nWe then apply our technique to a large dataset taken during embryonic\ndevelopment containing thousands of cell measurements. Our technique\nsynthesises matching Boolean networks, and analysis of these models yields new\npredictions about blood development which our experimental collaborators were\nable to verify.Comment: Final published version to appear in Computer Aided Verification\n  (CAV), Springer, July 2015", "1505.05312": "A New Oscillating-Error Technique for Classifiers,Greer, Kieran,Computer Science - Artificial Intelligence,This paper describes a new method for reducing the error in a classifier. It\nuses an error correction update that includes the very simple rule of either\nadding or subtracting the error adjustment, based on whether the variable value\nis currently larger or smaller than the desired value. While a traditional\nneuron would sum the inputs together and then apply a function to the total,\nthis new method can change the function decision for each input value. This\ngives added flexibility to the convergence procedure, where through a series of\ntranspositions, variables that are far away can continue towards the desired\nvalue, whereas variables that are originally much closer can oscillate from one\nside to the other. Tests show that the method can successfully classify some\nbenchmark datasets. It can also work in a batch mode, with reduced training\ntimes and can be used as part of a neural network architecture. Some\ncomparisons with an earlier wave shape paper are also made.", "1505.05451": "Fuzzy Least Squares Twin Support Vector Machines,Sartakhti, Javad SalimiAfrabandpey, HomayunGhadiri, Nasser,Computer Science - Artificial IntelligenceComputer Science - Machine Learning,Least Squares Twin Support Vector Machine (LST-SVM) has been shown to be an\nefficient and fast algorithm for binary classification. It combines the\noperating principles of Least Squares SVM (LS-SVM) and Twin SVM (T-SVM); it\nconstructs two non-parallel hyperplanes (as in T-SVM) by solving two systems of\nlinear equations (as in LS-SVM). Despite its efficiency, LST-SVM is still\nunable to cope with two features of real-world problems. First, in many\nreal-world applications, labels of samples are not deterministic; they come\nnaturally with their associated membership degrees. Second, samples in\nreal-world applications may not be equally important and their importance\ndegrees affect the classification. In this paper, we propose Fuzzy LST-SVM\n(FLST-SVM) to deal with these two characteristics of real-world data. Two\nmodels are introduced for FLST-SVM: the first model builds up crisp hyperplanes\nusing training samples and their corresponding membership degrees. The second\nmodel, on the other hand, constructs fuzzy hyperplanes using training samples\nand their membership degrees. Numerical evaluation of the proposed method with\nsynthetic and real datasets demonstrate significant improvement in the\nclassification accuracy of FLST-SVM when compared to well-known existing\nversions of SVM.", "1505.05917": "Decentralized Sequential Composite Hypothesis Test Based on One-Bit\n  Communication,Li, ShangLi, XiaoouWang, XiaodongLiu, Jingchen,Statistics - ApplicationsComputer Science - Information Theory,This paper considers the sequential composite hypothesis test with multiple\nsensors. The sensors observe random samples in parallel and communicate with a\nfusion center, who makes the global decision based on the sensor inputs. On one\nhand, in the centralized scenario, where local samples are precisely\ntransmitted to the fusion center, the generalized sequential likelihood ratio\ntest (GSPRT) is shown to be asymptotically optimal in terms of the expected\nsample size as error rates tend to zero. On the other hand, for systems with\nlimited power and bandwidth resources, decentralized solutions that only send a\nsummary of local samples (we particularly focus on a one-bit communication\nprotocol) to the fusion center is of great importance. To this end, we first\nconsider a decentralized scheme where sensors send their one-bit quantized\nstatistics every fixed period of time to the fusion center. We show that such a\nuniform sampling and quantization scheme is strictly suboptimal and its\nsuboptimality can be quantified by the KL divergence of the distributions of\nthe quantized statistics under both hypotheses. We then propose a decentralized\nGSPRT based on level-triggered sampling. That is, each sensor runs its own\nGSPRT repeatedly and reports its local decision to the fusion center\nasynchronously. We show that this scheme is asymptotically optimal as the local\nthresholds and global thresholds grow large at different rates. Lastly, two\nparticular models and their associated applications are studied to compare the\ncentralized and decentralized approaches. Numerical results are provided to\ndemonstrate that the proposed level-triggered sampling based decentralized\nscheme aligns closely with the centralized scheme with substantially lower\ncommunication overhead, and significantly outperforms the uniform sampling and\nquantization based decentralized scheme.Comment: 39 pages", "1505.06036": "VPG and EPG bend-numbers of Halin Graphs,Francis, Mathew C.Lahiri, Abhiruk,Mathematics - CombinatoricsComputer Science - Discrete Mathematics05C62,A piecewise linear curve in the plane made up of $k+1$ line segments, each of\nwhich is either horizontal or vertical, with consecutive segments being of\ndifferent orientation is called a $k$-bend path. Given a graph $G$, a\ncollection of $k$-bend paths in which each path corresponds to a vertex in $G$\nand two paths have a common point if and only if the vertices corresponding to\nthem are adjacent in $G$ is called a $B_k$-VPG representation of $G$.\nSimilarly, a collection of $k$-bend paths each of which corresponds to a vertex\nin $G$ is called an $B_k$-EPG representation of $G$ if any two paths have a\nline segment of non-zero length in common if and only if their corresponding\nvertices are adjacent in $G$. The VPG bend-number $b_v(G)$ of a graph $G$ is\nthe minimum $k$ such that $G$ has a $B_k$-VPG representation. Similarly, the\nEPG bend-number $b_e(G)$ of a graph $G$ is the minimum $k$ such that $G$ has a\n$B_k$-EPG representation. Halin graphs are the graphs formed by taking a tree\nwith no degree $2$ vertex and then connecting its leaves to form a cycle in\nsuch a way that the graph has a planar embedding. We prove that if $G$ is a\nHalin graph then $b_v(G) \\leq 1$ and $b_e(G) \\leq 2$. These bounds are tight.\nIn fact, we prove the stronger result that if $G$ is a planar graph formed by\nconnecting the leaves of any tree to form a simple cycle, then it has a\nVPG-representation using only one type of 1-bend paths and an\nEPG-representation using only one type of 2-bend paths.Comment: 11 pages, 3 figures", "1505.06362": "Polynomially Low Error PCPs with polyloglog n Queries via Modular\n  Composition,Dinur, IritHarsha, PrahladhKindler, Guy,Computer Science - Computational Complexity,We show that every language in NP has a PCP verifier that tosses $O(\\log n)$\nrandom coins, has perfect completeness, and a soundness error of at most\n$1/\\text{poly}(n)$, while making at most $O(\\text{poly}\\log\\log n)$ queries\ninto a proof over an alphabet of size at most $n^{1/\\text{poly}\\log\\log n}$.\nPrevious constructions that obtain $1/\\text{poly}(n)$ soundness error used\neither $\\text{poly}\\log n $ queries or an exponential sized alphabet, i.e. of\nsize $2^{n^c}$ for some $c>0$. Our result is an exponential improvement in both\nparameters simultaneously.\n  Our result can be phrased as a polynomial-gap hardness for approximate CSPs\nwith arity $\\text{poly}\\log\\log n$ and alphabet size $n^{1/\\text{poly}\\log n}$.\nThe ultimate goal, in this direction, would be to prove polynomial hardness for\nCSPs with constant arity and polynomial alphabet size (aka the sliding scale\nconjecture for inverse polynomial soundness error).\n  Our construction is based on a modular generalization of previous PCP\nconstructions in this parameter regime, which involves a composition theorem\nthat uses an extra `consistency' query but maintains the inverse polynomial\nrelation between the soundness error and the alphabet size.\n  Our main technical/conceptual contribution is a new notion of soundness,\nwhich we refer to as {\\em distributional soundness}, that replaces the previous\nnotion of \"list decoding soundness\", and that allows us to prove a modular\ncomposition theorem with tighter parameters. This new notion of soundness\nallows us to invoke composition a super-constant number of times without\nincurring a blow-up in the soundness error.", "1505.06770": "Sketching for Sequential Change-Point Detection,Cao, YangThompson, AndrewWang, MengXie, Yao,Computer Science - Machine LearningStatistics - Machine Learning,We study sequential change-point detection procedures based on linear\nsketches of high-dimensional signal vectors using generalized likelihood ratio\n(GLR) statistics. The GLR statistics allow for an unknown post-change mean that\nrepresents an anomaly or novelty. We consider both fixed and time-varying\nprojections, derive theoretical approximations to two fundamental performance\nmetrics: the average run length (ARL) and the expected detection delay (EDD);\nthese approximations are shown to be highly accurate by numerical simulations.\nWe further characterize the relative performance measure of the sketching\nprocedure compared to that without sketching and show that there can be little\nperformance loss when the signal strength is sufficiently large, and enough\nnumber of sketches are used. Finally, we demonstrate the good performance of\nsketching procedures using simulation and real-data examples on solar flare\ndetection and failure detection in power networks.Comment: Submitted", "1505.06819": "Coalgebraic Infinite Traces and Kleisli Simulations,Urabe, NatsukiHasuo, Ichiro,Computer Science - Logic in Computer Science,Kleisli simulation is a categorical notion introduced by Hasuo to verify\nfinite trace inclusion. They allow us to give definitions of forward and\nbackward simulation for various types of systems. A generic categorical theory\nbehind Kleisli simulation has been developed and it guarantees the soundness of\nthose simulations with respect to finite trace semantics. Moreover, those\nsimulations can be aided by forward partial execution (FPE)---a categorical\ntransformation of systems previously introduced by the authors.\n  In this paper, we give Kleisli simulation a theoretical foundation that\nassures its soundness also with respect to infinitary traces. There, following\nJacobs' work, infinitary trace semantics is characterized as the \"largest\nhomomorphism.\" It turns out that soundness of forward simulations is rather\nstraightforward; that of backward simulation holds too, although it requires\ncertain additional conditions and its proof is more involved. We also show that\nFPE can be successfully employed in the infinitary trace setting to enhance the\napplicability of Kleisli simulations as witnesses of trace inclusion. Our\nframework is parameterized in the monad for branching as well as in the functor\nfor linear-time behaviors; for the former we mainly use the powerset monad (for\nnondeterminism), the sub-Giry monad (for probability), and the lift monad (for\nexception).Comment: 39 pages, 1 figure", "1505.06897": "Times series averaging from a probabilistic interpretation of\n  time-elastic kernel,Marteau, Pierre-Fran\u00e7ois,Computer Science - Machine LearningComputer Science - Data Structures and Algorithms,At the light of regularized dynamic time warping kernels, this paper\nreconsider the concept of time elastic centroid (TEC) for a set of time series.\nFrom this perspective, we show first how TEC can easily be addressed as a\npreimage problem. Unfortunately this preimage problem is ill-posed, may suffer\nfrom over-fitting especially for long time series and getting a sub-optimal\nsolution involves heavy computational costs. We then derive two new algorithms\nbased on a probabilistic interpretation of kernel alignment matrices that\nexpresses in terms of probabilistic distributions over sets of alignment paths.\nThe first algorithm is an iterative agglomerative heuristics inspired from the\nstate of the art DTW barycenter averaging (DBA) algorithm proposed specifically\nfor the Dynamic Time Warping measure. The second proposed algorithm achieves a\nclassical averaging of the aligned samples but also implements an averaging of\nthe time of occurrences of the aligned samples. It exploits a straightforward\nprogressive agglomerative heuristics. An experimentation that compares for 45\ntime series datasets classification error rates obtained by first near\nneighbors classifiers exploiting a single medoid or centroid estimate to\nrepresent each categories show that: i) centroids based approaches\nsignificantly outperform medoids based approaches, ii) on the considered\nexperience, the two proposed algorithms outperform the state of the art DBA\nalgorithm, and iii) the second proposed algorithm that implements an averaging\njointly in the sample space and along the time axes emerges as the most\nsignificantly robust time elastic averaging heuristic with an interesting noise\nreduction capability. Index Terms-Time series averaging Time elastic kernel\nDynamic Time Warping Time series clustering and classification.", "1505.07368": "Revisiting Actor Programming in C++,Charousset, DominikHiesgen, RaphaelSchmidt, Thomas C.,Computer Science - Programming Languages,The actor model of computation has gained significant popularity over the\nlast decade. Its high level of abstraction makes it appealing for concurrent\napplications in parallel and distributed systems. However, designing a\nreal-world actor framework that subsumes full scalability, strong reliability,\nand high resource efficiency requires many conceptual and algorithmic additives\nto the original model.\n  In this paper, we report on designing and building CAF, the \"C++ Actor\nFramework\". CAF targets at providing a concurrent and distributed native\nenvironment for scaling up to very large, high-performance applications, and\nequally well down to small constrained systems. We present the key\nspecifications and design concepts---in particular a message-transparent\narchitecture, type-safe message interfaces, and pattern matching\nfacilities---that make native actors a viable approach for many robust,\nelastic, and highly distributed developments. We demonstrate the feasibility of\nCAF in three scenarios: first for elastic, upscaling environments, second for\nincluding heterogeneous hardware like GPGPUs, and third for distributed runtime\nsystems. Extensive performance evaluations indicate ideal runtime behaviour for\nup to 64 cores at very low memory footprint, or in the presence of GPUs. In\nthese tests, CAF continuously outperforms the competing actor environments\nErlang, Charm++, SalsaLite, Scala, ActorFoundry, and even the OpenMPI.Comment: 33 pages", "1505.07429": "Semi-algebraic colorings of complete graphs,Fox, JacobPach, JanosSuk, Andrew,Mathematics - CombinatoricsComputer Science - Computational Geometry,We consider $m$-colorings of the edges of a complete graph, where each color\nclass is defined semi-algebraically with bounded complexity. The case $m = 2$\nwas first studied by Alon et al., who applied this framework to obtain\nsurprisingly strong Ramsey-type results for intersection graphs of geometric\nobjects and for other graphs arising in computational geometry. Considering\nlarger values of $m$ is relevant, e.g., to problems concerning the number of\ndistinct distances determined by a point set.\n  For $p\\ge 3$ and $m\\ge 2$, the classical Ramsey number $R(p;m)$ is the\nsmallest positive integer $n$ such that any $m$-coloring of the edges of $K_n$,\nthe complete graph on $n$ vertices, contains a monochromatic $K_p$. It is a\nlongstanding open problem that goes back to Schur (1916) to decide whether\n$R(p;m)=2^{O(m)}$, for a fixed $p$. We prove that this is true if each color\nclass is defined semi-algebraically with bounded complexity. The order of\nmagnitude of this bound is tight. Our proof is based on the Cutting Lemma of\nChazelle {\\em et al.}, and on a Szemer\\'edi-type regularity lemma for\nmulticolored semi-algebraic graphs, which is of independent interest. The same\ntechnique is used to address the semi-algebraic variant of a more general\nRamsey-type problem of Erd\\H{o}s and Shelah.", "1505.08162": "Dimension and cut vertices: an application of Ramsey theory,Trotter, William T.Walczak, BartoszWang, Ruidong,Mathematics - CombinatoricsComputer Science - Discrete Mathematics06A07, 05C35,Motivated by quite recent research involving the relationship between the\ndimension of a poset and graph-theoretic properties of its cover graph, we show\nthat for every $d\\geq 1$, if $P$ is a poset and the dimension of a subposet $B$\nof $P$ is at most $d$ whenever the cover graph of $B$ is a block of the cover\ngraph of $P$, then the dimension of $P$ is at most $d+2$. We also construct\nexamples which show that this inequality is best possible. We consider the\nproof of the upper bound to be fairly elegant and relatively compact. However,\nwe know of no simple proof for the lower bound, and our argument requires a\npowerful tool known as the Product Ramsey Theorem. As a consequence, our\nconstructions involve posets of enormous size.Comment: Final published version with updated references", "1506.00147": "Team Performance with Test Scores,Kleinberg, JonRaghu, Maithra,Computer Science - Data Structures and AlgorithmsComputer Science - Computer Science and Game Theory,Team performance is a ubiquitous area of inquiry in the social sciences, and\nit motivates the problem of team selection -- choosing the members of a team\nfor maximum performance. Influential work of Hong and Page has argued that\ntesting individuals in isolation and then assembling the highest-scoring ones\ninto a team is not an effective method for team selection. For a broad class of\nperformance measures, based on the expected maximum of random variables\nrepresenting individual candidates, we show that tests directly measuring\nindividual performance are indeed ineffective, but that a more subtle family of\ntests used in isolation can provide a constant-factor approximation for team\nperformance. These new tests measure the \"potential\" of individuals, in a\nprecise sense, rather than performance, to our knowledge they represent the\nfirst time that individual tests have been shown to produce near-optimal teams\nfor a non-trivial team performance measure. We also show families of\nsubdmodular and supermodular team performance functions for which no test\napplied to individuals can produce near-optimal teams, and discuss implications\nfor submodular maximization via hill-climbing.", "1506.00272": "Synapse: Synthetic Application Profiler and Emulator,Merzky, AndreJha, Shantenu,Computer Science - Distributed, Parallel, and Cluster Computing,We introduce Synapse motivated by the needs to estimate and emulate workload\nexecution characteristics on high-performance and distributed heterogeneous\nresources. Synapse has a platform independent application profiler, and the\nability to emulate profiled workloads on a variety of heterogeneous resources.\nSynapse is used as a proxy application (or \"representative application\") for\nreal workloads, with the added advantage that it can be tuned at arbitrary\nlevels of granularity in ways that are simply not possible using real\napplications. Experiments show that automated profiling using Synapse\nrepresents application characteristics with high fidelity. Emulation using\nSynapse can reproduce the application behavior in the original runtime\nenvironment, as well as reproducing properties when used in a different\nrun-time environments.", "1506.00290": "Compressing Communication in Distributed Protocols,Kalai, Yael TaumanKomargodski, Ilan,Computer Science - Distributed, Parallel, and Cluster Computing,We show how to compress communication in selection protocols, where the goal\nis to agree on a sequence of random bits using only a broadcast channel. More\nspecifically, we present a generic method for converting any selection\nprotocol, into another selection protocol where each message is ``short'' while\npreserving the same number of rounds, the same output distribution, and the\nsame resilience to error. Assuming that the output of the protocol lies in some\nuniverse of size $M$, in our resulting protocol each message consists of only\n$\\mathsf{polylog}(M,n,d)$ many bits, where $n$ is the number of parties and $d$\nis the number of rounds. Our transformation works in the presence of either\nstatic or adaptive Byzantine faults.\n  As a corollary, we conclude that for any $\\mathsf{poly}(n)$-round collective\ncoin-flipping protocol, leader election protocol, or general selection\nprotocols, messages of length $\\mathsf{polylog}(n)$ suffice (in the presence of\neither static or adaptive Byzantine faults).Comment: 21 pages + 1 title page", "1506.00366": "Formal Concept Analysis for Knowledge Discovery from Biological Data,Raza, Khalid,Computer Science - Artificial IntelligenceComputer Science - Computational Engineering, Finance, and ScienceQuantitative Biology - Genomics,Due to rapid advancement in high-throughput techniques, such as microarrays\nand next generation sequencing technologies, biological data are increasing\nexponentially. The current challenge in computational biology and\nbioinformatics research is how to analyze these huge raw biological data to\nextract biologically meaningful knowledge. This review paper presents the\napplications of formal concept analysis for the analysis and knowledge\ndiscovery from biological data, including gene expression discretization, gene\nco-expression mining, gene expression clustering, finding genes in gene\nregulatory networks, enzyme/protein classifications, binding site\nclassifications, and so on. It also presents a list of FCA-based software tools\napplied in biological domain and covers the challenges faced so far.Comment: 14 pages, 2 figures", "1506.00529": "Desirability and the birth of incomplete preferences,Zaffalon, MarcoMiranda, Enrique,Computer Science - Artificial Intelligence,We establish an equivalence between two seemingly different theories: one is\nthe traditional axiomatisation of incomplete preferences on horse lotteries\nbased on the mixture independence axiom; the other is the theory of desirable\ngambles developed in the context of imprecise probability. The equivalence\nallows us to revisit incomplete preferences from the viewpoint of desirability\nand through the derived notion of coherent lower previsions. On this basis, we\nobtain new results and insights: in particular, we show that the theory of\nincomplete preferences can be developed assuming only the existence of a worst\nact---no best act is needed---, and that a weakened Archimedean axiom suffices\ntoo; this axiom allows us also to address some controversy about the regularity\nassumption (that probabilities should be positive---they need not), which\nenables us also to deal with uncountable possibility spaces; we show that it is\nalways possible to extend in a minimal way a preference relation to one with a\nworst act, and yet the resulting relation is never Archimedean, except in a\ntrivial case; we show that the traditional notion of state independence\ncoincides with the notion called strong independence in imprecise\nprobability---this leads us to give much a weaker definition of state\nindependence than the traditional one; we rework and uniform the notions of\ncomplete preferences, beliefs, values; we argue that Archimedeanity does not\ncapture all the problems that can be modelled with sets of expected utilities\nand we provide a new notion that does precisely that. Perhaps most importantly,\nwe argue throughout that desirability is a powerful and natural setting to\nmodel, and work with, incomplete preferences, even in case of non-Archimedean\nproblems. This leads us to suggest that desirability, rather than preference,\nshould be the primitive notion at the basis of decision-theoretic\naxiomatisations.", "1506.00552": "Coordinate Descent Converges Faster with the Gauss-Southwell Rule Than\n  Random Selection,Nutini, JulieSchmidt, MarkLaradji, Issam H.Friedlander, MichaelKoepke, Hoyt,Mathematics - Optimization and ControlComputer Science - Machine LearningStatistics - ComputationStatistics - Machine Learning,There has been significant recent work on the theory and application of\nrandomized coordinate descent algorithms, beginning with the work of Nesterov\n[SIAM J. Optim., 22(2), 2012], who showed that a random-coordinate selection\nrule achieves the same convergence rate as the Gauss-Southwell selection rule.\nThis result suggests that we should never use the Gauss-Southwell rule, as it\nis typically much more expensive than random selection. However, the empirical\nbehaviours of these algorithms contradict this theoretical result: in\napplications where the computational costs of the selection rules are\ncomparable, the Gauss-Southwell selection rule tends to perform substantially\nbetter than random coordinate selection. We give a simple analysis of the\nGauss-Southwell rule showing that---except in extreme cases---its convergence\nrate is faster than choosing random coordinates. Further, in this work we (i)\nshow that exact coordinate optimization improves the convergence rate for\ncertain sparse problems, (ii) propose a Gauss-Southwell-Lipschitz rule that\ngives an even faster convergence rate given knowledge of the Lipschitz\nconstants of the partial derivatives, (iii) analyze the effect of approximate\nGauss-Southwell rules, and (iv) analyze proximal-gradient variants of the\nGauss-Southwell rule.Comment: ICML 2015. v2: Updated the Gauss-Southwell-q result in Section 8 and\n  Appendix H, to remove the part depending on mu_1 (the proof had an error).\n  Added Section 8.1, which discusses conditions under which a rate depending on\n  mu_1 does hold", "1506.00571": "Calculation of the confidence bounds for the fraction nonconforming of\n  normal populations of measurements in clinical laboratory medicine,Hatjimihail, Aristides T.,Computer Science - Computational Engineering, Finance, and Science6804J.2,The fraction nonconforming is a key quality measure used in statistical\nquality control design in clinical laboratory medicine. The confidence bounds\nof normal populations of measurements for the fraction nonconforming each of\nthe lower and upper quality specification limits when both the random and the\nsystematic error are unknown can be calculated using the noncentral\nt-distribution, as it is described in detail and illustrated with examples.Comment: 22 pages, 5 tables, 8 figures", "1506.00573": "Two-dimensional Decoding Algorithms and Recording Techniques for Bit\n  Patterned Media Feasibility Demonstrations,Obukhov, YuriJubert, Pierre-OlivierBedau, DanielGrobis, Michael,Computer Science - Information Theory94A40 (Primary), 94B10, 82D40, 68P30 (Secondary)B.4.2B.3.2,Recording experiments and decoding algorithms are presented for evaluating\nthe bit-error-rate of state-of-the-art magnetic bitpatterned media. The\nrecording experiments are performed with a static tester and conventional\nhard-disk-drive heads. As the reader dimensions are larger than the bit\ndimensions in both the down-track and the cross-track directions, a\ntwo-dimensional bit decoding algorithm is required. Two such algorithms are\npresented in details together with the methodology implemented to accurately\nretrieve island positions during recording. Using these techniques, a 1.6\nTd/in$^2$ magnetic bit pattern media is demonstrated to support 2D bit error\nrates below 1e-2 under shingled magnetic recording conditions.Comment: 9 pages, 9 figures", "1506.00768": "Soft Computing Techniques for Change Detection in remotely sensed images\n  : A Review,Khurana, MadhuSaxena, Vikas,Computer Science - Neural and Evolutionary ComputingComputer Science - Computer Vision and Pattern Recognition,With the advent of remote sensing satellites, a huge repository of remotely\nsensed images is available. Change detection in remotely sensed images has been\nan active research area as it helps us understand the transitions that are\ntaking place on the Earths surface. This paper discusses the methods and their\nclassifications proposed by various researchers for change detection. Since use\nof soft computing based techniques are now very popular among research\ncommunity, this paper also presents a classification based on learning\ntechniques used in soft-computing methods for change detection.Comment: 9 pages, 1 table, 1 figure", "1506.01110": "Multi-View Factorization Machines,Cao, BokaiZhou, HuchengLi, GuoqiangYu, Philip S.,Computer Science - Machine LearningStatistics - Machine LearningH.2.8,For a learning task, data can usually be collected from different sources or\nbe represented from multiple views. For example, laboratory results from\ndifferent medical examinations are available for disease diagnosis, and each of\nthem can only reflect the health state of a person from a particular\naspect/view. Therefore, different views provide complementary information for\nlearning tasks. An effective integration of the multi-view information is\nexpected to facilitate the learning performance. In this paper, we propose a\ngeneral predictor, named multi-view machines (MVMs), that can effectively\ninclude all the possible interactions between features from multiple views. A\njoint factorization is embedded for the full-order interaction parameters which\nallows parameter estimation under sparsity. Moreover, MVMs can work in\nconjunction with different loss functions for a variety of machine learning\ntasks. A stochastic gradient descent method is presented to learn the MVM\nmodel. We further illustrate the advantages of MVMs through comparison with\nother methods for multi-view classification, including support vector machines\n(SVMs), support tensor machines (STMs) and factorization machines (FMs).Comment: WSDM 2016", "1506.01634": "Signs of universality in the structure of culture,B\u0103beanu, Alexandru-Ionu\u0163Talman, LeandrosGarlaschelli, Diego,Physics - Physics and SocietyComputer Science - Computers and SocietyPhysics - Data Analysis, Statistics and Probability,Understanding the dynamics of opinions, preferences and of culture as whole\nrequires more use of empirical data than has been done so far. It is clear that\nan important role in driving this dynamics is played by social influence, which\nis the essential ingredient of many quantitative models. Such models require\nthat all traits are fixed when specifying the \"initial cultural state\".\nTypically, this initial state is randomly generated, from a uniform\ndistribution over the set of possible combinations of traits. However, recent\nwork has shown that the outcome of social influence dynamics strongly depends\non the nature of the initial state. If the latter is sampled from empirical\ndata instead of being generated in a uniformly random way, a higher level of\ncultural diversity is found after long-term dynamics, for the same level of\npropensity towards collective behavior in the short-term. Moreover, if the\ninitial state is randomized by shuffling the empirical traits among people, the\nlevel of long-term cultural diversity is in-between those obtained for the\nempirical and uniformly random counterparts. The current study repeats the\nanalysis for multiple empirical data sets, showing that the results are\nremarkably similar, although the matrix of correlations between cultural\nvariables clearly differs across data sets. This points towards robust\nstructural properties inherent in empirical cultural states, possibly due to\nuniversal laws governing the dynamics of culture in the real world. The results\nalso suggest that this dynamics might be characterized by criticality and\ninvolve mechanisms beyond social influence.Comment: 16 pages, 7 figures; the same results as in version 3, but a shorter\n  Introduction, Discussion and Conclusion", "1506.01978": "Information measures and cognitive limits in multilayer navigation,Gallotti, RiccardoPorter, Mason A.Barthelemy, Marc,Physics - Physics and SocietyCondensed Matter - Disordered Systems and Neural NetworksComputer Science - Social and Information Networks,Cities and their transportation systems become increasingly complex and\nmultimodal as they grow, and it is natural to wonder if it is possible to\nquantitatively characterize our difficulty to navigate in them and whether such\nnavigation exceeds our cognitive limits. A transition between different\nsearching strategies for navigating in metropolitan maps has been observed for\nlarge, complex metropolitan networks. This evidence suggests the existence of\nanother limit associated to the cognitive overload and caused by large amounts\nof information to process. In this light, we analyzed the world's 15 largest\nmetropolitan networks and estimated the information limit for determining a\ntrip in a transportation system to be on the order of 8 bits. Similar to the\n\"Dunbar number,\" which represents a limit to the size of an individual's\nfriendship circle, our cognitive limit suggests that maps should not consist of\nmore than about $250$ connections points to be easily readable. We also show\nthat including connections with other transportation modes dramatically\nincreases the information needed to navigate in multilayer transportation\nnetworks: in large cities such as New York, Paris, and Tokyo, more than $80\\%$\nof trips are above the 8-bit limit. Multimodal transportation systems in large\ncities have thus already exceeded human cognitive limits and consequently the\ntraditional view of navigation in cities has to be revised substantially.Comment: 16 pages+9 pages of supplementary material", "1506.02228": "Strong converse exponents for the feedback-assisted classical capacity\n  of entanglement-breaking channels,Ding, DaweiWilde, Mark M.,Quantum PhysicsComputer Science - Information Theory,Quantum entanglement can be used in a communication scheme to establish a\ncorrelation between successive channel inputs that is impossible by classical\nmeans. It is known that the classical capacity of quantum channels can be\nenhanced by such entangled encoding schemes, but this is not always the case.\nIn this paper, we prove that a strong converse theorem holds for the classical\ncapacity of an entanglement-breaking channel even when it is assisted by a\nclassical feedback link from the receiver to the transmitter. In doing so, we\nidentify a bound on the strong converse exponent, which determines the\nexponentially decaying rate at which the success probability tends to zero, for\na sequence of codes with communication rate exceeding capacity. Proving a\nstrong converse, along with an achievability theorem, shows that the classical\ncapacity is a sharp boundary between reliable and unreliable communication\nregimes. One of the main tools in our proof is the sandwiched Renyi relative\nentropy. The same method of proof is used to derive an exponential bound on the\nsuccess probability when communicating over an arbitrary quantum channel\nassisted by classical feedback, provided that the transmitter does not use\nentangled encoding schemes.Comment: 24 pages, 2 figures, v4: final version accepted for publication in\n  Problems of Information Transmission", "1506.02438": "High-Dimensional Continuous Control Using Generalized Advantage\n  Estimation,Schulman, JohnMoritz, PhilippLevine, SergeyJordan, MichaelAbbeel, Pieter,Computer Science - Machine LearningComputer Science - RoboticsComputer Science - Systems and Control,Policy gradient methods are an appealing approach in reinforcement learning\nbecause they directly optimize the cumulative reward and can straightforwardly\nbe used with nonlinear function approximators such as neural networks. The two\nmain challenges are the large number of samples typically required, and the\ndifficulty of obtaining stable and steady improvement despite the\nnonstationarity of the incoming data. We address the first challenge by using\nvalue functions to substantially reduce the variance of policy gradient\nestimates at the cost of some bias, with an exponentially-weighted estimator of\nthe advantage function that is analogous to TD(lambda). We address the second\nchallenge by using trust region optimization procedure for both the policy and\nthe value function, which are represented by neural networks.\n  Our approach yields strong empirical results on highly challenging 3D\nlocomotion tasks, learning running gaits for bipedal and quadrupedal simulated\nrobots, and learning a policy for getting the biped to stand up from starting\nout lying on the ground. In contrast to a body of prior work that uses\nhand-crafted policy representations, our neural network policies map directly\nfrom raw kinematics to joint torques. Our algorithm is fully model-free, and\nthe amount of simulated experience required for the learning tasks on 3D bipeds\ncorresponds to 1-2 weeks of real time.", "1506.02930": "Arguments for the Effectiveness of Human Problem Solving,Duris, Frantisek,Computer Science - Artificial Intelligence68T20I.2.0I.2.8,The question of how humans solve problem has been addressed extensively.\nHowever, the direct study of the effectiveness of this process seems to be\noverlooked. In this paper, we address the issue of the effectiveness of human\nproblem solving: we analyze where this effectiveness comes from and what\ncognitive mechanisms or heuristics are involved. Our results are based on the\noptimal probabilistic problem solving strategy that appeared in Solomonoff\npaper on general problem solving system. We provide arguments that a certain\nset of cognitive mechanisms or heuristics drive human problem solving in the\nsimilar manner as the optimal Solomonoff strategy. The results presented in\nthis paper can serve both cognitive psychology in better understanding of human\nproblem solving processes as well as artificial intelligence in designing more\nhuman-like agents.", "1506.03171": "Error Correction by Structural Simplicity: Correcting Samplable Additive\n  Errors,Yasunaga, Kenji,Computer Science - Information Theory,This paper explores the possibilities and limitations of error correction by\nthe structural simplicity of error mechanisms. Specifically, we consider\nchannel models, called \\emph{samplable additive channels}, in which (a) errors\nare efficiently sampled without the knowledge of the coding scheme or the\ntransmitted codeword; (b) the entropy of the error distribution is bounded; and\n(c) the number of errors introduced by the channel is unbounded. For the\nchannels, several negative and positive results are provided. Assuming the\nexistence of one-way functions, there are samplable additive errors of entropy\n$n^{\\epsilon}$ for $\\epsilon \\in (0,1)$ that are pseudorandom, and thus not\ncorrectable by efficient coding schemes. It is shown that there is an oracle\nalgorithm that induces a samplable distribution over $\\{0,1\\}^n$ of entropy $m\n= \\omega( \\log n)$ that is not pseudorandom, but is uncorrectable by efficient\nschemes of rate less than $1 - m/n - o(1)$. The results indicate that\nrestricting error mechanisms to be efficiently samplable and not pseudorandom\nis insufficient for error correction. As positive results, some conditions are\nprovided under which efficient error correction is possible.", "1506.03410": "Random Projection Forests,Tomita, Tyler M.Browne, JamesShen, CenchengPatsolic, Jesse L.Yim, JasonPriebe, Carey E.Burns, RandalMaggioni, MauroVogelstein, Joshua T.,Statistics - Machine LearningComputer Science - Machine Learning68T10I.5.2,Ensemble methods---particularly those based on decision trees---have recently\ndemonstrated superior performance in a variety of machine learning settings. We\nintroduce a generalization of many existing decision tree methods called\n\"Random Projection Forests\" (RPF), which is any decision forest that uses\n(possibly data dependent and random) linear projections. Using this framework,\nwe introduce a special case, called \"Lumberjack\", using very sparse random\nprojections, that is, linear combinations of a small subset of features.\nLumberjack obtains statistically significantly improved accuracy over Random\nForests, Gradient Boosted Trees, and other approaches on a standard benchmark\nsuites for classification with varying dimension, sample size, and number of\nclasses. To illustrate how, why, and when Lumberjack outperforms other methods,\nwe conduct extensive simulated experiments, in vectors, images, and nonlinear\nmanifolds. Lumberjack typically yields improved performance over existing\ndecision trees ensembles, while mitigating computational efficiency and\nscalability, and maintaining interpretability. Lumberjack can easily be\nincorporated into other ensemble methods such as boosting to obtain potentially\nsimilar gains.Comment: 46 pages; submitted to Journal of Machine Learning Research for\n  review on 09/26/2018", "1506.03437": "Topology design for stochastically-forced consensus networks,Hassan-Moghaddam, SepidehJovanovi\u0107, Mihailo R.,Mathematics - Optimization and ControlComputer Science - Systems and Control,We study an optimal control problem aimed at achieving a desired tradeoff\nbetween the network coherence and communication requirements in the distributed\ncontroller. Our objective is to add a certain number of edges to an undirected\nnetwork, with a known graph Laplacian, in order to optimally enhance\nclosed-loop performance. To promote controller sparsity, we introduce\n$\\ell_1$-regularization into the optimal ${\\cal H}_2$ formulation and cast the\ndesign problem as a semidefinite program. We derive a Lagrange dual, provide\ninterpretation of dual variables, and exploit structure of the optimality\nconditions for undirected networks to develop customized proximal gradient and\nNewton algorithms that are well-suited for large problems. We illustrate that\nour algorithms can solve the problems with more than million edges in the\ncontroller graph in a few minutes, on a PC. We also exploit structure of\nconnected resistive networks to demonstrate how additional edges can be\nsystematically added in order to minimize the ${\\cal H}_2$ norm of the\nclosed-loop system.Comment: 11 pages; 5 figures", "1506.03523": "Sparsification of Matrices and Compressed Sensing,Hegarty, FintanCath\u00e1in, Padraig \u00d3Zhao, Yunbin,Computer Science - Information Theory94A12, 94A15,Compressed sensing is a signal processing technique whereby the limits\nimposed by the Shannon--Nyquist theorem can be exceeded provided certain\nconditions are imposed on the signal. Such conditions occur in many real-world\nscenarios, and compressed sensing has emerging applications in medical imaging,\nbig data, and statistics. Finding practical matrix constructions and\ncomputationally efficient recovery algorithms for compressed sensing is an area\nof intense research interest. Many probabilistic matrix constructions have been\nproposed, and it is now well known that matrices with entries drawn from a\nsuitable probability distribution are essentially optimal for compressed\nsensing.\n  Potential applications have motivated the search for constructions of sparse\ncompressed sensing matrices (i.e., matrices containing few non-zero entries).\nVarious constructions have been proposed, and simulations suggest that their\nperformance is comparable to that of dense matrices. In this paper, extensive\nsimulations are presented which suggest that sparsification leads to a marked\nimprovement in compressed sensing performance for a large class of matrix\nconstructions and for many different recovery algorithms.Comment: 10 pages, 4 figures", "1506.03872": "Diamond Sampling for Approximate Maximum All-pairs Dot-product (MAD)\n  Search,Ballard, GreyPinar, AliKolda, Tamara G.Seshadhri, C.,Computer Science - Social and Information NetworksComputer Science - Data Structures and Algorithms,Given two sets of vectors, $A = \\{{a_1}, \\dots, {a_m}\\}$ and\n$B=\\{{b_1},\\dots,{b_n}\\}$, our problem is to find the top-$t$ dot products,\ni.e., the largest $|{a_i}\\cdot{b_j}|$ among all possible pairs. This is a\nfundamental mathematical problem that appears in numerous data applications\ninvolving similarity search, link prediction, and collaborative filtering. We\npropose a sampling-based approach that avoids direct computation of all $mn$\ndot products. We select diamonds (i.e., four-cycles) from the weighted\ntripartite representation of $A$ and $B$. The probability of selecting a\ndiamond corresponding to pair $(i,j)$ is proportional to $({a_i}\\cdot{b_j})^2$,\namplifying the focus on the largest-magnitude entries. Experimental results\nindicate that diamond sampling is orders of magnitude faster than direct\ncomputation and requires far fewer samples than any competing approach. We also\napply diamond sampling to the special case of maximum inner product search, and\nget significantly better results than the state-of-the-art hashing methods.", "1506.04391": "CamFlow: Managed Data-sharing for Cloud Services,Pasquier, Thomas F. J. -M.Singh, JatinderEyers, DavidBacon, Jean,Computer Science - Cryptography and SecurityComputer Science - Distributed, Parallel, and Cluster ComputingD.4.6,A model of cloud services is emerging whereby a few trusted providers manage\nthe underlying hardware and communications whereas many companies build on this\ninfrastructure to offer higher level, cloud-hosted PaaS services and/or SaaS\napplications. From the start, strong isolation between cloud tenants was seen\nto be of paramount importance, provided first by virtual machines (VM) and\nlater by containers, which share the operating system (OS) kernel. Increasingly\nit is the case that applications also require facilities to effect isolation\nand protection of data managed by those applications. They also require\nflexible data sharing with other applications, often across the traditional\ncloud-isolation boundaries; for example, when government provides many related\nservices for its citizens on a common platform. Similar considerations apply to\nthe end-users of applications. But in particular, the incorporation of cloud\nservices within `Internet of Things' architectures is driving the requirements\nfor both protection and cross-application data sharing.\n  These concerns relate to the management of data. Traditional access control\nis application and principal/role specific, applied at policy enforcement\npoints, after which there is no subsequent control over where data flows; a\ncrucial issue once data has left its owner's control by cloud-hosted\napplications and within cloud-services. Information Flow Control (IFC), in\naddition, offers system-wide, end-to-end, flow control based on the properties\nof the data. We discuss the potential of cloud-deployed IFC for enforcing\nowners' dataflow policy with regard to protection and sharing, as well as\nsafeguarding against malicious or buggy software. In addition, the audit log\nassociated with IFC provides transparency, giving configurable system-wide\nvisibility over data flows. [...]Comment: 14 pages, 8 figures", "1506.04440": "Traces of Hecke Operators and Refined Weight Enumerators of Reed-Solomon\n  Codes,Kaplan, NathanPetrow, Ian,Mathematics - Number TheoryComputer Science - Information TheoryPrimary 11T71, Secondary 11F25, 11G20, 94B27,We study the quadratic residue weight enumerators of the dual projective\nReed-Solomon codes of dimensions $5$ and $q-4$ over the finite field\n$\\mathbb{F}_q$. Our main results are formulas for the coefficients of the the\nquadratic residue weight enumerators for such codes. If $q=p^v$ and we fix $v$\nand vary $p$ then our formulas for the coefficients of the dimension $q-4$ code\ninvolve only polynomials in $p$ and the trace of the $q$th and $(q/p^2)$th\nHecke operators acting on spaces of cusp forms for the congruence groups\n$\\operatorname{SL}_2 (\\mathbb{Z}), \\Gamma_0(2)$, and $\\Gamma_0(4)$. The main\ntool we use is the Eichler-Selberg trace formula, which gives along the way a\nvariation of a theorem of Birch on the distribution of rational point counts\nfor elliptic curves with prescribed $2$-torsion over a fixed finite field.", "1506.04496": "The Peano software - parallel, automaton-based, dynamically adaptive\n  grid traversals,Weinzierl, Tobias,Computer Science - Mathematical Software,We discuss the design decisions, design alternatives and rationale behind the\nthird generation of Peano, a framework for dynamically adaptive Cartesian\nmeshes derived from spacetrees. Peano ties the mesh traversal to the mesh\nstorage and supports only one element-wise traversal order resulting from\nspace-filling curves. The user is not free to choose a traversal order herself.\nThe traversal can exploit regular grid subregions and shared memory as well as\ndistributed memory systems with almost no modifications to a serial application\ncode. We formalize the software design by means of two interacting\nautomata---one automaton for the multiscale grid traversal and one for the\napplication-specific algorithmic steps. This yields a callback-based\nprogramming paradigm. We further sketch the supported application types and the\ntwo data storage schemes realized, before we detail high-performance computing\naspects and lessons learned. Special emphasis is put on observations regarding\nthe used programming idioms and algorithmic concepts. This transforms our\nreport from a \"one way to implement things\" code description into a generic\ndiscussion and summary of some alternatives, rationale and design decisions to\nbe made for any tree-based adaptive mesh refinement software.", "1506.04497": "Lower bounds for the dynamically defined measures,Werner, Ivan,Mathematics - Dynamical SystemsComputer Science - Information TheoryMathematical Physics28A99, 37A60, 37A05, 82C05,The dynamically defined measure (DDM) $\\Phi$ arising from a finite measure\n$\\phi_0$ on an initial $\\sigma$-algebra on a set and an invertible map acting\non the latter is considered. Several lower bounds for it are obtained and\nsufficient conditions for its positivity are deduced under the general\nassumption that there exists an invariant measure $\\Lambda$ such that\n$\\Lambda\\ll\\phi_0$.\n  In particular, DDMs arising from the Hellinger integral\n$\\mathcal{J}_\\alpha(\\Lambda,\\phi_0)\\geq\\mathcal{H}^{\\alpha,0}(\\Lambda,\\phi_0)\\geq\\mathcal{H}_\\alpha(\\Lambda,\\phi_0)$\nare constructed with $\\mathcal{H}_{0}\\left(\\Lambda,\\phi_0\\right)(Q) = \\Phi(Q)$,\n$\\mathcal{H}_{1}\\left(\\Lambda,\\phi_0\\right)(Q) = \\Lambda(Q)$, and\n\\[\\Phi(Q)^{1-\\alpha}\\Lambda(Q)^{\\alpha}\\geq\\mathcal{J}_{\\alpha}\\left(\\Lambda,\\phi_0\\right)(Q)\\]\nfor all measurable $Q$ and $\\alpha\\in[0,1]$, and further computable lower\nbounds for them are obtained and analyzed. It is shown, in particular, that\n$(0,1)\\owns\\alpha\\longmapsto\\mathcal{H}_{\\alpha}(\\Lambda,\\phi_0)(Q)$ is\ncompletely determined by the $\\Lambda$-essential supremum of $d\\Lambda/d\\phi_0$\nfor all $0<\\alpha<1$ if $\\Lambda$ is ergodic, and if also a condition for the\ncontinuity at $0$ is satisfied, the above inequalities become equalities. In\ngeneral, for every measurable $Q$, it is shown that\n$[0,1]\\owns\\alpha\\longmapsto\\mathcal{J}_{\\alpha}(\\Lambda,\\phi_0)(Q)$ is\nlog-convex, all one-sided derivatives of\n$(0,1)\\owns\\alpha\\longmapsto\\mathcal{H}^{\\alpha,0}(\\Lambda,\\phi_0)(Q)$ and\n$(0,1)\\owns\\alpha\\longmapsto\\mathcal{J}_{\\alpha}(\\Lambda,\\phi_0)(Q)$ are\nobtained, and some lower bounds for the functions by means of the derivatives\nare given. Some sufficient conditions for the continuity and a one-sided\ndifferentiability of\n$(0,1)\\owns\\alpha\\longmapsto\\mathcal{H}_{\\alpha}(\\Lambda,\\phi_0)(Q)$ are\nprovided.Comment: Made minor improvements to the text, added Remark 6 and reference [6]", "1506.04651": "Task-based adaptive multiresolution for time-space multi-scale\n  reaction-diffusion systems on multi-core architectures,Descombes, St\u00e9phaneDuarte, MaxDumont, ThierryGuillet, ThomasLouvet, ViolaineMassot, Marc,Computer Science - Numerical AnalysisComputer Science - Distributed, Parallel, and Cluster ComputingMathematics - Analysis of PDEsMathematics - Numerical Analysis,A new solver featuring time-space adaptation and error control has been\nrecently introduced to tackle the numerical solution of stiff\nreaction-diffusion systems. Based on operator splitting, finite volume adaptive\nmultiresolution and high order time integrators with specific stability\nproperties for each operator, this strategy yields high computational\nefficiency for large multidimensional computations on standard architectures\nsuch as powerful workstations. However, the data structure of the original\nimplementation, based on trees of pointers, provides limited opportunities for\nefficiency enhancements, while posing serious challenges in terms of parallel\nprogramming and load balancing. The present contribution proposes a new\nimplementation of the whole set of numerical methods including Radau5 and\nROCK4, relying on a fully different data structure together with the use of a\nspecific library, TBB, for shared-memory, task-based parallelism with\nwork-stealing. The performance of our implementation is assessed in a series of\ntest-cases of increasing difficulty in two and three dimensions on multi-core\nand many-core architectures, demonstrating high scalability.", "1506.04773": "DistFlow Extensions for AC Transmission Systems,Coffrin, CarletonHijazi, Hassan L.Van Hentenryck, Pascal,Mathematics - Optimization and ControlComputer Science - Systems and Control,Convex relaxations of the power flow equations and, in particular, the\nSemi-Definite Programming (SDP), Second-Order Cone (SOC), and Convex DistFlow\n(CDF) relaxations, have attracted significant interest in recent years. Thus\nfar, studies of the CDF model and its connection to the other relaxations have\nbeen limited to power distribution systems, which omit several parameters\nnecessary for modeling transmission systems. To increase the applicability of\nthe CDF relaxation, this paper develops an extended CDF model that is suitable\nfor transmission systems by incorporating bus shunts, line charging, and\ntransformers. Additionally, a theoretical result shows that the established\nequivalence of the SOC and CDF models for distribution systems also holds in\nthis transmission system extension.", "1506.04972": "A Unified Successive Pseudo-Convex Approximation Framework,Yang, YangPesavento, Marius,Mathematics - Optimization and ControlComputer Science - Numerical Analysis,In this paper, we propose a successive pseudo-convex approximation algorithm\nto efficiently compute stationary points for a large class of possibly\nnonconvex optimization problems. The stationary points are obtained by solving\na sequence of successively refined approximate problems, each of which is much\neasier to solve than the original problem. To achieve convergence, the\napproximate problem only needs to exhibit a weak form of convexity, namely,\npseudo-convexity. We show that the proposed framework not only includes as\nspecial cases a number of existing methods, for example, the gradient method\nand the Jacobi algorithm, but also leads to new algorithms which enjoy easier\nimplementation and faster convergence speed. We also propose a novel line\nsearch method for nondifferentiable optimization problems, which is carried out\nover a properly constructed differentiable function with the benefit of a\nsimplified implementation as compared to state-of-the-art line search\ntechniques that directly operate on the original nondifferentiable objective\nfunction. The advantages of the proposed algorithm are shown, both\ntheoretically and numerically, by several example applications, namely, MIMO\nbroadcast channel capacity computation, energy efficiency maximization in\nmassive MIMO systems and LASSO in sparse signal recovery.Comment: submitted to IEEE Transactions on Signal Processing; original title:\n  A Novel Iterative Convex Approximation Method", "1506.05193": "Anxiety, Alcohol, and Academics: A Textual Analysis of Student Facebook\n  Confessions Pages,Barari, Soubhik,Computer Science - Social and Information NetworksComputer Science - Computers and Society,What do college students reveal to their peers on social media under complete\nanonymity? Do their campus environments relate to the topics of their\ndisclosure? To answer these questions, I analyze Facebook confessions pages.\nPopular on hundreds of college campuses, these pages allow students to\nanonymously post personal confessions on a public community forum. In this\npreliminary research note, I analyze several explanatory factors of online\nstudent confessional behavior. Aggregating nearly 200,000 confessions posts\nspanning a period of 3 years, I combine Latent Dirichlet Allocation (LDA) with\nhuman verification through Mechanical Turk to scalably identify topics in these\nonline confessions. Where possible, I also link posts to real-world news events\nparsed from Twitter. I find that confessions mentioning socioeconomics as well\nas mental and physical health occur more often at top-ranking, expensive\nprivate colleges. While event-related confessions most often mention timely\nschool-related events, many mention global and domestic events outside of the\nlocal campus sphere. Results suggest that undergraduates from different\ncampuses disclose about topics such as race, socioeonomics, and politics\ndifferently, but in aggregate, post in similar patterns over time.\nAdditionally, results confirm that anonymous Facebook confessors receive\nsupport for confessions on important, but taboo topics such as health and\nsocioeconomic status.", "1506.05231": "The Fractality of Polar and Reed-Muller Codes,Geiger, Bernhard C.,Computer Science - Information Theory,The generator matrices of polar codes and Reed-Muller codes are obtained by\nselecting rows from the Kronecker product of a lower-triangular binary square\nmatrix. For polar codes, the selection is based on the Bhattacharyya parameter\nof the row, which is closely related to the error probability of the\ncorresponding input bit under sequential decoding. For Reed-Muller codes, the\nselection is based on the Hamming weight of the row. This work investigates the\nproperties of the index sets pointing to those rows in the infinite blocklength\nlimit. In particular, the Lebesgue measure, the Hausdorff dimension, and the\nself-similarity of these sets will be discussed. It is shown that these index\nsets have several properties that are common to fractals.Comment: 9 pages, one figure", "1506.05855": "Information-based inference for singular models and finite sample sizes:\n  A frequentist information criterion,LaMont, Colin H.Wiggins, Paul A.,Statistics - Machine LearningComputer Science - Machine LearningPhysics - Data Analysis, Statistics and Probability,In the information-based paradigm of inference, model selection is performed\nby selecting the candidate model with the best estimated predictive\nperformance. The success of this approach depends on the accuracy of the\nestimate of the predictive complexity. In the large-sample-size limit of a\nregular model, the predictive performance is well estimated by the Akaike\nInformation Criterion (AIC). However, this approximation can either\nsignificantly under or over-estimating the complexity in a wide range of\nimportant applications where models are either non-regular or\nfinite-sample-size corrections are significant. We introduce an improved\napproximation for the complexity that is used to define a new information\ncriterion: the Frequentist Information Criterion (QIC). QIC extends the\napplicability of information-based inference to the finite-sample-size regime\nof regular models and to singular models. We demonstrate the power and the\ncomparative advantage of QIC in a number of example analyses.Comment: 30 Pages, 6 figures", "1506.06011": "A Markovian Analysis of IEEE 802.11 Broadcast Transmission Networks with\n  Buffering,Fayolle, GuyMuhlethaler, Paul,Computer Science - PerformanceMathematics - ProbabilityPrimary 60J10, secondary 30D05, 30E99,The purpose of this paper is to analyze the so-called back-off technique of\nthe IEEE 802.11 protocol in broadcast mode with waiting queues. In contrast to\nexisting models, packets arriving when a station (or node) is in back-off state\nare not discarded, but are stored in a buffer of infinite capacity. As in\nprevious studies, the key point of our analysis hinges on the assumption that\nthe time on the channel is viewed as a random succession of transmission slots\n(whose duration corresponds to the length of a packet) and mini-slots during\nwhich the back-o? of the station is decremented. These events occur\nindependently, with given probabilities. The state of a node is represented by\na two-dimensional Markov chain in discrete-time, formed by the back-off counter\nand the number of packets at the station. Two models are proposed both of which\nare shown to cope reasonably well with the physical principles of the protocol.\nThe stabillity (ergodicity) conditions are obtained and interpreted in terms of\nmaximum throughput. Several approximations related to these models are also\ndiscussed.", "1506.06055": "Low PMEPR OFDM radar waveform design using the iterative least squares\n  algorithm,Huang, TianyaoZhao, Tong,Electrical Engineering and Systems Science - Signal ProcessingComputer Science - Information Theory,This letter considers waveform design of orthogonal frequency division\nmultiplexing (OFDM) signal for radar applications, and aims at mitigating the\nenvelope fluctuation in OFDM. A novel method is proposed to reduce the\npeak-to-mean envelope power ratio (PMEPR), which is commonly used to evaluate\nthe fluctuation. The proposed method is based on the tone reservation approach,\nin which some bits or subcarriers of OFDM are allocated for decreasing PMEPR.\nWe introduce the coefficient of variation of envelopes (CVE) as the cost\nfunction for waveform optimization, and develop an iterative least squares\nalgorithm. Minimizing CVE leads to distinct PMEPR reduction, and it is\nguaranteed that the cost function monotonically decreases by applying the\niterative algorithm. Simulations demonstrate that the envelope is significantly\nsmoothed by the proposed method.Comment: 6 pages, 8 figures", "1506.06138": "The evolution of lossy compression,Marzen, Sarah E.DeDeo, Simon,Quantitative Biology - Neurons and CognitionComputer Science - Information TheoryNonlinear Sciences - Adaptation and Self-Organizing SystemsPhysics - Physics and SocietyQuantitative Biology - Populations and Evolution,In complex environments, there are costs to both ignorance and perception. An\norganism needs to track fitness-relevant information about its world, but the\nmore information it tracks, the more resources it must devote to memory and\nprocessing. Rate-distortion theory shows that, when errors are allowed,\nremarkably efficient internal representations can be found by\nbiologically-plausible hill-climbing mechanisms. We identify two regimes: a\nhigh-fidelity regime where perceptual costs scale logarithmically with\nenvironmental complexity, and a low-fidelity regime where perceptual costs are,\nremarkably, independent of the environment. When environmental complexity is\nrising, Darwinian evolution should drive organisms to the threshold between the\nhigh- and low-fidelity regimes. Organisms that code efficiently will find\nthemselves able to make, just barely, the most subtle distinctions in their\nenvironment.Comment: 14 pages, 4 figures", "1506.06305": "Social media affects the timing, location, and severity of school\n  shootings,Garcia-Bernardo, J.Qi, H.Shultz, J. M.Cohen, A. M.Johnson, N. F.Dodds, P. S.,Physics - Physics and SocietyComputer Science - Social and Information Networks,Over the past two decades, school shootings within the United States have\nrepeatedly devastated communities and shaken public opinion. Many of these\nattacks appear to be `lone wolf' ones driven by specific individual\nmotivations, and the identification of precursor signals and hence actionable\npolicy measures would thus seem highly unlikely. Here, we take a system-wide\nview and investigate the timing of school attacks and the dynamical feedback\nwith social media. We identify a trend divergence in which college attacks have\ncontinued to accelerate over the last 25 years while those carried out on K-12\nschools have slowed down. We establish the copycat effect in school shootings\nand uncover a statistical association between social media chatter and the\nprobability of an attack in the following days. While hinting at causality,\nthis relationship may also help mitigate the frequency and intensity of future\nattacks.Comment: Main text: 7 pages, 4 figures; Supplementary: 6 pages, 7 figures", "1506.07094": "pyMOR - Generic Algorithms and Interfaces for Model Order Reduction,Milk, Ren\u00e9Rave, StephanSchindler, Felix,Computer Science - Mathematical SoftwareMathematics - Numerical Analysis35-04, 35J20, 35L03, 65-04, 65N30, 65Y05, 68N01,Reduced basis methods are projection-based model order reduction techniques\nfor reducing the computational complexity of solving parametrized partial\ndifferential equation problems. In this work we discuss the design of pyMOR, a\nfreely available software library of model order reduction algorithms, in\nparticular reduced basis methods, implemented with the Python programming\nlanguage. As its main design feature, all reduction algorithms in pyMOR are\nimplemented generically via operations on well-defined vector array, operator\nand discretization interface classes. This allows for an easy integration with\nexisting open-source high-performance partial differential equation solvers\nwithout adding any model reduction specific code to these solvers. Besides an\nin-depth discussion of pyMOR's design philosophy and architecture, we present\nseveral benchmark results and numerical examples showing the feasibility of our\napproach.", "1506.07212": "Elicitation Complexity of Statistical Properties,Frongillo, RafaelKash, Ian A.,Computer Science - Machine LearningMathematics - Optimization and ControlMathematics - Statistics TheoryQuantitative Finance - Mathematical Finance,A property, or statistical functional, is said to be elicitable if it\nminimizes expected loss for some loss function. The study of which properties\nare elicitable sheds light on the capabilities and limits of empirical risk\nminimization. While several recent papers have asked which properties are\nelicitable, we instead advocate for a more nuanced question: how many\ndimensions are required to indirectly elicit a given property? This number is\ncalled the elicitation complexity of the property. We lay the foundation for a\ngeneral theory of elicitation complexity, including several basic results about\nhow elicitation complexity behaves, and the complexity of standard properties\nof interest. Building on this foundation, we establish several upper and lower\nbounds for the broad class of Bayes risks. We apply these results by proving\ntight complexity bounds, with respect to identifiable properties, for variance,\nfinancial risk measures, entropy, norms, and new properties of interest. We\nthen show how some of these bounds can extend to other practical classes of\nproperties, and conclude with a discussion of open directions.Comment: A previous version appeared in Neural Information Processing Systems\n  (NIPS) 2015", "1506.07437": "The Truncated & Supplemented Pascal Matrix and Applications,Hua, M.Damelin, S. B.Sun, J.Yu, M.,Mathematics - CombinatoricsComputer Science - Information Theory05B20, 05B35,In this paper, we introduce the $k\\times n$ (with $k\\leq n$) truncated,\nsupplemented Pascal matrix which has the property that any $k$ columns form a\nlinearly independent set. This property is also present in Reed-Solomon codes;\nhowever, Reed-Solomon codes are completely dense, whereas the truncated,\nsupplemented Pascal matrix has multiple zeros. If the maximal-distance\nseparable code conjecture is correct, then our matrix has the maximal number of\ncolumns (with the aformentioned property) that the conjecture allows. This\nmatrix has applications in coding, network coding, and matroid theory.", "1506.07990": "Bisimulation and expressivity for conditional belief, degrees of belief,\n  and safe belief,Andersen, Mikkel BirkegaardBolander, Thomasvan Ditmarsch, HansJensen, Martin Holm,Computer Science - Artificial IntelligenceComputer Science - Logic in Computer Science,Plausibility models are Kripke models that agents use to reason about\nknowledge and belief, both of themselves and of each other. Such models are\nused to interpret the notions of conditional belief, degrees of belief, and\nsafe belief. The logic of conditional belief contains that modality and also\nthe knowledge modality, and similarly for the logic of degrees of belief and\nthe logic of safe belief. With respect to these logics, plausibility models may\ncontain too much information. A proper notion of bisimulation is required that\ncharacterises them. We define that notion of bisimulation and prove the\nrequired characterisations: on the class of image-finite and preimage-finite\nmodels (with respect to the plausibility relation), two pointed Kripke models\nare modally equivalent in either of the three logics, if and only if they are\nbisimilar. As a result, the information content of such a model can be\nsimilarly expressed in the logic of conditional belief, or the logic of degrees\nof belief, or that of safe belief. This, we found a surprising result. Still,\nthat does not mean that the logics are equally expressive: the logics of\nconditional and degrees of belief are incomparable, the logics of degrees of\nbelief and safe belief are incomparable, while the logic of safe belief is more\nexpressive than the logic of conditional belief. In view of the result on\nbisimulation characterisation, this is an equally surprising result. We hope\nour insights may contribute to the growing community of formal epistemology and\non the relation between qualitative and quantitative modelling.", "1506.08009": "Skopus: Mining top-k sequential patterns under leverage,Petitjean, FrancoisLi, TaoTatti, NikolajWebb, Geoffrey I.,Computer Science - Artificial IntelligenceComputer Science - Machine LearningStatistics - Machine Learning,This paper presents a framework for exact discovery of the top-k sequential\npatterns under Leverage. It combines (1) a novel definition of the expected\nsupport for a sequential pattern - a concept on which most interestingness\nmeasures directly rely - with (2) SkOPUS: a new branch-and-bound algorithm for\nthe exact discovery of top-k sequential patterns under a given measure of\ninterest. Our interestingness measure employs the partition approach. A pattern\nis interesting to the extent that it is more frequent than can be explained by\nassuming independence between any of the pairs of patterns from which it can be\ncomposed. The larger the support compared to the expectation under\nindependence, the more interesting is the pattern. We build on these two\nelements to exactly extract the k sequential patterns with highest leverage,\nconsistent with our definition of expected support. We conduct experiments on\nboth synthetic data with known patterns and real-world datasets; both\nexperiments confirm the consistency and relevance of our approach with regard\nto the state of the art. This article was published in Data Mining and\nKnowledge Discovery and is accessible at\nhttp://dx.doi.org/10.1007/s10618-016-0467-9.", "1506.08231": "A zero-sum monetary system, interest rates, and implications,Hanley, Brian P.,Computer Science - Computational Engineering, Finance, and ScienceJ.4.1,To the knowledge of the author, this is the first time it has been shown that\ninterest rates that are extremely high by modern standards (100% and higher)\nare necessary within a zero-sum monetary system, and not just driven by greed.\nExtreme interest rates that appeared in various places and times reinforce the\nidea that hard money may have contributed to high rates of interest. Here a\nmodel is presented that examines the interest rate required to succeed as an\ninvestor in a zero-sum fixed quantity hard-money system. Even when the playing\nfield is significantly tilted toward the investor, interest rates need to be\nmuch higher than expected. In a completely fair zero-sum system, an investor\ncannot break even without charging 100% interest. Even with a 5% advantage, an\ninvestor won't break even at 15% interest. From this it is concluded that what\nwe consider usurious rates today are, within a hard-money system, driven by\nnecessity.\n  Cryptocurrency is a novel form of hard-currency. The inability to virtualize\nthe money creates a system close to zero-sum because of the limited supply\ndesign. Therefore, within the bounds of a cryptocurrency system that limits\nmoney creation, interest rates must rise to levels that the modern world\nconsiders usury. It is impossible, therefore, that a cryptocurrency that is not\nexpandable could take over a modern economy and replace modern fiat currency.Comment: 12 pages, 4 figures, 2 tables, 3 equations", "1506.08235": "Optimal Seed Solver: Optimizing Seed Selection in Read Mapping,Xin, HongyiZhu, RichardNahar, SunnyEmmons, JohnPekhimenko, GennadyKingsford, CarlAlkan, CanMutlu, Onur,Computer Science - Computational Engineering, Finance, and ScienceQuantitative Biology - Genomics,Motivation: Optimizing seed selection is an important problem in read\nmapping. The number of non-overlapping seeds a mapper selects determines the\nsensitivity of the mapper while the total frequency of all selected seeds\ndetermines the speed of the mapper. Modern seed-and-extend mappers usually\nselect seeds with either an equal and fixed-length scheme or with an inflexible\nplacement scheme, both of which limit the potential of the mapper to select\nless frequent seeds to speed up the mapping process. Therefore, it is crucial\nto develop a new algorithm that can adjust both the individual seed length and\nthe seed placement, as well as derive less frequent seeds.\n  Results: We present the Optimal Seed Solver (OSS), a dynamic programming\nalgorithm that discovers the least frequently-occurring set of x seeds in an\nL-bp read in $O(x \\times L)$ operations on average and in $O(x \\times L^{2})$\noperations in the worst case. We compared OSS against four state-of-the-art\nseed selection schemes and observed that OSS provides a 3-fold reduction of\naverage seed frequency over the best previous seed selection optimizations.Comment: 10 pages of main text. 6 pages of supplementary materials. Under\n  review by Oxford Bioinformatics", "1506.08238": "Deciding Univariate Polynomial Problems Using Untrusted Certificates in\n  Isabelle/HOL,Li, WendaPassmore, Grant OlneyPaulson, Lawrence C.,Computer Science - Logic in Computer Science,We present a proof procedure for univariate real polynomial problems in\nIsabelle/HOL. The core mathematics of our procedure is based on univariate\ncylindrical algebraic decomposition. We follow the approach of untrusted\ncertificates, separating solving from verifying: efficient external tools\nperform expensive real algebraic computations, producing evidence that is\nformally checked within Isabelle's logic. This allows us to exploit\nhighly-tuned computer algebra systems like Mathematica to guide our procedure\nwithout impacting the correctness of its results. We present experiments\ndemonstrating the efficacy of this approach, in many cases yielding orders of\nmagnitude improvements over previous methods.Comment: 24 pages", "1506.08353": "A note on patch-based low-rank minimization for fast image denoising,Hu, HaijuanFroment, JacquesLiu, Quansheng,Computer Science - Computer Vision and Pattern Recognition,Patch-based low-rank minimization for image processing attracts much\nattention in recent years. The minimization of the matrix rank coupled with the\nFrobenius norm data fidelity can be solved by the hard thresholding filter with\nprinciple component analysis (PCA) or singular value decomposition (SVD). Based\non this idea, we propose a patch-based low-rank minimization method for image\ndenoising. The main denoising process is stated in three equivalent way: PCA,\nSVD and low-rank minimization. Compared to recent patch-based sparse\nrepresentation methods, experiments demonstrate that the proposed method is\nrather rapid, and it is effective for a variety of natural grayscale images and\ncolor images, especially for texture parts in images. Further improvements of\nthis method are also given. In addition, due to the simplicity of this method,\nwe could provide an explanation of the choice of the threshold parameter,\nestimation of PSNR values, and give other insights into this method.Comment: 4pages (two columns)", "1506.08435": "Large-scale Optimization-based Non-negative Computational Framework for\n  Diffusion Equations: Parallel Implementation and Performance Studies,Chang, J.Karra, S.Nakshatrala, K. B.,Computer Science - Numerical AnalysisComputer Science - Computational Engineering, Finance, and ScienceComputer Science - Performance,It is well-known that the standard Galerkin formulation, which is often the\nformulation of choice under the finite element method for solving self-adjoint\ndiffusion equations, does not meet maximum principles and the non-negative\nconstraint for anisotropic diffusion equations. Recently, optimization-based\nmethodologies that satisfy maximum principles and the non-negative constraint\nfor steady-state and transient diffusion-type equations have been proposed. To\ndate, these methodologies have been tested only on small-scale academic\nproblems. The purpose of this paper is to systematically study the performance\nof the non-negative methodology in the context of high performance computing\n(HPC). PETSc and TAO libraries are, respectively, used for the parallel\nenvironment and optimization solvers. For large-scale problems, it is important\nfor computational scientists to understand the computational performance of\ncurrent algorithms available in these scientific libraries. The numerical\nexperiments are conducted on the state-of-the-art HPC systems, and a\nsingle-core performance model is used to better characterize the efficiency of\nthe solvers. Our studies indicate that the proposed non-negative computational\nframework for diffusion-type equations exhibits excellent strong scaling for\nreal-world large-scale problems.", "1506.08544": "Exact and approximate inference in graphical models: variable\n  elimination and beyond,Peyrard, NathalieCros, Marie-Jos\u00e9ede Givry, SimonFranc, AlainRobin, St\u00e9phaneSabbadin, R\u00e9gisSchiex, ThomasVignes, Matthieu,Statistics - Machine LearningComputer Science - Artificial IntelligenceComputer Science - Machine Learning,Probabilistic graphical models offer a powerful framework to account for the\ndependence structure between variables, which is represented as a graph.\nHowever, the dependence between variables may render inference tasks\nintractable. In this paper we review techniques exploiting the graph structure\nfor exact inference, borrowed from optimisation and computer science. They are\nbuilt on the principle of variable elimination whose complexity is dictated in\nan intricate way by the order in which variables are eliminated. The so-called\ntreewidth of the graph characterises this algorithmic complexity: low-treewidth\ngraphs can be processed efficiently. The first message that we illustrate is\ntherefore the idea that for inference in graphical model, the number of\nvariables is not the limiting factor, and it is worth checking for the\ntreewidth before turning to approximate methods. We show how algorithms\nproviding an upper bound of the treewidth can be exploited to derive a 'good'\nelimination order enabling to perform exact inference. The second message is\nthat when the treewidth is too large, algorithms for approximate inference\nlinked to the principle of variable elimination, such as loopy belief\npropagation and variational approaches, can lead to accurate results while\nbeing much less time consuming than Monte-Carlo approaches. We illustrate the\ntechniques reviewed in this article on benchmarks of inference problems in\ngenetic linkage analysis and computer vision, as well as on hidden variables\nrestoration in coupled Hidden Markov Models.Comment: 47 pages, 3 tables, 12 figures", "1506.08547": "Commutativity in the Algorithmic Lovasz Local Lemma,Kolmogorov, Vladimir,Computer Science - Data Structures and Algorithms,We consider the recent formulation of the Algorithmic Lov\\'asz Local Lemma\n[10,2,3] for finding objects that avoid `bad features', or `flaws'. It extends\nthe Moser-Tardos resampling algorithm [17] to more general discrete spaces. At\neach step the method picks a flaw present in the current state and goes to a\nnew state according to some prespecified probability distribution (which\ndepends on the current state and the selected flaw). However, it is less\nflexible than the Moser-Tardos method since [10,2,3] require a specific flaw\nselection rule, whereas [17] allows an arbitrary rule (and thus can potentially\nbe implemented more efficiently).\n  We formulate a new \"commutativity\" condition, and prove that it is sufficient\nfor an arbitrary rule to work. It also enables an efficient parallelization\nunder an additional assumption. We then show that existing resampling oracles\nfor perfect matchings and permutations do satisfy this condition.Comment: Accepted to SIAM Journal on Computing (SICOMP). Some proofs are\n  simplified compared to the previous version", "1506.08752": "On Tightly Bounding the Dubins Traveling Salesman's Optimum,Manyam, SatyanarayanaRathinam, Sivakumar,Mathematics - Optimization and ControlComputer Science - Discrete MathematicsComputer Science - Data Structures and AlgorithmsComputer Science - Robotics,The Dubins Traveling Salesman Problem (DTSP) has generated significant\ninterest over the last decade due to its occurrence in several civil and\nmilitary surveillance applications. Currently, there is no algorithm that can\nfind an optimal solution to the problem. In addition, relaxing the motion\nconstraints and solving the resulting Euclidean TSP (ETSP) provides the only\nlower bound available for the problem. However, in many problem instances, the\nlower bound computed by solving the ETSP is far below the cost of the feasible\nsolutions obtained by some well-known algorithms for the DTSP. This article\naddresses this fundamental issue and presents the first systematic procedure\nfor developing tight lower bounds for the DTSP.Comment: Presented at the International Symposium on Mathematical Programming,\n  2015.\n  https://informs.emeetingsonline.com/emeetings/formbuilder/clustersessiondtl.asp?csnno=22283&mmnno=264&ppnno=86444", "1506.08977": "A comparative study of divisive hierarchical clustering algorithms,Roux, Maurice,Computer Science - Data Structures and AlgorithmsQuantitative Biology - Quantitative Methods62-07,A general scheme for divisive hierarchical clustering algorithms is proposed.\nIt is made of three main steps : first a splitting procedure for the\nsubdivision of clusters into two subclusters, second a local evaluation of the\nbipartitions resulting from the tentative splits and, third, a formula for\ndetermining the nodes levels of the resulting dendrogram. A number of such\nalgorithms is given. These algorithms are compared using the Goodman-Kruskal\ncorrelation coefficient. As a global criterion it is an internal\ngoodness-of-fit measure based on the set order induced by the hierarchy\ncompared to the order associated to the given dissimilarities. Applied to a\nhundred of random data tables, these comparisons are in favor of two methods\nbased on unusual ratio-type formulas for the splitting procedures, namely the\nSilhouette criterion and Dunn's criterion. These two criteria take into account\nboth the within cluster and the between cluster mean dissimilarity. In general\nthe results of these two algorithms are better than the classical Agglomerative\nAverage Link method.Comment: 11 pages, 1 figure", "1506.09140": "Pure Strategies in Imperfect Information Stochastic Games,Carayol, ArnaudL\u00f6ding, ChristofSerre, Olivier,Computer Science - Formal Languages and Automata TheoryComputer Science - Computer Science and Game Theory,We consider imperfect information stochastic games where we require the\nplayers to use pure (i.e. non randomised) strategies. We consider reachability,\nsafety, B\\\"uchi and co-B\\\"uchi objectives, and investigate the existence of\nalmost-sure/positively winning strategies for the first player when the second\nplayer is perfectly informed or more informed than the first player. We obtain\ndecidability results for positive reachability and almost-sure B\\\"uchi with\noptimal algorithms to decide existence of a pure winning strategy and to\ncompute one if exists. We complete the picture by showing that positive safety\nis undecidable when restricting to pure strategies even if the second player is\nperfectly informed.", "1506.09145": "Track Layouts, Layered Path Decompositions, and Leveled Planarity,Bannister, Michael J.Devanny, William E.Dujmovi\u0107, VidaEppstein, DavidWood, David R.,Mathematics - CombinatoricsComputer Science - Data Structures and Algorithms05C10,We investigate two types of graph layouts, track layouts and layered path\ndecompositions, and the relations between their associated parameters\ntrack-number and layered pathwidth. We use these two types of layouts to\ncharacterize leveled planar graphs, which are the graphs with planar leveled\ndrawings with no dummy vertices. It follows from the known NP-completeness of\nleveled planarity that track-number and layered pathwidth are also NP-complete,\neven for the smallest constant parameter values that make these parameters\nnontrivial. We prove that the graphs with bounded layered pathwidth include\nouterplanar graphs, Halin graphs, and squaregraphs, but that (despite having\nbounded track-number) series-parallel graphs do not have bounded layered\npathwidth. Finally, we investigate the parameterized complexity of these\nlayouts, showing that past methods used for book layouts do not work to\nparameterize the problem by treewidth or almost-tree number but that the\nproblem is (non-uniformly) fixed-parameter tractable for tree-depth.Comment: 19 pages, 8 figures", "1507.01088": "Generic properties of subgroups of free groups and finite presentations,Bassino, Fr\u00e9d\u00e9riqueNicaud, CyrilWeil, Pascal,Mathematics - Group TheoryComputer Science - Discrete MathematicsMathematics - Combinatorics,Asymptotic properties of finitely generated subgroups of free groups, and of\nfinite group presentations, can be considered in several fashions, depending on\nthe way these objects are represented and on the distribution assumed on these\nrepresentations: here we assume that they are represented by tuples of reduced\nwords (generators of a subgroup) or of cyclically reduced words (relators).\nClassical models consider fixed size tuples of words (e.g. the few-generator\nmodel) or exponential size tuples (e.g. Gromov's density model), and they\nusually consider that equal length words are equally likely. We generalize both\nthe few-generator and the density models with probabilistic schemes that also\nallow variability in the size of tuples and non-uniform distributions on words\nof a given length.Our first results rely on a relatively mild prefix-heaviness\nhypothesis on the distributions, which states essentially that the probability\nof a word decreases exponentially fast as its length grows. Under this\nhypothesis, we generalize several classical results: exponentially generically\na randomly chosen tuple is a basis of the subgroup it generates, this subgroup\nis malnormal and the tuple satisfies a small cancellation property, even for\nexponential size tuples. In the special case of the uniform distribution on\nwords of a given length, we give a phase transition theorem for the central\ntree property, a combinatorial property closely linked to the fact that a tuple\nfreely generates a subgroup. We then further refine our results when the\ndistribution is specified by a Markovian scheme, and in particular we give a\nphase transition theorem which generalizes the classical results on the\ndensities up to which a tuple of cyclically reduced words chosen uniformly at\nrandom exponentially generically satisfies a small cancellation property, and\nbeyond which it presents a trivial group.", "1507.01089": "(Pure) transcendence bases in $\\phi$-deformed shuffle bialgebras,Bui, Van Chi\u00eanDuchamp, G\u00e9rard H. E.Ng\u00f4, Quoc HoanMinh, Vincel Hoang NgocTollu, Christophe,Computer Science - Symbolic ComputationMathematical PhysicsMathematics - CombinatoricsMathematics - Group Theory,Computations with integro-differential operators are often carried out in an\nassociative algebra with unit, and they are essentially non-commutative\ncomputations. By adjoining a cocommutative co-product, one can have those\noperators perform act on a bialgebra isomorphic to an enveloping algebra. That\ngives an adequate framework for a computer-algebra implementation via monoidal\nfactorization, (pure) transcendence bases and Poincar\\'e--Birkhoff--Witt bases.\nIn this paper, we systematically study these deformations, obtaining necessary\nand sufficient conditions for the operators to exist, and we give the most\ngeneral cocommutative deformations of the shuffle co-product and an effective\nconstruction of pairs of bases in duality. The paper ends by the combinatorial\nsetting of local systems of coordinates on the group of group-like series.Comment: The present work is part of a series of papers devoted to the study\n  of the renormalization of divergent polyzetas (at positive and at\n  non-positive indices) via the factorization of the non commutative generating\n  series of polylogarithms and of harmonic sums and via the effective\n  construction of pairs of dual bases in duality in $\\phi$ deformed shuffle\n  algebras. It is a sequel to [3] and its content was presented in several\n  seminars and meetings, including the 74th S\\'eminaire Lotharingien de\n  Combinatoire", "1507.01239": "Experiments on Parallel Training of Deep Neural Network using Model\n  Averaging,Su, HangChen, Haoyu,Computer Science - Machine LearningComputer Science - Neural and Evolutionary Computing,In this work we apply model averaging to parallel training of deep neural\nnetwork (DNN). Parallelization is done in a model averaging manner. Data is\npartitioned and distributed to different nodes for local model updates, and\nmodel averaging across nodes is done every few minibatches. We use multiple\nGPUs for data parallelization, and Message Passing Interface (MPI) for\ncommunication between nodes, which allows us to perform model averaging\nfrequently without losing much time on communication. We investigate the\neffectiveness of Natural Gradient Stochastic Gradient Descent (NG-SGD) and\nRestricted Boltzmann Machine (RBM) pretraining for parallel training in\nmodel-averaging framework, and explore the best setups in term of different\nlearning rate schedules, averaging frequencies and minibatch sizes. It is shown\nthat NG-SGD and RBM pretraining benefits parameter-averaging based model\ntraining. On the 300h Switchboard dataset, a 9.3 times speedup is achieved\nusing 16 GPUs and 17 times speedup using 32 GPUs with limited decoding accuracy\nloss.", "1507.01279": "Scan $B$-Statistic for Kernel Change-Point Detection,Li, ShuangXie, YaoDai, HanjunSong, Le,Computer Science - Machine LearningMathematics - Statistics TheoryStatistics - Machine Learning,Detecting the emergence of an abrupt change-point is a classic problem in\nstatistics and machine learning. Kernel-based nonparametric statistics have\nbeen used for this task which enjoy fewer assumptions on the distributions than\nthe parametric approach and can handle high-dimensional data. In this paper we\nfocus on the scenario when the amount of background data is large, and propose\ntwo related computationally efficient kernel-based statistics for change-point\ndetection, which are inspired by the recently developed $B$-statistics. A novel\ntheoretical result of the paper is the characterization of the tail probability\nof these statistics using the change-of-measure technique, which focuses on\ncharacterizing the tail of the detection statistics rather than obtaining its\nasymptotic distribution under the null distribution. Such approximations are\ncrucial to control the false alarm rate, which corresponds to the significance\nlevel in offline change-point detection and the average-run-length in online\nchange-point detection. Our approximations are shown to be highly accurate.\nThus, they provide a convenient way to find detection thresholds for both\noffline and online cases without the need to resort to the more expensive\nsimulations or bootstrapping. We show that our methods perform well on both\nsynthetic data and real data.Comment: Submitted for journal publication. Partial results appeared in NIPS\n  2015", "1507.01345": "DiffNodesets: An Efficient Structure for Fast Mining Frequent Itemsets,Deng, Zhi-Hong,Computer Science - Data Structures and AlgorithmsComputer Science - Databases,Mining frequent itemsets is an essential problem in data mining and plays an\nimportant role in many data mining applications. In recent years, some itemset\nrepresentations based on node sets have been proposed, which have shown to be\nvery efficient for mining frequent itemsets. In this paper, we propose\nDiffNodeset, a novel and more efficient itemset representation, for mining\nfrequent itemsets. Based on the DiffNodeset structure, we present an efficient\nalgorithm, named dFIN, to mining frequent itemsets. To achieve high efficiency,\ndFIN finds frequent itemsets using a set-enumeration tree with a hybrid search\nstrategy and directly enumerates frequent itemsets without candidate generation\nunder some case. For evaluating the performance of dFIN, we have conduct\nextensive experiments to compare it against with existing leading algorithms on\na variety of real and synthetic datasets. The experimental results show that\ndFIN is significantly faster than these leading algorithms.Comment: 22 pages, 13 figures", "1507.01581": "Joint Calibration for Semantic Segmentation,Caesar, HolgerUijlings, JasperFerrari, Vittorio,Computer Science - Computer Vision and Pattern Recognition68T45,Semantic segmentation is the task of assigning a class-label to each pixel in\nan image. We propose a region-based semantic segmentation framework which\nhandles both full and weak supervision, and addresses three common problems:\n(1) Objects occur at multiple scales and therefore we should use regions at\nmultiple scales. However, these regions are overlapping which creates\nconflicting class predictions at the pixel-level. (2) Class frequencies are\nhighly imbalanced in realistic datasets. (3) Each pixel can only be assigned to\na single class, which creates competition between classes. We address all three\nproblems with a joint calibration method which optimizes a multi-class loss\ndefined over the final pixel-level output labeling, as opposed to simply region\nclassification. Our method outperforms the state-of-the-art on the popular SIFT\nFlow [18] dataset in both the fully and weakly supervised setting by a\nconsiderably margin (+6% and +10%, respectively).Comment: Includes improved results based on VGG16 CNN", "1507.01988": "Automata and Quantum Computing,Ambainis, AndrisYakary\u0131lmaz, Abuzer,Computer Science - Formal Languages and Automata TheoryComputer Science - Computational ComplexityQuantum Physics68Q10, 68Q12, 68Q15, 68Q19, 68Q45,Quantum computing is a new model of computation, based on quantum physics.\nQuantum computers can be exponentially faster than conventional computers for\nproblems such as factoring. Besides full-scale quantum computers, more\nrestricted models such as quantum versions of finite automata have been\nstudied. In this paper, we survey various models of quantum finite automata and\ntheir properties. We also provide some open questions and new directions for\nresearchers.\n  Keywords: quantum finite automata, probabilistic finite automata,\nnondeterminism, bounded error, unbounded error, state complexity, decidability\nand undecidability, computational complexityComment: 33 pages. A revised and updated version (June 2018). To appear in\n  Automata: From Mathematics to Applications edited by Jean-\\'Eric Pin", "1507.02103": "Measuring centrality by a generalization of degree,Csat\u00f3, L\u00e1szl\u00f3,Computer Science - Social and Information NetworksPhysics - Physics and Society15A06, 91D30,Network analysis has emerged as a key technique in communication studies,\neconomics, geography, history and sociology, among others. A fundamental issue\nis how to identify key nodes, for which purpose a number of centrality measures\nhave been developed. This paper proposes a new parametric family of centrality\nmeasures called generalized degree. It is based on the idea that a relationship\nto a more interconnected node contributes to centrality in a greater extent\nthan a connection to a less central one. Generalized degree improves on degree\nby redistributing its sum over the network with the consideration of the global\nstructure. Application of the measure is supported by a set of basic\nproperties. A sufficient condition is given for generalized degree to be rank\nmonotonic, excluding counter-intuitive changes in the centrality ranking after\ncertain modifications of the network. The measure has a graph interpretation\nand can be calculated iteratively. Generalized degree is recommended to apply\nbesides degree since it preserves most favourable attributes of degree, but\nbetter reflects the role of the nodes in the network and has an increased\nability to distinguish among their importance.Comment: 20 pages, 8 figures", "1507.02178": "Directed multicut is W[1]-hard, even for four terminal pairs,Pilipczuk, MarcinWahlstr\u00f6m, Magnus,Computer Science - Data Structures and Algorithms,We prove that Multicut in directed graphs, parameterized by the size of the\ncutset, is W[1]-hard and hence unlikely to be fixed-parameter tractable even if\nrestricted to instances with only four terminal pairs. This negative result\nalmost completely resolves one of the central open problems in the area of\nparameterized complexity of graph separation problems, posted originally by\nMarx and Razgon [SIAM J. Comput. 43(2):355-388 (2014)], leaving only the case\nof three terminal pairs open.\n  Our gadget methodology allows us also to prove W[1]-hardness of the Steiner\nOrientation problem parameterized by the number of terminal pairs, resolving an\nopen problem of Cygan, Kortsarz, and Nutov [SIAM J. Discrete Math.\n27(3):1503-1513 (2013)].Comment: v2: Added almost tight ETH lower bounds", "1507.02180": "A note on the definition of sliding block codes and the\n  Curtis-Hedlund-Lyndon Theorem,Sobottka, MarceloGon\u00e7alves, Daniel,Mathematics - Dynamical SystemsComputer Science - Information TheoryMathematics - History and Overview37B10, 37B15,In this note we propose an alternative definition for sliding block codes\nbetween shift spaces. This definition coincides with the usual definition in\nthe case that the shift space is defined on a finite alphabet, but it encompass\na larger class of maps when the alphabet is infinite. In any case, the proposed\ndefinition keeps the idea that a sliding block code is a map with a local rule.\nUsing this new definition we prove that the Curtis-Hedlund-Lyndon Theorem\nalways holds for shift spaces over countable alphabets.Comment: 5 pages", "1507.02184": "The \"art of trellis decoding\" is fixed-parameter tractable,Jeong, JisuKim, Eun JungOum, Sang-il,Computer Science - Data Structures and AlgorithmsComputer Science - Computational ComplexityComputer Science - Discrete MathematicsMathematics - Combinatorics,Given n subspaces of a finite-dimensional vector space over a fixed finite\nfield $\\mathbb F$, we wish to find a linear layout $V_1,V_2,\\ldots,V_n$ of the\nsubspaces such that $\\dim((V_1+V_2+\\cdots+V_i) \\cap (V_{i+1}+\\cdots+V_n))\\le k$\nfor all i, such a linear layout is said to have width at most k. When\nrestricted to 1-dimensional subspaces, this problem is equivalent to computing\nthe trellis-width (or minimum trellis state-complexity) of a linear code in\ncoding theory and computing the path-width of an $\\mathbb F$-represented\nmatroid in matroid theory.\n  We present a fixed-parameter tractable algorithm to construct a linear layout\nof width at most k, if it exists, for input subspaces of a finite-dimensional\nvector space over $\\mathbb F$. As corollaries, we obtain a fixed-parameter\ntractable algorithm to produce a path-decomposition of width at most k for an\ninput $\\mathbb F$-represented matroid of path-width at most k, and a\nfixed-parameter tractable algorithm to find a linear rank-decomposition of\nwidth at most k for an input graph of linear rank-width at most k. In both\ncorollaries, no such algorithms were known previously.\n  It was previously known that a fixed-parameter tractable algorithm exists for\nthe decision version of the problem for matroid path-width, a theorem by\nGeelen, Gerards, and Whittle~(2002) implies that for each fixed finite field\n$\\mathbb F$, there are finitely many forbidden $\\mathbb F$-representable minors\nfor the class of matroids of path-width at most k. An algorithm by\nHlin\\v{e}n\\'y (2006) can detect a minor in an input $\\mathbb F$-represented\nmatroid of bounded branch-width. However, this indirect approach would not\nproduce an actual path-decomposition. Our algorithm is the first one to\nconstruct such a path-decomposition and does not depend on the finiteness of\nforbidden minors.Comment: 50 pages. Accepted to SODA 2016 under the title \"constructive\n  algorithms for path-width of matroids\". We added several figures to improve\n  its presentation. We found a mistake in the proof of Lemma 3.24 of the\n  previous version. In order to fix it, we changed some definitions in Section\n  3 and were able to recover our theorem", "1507.02250": "Privacy-Preserving Nonlinear Observer Design Using Contraction Analysis,Ny, Jerome Le,Computer Science - Systems and ControlComputer Science - Information TheoryComputer Science - Social and Information Networks,Real-time information processing applications such as those enabling a more\nintelligent infrastructure are increasingly focused on analyzing\nprivacy-sensitive data obtained from individuals. To produce accurate\nstatistics about the habits of a population of users of a system, this data\nmight need to be processed through model-based estimators. Moreover, models of\npopulation dynamics, originating for example from epidemiology or the social\nsciences, are often necessarily nonlinear. Motivated by these trends, this\npaper presents an approach to design nonlinear privacy-preserving model-based\nobservers, relying on additive input or output noise to give differential\nprivacy guarantees to the individuals providing the input data. For the case of\noutput perturbation, contraction analysis allows us to design convergent\nobservers as well as set the level of privacy-preserving noise appropriately.\nTwo examples illustrate the approach: estimating the edge formation\nprobabilities in a dynamic social network, and syndromic surveillance relying\non an epidemiological model.Comment: 23 pages, 3 figures", "1507.02385": "Towards Effective Codebookless Model for Image Classification,Wang, QilongLi, PeihuaZhang, LeiZuo, Wangmeng,Computer Science - Computer Vision and Pattern Recognition,The bag-of-features (BoF) model for image classification has been thoroughly\nstudied over the last decade. Different from the widely used BoF methods which\nmodeled images with a pre-trained codebook, the alternative codebook free image\nmodeling method, which we call Codebookless Model (CLM), attracted little\nattention. In this paper, we present an effective CLM that represents an image\nwith a single Gaussian for classification. By embedding Gaussian manifold into\na vector space, we show that the simple incorporation of our CLM into a linear\nclassifier achieves very competitive accuracy compared with state-of-the-art\nBoF methods (e.g., Fisher Vector). Since our CLM lies in a high dimensional\nRiemannian manifold, we further propose a joint learning method of low-rank\ntransformation with support vector machine (SVM) classifier on the Gaussian\nmanifold, in order to reduce computational and storage cost. To study and\nalleviate the side effect of background clutter on our CLM, we also present a\nsimple yet effective partial background removal method based on saliency\ndetection. Experiments are extensively conducted on eight widely used databases\nto demonstrate the effectiveness and efficiency of our CLM method.", "1507.02908": "On Existence and Properties of Approximate Pure Nash Equilibria in\n  Bandwidth Allocation Games,Drees, MaximilianFeldotto, MatthiasRiechers, S\u00f6renSkopalik, Alexander,Computer Science - Computer Science and Game Theory,In \\emph{bandwidth allocation games} (BAGs), the strategy of a player\nconsists of various demands on different resources. The player's utility is at\nmost the sum of these demands, provided they are fully satisfied. Every\nresource has a limited capacity and if it is exceeded by the total demand, it\nhas to be split between the players. Since these games generally do not have\npure Nash equilibria, we consider approximate pure Nash equilibria, in which no\nplayer can improve her utility by more than some fixed factor $\\alpha$ through\nunilateral strategy changes. There is a threshold $\\alpha_\\delta$ (where\n$\\delta$ is a parameter that limits the demand of each player on a specific\nresource) such that $\\alpha$-approximate pure Nash equilibria always exist for\n$\\alpha \\geq \\alpha_\\delta$, but not for $\\alpha < \\alpha_\\delta$. We give both\nupper and lower bounds on this threshold $\\alpha_\\delta$ and show that the\ncorresponding decision problem is ${\\sf NP}$-hard. We also show that the\n$\\alpha$-approximate price of anarchy for BAGs is $\\alpha+1$. For a restricted\nversion of the game, where demands of players only differ slightly from each\nother (e.g. symmetric games), we show that approximate Nash equilibria can be\nreached (and thus also be computed) in polynomial time using the best-response\ndynamic. Finally, we show that a broader class of utility-maximization games\n(which includes BAGs) converges quickly towards states whose social welfare is\nclose to the optimum.", "1507.02954": "An Iterative Receiver for OFDM With Sparsity-Based Parametric Channel\n  Estimation,Hansen, Thomas L.J\u00f8rgensen, Peter B.Badiu, Mihai-AlinFleury, Bernard H.,Computer Science - Information TheoryElectrical Engineering and Systems Science - Signal ProcessingStatistics - Applications,In this work we design a receiver that iteratively passes soft information\nbetween the channel estimation and data decoding stages. The receiver\nincorporates sparsity-based parametric channel estimation. State-of-the-art\nsparsity-based iterative receivers simplify the channel estimation problem by\nrestricting the multipath delays to a grid. Our receiver does not impose such a\nrestriction. As a result it does not suffer from the leakage effect, which\ndestroys sparsity. Communication at near capacity rates in high SNR requires a\nlarge modulation order. Due to the close proximity of modulation symbols in\nsuch systems, the grid-based approximation is of insufficient accuracy. We show\nnumerically that a state-of-the-art iterative receiver with grid-based sparse\nchannel estimation exhibits a bit-error-rate floor in the high SNR regime. On\nthe contrary, our receiver performs very close to the perfect channel state\ninformation bound for all SNR values. We also demonstrate both theoretically\nand numerically that parametric channel estimation works well in dense\nchannels, i.e., when the number of multipath components is large and each\nindividual component cannot be resolved.Comment: Major revision, accepted for IEEE Transactions on Signal Processing", "1507.02980": "A hybrid mathematical model of collective motion under alignment and\n  chemotaxis,Di Costanzo, EzioMenci, MartaMessina, EleonoraNatalini, RobertoVecchio, Antonia,Mathematics - Classical Analysis and ODEsComputer Science - Systems and ControlMathematics - Dynamical SystemsMathematics - Optimization and ControlQuantitative Biology - Cell Behavior82C22, 34D05, 92C17,In this paper we propose and study a hybrid discrete in continuous\nmathematical model of collective motion under alignment and chemotaxis effect.\nStarting from the paper by Di Costanzo et al (2015a), in which the Cucker-Smale\nmodel (Cucker and Smale, 2007) was coupled with other cell mechanisms, to\ndescribe the cell migration and self-organization in the zebrafish lateral line\nprimordium, we introduce a simplified model in which the coupling between an\nalignment and chemotaxis mechanism acts on a system of interacting particles.\nIn particular we rely on a hybrid description in which the agents are discrete\nentities, while the chemoattractant is considered as a continuous signal. The\nproposed model is then studied both from an analytical and a numerical point of\nview. From the analytic point of view we prove, globally in time, existence and\nuniqueness of the solution. Then, the asymptotic behaviour of a linearised\nversion of the system is investigated. Through a suitable Lyapunov functional\nwe show that for $t\\rightarrow +\\infty$, the migrating aggregate exponentially\nconverges to a state in which all the particles have a same position with zero\nvelocity. Finally, we present a comparison between the analytical findings and\nsome numerical results, concerning the behaviour of the full nonlinear system.", "1507.03344": "Entanglement in Reversible Quantum Computing,Wang, Yong,Computer Science - Logic in Computer Science,Similarly to the modelling of entanglement in the algebra of quantum\ncomputing, we also model entanglement as a synchronization among an event and\nits shadows in reversible quantum computing. We give the semantics and axioms\nof shadow constant for reversible quantum computing.", "1507.03348": "Deciding Circular-Arc Graph Isomorphism in Parameterized Logspace,Chandoo, Maurice,Computer Science - Data Structures and AlgorithmsComputer Science - Discrete MathematicsG.2.2,We compute a canonical circular-arc representation for a given circular-arc\n(CA) graph which implies solving the isomorphism and recognition problem for\nthis class. To accomplish this we split the class of CA graphs into uniform and\nnon-uniform ones and employ a generalized version of the argument given by\nK\\\"obler et al (2013) that has been used to show that the subclass of Helly CA\ngraphs can be canonized in logspace. For uniform CA graphs our approach works\nin logspace and in addition to that Helly CA graphs are a strict subset of\nuniform CA graphs. Thus our result is a generalization of the canonization\nresult for Helly CA graphs. In the non-uniform case a specific set of ambiguous\nvertices arises. By choosing the parameter to be the cardinality of this set\nthe obstacle can be solved by brute force. This leads to an O(k + log n) space\nalgorithm to compute a canonical representation for non-uniform and therefore\nall CA graphs.Comment: 14 pages, 3 figures", "1507.03403": "Time-Space Trade-offs for Triangulations and Voronoi Diagrams,Korman, MatiasMulzer, Wolfgangvan Renssen, AndreRoeloffzen, MarcelSeiferth, PaulStein, Yannik,Computer Science - Computational GeometryComputer Science - Data Structures and Algorithms,Let $S$ be a planar $n$-point set. A triangulation for $S$ is a maximal plane\nstraight-line graph with vertex set $S$. The Voronoi diagram for $S$ is the\nsubdivision of the plane into cells such that all points in a cell have the\nsame nearest neighbor in $S$. Classically, both structures can be computed in\n$O(n \\log n)$ time and $O(n)$ space. We study the situation when the available\nworkspace is limited: given a parameter $s \\in \\{1, \\dots, n\\}$, an\n$s$-workspace algorithm has read-only access to an input array with the points\nfrom $S$ in arbitrary order, and it may use only $O(s)$ additional words of\n$\\Theta(\\log n)$ bits for reading and writing intermediate data. The output\nshould then be written to a write-only structure. We describe a deterministic\n$s$-workspace algorithm for computing an arbitrary triangulation of $S$ in time\n$O(n^2/s + n \\log n \\log s )$ and a randomized $s$-workspace algorithm for\nfinding the Voronoi diagram of $S$ in expected time $O((n^2/s) \\log s + n \\log\ns \\log^*s)$.Comment: 17 pages, 4 figures, a preliminary version appeared in WADS 2015", "1507.03528": "Visibility-Aware Optimal Contagion of Malware Epidemics,Eshghi, SoheilSarkar, SaswatiVenkatesh, Santosh S.,Computer Science - Cryptography and SecurityComputer Science - Systems and ControlMathematics - Optimization and Control,Recent innovations in the design of computer viruses have led to new\ntrade-offs for the attacker. Multiple variants of a malware may spread at\ndifferent rates and have different levels of visibility to the network. In this\nwork we examine the optimal strategies for the attacker so as to trade off the\nextent of spread of the malware against the need for stealth. We show that in\nthe mean-field deterministic regime, this spread-stealth trade-off is optimized\nby computationally simple single-threshold policies. Specifically, we show that\nonly one variant of the malware is spread by the attacker at each time, as\nthere exists a time up to which the attacker prioritizes maximizing the spread\nof the malware, and after which she prioritizes stealth.Comment: Amended to include more explanations on assumptions, add more\n  real-world context on new stealthy malware, and improve figures", "1507.03838": "Towards Green and Infinite Capacity in Wireless Communication Networks:\n  Beyond The Shannon Theorem,Elmusrati, Mohammed,Computer Science - Information Theory,New and novel way for resources allocation in wireless communication has been\nproposed in this paper. Under this new method, it has been shown that the\nrequired power budget becomes independent of the number of served terminals in\nthe downlink. However, the required power depends only of the coverage area,\ni.e. the channel losses at the cell boarder. Therefore, huge number\n(theoretically any number) of terminals could be supported concurrently at\nfinite and small downlink power budget. This could be very useful to support\nthe downlink signalling channels in HSPA+, LTE, and 5G. It can be very useful\nalso to support huge D2D communication downlinks. Moreover, and based on the\nsame concept, a new system configuration for a single link point-to-point\ncommunication has been presented. With this new configuration, the achieved\ndata rate becomes independent of the required transmit power. This means that\nany data rate can be achieved at the target BER and with small and finite\ntransmit power. This seems violating with some major results of the Shannon\ntheorem. This issue will be discussed in details in this article.Comment: Version of this paper has been submitted to IEEE Transaction on\n  Wireless Communication", "1507.04027": "Fuzzy Overlapping Community Quality Metrics,Chen, MingmingSzymanski, Boleslaw K.,Computer Science - Social and Information NetworksPhysics - Physics and Society,Modularity is widely used to effectively measure the strength of the disjoint\ncommunity structure found by community detection algorithms. Several\noverlapping extensions of modularity were proposed to measure the quality of\noverlapping community structure. However, all these extensions differ just in\nthe way they define the belonging coefficient and belonging function. Yet,\nthere is lack of systematic comparison of different extensions. To fill this\ngap, we overview overlapping extensions of modularity and generalize them with\na uniform definition enabling application of different belonging coefficients\nand belonging functions to select the best. In addition, we extend localized\nmodularity, modularity density, and eight local community quality metrics to\nenable their usages for overlapping communities. The experimental results on a\nlarge number of real networks and synthetic networks using overlapping\nextensions of modularity, overlapping modularity density, and local metrics\nshow that the best results are obtained when the product of the belonging\ncoefficients of two nodes is used as the belonging function. Moreover, the\nresults may be used to guide researchers on which metrics to adopt when\nmeasuring the quality of overlapping community structure.Comment: 40 pages in Social Network Analysis and Mining 5(1) 2015", "1507.04394": "Time-triggered smart transducer networks,Elmenreich, Wilfried,Computer Science - Networking and Internet Architecture,The time-triggered approach is a well-suited approach for building\ndistributed hard real-time systems. Since many applications of transducer\nnetworks have real-time requirements, a time-triggered communication interface\nfor smart transducers is desirable, however such a time-triggered interface\nmust still support features for monitoring, maintenance, plug-and-play, etc.\nThe approach of the OMG Smart Transducer Interface consists of clusters of\ntime-triggered smart transducer nodes that contain special interfaces\nsupporting configuration, diagnostics, and maintenance without affecting the\ndeterministic real-time communication. This paper discusses the applicability\nof the time-triggered approach for smart transducer networks and presents a\ncase study application of a time-triggered smart transducer network.", "1507.04500": "The Complexity of All-switches Strategy Improvement,Fearnley, JohnSavani, Rahul,Computer Science - Data Structures and AlgorithmsComputer Science - Computational ComplexityComputer Science - Computer Science and Game TheoryComputer Science - Logic in Computer Science,Strategy improvement is a widely-used and well-studied class of algorithms\nfor solving graph-based infinite games. These algorithms are parameterized by a\nswitching rule, and one of the most natural rules is \"all switches\" which\nswitches as many edges as possible in each iteration. Continuing a recent line\nof work, we study all-switches strategy improvement from the perspective of\ncomputational complexity. We consider two natural decision problems, both of\nwhich have as input a game $G$, a starting strategy $s$, and an edge $e$. The\nproblems are: 1.) The edge switch problem, namely, is the edge $e$ ever\nswitched by all-switches strategy improvement when it is started from $s$ on\ngame $G$? 2.) The optimal strategy problem, namely, is the edge $e$ used in the\nfinal strategy that is found by strategy improvement when it is started from\n$s$ on game $G$? We show $\\mathtt{PSPACE}$-completeness of the edge switch\nproblem and optimal strategy problem for the following settings: Parity games\nwith the discrete strategy improvement algorithm of V\\\"oge and Jurdzi\\'nski;\nmean-payoff games with the gain-bias algorithm [14,37]; and discounted-payoff\ngames and simple stochastic games with their standard strategy improvement\nalgorithms. We also show $\\mathtt{PSPACE}$-completeness of an analogous problem\nto edge switch for the bottom-antipodal algorithm for finding the sink of an\nAcyclic Unique Sink Orientation on a cube.", "1507.04606": "Extension of Modularity Density for Overlapping Community Structure,Chen, MingmingKuzmin, KonstantinSzymanski, Boleslaw K.,Computer Science - Social and Information NetworksPhysics - Physics and Society,Modularity is widely used to effectively measure the strength of the disjoint\ncommunity structure found by community detection algorithms. Although several\noverlapping extensions of modularity were proposed to measure the quality of\noverlapping community structure, there is lack of systematic comparison of\ndifferent extensions. To fill this gap, we overview overlapping extensions of\nmodularity to select the best. In addition, we extend the Modularity Density\nmetric to enable its usage for overlapping communities. The experimental\nresults on four real networks using overlapping extensions of modularity,\noverlapping modularity density, and six other community quality metrics show\nthat the best results are obtained when the product of the belonging\ncoefficients of two nodes is used as the belonging function. Moreover, our\nexperiments indicate that overlapping modularity density is a better measure of\nthe quality of overlapping community structure than other metrics considered.Comment: 8 pages in Advances in Social Networks Analysis and Mining (ASONAM),\n  2014 IEEE/ACM International Conference on", "1507.05014": "Compositional Construction of Approximate Abstractions of Interconnected\n  Control Systems,Rungger, MatthiasZamani, Majid,Mathematics - Optimization and ControlComputer Science - Systems and Control93C10I.2.8,We consider a compositional construction of approximate abstractions of\ninterconnected control systems. In our framework, an abstraction acts as a\nsubstitute in the controller design process and is itself a continuous control\nsystem. The abstraction is related to the concrete control system via a\nso-called simulation function: a Lyapunov-like function, which is used to\nestablish a quantitative bound between the behavior of the approximate\nabstraction and the concrete system. In the first part of the paper, we provide\na small gain type condition that facilitates the compositional construction of\nan abstraction of an interconnected control system together with a simulation\nfunction from the abstractions and simulation functions of the individual\nsubsystems. In the second part of the paper, we restrict our attention to\nlinear control system and characterize simulation functions in terms of\ncontrolled invariant, externally stabilizable subspaces. Based on those\ncharacterizations, we propose a particular scheme to construct abstractions for\nlinear control systems. We illustrate the compositional construction of an\nabstraction on an interconnected system consisting of four linear subsystems.\nWe use the abstraction as a substitute to synthesize a controller to enforce a\ncertain linear temporal logic specification.", "1507.05305": "Computability and Complexity of Categorical Structures,Yanofsky, Noson S.,Computer Science - Computational ComplexityComputer Science - Logic in Computer ScienceMathematics - Category Theory18-XX, 03-XX, 03D15, 68Q30, 03D10,We examine various categorical structures that can and cannot be constructed.\nWe show that total computable functions can be mimicked by constructible\nfunctors. More generally, whatever can be done by a Turing machine can be\nconstructed by categories. Since there are infinitary constructions in category\ntheory, it is shown that category theory is strictly more powerful than Turing\nmachines. In particular, categories can solve the Halting Problem for Turing\nmachines. We also show that categories can solve any problem in the arithmetic\nhierarchy.Comment: 36 pages. Some proofs were improved and typos were eliminated", "1507.05492": "Parallel Toolkit for Measuring the Quality of Network Community\n  Structure,Chen, MingmingLiu, SisiSzymanski, Boleslaw K.,Computer Science - Social and Information NetworksPhysics - Physics and Society,Many networks display community structure which identifies groups of nodes\nwithin which connections are denser than between them. Detecting and\ncharacterizing such community structure, which is known as community detection,\nis one of the fundamental issues in the study of network systems. It has\nreceived a considerable attention in the last years. Numerous techniques have\nbeen developed for both efficient and effective community detection. Among\nthem, the most efficient algorithm is the label propagation algorithm whose\ncomputational complexity is O(|E|). Although it is linear in the number of\nedges, the running time is still too long for very large networks, creating the\nneed for parallel community detection. Also, computing community quality\nmetrics for community structure is computationally expensive both with and\nwithout ground truth. However, to date we are not aware of any effort to\nintroduce parallelism for this problem. In this paper, we provide a parallel\ntoolkit to calculate the values of such metrics. We evaluate the parallel\nalgorithms on both distributed memory machine and shared memory machine. The\nexperimental results show that they yield a significant performance gain over\nsequential execution in terms of total running time, speedup, and efficiency.Comment: 8 pages; in Network Intelligence Conference (ENIC), 2014 European", "1507.05500": "The Complexity of Non-Iterated Probabilistic Justification Logic,Kokkinis, Ioannis,Computer Science - Logic in Computer Science,The logic PJ is a probabilistic logic defined by adding (non-iterated)\nprobability operators to the basic justification logic J. In this paper we\nestablish upper and lower bounds for the complexity of the derivability problem\nin the logic PJ. The main result of the paper is that the complex- ity of the\nderivability problem in PJ remains the same as the complexity of the\nderivability problem in the underlying logic J, which is {\\Pi}p2-complete. This\nimplies hat the probability operators do not increase the complex- ity of the\nlogic, although they arguably enrich the expressiveness of the language.", "1507.05819": "On Identifying Anomalies in Tor Usage with Applications in Detecting\n  Internet Censorship,Wright, JossDarer, AlexanderFarnan, Oliver,Computer Science - Computers and SocietyComputer Science - Machine LearningComputer Science - Networking and Internet Architecture,We develop a means to detect ongoing per-country anomalies in the daily usage\nmetrics of the Tor anonymous communication network, and demonstrate the\napplicability of this technique to identifying likely periods of internet\ncensorship and related events. The presented approach identifies contiguous\nanomalous periods, rather than daily spikes or drops, and allows anomalies to\nbe ranked according to deviation from expected behaviour.\n  The developed method is implemented as a running tool, with outputs published\ndaily by mailing list. This list highlights per-country anomalous Tor usage,\nand produces a daily ranking of countries according to the level of detected\nanomalous behaviour. This list has been active since August 2016, and is in use\nby a number of individuals, academics, and NGOs as an early warning system for\npotential censorship events.\n  We focus on Tor, however the presented approach is more generally applicable\nto usage data of other services, both individually and in combination. We\ndemonstrate that combining multiple data sources allows more specific\nidentification of likely Tor blocking events. We demonstrate the our approach\nin comparison to existing anomaly detection tools, and against both known\nhistorical internet censorship events and synthetic datasets. Finally, we\ndetail a number of significant recent anomalous events and behaviours\nidentified by our tool.Comment: To appear in ACM WebSci 2018", "1507.05880": "A study of the classification of low-dimensional data with supervised\n  manifold learning,Vural, ElifGuillemot, Christine,Computer Science - Machine Learning,Supervised manifold learning methods learn data representations by preserving\nthe geometric structure of data while enhancing the separation between data\nsamples from different classes. In this work, we propose a theoretical study of\nsupervised manifold learning for classification. We consider nonlinear\ndimensionality reduction algorithms that yield linearly separable embeddings of\ntraining data and present generalization bounds for this type of algorithms. A\nnecessary condition for satisfactory generalization performance is that the\nembedding allow the construction of a sufficiently regular interpolation\nfunction in relation with the separation margin of the embedding. We show that\nfor supervised embeddings satisfying this condition, the classification error\ndecays at an exponential rate with the number of training samples. Finally, we\nexamine the separability of supervised nonlinear embeddings that aim to\npreserve the low-dimensional geometric structure of data based on graph\nrepresentations. The proposed analysis is supported by experiments on several\nreal data sets.", "1507.05995": "A Warm Restart Strategy for Solving Sudoku by Sparse Optimization\n  Methods,Tang, YuchaoWu, ZhenggangZhu, Chuanxi,Mathematics - Optimization and ControlComputer Science - Distributed, Parallel, and Cluster Computing90C05, 90C25,This paper is concerned with the popular Sudoku problem. We proposed a warm\nrestart strategy for solving Sudoku puzzles, based on the sparse optimization\ntechnique. Furthermore, we defined a new difficulty level for Sudoku puzzles.\nThe efficiency of the proposed method is tested using a dataset of Sudoku\npuzzles, and the numerical results show that the accurate recovery rate can be\nenhanced from 84%+ to 99%+ using the L1 sparse optimization method.Comment: 11 pages,5 figures", "1507.06011": "Using coarse GPS data to quantify city-scale transportation system\n  resilience to extreme events,Donovan, BrianWork, Daniel B.,Physics - Physics and SocietyComputer Science - Social and Information Networks,This article proposes a method to quantitatively measure the resilience of\ntransportation systems using GPS data from taxis. The granularity of the GPS\ndata necessary for this analysis is relatively coarse; it only requires\ncoordinates for the beginning and end of trips, the metered distance, and the\ntotal travel time. The method works by computing the historical distribution of\npace (normalized travel times) between various regions of a city and measuring\nthe pace deviations during an unusual event. This method is applied to a\ndataset of nearly 700 million taxi trips in New York City, which is used to\nanalyze the transportation infrastructure resilience to Hurricane Sandy. The\nanalysis indicates that Hurricane Sandy impacted traffic conditions for more\nthan five days, and caused a peak delay of two minutes per mile. Practically,\nit identifies that the evacuation caused only minor disruptions, but\nsignificant delays were encountered during the post-disaster reentry process.\nSince the implementation of this method is very efficient, it could potentially\nbe used as an online monitoring tool, representing a first step toward\nquantifying city scale resilience with coarse GPS data.Comment: presented at the 2015 Transportation Research Board Annual Meeting,\n  paper number 15-5465", "1507.06111": "COMs: Complexes of Oriented Matroids,Bandelt, Hans-JuergenChepoi, VictorKnauer, Kolja,Mathematics - CombinatoricsComputer Science - Discrete Mathematics,In his seminal 1983 paper, Jim Lawrence introduced lopsided sets and featured\nthem as asymmetric counterparts of oriented matroids, both sharing the key\nproperty of strong elimination. Moreover, symmetry of faces holds in both\nstructures as well as in the so-called affine oriented matroids. These two\nfundamental properties (formulated for covectors) together lead to the natural\nnotion of \"conditional oriented matroid\" (abbreviated COM). These novel\nstructures can be characterized in terms of three cocircuits axioms,\ngeneralizing the familiar characterization for oriented matroids. We describe a\nbinary composition scheme by which every COM can successively be erected as a\ncertain complex of oriented matroids, in essentially the same way as a lopsided\nset can be glued together from its maximal hypercube faces. A realizable COM is\nrepresented by a hyperplane arrangement restricted to an open convex set. Among\nthese are the examples formed by linear extensions of ordered sets,\ngeneralizing the oriented matroids corresponding to the permutohedra. Relaxing\nrealizability to local realizability, we capture a wider class of combinatorial\nobjects: we show that non-positively curved Coxeter zonotopal complexes give\nrise to locally realizable COMs.Comment: 40 pages, 6 figures, (improved exposition)", "1507.06576": "Abstract Gringo,Gebser, MartinHarrison, AmeliaKaminski, RolandLifschitz, VladimirSchaub, Torsten,Computer Science - Programming Languages,This paper defines the syntax and semantics of the input language of the ASP\ngrounder GRINGO. The definition covers several constructs that were not\ndiscussed in earlier work on the semantics of that language, including\nintervals, pools, division of integers, aggregates with non-numeric values, and\nlparse-style aggregate expressions. The definition is abstract in the sense\nthat it disregards some details related to representing programs by strings of\nASCII characters. It serves as a specification for GRINGO from Version 4.5 on.", "1507.06616": "Robust Monotone Submodular Function Maximization,Orlin, James B.Schulz, Andreas S.Udwani, Rajan,Computer Science - Data Structures and AlgorithmsComputer Science - Discrete MathematicsMathematics - Optimization and Control,We consider a robust formulation, introduced by Krause et al. (2008), of the\nclassical cardinality constrained monotone submodular function maximization\nproblem, and give the first constant factor approximation results. The\nrobustness considered is w.r.t. adversarial removal of up to $\\tau$ elements\nfrom the chosen set. For the fundamental case of $\\tau=1$, we give a\ndeterministic $(1-1/e)-1/\\Theta(m)$ approximation algorithm, where $m$ is an\ninput parameter and number of queries scale as $O(n^{m+1})$. In the process, we\ndevelop a deterministic $(1-1/e)-1/\\Theta(m)$ approximate greedy algorithm for\nbi-objective maximization of (two) monotone submodular functions. Generalizing\nthe ideas and using a result from Chekuri et al. (2010), we show a randomized\n$(1-1/e)-\\epsilon$ approximation for constant $\\tau$ and $\\epsilon\\leq\n\\frac{1}{\\tilde{\\Omega}(\\tau)}$, making $O(n^{1/\\epsilon^3})$ queries. Further,\nfor $\\tau\\ll \\sqrt{k}$, we give a fast and practical 0.387 algorithm. Finally,\nwe also give a black box result result for the much more general setting of\nrobust maximization subject to an Independence System.Comment: Preliminary version in IPCO 2016", "1507.07045": "A Truth Serum for Large-Scale Evaluations,Kamble, VijayMarn, DavidShah, NiharParekh, AbhayRamachandran, Kannan,Computer Science - Computer Science and Game TheoryComputer Science - Artificial IntelligenceComputer Science - Multiagent Systems,A major challenge in obtaining large-scale evaluations, e.g., product or\nservice reviews on online platforms, labeling images, grading in online\ncourses, etc., is that of eliciting honest responses from agents in the absence\nof verifiability. We propose a new reward mechanism with strong incentive\nproperties applicable in a wide variety of such settings. This mechanism has a\nsimple and intuitive output agreement structure: an agent gets a reward only if\nher response for an evaluation matches that of her peer. But instead of the\nreward being the same across different answers, it is inversely proportional to\na popularity index of each answer. This index is a second order population\nstatistic that captures how frequently two agents performing the same\nevaluation agree on the particular answer. Rare agreements thus earn a higher\nreward than agreements that are relatively more common.\n  In the regime where there are a large number of evaluation tasks, we show\nthat truthful behavior is a strict Bayes-Nash equilibrium of the game induced\nby the mechanism. Further, we show that the truthful equilibrium is\napproximately optimal in terms of expected payoffs to the agents across all\nsymmetric equilibria, where the approximation error vanishes in the number of\nevaluation tasks. Moreover, under a mild condition on strategy space, we show\nthat any symmetric equilibrium that gives a higher expected payoff than the\ntruthful equilibrium must be close to being fully informative if the number of\nevaluations is large. These last two results are driven by a new notion of an\nagreement measure that is shown to be monotonic in information loss. This\nnotion and its properties are of independent interest.", "1507.07091": "The Wiretap Channel with Generalized Feedback: Secure Communication and\n  Key Generation,Bassi, Germ\u00e1nPiantanida, PabloShamai, Shlomo,Computer Science - Information Theory,It is a well-known fact that feedback does not increase the capacity of\npoint-to-point memoryless channels, however, its effect in secure\ncommunications is not fully understood yet. In this work, an achievable scheme\nfor the wiretap channel with generalized feedback is presented. This scheme,\nwhich uses the feedback signal to generate a shared secret key between the\nlegitimate users, encrypts the message to be sent at the bit level. New\ncapacity results for a class of channels are provided, as well as some new\ninsights into the secret key agreement problem. Moreover, this scheme recovers\npreviously reported rate regions from the literature, and thus it can be seen\nas a generalization that unifies several results in the field.Comment: 20 pages, 3 figures. Submitted to IEEE Transactions on Information\n  Theory (accepted version)", "1507.07402": "Partial resampling to approximate covering integer programs,Chen, AntaresHarris, David G.Srinivasan, Aravind,Computer Science - Data Structures and AlgorithmsComputer Science - Discrete Mathematics,We consider column-sparse covering integer programs, a generalization of set\ncover, which have attracted a long line of research developing (randomized)\napproximation algorithms. We develop a new rounding scheme based on the Partial\nResampling variant of the Lov\\'{a}sz Local Lemma developed by Harris &\nSrinivasan (2013).\n  This achieves an approximation ratio of $1 + \\frac{\\ln\n(\\Delta_1+1)}{a_{\\text{min}}} + O\\Big( \\log(1 + \\sqrt{ \\frac{\\log\n(\\Delta_1+1)}{a_{\\text{min}}}}) \\Big)$, where $a_{\\text{min}}$ is the minimum\ncovering constraint and $\\Delta_1$ is the maximum $\\ell_1$-norm of any column\nof the covering matrix (whose entries are scaled to lie in $[0,1]$). When there\nare additional constraints on the sizes of the variables, we show an\napproximation ratio of $\\ln \\Delta_0 + O(\\log \\log \\Delta_0)$ (where $\\Delta_0$\nis the maximum number of non-zero entries in any column of the covering\nmatrix). We also show nearly-matching inapproximability and integrality-gap\nlower bounds. These results improve asymptotically, in several different ways,\nover results shown by Srinivasan (2006) and Kolliopoulos & Young (2005).\n  We show also that the rounding process leads to negative correlation among\nthe variables. This allows us to automatically handle multi-criteria programs,\nefficiently achieving approximation ratios which are essentially equivalent to\nthe single-criterion case and apply even when the number of criteria is large.", "1507.07583": "Mapping Auto-context Decision Forests to Deep ConvNets for Semantic\n  Segmentation,Richmond, David L.Kainmueller, DagmarYang, Michael Y.Myers, Eugene W.Rother, Carsten,Computer Science - Computer Vision and Pattern Recognition,We consider the task of pixel-wise semantic segmentation given a small set of\nlabeled training images. Among two of the most popular techniques to address\nthis task are Decision Forests (DF) and Neural Networks (NN). In this work, we\nexplore the relationship between two special forms of these techniques: stacked\nDFs (namely Auto-context) and deep Convolutional Neural Networks (ConvNet). Our\nmain contribution is to show that Auto-context can be mapped to a deep ConvNet\nwith novel architecture, and thereby trained end-to-end. This mapping can be\nused as an initialization of a deep ConvNet, enabling training even in the face\nof very limited amounts of training data. We also demonstrate an approximate\nmapping back from the refined ConvNet to a second stacked DF, with improved\nperformance over the original. We experimentally verify that these mappings\noutperform stacked DFs for two different applications in computer vision and\nbiology: Kinect-based body part labeling from depth images, and somite\nsegmentation in microscopy images of developing zebrafish. Finally, we revisit\nthe core mapping from a Decision Tree (DT) to a NN, and show that it is also\npossible to map a fuzzy DT, with sigmoidal split decisions, to a NN. This\naddresses multiple limitations of the previous mapping, and yields new insights\ninto the popular Rectified Linear Unit (ReLU), and more recently proposed\nconcatenated ReLU (CReLU), activation functions.", "1507.07622": "Fully-Online Suffix Tree and Directed Acyclic Word Graph Construction\n  for Multiple Texts,Takagi, TakuyaInenaga, ShunsukeArimura, HirokiBreslauer, DanyHendrian, Diptarama,Computer Science - Data Structures and Algorithms,We consider construction of the suffix tree and the directed acyclic word\ngraph (DAWG) indexing data structures for a collection $\\mathcal{T}$ of texts,\nwhere a new symbol may be appended to any text in $\\mathcal{T} = \\{T_1, \\ldots,\nT_K\\}$, at any time. This fully-online scenario, which arises in dynamically\nindexing multi-sensor data, is a natural generalization of the long solved\nsemi-online text indexing problem, where texts $T_1, \\ldots, T_{k}$ are\npermanently fixed before the next text $T_{k+1}$ is processed for each $1 \\leq\nk < K$. We present fully-online algorithms that construct the suffix tree and\nthe DAWG for $\\mathcal{T}$ in $O(N \\log \\sigma)$ time and $O(N)$ space, where\n$N$ is the total lengths of the strings in $\\mathcal{T}$ and $\\sigma$ is their\nalphabet size. The standard explicit representation of the suffix tree leaf\nedges and some DAWG edges must be relaxed in our fully-online scenario, since\ntoo many updates on these edges are required in the worst case. Instead, we\nprovide access to the updated suffix tree leaf edge labels and the DAWG edges\nto be redirected via auxiliary data structures, in $O(\\log \\sigma)$ time per\nadded character.Comment: 28 pages, 6 figures, LaTeX", "1507.07855": "Generalized Twisted Gabidulin Codes,Lunardon, GuglielmoTrombetti, RoccoZhou, Yue,Mathematics - CombinatoricsComputer Science - Information Theory,Let $\\mathcal{C}$ be a set of $m$ by $n$ matrices over $\\mathbb{F}_q$ such\nthat the rank of $A-B$ is at least $d$ for all distinct $A,B\\in \\mathcal{C}$.\nSuppose that $m\\leqslant n$. If $\\#\\mathcal{C}= q^{n(m-d+1)}$, then\n$\\mathcal{C}$ is a maximum rank distance (MRD for short) code. Until 2016,\nthere were only two known constructions of MRD codes for arbitrary $1<d<m-1$.\nOne was found by Delsarte (1978) and Gabidulin (1985) independently, and it was\nlater generalized by Kshevetskiy and Gabidulin (2005). We often call them\n(generalized) Gabidulin codes. Another family was recently obtained by Sheekey\n(2016), and its elements are called twisted Gabidulin codes. In the same paper,\nSheekey also proposed a generalization of the twisted Gabidulin codes. However\nthe equivalence problem for it is not considered, whence it is not clear\nwhether there exist new MRD codes in this generalization. We call the members\nof this putative larger family generalized twisted Gabidulin codes. In this\npaper, we first compute the Delsarte duals and adjoint codes of them, then we\ncompletely determine the equivalence between different generalized twisted\nGabidulin codes. In particular, it can be proven that, up to equivalence,\ngeneralized Gabidulin codes and twisted Gabidulin codes are both proper subsets\nof this family.Comment: One missing case (n=4) has been included in the appendix. Typos are\n  corrected, Journal of Combinatorial Theory, Series A, 2018", "1507.08861": "Mobile Multi-View Object Image Search,Calisir, FatihBastan, MuhammetUlusoy, OzgurGudukbay, Ugur,Computer Science - MultimediaComputer Science - Computer Vision and Pattern Recognition,High user interaction capability of mobile devices can help improve the\naccuracy of mobile visual search systems. At query time, it is possible to\ncapture multiple views of an object from different viewing angles and at\ndifferent scales with the mobile device camera to obtain richer information\nabout the object compared to a single view and hence return more accurate\nresults. Motivated by this, we developed a mobile multi-view object image\nsearch system, using a client-server architecture. Multi-view images of objects\nacquired by the mobile clients are processed and local features are sent to the\nserver, which combines the query image representations with early/late fusion\nmethods based on bag-of-visual-words and sends back the query results. We\nperformed a comprehensive analysis of early and late fusion approaches using\nvarious similarity functions, on an existing single view and a new multi-view\nobject image database. The experimental results show that multi-view search\nprovides significantly better retrieval accuracy compared to single view\nsearch.Comment: Multimedia Tools and Applications, 2017", "1508.00217": "Indexing of CNN Features for Large Scale Image Search,Liu, RuoyuZhao, YaoWei, ShikuiYang, Yi,Computer Science - Computer Vision and Pattern Recognition,The convolutional neural network (CNN) features can give a good description\nof image content, which usually represent images with unique global vectors.\nAlthough they are compact compared to local descriptors, they still cannot\nefficiently deal with large-scale image retrieval due to the cost of the linear\nincremental computation and storage. To address this issue, we build a simple\nbut effective indexing framework based on inverted table, which significantly\ndecreases both the search time and memory usage. In addition, several\nstrategies are fully investigated under an indexing framework to adapt it to\nCNN features and compensate for quantization errors. First, we use multiple\nassignment for the query and database images to increase the probability of\nrelevant images' co-existing in the same Voronoi cells obtained via the\nclustering algorithm. Then, we introduce embedding codes to further improve\nprecision by removing false matches during a search. We demonstrate that by\nusing hashing schemes to calculate the embedding codes and by changing the\nranking rule, indexing framework speeds can be greatly improved. Extensive\nexperiments conducted on several unsupervised and supervised benchmarks support\nthese results and the superiority of the proposed indexing framework. We also\nprovide a fair comparison between the popular CNN features.Comment: 21 pages, 9 figures, submitted to Multimedia Tools and Applications", "1508.00315": "Low-rank spectral optimization via gauge duality,Friedlander, Michael P.Macedo, Ives,Mathematics - Optimization and ControlComputer Science - Numerical AnalysisMathematics - Numerical Analysis90C15, 90C25,Various applications in signal processing and machine learning give rise to\nhighly structured spectral optimization problems characterized by low-rank\nsolutions. Two important examples that motivate this work are optimization\nproblems from phase retrieval and from blind deconvolution, which are designed\nto yield rank-1 solutions. An algorithm is described that is based on solving a\ncertain constrained eigenvalue optimization problem that corresponds to the\ngauge dual which, unlike the more typical Lagrange dual, has an especially\nsimple constraint. The dominant cost at each iteration is the computation of\nrightmost eigenpairs of a Hermitian operator. A range of numerical examples\nillustrate the scalability of the approach.Comment: Final version. To appear in SIAM J. Scientific Computing", "1508.00510": "Proving the Turing Universality of Oritatami Co-Transcriptional Folding\n  (Full Text),Geary, CodyMeunier, Pierre-\u00c9tienneSchabanel, NicolasSeki, Shinnosuke,Computer Science - Computational GeometryComputer Science - Computational ComplexityComputer Science - Emerging Technologies,We study the oritatami model for molecular co-transcriptional folding. In\noritatami systems, the transcript (the \"molecule\") folds as it is synthesized\n(transcribed), according to a local energy optimisation process, which is\nsimilar to how actual biomolecules such as RNA fold into complex shapes and\nfunctions as they are transcribed. We prove that there is an oritatami system\nembedding universal computation in the folding process itself.\n  Our result relies on the development of a generic toolbox, which is easily\nreusable for future work to design complex functions in oritatami systems. We\ndevelop \"low-level\" tools that allow to easily spread apart the encoding of\ndifferent \"functions\" in the transcript, even if they are required to be\napplied at the same geometrical location in the folding. We build upon these\nlow-level tools, a programming framework with increasing levels of abstraction,\nfrom encoding of instructions into the transcript to logical analysis. This\nframework is similar to the hardware-to-algorithm levels of abstractions in\nstandard algorithm theory. These various levels of abstractions allow to\nseparate the proof of correctness of the global behavior of our system, from\nthe proof of correctness of its implementation. Thanks to this framework, we\nwere able to computerize the proof of correctness of its implementation and\nproduce certificates, in the form of a relatively small number of proof trees,\ncompact and easily readable and checkable by human, while encapsulating huge\ncase enumerations. We believe this particular type of certificates can be\ngeneralized to other discrete dynamical systems, where proofs involve large\ncase enumerations as well.", "1508.00641": "Episodic Multi-armed Bandits,Tekin, Cemvan der Schaar, Mihaela,Computer Science - Machine LearningStatistics - Machine Learning,We introduce a new class of reinforcement learning methods referred to as\n{\\em episodic multi-armed bandits} (eMAB). In eMAB the learner proceeds in {\\em\nepisodes}, each composed of several {\\em steps}, in which it chooses an action\nand observes a feedback signal. Moreover, in each step, it can take a special\naction, called the $stop$ action, that ends the current episode. After the\n$stop$ action is taken, the learner collects a terminal reward, and observes\nthe costs and terminal rewards associated with each step of the episode. The\ngoal of the learner is to maximize its cumulative gain (i.e., the terminal\nreward minus costs) over all episodes by learning to choose the best sequence\nof actions based on the feedback. First, we define an {\\em oracle} benchmark,\nwhich sequentially selects the actions that maximize the expected immediate\ngain. Then, we propose our online learning algorithm, named {\\em FeedBack\nAdaptive Learning} (FeedBAL), and prove that its regret with respect to the\nbenchmark is bounded with high probability and increases logarithmically in\nexpectation. Moreover, the regret only has polynomial dependence on the number\nof steps, actions and states. eMAB can be used to model applications that\ninvolve humans in the loop, ranging from personalized medical screening to\npersonalized web-based education, where sequences of actions are taken in each\nepisode, and optimal behavior requires adapting the chosen actions based on the\nfeedback.", "1508.00688": "Accelerating R with high performance linear algebra libraries,Oancea, BogdanAndrei, TudorelDragoescu, Raluca Mariana,Computer Science - Mathematical Software68N99H.3.4,Linear algebra routines are basic building blocks for the statistical\nsoftware. In this paper we analyzed how can we can improve R performance for\nmatrix computations. We benchmarked few matrix operations using the standard\nlinear algebra libraries included in the R distribution and high performance\nlibraries like OpenBLAS, GotoBLAS and MKL. Our tests showed the the best\nresults are obtained with the MKL library, the other two libraries having\nsimilar performances, but lower than MKL", "1508.00945": "Structured Prediction: From Gaussian Perturbations to Linear-Time\n  Principled Algorithms,Honorio, JeanJaakkola, Tommi,Statistics - Machine LearningComputer Science - Machine Learning,Margin-based structured prediction commonly uses a maximum loss over all\npossible structured outputs \\cite{Altun03,Collins04b,Taskar03}. In natural\nlanguage processing, recent work \\cite{Zhang14,Zhang15} has proposed the use of\nthe maximum loss over random structured outputs sampled independently from some\nproposal distribution. This method is linear-time in the number of random\nstructured outputs and trivially parallelizable. We study this family of loss\nfunctions in the PAC-Bayes framework under Gaussian perturbations\n\\cite{McAllester07}. Under some technical conditions and up to statistical\naccuracy, we show that this family of loss functions produces a tighter upper\nbound of the Gibbs decoder distortion than commonly used methods. Thus, using\nthe maximum loss over random structured outputs is a principled way of learning\nthe parameter of structured prediction models. Besides explaining the\nexperimental success of \\cite{Zhang14,Zhang15}, our theoretical results show\nthat more general techniques are possible.Comment: Uncertainty in Artificial Intelligence (UAI) 2016", "1508.01014": "Computational complexity of distance edge labeling,Knop, Du\u0161anMasa\u0159\u00edk, Tom\u00e1\u0161,Computer Science - Discrete MathematicsComputer Science - Computational ComplexityG.2.2F.2.2,The problem of Distance Edge Labeling is a variant of Distance Vertex\nLabeling (also known as $L_{2,1}$ labeling) that has been studied for more than\ntwenty years and has many applications, such as frequency assignment.\n  The Distance Edge Labeling problem asks whether the edges of a given graph\ncan be labeled such that the labels of adjacent edges differ by at least two\nand the labels of edges of distance two differ by at least one. Labels are\nchosen from the set $\\{0,1,\\dots,\\lambda\\}$ for $\\lambda$ fixed.\n  We present a full classification of its computational complexity - a\ndichotomy between the polynomially solvable cases and the remaining cases which\nare NP-complete. We characterise graphs with $\\lambda \\le 4$ which leads to a\npolynomial-time algorithm recognizing the class and we show NP-completeness for\n$\\lambda \\ge 5$ by several reductions from Monotone Not All Equal 3-SAT.Comment: 21 pages, IWOCA 2015", "1508.01059": "Offline and Online Models of Budget Allocation for Maximizing Influence\n  Spread,Avigdor-Elgrabli, NoaBlocq, GideonGamzu, IftahOrda, Ariel,Computer Science - Data Structures and AlgorithmsComputer Science - Computer Science and Game TheoryComputer Science - Social and Information Networks,The research of influence propagation in social networks via word-of-mouth\nprocesses has been given considerable attention in recent years. Arguably, the\nmost fundamental problem in this domain is influence maximization, where the\ngoal is to identify a seed set of individuals that can trigger a large cascade\nof influence in the network. While there has been significant progress\nregarding this problem and its variants, one basic shortcoming of the models is\nthat they lack the flexibility in the way the budget is allocated to\nindividuals. Indeed, budget allocation is a critical issue in advertising and\nviral marketing. Taking the other point of view, known models allowing flexible\nbudget allocation do not take into account the influence spread in the network.\nWe introduce a generalized model that captures both budgets and influence\npropagation simultaneously.\n  For the offline setting, we identify a large family of budget-based\npropagation functions that admit tight approximation guarantee. This family\nextends most of the previously studied influence models, including the\nwell-known Triggering model. We establish that any function in this family\nimplies an instance of a monotone submodular function maximization over the\ninteger lattice subject to a knapsack constraint. This problem is known to\nadmit an optimal (1-1/e)-approximation. We also study the price of anarchy of\nthe multi-player game that extends the model and establish tight results.\n  For the online setting, in which an unknown subset of agents arrive in a\nrandom order and the algorithm needs to make an irrevocable budget allocation\nin each step, we develop a 1/(15e)-competitive algorithm. This setting extends\nthe secretary problem, and its variant, the submodular knapsack secretary\nproblem. Notably, our algorithm improves over the best known approximation for\nthe latter problem, even though it applies to a more general setting.", "1508.01775": "Cascading Power Outages Propagate Locally in an Influence Graph that is\n  not the Actual Grid Topology,Hines, Paul D. H.Dobson, IanRezaei, Pooya,Physics - Physics and SocietyComputer Science - Systems and Control,In a cascading power transmission outage, component outages propagate\nnon-locally, after one component outages, the next failure may be very distant,\nboth topologically and geographically. As a result, simple models of\ntopological contagion do not accurately represent the propagation of cascades\nin power systems. However, cascading power outages do follow patterns, some of\nwhich are useful in understanding and reducing blackout risk. This paper\ndescribes a method by which the data from many cascading failure simulations\ncan be transformed into a graph-based model of influences that provides\nactionable information about the many ways that cascades propagate in a\nparticular system. The resulting \"influence graph\" model is Markovian, in that\ncomponent outage probabilities depend only on the outages that occurred in the\nprior generation. To validate the model we compare the distribution of cascade\nsizes resulting from $n-2$ contingencies in a $2896$ branch test case to\ncascade sizes in the influence graph. The two distributions are remarkably\nsimilar. In addition, we derive an equation with which one can quickly identify\nmodifications to the proposed system that will substantially reduce cascade\npropagation. With this equation one can quickly identify critical components\nthat can be improved to substantially reduce the risk of large cascading\nblackouts.Comment: Accepted for publication at the IEEE Transactions on Power Systems", "1508.01841": "Hypergraph coloring up to condensation,Ayre, PeterCoja-Oghlan, AminGreenhill, Catherine,Computer Science - Discrete MathematicsMathematics - Combinatorics,Improving a result of Dyer, Frieze and Greenhill [Journal of Combinatorial\nTheory, Series B, 2015], we determine the $q$-colorability threshold in random\n$k$-uniform hypergraphs up to an additive error of $\\ln 2+\\varepsilon_q$, where\n$\\lim_{q\\to\\infty}\\varepsilon_q=0$. The new lower bound on the threshold\nmatches the \"condensation phase transition\" predicted by statistical physics\nconsiderations [Krzakala et al., PNAS 2007].Comment: 31 pages. Revised version, addressing referees' comments", "1508.01950": "Defending Against Stealthy Attacks on Multiple Nodes with Limited\n  Resources: A Game-Theoretic Analysis,Zhang, MingZheng, ZizhanShroff, Ness B.,Computer Science - Computer Science and Game Theory,Stealthy attacks are a major cyber-security threat. In practice, both\nattackers and defenders have resource constraints that could limit their\ncapabilities. Hence, to develop robust defense strategies, a promising approach\nis to utilize game theory to understand the fundamental trade-offs involved.\nPrevious works in this direction, however, mainly focus on the single-node case\nwithout considering strict resource constraints. In this paper, a\ngame-theoretic model for protecting a system of multiple nodes against stealthy\nattacks is proposed. We consider the practical setting where the frequencies of\nboth attack and defense are constrained by limited resources, and an asymmetric\nfeedback structure where the attacker can fully observe the states of nodes\nwhile largely hiding its actions from the defender. We characterize the best\nresponse strategies for both attacker and defender in the space of both\nnon-adaptive and adaptive strategies, and study the Nash Equilibria of the\ngame. We further study a sequential game where the defender first announces its\nstrategy and the attacker then responds accordingly, and design an algorithm\nthat finds a nearly optimal strategy for the defender to commit to.Comment: 17 Pages, updated with the latest journal version", "1508.01993": "Improving Decision Analytics with Deep Learning: The Case of Financial\n  Disclosures,Feuerriegel, StefanFehrer, Ralph,Statistics - Machine LearningComputer Science - Computation and LanguageComputer Science - Machine Learning,Decision analytics commonly focuses on the text mining of financial news\nsources in order to provide managerial decision support and to predict stock\nmarket movements. Existing predictive frameworks almost exclusively apply\ntraditional machine learning methods, whereas recent research indicates that\ntraditional machine learning methods are not sufficiently capable of extracting\nsuitable features and capturing the non-linear nature of complex tasks. As a\nremedy, novel deep learning models aim to overcome this issue by extending\ntraditional neural network models with additional hidden layers. Indeed, deep\nlearning has been shown to outperform traditional methods in terms of\npredictive performance. In this paper, we adapt the novel deep learning\ntechnique to financial decision support. In this instance, we aim to predict\nthe direction of stock movements following financial disclosures. As a result,\nwe show how deep learning can outperform the accuracy of random forests as a\nbenchmark for machine learning by 5.66%.", "1508.02340": "The Pontryagin Maximum Principle for Nonlinear Infinite Horizon Optimal\n  Control Problems with State Constraints,Tauchnitz, Nico,Mathematics - Optimization and ControlComputer Science - Systems and Control34, 46, 49,The famous proof of the Pontryagin maximum principle for control problems on\na finite horizon bases on the needle variation technique, as well as the\nseparability concept of cones created by disturbances of the trajectories. In\nthis preprint, we develop this method for infinite horizon optimal control\nproblems. The results are necessary conditions for a strong local minimizer in\nform of the Pontryagin maximum principle, Arrow type sufficiency conditions and\nthe validity of diverse transversality conditions.Comment: 52 pages, in german, revised", "1508.02521": "Topology Control of wireless sensor network using Quantum Inspired\n  Genetic algorithm,Ullah, SajidWahid, Mussarat,Computer Science - Neural and Evolutionary ComputingComputer Science - Networking and Internet Architecture,In this work, an evolving Linked Quantum register has been introduced, which\nare group vector of binary pair of genes, which in its local proximity\nrepresent those nodes that will have high connectivity and keep the energy\nconsumption at low, and which are taken into account for topology control. The\nregister works in higher dimension. Here order-2 Quantum inspired genetic\nalgorithm has been used and also higher order can be used to achieve greater\nversatility in topology control of nodes. Numerical result has been obtained,\nanalysis is done as how the result has previously been obtained with Quantum\ngenetic algorithm and results are compared too. For future work, factor is\nhinted which would exploit the algorithm to work in more computational\nintensive problem.Comment: 4 Figures/6 pages", "1508.02570": "A Combinatorial Model of Interference in Frequency Hopping Schemes,Nyirenda, Mwawi M.Ng, Siaw-LynnMartin, Keith M.,Computer Science - Information TheoryMathematics - Combinatorics94A05, 94A55, 94B60,In a frequency hopping (FH) scheme users communicate simultaneously using FH\nsequences defined on the same set of frequency channels. An FH sequence\nspecifies the frequency channel to be used as communication progresses. Much of\nthe research on the performance of FH schemes is based on either pairwise\nmutual interference or adversarial interference but not both. In this paper, we\nevaluate the performance of an FH scheme with respect to both group-wise mutual\ninterference and adversarial interference (jamming), bearing in mind that more\nthan two users may be transmitting simultaneously in the presence of a jammer.\nWe establish a correspondence between a cover-free code and an FH scheme. This\ngives a lower bound on the transmission capacity. Furthermore, we specify a\njammer model and consider what additional properties a cover-free code should\nhave to resist the jammer. We demonstrate that a purely combinatorial approach\nis inadequate against such a jammer, but that with the use of pseudorandomness,\nwe can have a system that has high throughput as well as security against\njamming.Comment: 18 pages, submitted to journal", "1508.02759": "Technical Note: Split Algorithm in O(n) for the Capacitated Vehicle\n  Routing Problem,Vidal, Thibaut,Computer Science - Data Structures and Algorithms,The Split algorithm is an essential building block of route-first\ncluster-second heuristics and modern genetic algorithms for vehicle routing\nproblems. The algorithm is used to partition a solution, represented as a giant\ntour without occurrences of the depot, into separate routes with minimum cost.\nAs highlighted by the recent survey of [Prins, Lacomme and Prodhon, Transport\nRes. C (40), 179-200], no less than 70 recent articles use this technique. In\nthe vehicle routing literature, Split is usually assimilated to the search for\na shortest path in a directed acyclic graph $\\mathcal{G}$ and solved in $O(nB)$\nusing Bellman's algorithm, where $n$ is the number of delivery points and $B$\nis the average number of feasible routes that start with a given customer in\nthe giant tour. Some linear-time algorithms are also known for this problem as\na consequence of a Monge property of $\\mathcal{G}$. In this article, we\nhighlight a stronger property of this graph, leading to a simple alternative\nalgorithm in $O(n)$. Experimentally, we observe that the approach is faster\nthan the classical Split for problem instances of practical size. We also\nextend the method to deal with a limited fleet and soft capacity constraints.", "1508.02793": "A generalized Goulden-Jackson cluster method and lattice path\n  enumeration,Zhuang, Yan,Mathematics - CombinatoricsComputer Science - Discrete MathematicsComputer Science - Formal Languages and Automata Theory05A15, 05A05, 05C50, 68R05,The Goulden-Jackson cluster method is a powerful tool for obtaining\ngenerating functions for counting words in a free monoid by occurrences of a\nset of subwords. We introduce a generalization of the cluster method for monoid\nnetworks, which generalize the combinatorial framework of free monoids. As a\nsample application of the generalized cluster method, we compute bivariate and\nmultivariate generating functions counting Motzkin paths---both with height\nbounded and unbounded---by statistics corresponding to the number of\noccurrences of various subwords, yielding both closed-form and continued\nfraction formulae.Comment: 31 pages", "1508.03117": "Optimized Projections for Compressed Sensing via Direct Mutual Coherence\n  Minimization,Lu, CanyiLi, HuanLin, Zhouchen,Computer Science - Information TheoryComputer Science - Machine Learning,Compressed Sensing (CS) is a novel technique for simultaneous signal sampling\nand compression based on the existence of a sparse representation of signal and\na projected dictionary $PD$, where $P\\in\\mathbb{R}^{m\\times d}$ is the\nprojection matrix and $D\\in\\mathbb{R}^{d\\times n}$ is the dictionary. To\nexactly recover the signal with a small number of measurements $m$, the\nprojected dictionary $PD$ is expected to be of low mutual coherence. Several\nprevious methods attempt to find the projection $P$ such that the mutual\ncoherence of $PD$ can be as low as possible. However, they do not minimize the\nmutual coherence directly and thus their methods are far from optimal. Also the\nsolvers they used lack of the convergence guarantee and thus there has no\nguarantee on the quality of their obtained solutions. This work aims to address\nthese issues. We propose to find an optimal projection by minimizing the mutual\ncoherence of $PD$ directly. This leads to a nonconvex nonsmooth minimization\nproblem. We then approximate it by smoothing and solve it by alternate\nminimization. We further prove the convergence of our algorithm. To the best of\nour knowledge, this is the first work which directly minimizes the mutual\ncoherence of the projected dictionary with a convergence guarantee. Numerical\nexperiments demonstrate that the proposed method can recover sparse signals\nbetter than existing methods.", "1508.03263": "Logic Programming with Macro Connectives,Kwon, Keehang,Computer Science - Programming Languages,Logic programming such as Prolog is often sequential and slow because each\nexecution step processes only a single, $micro$ connective. To fix this\nproblem, we propose to use $macro$ connectives as the means of improving both\nreadability and performance.Comment: 6 pages, some new connectives are added to version 3", "1508.03269": "A New Approach to an Old Problem: The Reconstruction of a Go Game\n  through a Series of Photographs,Corsolini, MarioCarta, Andrea,Computer Science - Computer Vision and Pattern RecognitionI.2.10I.4.8I.5.5,Given a series of photographs taken during a Go game, we describe the\ntechniques we successfully employ for pinpointing the grid lines of the Go\nboard and for tracking their small movements between consecutive photographs;\nthen we discuss how to approximate the location and orientation of the\nobserver's point of view, in order to compensate for projection effects.\nFinally we describe the different criteria that jointly form the algorithm for\nstones' detection, thus enabling us to automatically reconstruct the whole move\nsequence.Comment: 13 pages, 18 figures, datasets available from\n  http://www.oipaz.net/VideoKifu.html - added references in section 1, updated\n  addresses, added indication that both authors contributed equally", "1508.03401": "Binary Compressive Sensing via Analog Fountain Coding,Shirvanimoghaddam, MahyarLi, YonghuiVucetic, BrankaYuan, Jinhong,Computer Science - Information Theory,In this paper, a compressive sensing (CS) approach is proposed for sparse\nbinary signals' compression and reconstruction based on analog fountain codes\n(AFCs). In the proposed scheme, referred to as the analog fountain compressive\nsensing (AFCS), each measurement is generated from a linear combination of L\nrandomly selected binary signal elements with real weight coefficients. The\nweight coefficients are chosen from a finite weight set and L, called\nmeasurement degree, is obtained based on a predefined degree distribution\nfunction. We propose a simple verification based reconstruction algorithm for\nthe AFCS in the noiseless case. The proposed verification based decoder is\nanalyzed through SUM-OR tree analytical approach and an optimization problem is\nformulated to find the optimum measurement degree to minimize the number of\nmeasurements required for the reconstruction of binary sparse signals. We show\nthat in the AFCS, the number of required measurements is of O(-n log(1-k/n)),\nwhere n is the signal length and k is the signal sparsity level. We then\nconsider the signal reconstruction of AFCS in the presence of additive white\nGaussian noise (AWGN) and the standard message passing decoder is then used for\nthe signal recovery. Simulation results show that the AFCS can perfectly\nrecover all non-zero elements of the sparse binary signal with a significantly\nreduced number of measurements, compared to the conventional binary CS and\nL1-minimization approaches in a wide range of signal to noise ratios (SNRs).\nFinally, we show a practical application of the AFCS for the sparse event\ndetection in wireless sensor networks (WSNs), where the sensors' readings can\nbe treated as measurements from the CS point of view.Comment: The paper is accepted to publish in IEEE Transactions on Signal\n  Processing", "1508.03773": "No acute tetrahedron is an 8-reptile,Haverkort, Herman,Computer Science - Computational GeometryMathematics - Metric Geometry,An $r$-gentiling is a dissection of a shape into $r \\geq 2$ parts which are\nall similar to the original shape. An $r$-reptiling is an $r$-gentiling of\nwhich all parts are mutually congruent. This article shows that no acute\ntetrahedron is an $r$-gentile or $r$-reptile for any $r < 9$, by showing that\nno acute spherical diangle can be dissected into less than nine acute spherical\ntriangles.Comment: updated text, as in press with Discrete Mathematics, Discrete\n  Mathematics Available online 10 November 2017", "1508.03837": "Incorporating User Interaction into Imperative Languages,Kwon, Keehang,Computer Science - Programming Languages,In this paper, we present two new forms of the $write$ statement: one of the\nform $write(x);G$ where $G$ is a statement and the other of the form\n$write(x);D$ where $D$ is a module. The former is a generalization of\ntraditional $write$ statement and is quite useful. The latter is useful for\nimplementing interactive modules.Comment: 6 pages. arXiv admin note: text overlap with arXiv:1709.08193", "1508.03878": "A Pessimistic Approximation for the Fisher Information Measure,Stein, ManuelNossek, Josef A.,Computer Science - Information TheoryElectrical Engineering and Systems Science - Signal Processing,The problem of determining the intrinsic quality of a signal processing\nsystem with respect to the inference of an unknown deterministic parameter\n$\\theta$ is considered. While the Fisher information measure $F(\\theta)$ forms\na classical tool for such a problem, direct computation of the information\nmeasure can become difficult in various situations. For the estimation\ntheoretic performance analysis of nonlinear measurement systems, the form of\nthe likelihood function can make the calculation of the information measure\n$F(\\theta)$ challenging. In situations where no closed-form expression of the\nstatistical system model is available, the analytical derivation of $F(\\theta)$\nis not possible at all. Based on the Cauchy-Schwarz inequality, we derive an\nalternative information measure $S(\\theta)$. It provides a lower bound on the\nFisher information $F(\\theta)$ and has the property of being evaluated with the\nmean, the variance, the skewness and the kurtosis of the system model at hand.\nThese entities usually exhibit good mathematical tractability or can be\ndetermined at low-complexity by real-world measurements in a calibrated setup.\nWith various examples, we show that $S(\\theta)$ provides a good conservative\napproximation for $F(\\theta)$ and outline different estimation theoretic\nproblems where the presented information bound turns out to be useful.", "1508.03891": "REBA: A Refinement-Based Architecture for Knowledge Representation and\n  Reasoning in Robotics,Sridharan, MohanGelfond, MichaelZhang, ShiqiWyatt, Jeremy,Computer Science - RoboticsComputer Science - Artificial IntelligenceComputer Science - Logic in Computer Science,This paper describes an architecture for robots that combines the\ncomplementary strengths of probabilistic graphical models and declarative\nprogramming to represent and reason with logic-based and probabilistic\ndescriptions of uncertainty and domain knowledge. An action language is\nextended to support non-boolean fluents and non-deterministic causal laws. This\naction language is used to describe tightly-coupled transition diagrams at two\nlevels of granularity, with a fine-resolution transition diagram defined as a\nrefinement of a coarse-resolution transition diagram of the domain. The\ncoarse-resolution system description, and a history that includes (prioritized)\ndefaults, are translated into an Answer Set Prolog (ASP) program. For any given\ngoal, inference in the ASP program provides a plan of abstract actions. To\nimplement each such abstract action, the robot automatically zooms to the part\nof the fine-resolution transition diagram relevant to this action. A\nprobabilistic representation of the uncertainty in sensing and actuation is\nthen included in this zoomed fine-resolution system description, and used to\nconstruct a partially observable Markov decision process (POMDP). The policy\nobtained by solving the POMDP is invoked repeatedly to implement the abstract\naction as a sequence of concrete actions, with the corresponding observations\nbeing recorded in the coarse-resolution history and used for subsequent\nreasoning. The architecture is evaluated in simulation and on a mobile robot\nmoving objects in an indoor domain, to show that it supports reasoning with\nviolation of defaults, noisy observations and unreliable actions, in complex\ndomains.Comment: 72 pages, 14 figures", "1508.04095": "Algorithmic Aspects of Optimal Channel Coding,Barman, SiddharthFawzi, Omar,Computer Science - Information TheoryComputer Science - Data Structures and AlgorithmsQuantum Physics,A central question in information theory is to determine the maximum success\nprobability that can be achieved in sending a fixed number of messages over a\nnoisy channel. This was first studied in the pioneering work of Shannon who\nestablished a simple expression characterizing this quantity in the limit of\nmultiple independent uses of the channel. Here we consider the general setting\nwith only one use of the channel. We observe that the maximum success\nprobability can be expressed as the maximum value of a submodular function.\nUsing this connection, we establish the following results:\n  1. There is a simple greedy polynomial-time algorithm that computes a code\nachieving a (1-1/e)-approximation of the maximum success probability. Moreover,\nfor this problem it is NP-hard to obtain an approximation ratio strictly better\nthan (1-1/e).\n  2. Shared quantum entanglement between the sender and the receiver can\nincrease the success probability by a factor of at most 1/(1-1/e). In addition,\nthis factor is tight if one allows an arbitrary non-signaling box between the\nsender and the receiver.\n  3. We give tight bounds on the one-shot performance of the meta-converse of\nPolyanskiy-Poor-Verdu.Comment: v2: 16 pages. Added alternate proof of main result with random coding", "1508.04417": "Social Influence in the Concurrent Diffusion of Information and\n  Behaviors in Online Social Networks,Zhao, KangWang, ShiyaoVasi, Ion B.Zhang, Qi,Computer Science - Social and Information NetworksPhysics - Physics and Society,The emergence of online social networks has greatly facilitated the diffusion\nof information and behaviors. While the two diffusion processes are often\nintertwined, \"talking the talk\" does not necessarily mean \"walking the\ntalk\"--those who share information about an action may not actually participate\nin it. We do not know if the diffusion of information and behaviors are\nsimilar, or if social influence plays an equally important role in these\nprocesses. Integrating text mining, social network analyses, and survival\nanalysis, this research examines the concurrent spread of information and\nbehaviors related to the Ice Bucket Challenge on Twitter. We show that the two\nprocesses follow different patterns. Unilateral social influence contributes to\nthe diffusion of information, but not to the diffusion of behaviors; bilateral\ninfluence conveyed via the communication process is a significant and positive\npredictor of the diffusion of behaviors, but not of information. These results\nhave implications for theories of social influence, social networks, and\ncontagion.", "1508.04596": "Large scale three-dimensional topology optimisation of heat sinks cooled\n  by natural convection,Alexandersen, JoeSigmund, OleAage, Niels,Physics - Fluid DynamicsComputer Science - Computational Engineering, Finance, and Science,This work presents the application of density-based topology optimisation to\nthe design of three-dimensional heat sinks cooled by natural convection. The\ngoverning equations are the steady-state incompressible Navier-Stokes equations\ncoupled to the thermal convection-diffusion equation through the Bousinessq\napproximation. The fully coupled non-linear multiphysics system is solved using\nstabilised trilinear equal-order finite elements in a parallel framework\nallowing for the optimisation of large scale problems with order of 40-330\nmillion state degrees of freedom. The flow is assumed to be laminar and several\noptimised designs are presented for Grashof numbers between $10^3$ and $10^6$.\nInterestingly, it is observed that the number of branches in the optimised\ndesign increases with increasing Grashof numbers, which is opposite to\ntwo-dimensional optimised designs.Comment: Submitted (18th of August 2015)", "1508.04606": "Distributed Event-Triggered Control for Asymptotic Synchronization of\n  Dynamical Networks,Liu, TaoCao, MingDe Persis, ClaudioHendrickx, Julien M.,Computer Science - Systems and ControlComputer Science - Multiagent SystemsMathematics - Dynamical Systems,This paper studies synchronization of dynamical networks with event-based\ncommunication. Firstly, two estimators are introduced into each node, one to\nestimate its own state, and the other to estimate the average state of its\nneighbours. Then, with these two estimators, a distributed event-triggering\nrule (ETR) with a dwell time is designed such that the network achieves\nsynchronization asymptotically with no Zeno behaviours. The designed ETR only\ndepends on the information that each node can obtain, and thus can be\nimplemented in a decentralized way.Comment: 8 pages, 2 figues, 1 table", "1508.04720": "Quickest Detection for Changes in Maximal kNN Coherence of Random\n  Matrices,Banerjee, TaposhFirouzi, HamedHero III, Alfred O.,Mathematics - Statistics TheoryComputer Science - Information TheoryMathematics - Probability,This paper addresses the problem of quickest detection of a change in the\nmaximal coherence between columns of a $n\\times p$ random matrix based on a\nsequence of matrix observations having a single unknown change point. The\nrandom matrix is assumed to have identically distributed rows and the maximal\ncoherence is defined as the largest of the $p \\choose 2$ correlation\ncoefficients associated with any row. Likewise, the $k$ nearest neighbor (kNN)\ncoherence is defined as the $k$-th largest of these correlation coefficients.\nThe forms of the pre- and post-change distributions of the observed matrices\nare assumed to belong to the family of elliptically contoured densities with\nsparse dispersion matrices but are otherwise unknown. A non-parametric stopping\nrule is proposed that is based on the maximal k-nearest neighbor sample\ncoherence between columns of each observed random matrix. This is a summary\nstatistic that is related to a test of the existence of a hub vertex in a\nsample correlation graph having a degree at least $k$. Performance bounds on\nthe delay and false alarm performance of the proposed stopping rule are\nobtained in the purely high dimensional regime where $p\\rightarrow \\infty$ and\n$n$ is fixed. When the pre-change dispersion matrix is diagonal it is shown\nthat, among all functions of the proposed summary statistic, the proposed\nstopping rule is asymptotically optimal under a minimax quickest change\ndetection (QCD) model as the stopping threshold approaches infinity. The theory\ndeveloped also applies to sequential hypothesis testing and fixed sample size\ntests.Comment: Submitted", "1508.05117": "The backtracking survey propagation algorithm for solving random K-SAT\n  problems,Marino, RaffaeleParisi, GiorgioRicci-Tersenghi, Federico,Computer Science - Computational ComplexityComputer Science - Artificial IntelligenceComputer Science - Data Structures and Algorithms,Discrete combinatorial optimization has a central role in many scientific\ndisciplines, however, for hard problems we lack linear time algorithms that\nwould allow us to solve very large instances. Moreover, it is still unclear\nwhat are the key features that make a discrete combinatorial optimization\nproblem hard to solve. Here we study random K-satisfiability problems with\n$K=3,4$, which are known to be very hard close to the SAT-UNSAT threshold,\nwhere problems stop having solutions. We show that the backtracking survey\npropagation algorithm, in a time practically linear in the problem size, is\nable to find solutions very close to the threshold, in a region unreachable by\nany other algorithm. All solutions found have no frozen variables, thus\nsupporting the conjecture that only unfrozen solutions can be found in linear\ntime, and that a problem becomes impossible to solve in linear time when all\nsolutions contain frozen variables.Comment: 11 pages, 10 figures. v2: data largely improved and manuscript\n  rewritten", "1508.05232": "Variable-mixing parameter quantized kernel robust mixed-norm algorithms\n  for combating impulsive interference,Lu, LuZhao, HaiquanChen, Badong,Computer Science - Systems and Control,Although the kernel robust mixed-norm (KRMN) algorithm outperforms the kernel\nleast mean square (KLMS) algorithm in impulsive noise, it still has two major\nproblems as follows: (1) The choice of the mixing parameter in the KRMN is\ncrucial to obtain satisfactory performance. (2) The structure of the KRMN\nalgorithm grows linearly as the iteration goes on, thus it has high\ncomputational complexity and memory requirements. To solve the parameter\nselection problem, two variable-mixing parameter KRMN (VPKRMN) algorithms are\ndeveloped in this paper. Moreover, a sparsification algorithm, quantized VPKRMN\n(QVPKRMN) algorithm is introduced for nonlinear system identification with\nimpulsive interferences. The energy conservation relation (ECR) and convergence\nproperty of the QVPKRMN algorithm are analyzed. Simulation results in the\ncontext of nonlinear system identification under impulsive interference\ndemonstrate the superior performance of the proposed VPKRMN and QVPKRMN\nalgorithms as compared with the existing algorithms.Comment: 23 pages, 10 figures", "1508.05465": "A representation of antimatroids by Horn rules and its application to\n  educational systems,Yoshikawa, HiyoriHirai, HiroshiMakino, Kazuhisa,Mathematics - CombinatoricsComputer Science - Logic in Computer Science,We study a representation of an antimatroid by Horn rules, motivated by its\nrecent application to computer-aided educational systems. We associate any set\n$\\mathcal{R}$ of Horn rules with the unique maximal antimatroid\n$\\mathcal{A}(\\mathcal{R})$ that is contained in the union-closed family\n$\\mathcal{K}(\\mathcal{R})$ naturally determined by ${\\cal R}$. We address\nalgorithmic and Boolean function theoretic aspects on the association ${\\cal R}\n\\mapsto \\mathcal{A}(\\mathcal{R})$, where ${\\cal R}$ is viewed as the input. We\npresent linear time algorithms to solve the membership problem and the\ninference problem for ${\\cal A}({\\cal R})$. We also provide efficient\nalgorithms for generating all members and all implicates of ${\\cal A}({\\cal\nR})$. We show that this representation is essentially equivalent to the\nKorte-Lov\\'{a}sz representation of antimatroids by rooted sets. Based on the\nequivalence, we provide a quadratic time algorithm to construct the\nuniquely-determined minimal representation. % These results have potential\napplications to computer-aided educational systems, where an antimatroid is\nused as a model of the space of possible knowledge states of learners, and is\nconstructed by giving Horn queries to a human expert.Comment: Major revision; including references/connections on implicational\n  systems and updating experiments; Version 3 (final) to appear in Journal of\n  Mathematical Psychology; Version 4 (fixing an error in Example 2.1)", "1508.05559": "Structured Interactive Music Scores,Toro, Mauricio,Computer Science - Logic in Computer ScienceD.1.6F.4.1,Interactive Scores is a formalism for the design and performance of\ninteractive scenarios that provides temporal relations (TRs) among the objects\nof the scenario. We can model TRs among objects in Time Stream Petri nets, but\nit is difficult to represent global constraints. This can be done explicitly in\nthe Non-deterministic Timed Concurrent Constraint (ntcc) calculus. We want to\nformalize a heterogeneous system that controls in one subsystem the concurrent\nexecution of the objects using ntcc, and audio and video processing in the\nother. We also plan to develop an automatic verifier for ntcc.", "1508.05766": "$n$-permutability and linear Datalog implies symmetric Datalog,Kazda, Alexandr,Computer Science - Computational Complexity68Q17, 68R05, 03C05,We show that if $\\mathbb A$ is a core relational structure such that\nCSP($\\mathbb A$) can be solved by a linear Datalog program, and $\\mathbb A$ is\n$n$-permutable for some $n$, then CSP($\\mathbb A$) can be solved by a symmetric\nDatalog program (and thus CSP($\\mathbb A$) lies in deterministic logspace). At\nthe moment, it is not known for which structures $\\mathbb A$ will CSP($\\mathbb\nA$) be solvable by a linear Datalog program. However, once somebody obtains a\ncharacterization of linear Datalog, our result immediately gives a\ncharacterization of symmetric Datalog.", "1508.06269": "A systematic process for evaluating structured perfect Bayesian\n  equilibria in dynamic games with asymmetric information,Vasal, DeepanshuSinha, AbhinavAnastasopoulos, Achilleas,Mathematics - Optimization and ControlComputer Science - Computer Science and Game TheoryComputer Science - Systems and Control,We consider finite-horizon and infinite-horizon versions of a dynamic game\nwith $N$ selfish players who observe their types privately and take actions\nthat are publicly observed. Players' types evolve as conditionally independent\nMarkov processes, conditioned on their current actions. Their actions and types\njointly determine their instantaneous rewards. In dynamic games with asymmetric\ninformation, a widely used concept of equilibrium is perfect Bayesian\nequilibrium (PBE), which consists of a strategy and belief pair that\nsimultaneously satisfy sequential rationality and belief consistency. In\ngeneral, there does not exist a universal algorithm that decouples the\ninterdependence of strategies and beliefs over time in calculating PBE. In this\npaper, for the finite-horizon game with independent types we develop a two-step\nbackward-forward recursive algorithm that sequentially decomposes the problem\n(w.r.t. time) to obtain a subset of PBEs, which we refer to as structured\nBayesian perfect equilibria (SPBE). In such equilibria, a player's strategy\ndepends on its history only through a common public belief and its current\nprivate type. The backward recursive part of this algorithm defines an\nequilibrium generating function. Each period in the backward recursion involves\nsolving a fixed-point equation on the space of probability simplexes for every\npossible belief on types. Using this function, equilibrium strategies and\nbeliefs are generated through a forward recursion. We then extend this\nmethodology to the infinite-horizon model, where we propose a time-invariant\nsingle-shot fixed-point equation, which in conjunction with a forward recursive\nstep, generates the SPBE. Sufficient conditions for the existence of SPBE are\nprovided. With our proposed method, we find equilibria that exhibit signaling\nbehavior. This is illustrated with the help of a concrete public goods example.Comment: 36 pages, 3 figures, IEEE Transactions on Automatic Control, vol. PP,\n  no. 99, pp. 1-1, 2018", "1508.06464": "SPF-CellTracker: Tracking multiple cells with strongly-correlated moves\n  using a spatial particle filter,Hirose, OsamuKawaguchi, ShotaroTokunaga, TerumasaToyoshima, YuTeramoto, TakayukiKuge, SayuriIshihara, TakeshiIino, YuichiYoshida, Ryo,Computer Science - Computer Vision and Pattern Recognition,Tracking many cells in time-lapse 3D image sequences is an important\nchallenging task of bioimage informatics. Motivated by a study of brain-wide 4D\nimaging of neural activity in C. elegans, we present a new method of multi-cell\ntracking. Data types to which the method is applicable are characterized as\nfollows: (i) cells are imaged as globular-like objects, (ii) it is difficult to\ndistinguish cells based only on shape and size, (iii) the number of imaged\ncells ranges in several hundreds, (iv) moves of nearly-located cells are\nstrongly correlated and (v) cells do not divide. We developed a tracking\nsoftware suite which we call SPF-CellTracker. Incorporating dependency on\ncells' moves into prediction model is the key to reduce the tracking errors:\ncell-switching and coalescence of tracked positions. We model target cells'\ncorrelated moves as a Markov random field and we also derive a fast computation\nalgorithm, which we call spatial particle filter. With the live-imaging data of\nnuclei of C. elegans neurons in which approximately 120 nuclei of neurons are\nimaged, we demonstrate an advantage of the proposed method over the standard\nparticle filter and a method developed by Tokunaga et al. (2014).Comment: 14 pages, 6 figures", "1508.06589": "Cooperative Spectrum Sharing Relaying Protocols With Energy Harvesting\n  Cognitive User,Kalluri, TarunPeer, MansiBohara, Vivek Ashokda Costa, Daniel B.Dias, Ugo S.,Computer Science - Networking and Internet ArchitectureComputer Science - Information Theory,The theory of wireless information and power transfer in energy constrained\nwireless networks has caught the interest of researchers due to its potential\nin increasing the lifetime of sensor nodes and mitigate the environment hazards\ncaused by conventional cell batteries. Similarly, the advancements in areas of\ncooperative spectrum sharing protocols has enabled efficient use of frequency\nspectrum between a licensed primary user and a secondary user. In this paper,\nwe consider an energy constrained secondary user which harvests energy from the\nprimary signal and relays the primary signal in exchange for the spectrum\naccess. We consider Nakagami-m fading model and propose two key protocols,\nnamely time-splitting cooperative spectrum sharing (TS-CSS) and power-sharing\ncooperative spectrum sharing (PS-CSS), and derive expressions for the outage\nprobabilities of the primary and secondary user in decode-forward and\namplify-forward relaying modes. From the obtained results, it has been shown\nthat the secondary user can carry its own transmission without adversely\naffecting the performance of the primary user and that PS-CSS protocol\noutperforms the TS-PSS protocol in terms of outage probability over a wide\nrange of Signal to noise ratio(SNRs). The effect of various system parameters\non the outage performance of these protocols have also been studied.", "1508.07065": "A dual descent algorithm for node-capacitated multiflow problems and its\n  applications,Hirai, Hiroshi,Computer Science - Data Structures and AlgorithmsMathematics - Optimization and Control90C27, 05C21,In this paper, we develop an $O((m \\log k) {\\rm MSF} (n,m,1))$-time algorithm\nto find a half-integral node-capacitated multiflow of the maximum total\nflow-value in a network with $n$ nodes, $m$ edges, and $k$ terminals, where\n${\\rm MSF} (n',m',\\gamma)$ denotes the time complexity of solving the maximum\nsubmodular flow problem in a network with $n'$ nodes, $m'$ edges, and the\ncomplexity $\\gamma$ of computing the exchange capacity of the submodular\nfunction describing the problem. By using Fujishige-Zhang algorithm for\nsubmodular flow, we can find a maximum half-integral multiflow in $O(m n^3 \\log\nk)$ time. This is the first combinatorial strongly polynomial time algorithm\nfor this problem. Our algorithm is built on a developing theory of discrete\nconvex functions on certain graph structures. Applications include\n\"ellipsoid-free\" combinatorial implementations of a 2-approximation algorithm\nfor the minimum node-multiway cut problem by Garg, Vazirani, and Yannakakis.Comment: To appear in ACM Transactions on Algorithms", "1508.07435": "Subdifferential-based implicit return-mapping operators in Mohr-Coulomb\n  plasticity,Sysala, StanislavCermak, Martin,Computer Science - Computational Engineering, Finance, and Science,The paper is devoted to a constitutive solution, limit load analysis and\nNewton-like methods in elastoplastic problems containing the Mohr-Coulomb yield\ncriterion. Within the constitutive problem, we introduce a self-contained\nderivation of the implicit return-mapping solution scheme using a recent\nsubdifferential-based treatment. Unlike conventional techniques based on\nKoiter's rules, the presented scheme a priori detects a position of the unknown\nstress tensor on the yield surface even if the constitutive solution cannot be\nfound in closed form. This fact eliminates blind guesswork from the scheme,\nenables to analyze properties of the constitutive operator, and simplifies\nconstruction of the consistent tangent operator which is important for the\nsemismooth Newton method applied on the incremental boundary value\nelastoplastic problem. The incremental problem in Mohr-Coulomb plasticity is\ncombined with the limit load analysis. Beside a conventional direct method of\nthe incremental limit analysis, a recent indirect one is introduced and its\nadvantages are described. The paper contains 2D and 3D numerical experiments on\nslope stability with publicly available Matlab implementations.Comment: 26 pages, 10 figures", "1509.00144": "Automatic Software Diversity in the Light of Test Suites,Baudry, BenoitAllier, SimonRodriguez-Cancio, MarcelinoMonperrus, Martin,Computer Science - Software EngineeringD.2.5,A few works address the challenge of automating software diversification, and\nthey all share one core idea: using automated test suites to drive\ndiversification. However, there is is lack of solid understanding of how test\nsuites, programs and transformations interact one with another in this process.\nWe explore this intricate interplay in the context of a specific\ndiversification technique called \"sosiefication\". Sosiefication generates sosie\nprograms, i.e., variants of a program in which some statements are deleted,\nadded or replaced but still pass the test suite of the original program. Our\ninvestigation of the influence of test suites on sosiefication exploits the\nfollowing observation: test suites cover the different regions of programs in\nvery unequal ways. Hence, we hypothesize that sosie synthesis has different\nperformances on a statement that is covered by one hundred test case and on a\nstatement that is covered by a single test case. We synthesize 24583 sosies on\n6 popular open-source Java programs. Our results show that there are two\ndimensions for diversification. The first one lies in the specification: the\nmore test cases cover a statement, the more difficult it is to synthesize\nsosies. Yet, to our surprise, we are also able to synthesize sosies on highly\ntested statements (up to 600 test cases), which indicates an intrinsic property\nof the programs we study. The second dimension is in the code: we manually\nexplore dozens of sosies and characterize new types of forgiving code regions\nthat are prone to diversification.Comment: 11 pages, 4 figures, 7 listings, 26 references", "1509.00773": "A Big Data Analyzer for Large Trace Logs,Balliu, AlkidaOlivetti, DennisBabaoglu, OzalpMarzolla, MorenoS\u00eerbu, Alina,Computer Science - Distributed, Parallel, and Cluster Computing,Current generation of Internet-based services are typically hosted on large\ndata centers that take the form of warehouse-size structures housing tens of\nthousands of servers. Continued availability of a modern data center is the\nresult of a complex orchestration among many internal and external actors\nincluding computing hardware, multiple layers of intricate software, networking\nand storage devices, electrical power and cooling plants. During the course of\ntheir operation, many of these components produce large amounts of data in the\nform of event and error logs that are essential not only for identifying and\nresolving problems but also for improving data center efficiency and\nmanagement. Most of these activities would benefit significantly from data\nanalytics techniques to exploit hidden statistical patterns and correlations\nthat may be present in the data. The sheer volume of data to be analyzed makes\nuncovering these correlations and patterns a challenging task. This paper\npresents BiDAl, a prototype Java tool for log-data analysis that incorporates\nseveral Big Data technologies in order to simplify the task of extracting\ninformation from data traces produced by large clusters and server farms. BiDAl\nprovides the user with several analysis languages (SQL, R and Hadoop MapReduce)\nand storage backends (HDFS and SQLite) that can be freely mixed and matched so\nthat a custom tool for a specific task can be easily constructed. BiDAl has a\nmodular architecture so that it can be extended with other backends and\nanalysis languages in the future. In this paper we present the design of BiDAl\nand describe our experience using it to analyze publicly-available traces from\nGoogle data clusters, with the goal of building a realistic model of a complex\ndata center.Comment: 26 pages, 10 figures", "1509.00864": "Strong Pseudoprimes to Twelve Prime Bases,Sorenson, Jonathan P.Webster, Jonathan,Mathematics - Number TheoryComputer Science - Data Structures and AlgorithmsComputer Science - Mathematical SoftwarePrimary 11Y16, 11Y16, Secondary 11A41, 68W40, 68W10,Let $\\psi_m$ be the smallest strong pseudoprime to the first $m$ prime bases.\nThis value is known for $1 \\leq m \\leq 11$. We extend this by finding\n$\\psi_{12}$ and $\\psi_{13}$. We also present an algorithm to find all integers\n$n\\le B$ that are strong pseudoprimes to the first $m$ prime bases; with a\nreasonable heuristic assumption we can show that it takes at most\n$B^{2/3+o(1)}$ time.", "1509.00926": "Using Inclusion Diagrams as an Alternative to Venn Diagrams to Determine\n  the Validity of Categorical Syllogisms,Skliar, OsvaldoMonge, Ricardo E.Gapper, Sherry,Computer Science - Logic in Computer ScienceMathematics - Logic03B05, 03B10, 97E30, 00A66,Inclusion diagrams are introduced as an alternative to using Venn diagrams to\ndetermine the validity of categorical syllogisms, and are used here for the\nanalysis of diverse categorical syllogisms. As a preliminary example of a\npossible generalization of the use of inclusion diagrams, consideration is\ngiven also to an argument that includes more than two premises and more than\nthree terms, the classic major, middle and minor terms in categorical\nsyllogisms.Comment: 29 pages", "1509.01347": "Verificarlo: checking floating point accuracy through Monte Carlo\n  Arithmetic,Denis, ChristopheCastro, Pablo De OliveiraPetit, Eric,Computer Science - Mathematical SoftwareComputer Science - Numerical Analysis,Numerical accuracy of floating point computation is a well studied topic\nwhich has not made its way to the end-user in scientific computing. Yet, it has\nbecome a critical issue with the recent requirements for code modernization to\nharness new highly parallel hardware and perform higher resolution computation.\nTo democratize numerical accuracy analysis, it is important to propose tools\nand methodologies to study large use cases in a reliable and automatic way. In\nthis paper, we propose verificarlo, an extension to the LLVM compiler to\nautomatically use Monte Carlo Arithmetic in a transparent way for the end-user.\nIt supports all the major languages including C, C++, and Fortran. Unlike\nsource-to-source approaches, our implementation captures the influence of\ncompiler optimizations on the numerical accuracy. We illustrate how Monte Carlo\nArithmetic using the verificarlo tool outperforms the existing approaches on\nvarious use cases and is a step toward automatic numerical analysis.", "1509.01676": "Optimum Traffic Allocation in Bundled Energy Efficient Ethernet Links,P\u00e9rez, Miguel Rodr\u00edguezVeiga, Manuel Fern\u00e1ndezAlonso, Sergio Herrer\u00edaHmila, MariemGarc\u00eda, C\u00e1ndido L\u00f3pez,Computer Science - Networking and Internet Architecture,The energy demands of Ethernet links have been an active focus of research in\nthe recent years. This work has enabled a new generation of Energy Efficient\nEthernet (EEE) interfaces able to adapt their power consumption to the actual\ntraffic demands, thus yielding significant energy savings. With the energy\nconsumption of single network connections being a solved problem, in this paper\nwe focus on the energy demands of link aggregates that are commonly used to\nincrease the capacity of a network connection. We build on known energy models\nof single EEE links to derive the energy demands of the whole aggregate as a\nfunction on how the traffic load is spread among its powered links. We then\nprovide a practical method to share the load that minimizes overall energy\nconsumption with controlled packet delay, and prove that it is valid for a wide\nrange of EEE links. Finally, we validate our method with both synthetic and\nreal traffic traces captured in Internet backbones.", "1509.01683": "Inference From Visible Information And Background Knowledge,Benedikt, MichaelBourhis, PierreCate, Balder tenPuppis, GabrieleBoom, Michael Vanden,Computer Science - Logic in Computer Science,We provide a wide-ranging study of the scenario where a subset of the\nrelations in a relational vocabulary are visible to a user --- that is, their\ncomplete contents are known --- while the remaining relations are invisible. We\nalso have a background theory --- invariants given by logical sentences ---\nwhich may relate the visible relations to invisible ones, and also may\nconstrain both the visible and invisible relations in isolation. We want to\ndetermine whether some other information, given as a positive existential\nformula, can be inferred using only the visible information and the background\ntheory. This formula whose inference we are concered with is denoted as the\n\\emph{query}. We consider whether positive information about the query can be\ninferred, and also whether negative information -- the sentence does not hold\n-- can be inferred. We further consider both the instance-level version of the\nproblem, where both the query and the visible instance are given, and the\nschema-level version, where we want to know whether truth or falsity of the\nquery can be inferred in some instance of the schema.", "1509.02223": "Diffusion tensor imaging with deterministic error bounds,Gorokh, ArturKorolev, YuryValkonen, Tuomo,Computer Science - Computer Vision and Pattern RecognitionComputer Science - Numerical Analysis,Errors in the data and the forward operator of an inverse problem can be\nhandily modelled using partial order in Banach lattices. We present some\nexisting results of the theory of regularisation in this novel framework, where\nerrors are represented as bounds by means of the appropriate partial order.\n  We apply the theory to Diffusion Tensor Imaging, where correct noise\nmodelling is challenging: it involves the Rician distribution and the nonlinear\nStejskal-Tanner equation. Linearisation of the latter in the statistical\nframework would complicate the noise model even further. We avoid this using\nthe error bounds approach, which preserves simple error structure under\nmonotone transformations.", "1509.02479": "Hofstadter's problem for curious readers,Letouzey, Pierre,Computer Science - Logic in Computer ScienceMathematics - History and Overview,This document summarizes the proofs made during a Coq development inSummer\n2015. This development investigates the function G introducedby Hofstadter in\nhis famous \"G{\\\"o}del, Escher, Bach\" bookas well as a related infinite tree.\nThe left/right flipped variantof this G tree has also been studied here,\nfollowingHofstadter's \"problem for the curious reader\".The initial G function\nis refered as sequence A005206 inOEIS, while the flipped version is the\nsequence A123070.", "1509.02601": "On the $O_\\beta$-hull of a planar point set,Alegr\u00eda-Galicia, CarlosOrden, DavidSeara, CarlosUrrutia, Jorge,Computer Science - Computational Geometry68U05I.3.5,We study the $O_\\beta$-hull of a planar point set, a generalization of the\nOrthogonal Convex Hull where the coordinate axes form an angle $\\beta$. Given a\nset $P$ of $n$ points in the plane, we show how to maintain the $O_\\beta$-hull\nof $P$ while $\\beta$ runs from $0$ to $\\pi$ in $O(n \\log n)$ time and $O(n)$\nspace. With the same complexity, we also find the values of $\\beta$ that\nmaximize the area and the perimeter of the $O_\\beta$-hull and, furthermore, we\nfind the value of $\\beta$ achieving the best fitting of the point set $P$ with\na two-joint chain of alternate interior angle $\\beta$.", "1509.02709": "A Topological Approach to Meta-heuristics: Analytical Results on the BFS\n  vs. DFS Algorithm Selection Problem,Everitt, TomHutter, Marcus,Computer Science - Artificial IntelligenceI.2.8,Search is a central problem in artificial intelligence, and breadth-first\nsearch (BFS) and depth-first search (DFS) are the two most fundamental ways to\nsearch. In this paper we derive estimates for average BFS and DFS runtime. The\naverage runtime estimates can be used to allocate resources or judge the\nhardness of a problem. They can also be used for selecting the best graph\nrepresentation, and for selecting the faster algorithm out of BFS and DFS. They\nmay also form the basis for an analysis of more advanced search methods. The\npaper treats both tree search and graph search. For tree search, we employ a\nprobabilistic model of goal distribution; for graph search, the analysis\ndepends on an additional statistic of path redundancy and average branching\nfactor. As an application, we use the results to predict BFS and DFS runtime on\ntwo concrete grammar problems and on the N-puzzle. Experimental verification\nshows that our analytical approximations come close to empirical reality.Comment: Main results published in 28th Australian Joint Conference on\n  Artificial Intelligence, 2015", "1509.02900": "Statistical Inference, Learning and Models in Big Data,Franke, BeatePlante, Jean-Fran\u00e7oisRoscher, RibanaLee, AnnieSmyth, CathalHatefi, ArminChen, FuqiGil, EinatSchwing, AlexanderSelvitella, AlessandroHoffman, Michael M.Grosse, RogerHendricks, DieterReid, Nancy,Statistics - Machine LearningComputer Science - Machine Learning62-07I.2.6I.2.3I.5.1G.3,The need for new methods to deal with big data is a common theme in most\nscientific fields, although its definition tends to vary with the context.\nStatistical ideas are an essential part of this, and as a partial response, a\nthematic program on statistical inference, learning, and models in big data was\nheld in 2015 in Canada, under the general direction of the Canadian Statistical\nSciences Institute, with major funding from, and most activities located at,\nthe Fields Institute for Research in Mathematical Sciences. This paper gives an\noverview of the topics covered, describing challenges and strategies that seem\ncommon to many different areas of application, and including some examples of\napplications to make these challenges and strategies more concrete.Comment: Thematic Program on Statistical Inference, Learning, and Models for\n  Big Data, Fields Institute; 23 pages, 2 figures", "1509.03258": "Entropic CLT and phase transition in high-dimensional Wishart matrices,Bubeck, S\u00e9bastienGanguly, Shirshendu,Mathematics - ProbabilityComputer Science - Information TheoryMathematics - Functional AnalysisMathematics - Statistics Theory,We consider high dimensional Wishart matrices $\\mathbb{X} \\mathbb{X}^{\\top}$\nwhere the entries of $\\mathbb{X} \\in {\\mathbb{R}^{n \\times d}}$ are i.i.d. from\na log-concave distribution. We prove an information theoretic phase transition:\nsuch matrices are close in total variation distance to the corresponding\nGaussian ensemble if and only if $d$ is much larger than $n^3$. Our proof is\nentropy-based, making use of the chain rule for relative entropy along with the\nrecursive structure in the definition of the Wishart ensemble. The proof\ncrucially relies on the well known relation between Fisher information and\nentropy, a variational representation for Fisher information, concentration\nbounds for the spectral norm of a random matrix, and certain small ball\nprobability estimates for log-concave measures.Comment: 16 pages. Final Version. Appeared in IMRN (2018), Issue 2, Pages\n  588-606", "1509.03476": "Relational reasoning via probabilistic coupling,Barthe, GillesEspitau, ThomasGr\u00e9goire, BenjaminHsu, JustinStefanesco, L\u00e9oStrub, Pierre-Yves,Computer Science - Logic in Computer ScienceComputer Science - Programming Languages,Probabilistic coupling is a powerful tool for analyzing pairs of\nprobabilistic processes. Roughly, coupling two processes requires finding an\nappropriate witness process that models both processes in the same probability\nspace. Couplings are powerful tools proving properties about the relation\nbetween two processes, include reasoning about convergence of distributions and\nstochastic dominance---a probabilistic version of a monotonicity property.\n  While the mathematical definition of coupling looks rather complex and\ncumbersome to manipulate, we show that the relational program logic pRHL---the\nlogic underlying the EasyCrypt cryptographic proof assistant---already\ninternalizes a generalization of probabilistic coupling. With this insight,\nconstructing couplings is no harder than constructing logical proofs. We\ndemonstrate how to express and verify classic examples of couplings in pRHL,\nand we mechanically verify several couplings in EasyCrypt.", "1509.03484": "Local structure can identify and quantify influential global spreaders\n  in large scale social networks,Hu, YanqingJi, ShenggongJin, YuliangFeng, LingStanley, H. EugeneHavlin, Shlomo,Physics - Physics and SocietyComputer Science - Computers and SocietyComputer Science - Data Structures and AlgorithmsComputer Science - Social and Information Networks,Measuring and optimizing the influence of nodes in big-data online social\nnetworks are important for many practical applications, such as the viral\nmarketing and the adoption of new products. As the viral spreading on social\nnetwork is a global process, it is commonly believed that measuring the\ninfluence of nodes inevitably requires the knowledge of the entire network.\nEmploying percolation theory, we show that the spreading process displays a\nnucleation behavior: once a piece of information spread from the seeds to more\nthan a small characteristic number of nodes, it reaches a point of no return\nand will quickly reach the percolation cluster, regardless of the entire\nnetwork structure, otherwise the spreading will be contained locally. Thus, we\nfind that, without the knowledge of entire network, any nodes' global influence\ncan be accurately measured using this characteristic number, which is\nindependent of the network size. This motivates an efficient algorithm with\nconstant time complexity on the long standing problem of best seed spreaders\nselection, with performance remarkably close to the true optimum.Comment: 6 pages, 5 figures, Proceedings of the National Academy of Sciences\n  of the United States of America (PNAS), July 3, 2018", "1509.03784": "Solving underdetermined systems with error-correcting codes,Hurley, Ted,Computer Science - Information Theory94A99, 15B99,In an underdetermined system of equations $Ax=y$, where $A$ is an $m\\times n$\nmatrix, only $u$ of the entries of $y$ with $u < m$ are known. Thus $E_jw$,\ncalled `measurements', are known for certain $j\\in J \\subset\n\\{0,1,\\ldots,m-1\\}$ where $\\{E_i, i=0,1,\\ldots, m-1\\}$ are the rows of $A$ and\n$|J|=u$. It is required, if possible, to solve the system uniquely when $x$ has\nat most $t$ non-zero entries with $u\\geq 2t$.\n  Here such systems are considered from an error-correcting coding point of\nview. The unknown $x$ can be shown to be the error vector of a code subject to\ncertain conditions on the rows of the matrix $A$. This reduces the problem to\nfinding a suitable decoding algorithm which then finds $x$.\n  Decoding workable algorithms are shown to exist, from which the unknown $x$\nmay be determined, in cases where the known $2t$ values are evenly spaced (that\nis, when the elements of $J$ are in arithmetic progression) for classes of\nmatrices satisfying certain row properties. These cases include Fourier\n$n\\times n $ matrices where the arithmetic difference $k$ satisfies\n$\\gcd(n,k)=1$, and classes of Vandermonde matrices $V(x_1,x_2,\\ldots,x_n)$\n(with $x_i\\neq 0$) with arithmetic difference $k$ where the ratios $x_i/x_j$\nfor $i\\neq j$ are not $k^{th}$ roots of unity. The decoding algorithm has\ncomplexity $O(nt)$ and in some cases, including the Fourier matrix cases, the\ncomplexity is $O(t^2)$.\n  Matrices which have the property that the determinant of any square submatrix\nis non-zero are of particular interest. Randomly choosing rows of such matrices\ncan then give $t$ error-correcting pairs to generate a `measuring' code\n$C^\\perp=\\{E_j | j\\in J\\}$ with a decoding algorithm which finds $x$.\n  This has applications to signal processing and compressed sensing.", "1509.03915": "An Impossibility Result for Housing Markets with Fractional Endowments,Aziz, Haris,Computer Science - Computer Science and Game TheoryComputer Science - Data Structures and Algorithms91A12, 68Q15F.2J.4,The housing market setting constitutes a fundamental model of exchange\neconomies of goods. Most of the work concerning housing markets does not cater\nfor randomized assignments or allocation of time-shares. House allocation with\nfractional endowments of houses was considered by Athanassoglou and Sethuraman\n(2011) who posed the open problem whether individual rationality, weak\nstrategyproofness, and efficiency are compatible for the setting. We show that\nthe three axioms are incompatible.Comment: removed an incorrect claim in the previous version regarding an\n  algorithm satisfying SD-core stability", "1509.04037": "Measuring Partial Balance in Signed Networks,Aref, SaminWilson, Mark C.,Computer Science - Social and Information NetworksPhysics - Physics and Society05C22, 05C38, 91D30, 90B10,Is the enemy of an enemy necessarily a friend? If not, to what extent does\nthis tend to hold? Such questions were formulated in terms of signed (social)\nnetworks and necessary and sufficient conditions for a network to be \"balanced\"\nwere obtained around 1960. Since then the idea that signed networks tend over\ntime to become more balanced has been widely used in several application areas.\nHowever, investigation of this hypothesis has been complicated by the lack of a\nstandard measure of partial balance, since complete balance is almost never\nachieved in practice. We formalize the concept of a measure of partial balance,\ndiscuss various measures, compare the measures on synthetic datasets, and\ninvestigate their axiomatic properties. The synthetic data involves\nErd\\H{o}s-R\\'enyi and specially structured random graphs. We show that some\nmeasures behave better than others in terms of axioms and ability to\ndifferentiate between graphs. We also use well-known datasets from the\nsociology and biology literature, such as Read's New Guinean tribes, gene\nregulatory networks related to two organisms, and a network involving senate\nbill co-sponsorship. Our results show that substantially different levels of\npartial balance is observed under cycle-based, eigenvalue-based, and\nfrustration-based measures. We make some recommendations for measures to be\nused in future work.Comment: Peer-reviewed author copy, 31 pages, 6 figures, 5 tables", "1509.04634": "Modeling and interpolation of the ambient magnetic field by Gaussian\n  processes,Solin, ArnoKok, ManonWahlstr\u00f6m, NiklasSch\u00f6n, Thomas B.S\u00e4rkk\u00e4, Simo,Computer Science - RoboticsStatistics - Machine Learning,Anomalies in the ambient magnetic field can be used as features in indoor\npositioning and navigation. By using Maxwell's equations, we derive and present\na Bayesian non-parametric probabilistic modeling approach for interpolation and\nextrapolation of the magnetic field. We model the magnetic field components\njointly by imposing a Gaussian process (GP) prior on the latent scalar\npotential of the magnetic field. By rewriting the GP model in terms of a\nHilbert space representation, we circumvent the computational pitfalls\nassociated with GP modeling and provide a computationally efficient and\nphysically justified modeling tool for the ambient magnetic field. The model\nallows for sequential updating of the estimate and time-dependent changes in\nthe magnetic field. The model is shown to work well in practice in different\napplications: we demonstrate mapping of the magnetic field both with an\ninexpensive Raspberry Pi powered robot and on foot using a standard smartphone.Comment: 17 pages, 12 figures, to appear in IEEE Transactions on Robotics", "1509.04857": "Markov modeling of online inter-arrival times,Kerckhove, Corentin VandeGerencs\u00e9r, Bal\u00e1zsHendrickx, Julien M.Blondel, Vincent D.,Statistics - ApplicationsComputer Science - Social and Information NetworksPhysics - Physics and Society62P25 (Primary), 91C20(Secondary),In this paper, we investigate the arising communication patterns on social\nmedia, and in particular the series of events happening for a single user.\nWhile the distribution of inter-event times is often assimilated to power-law\ndensity functions, a debate persists on the nature of an underlying model that\nexplains the observed distribution. In the present, we propose an intuitive\nexplanation to understand the observed dependence of subsequent waiting times.\nOur contribution is twofold. The first idea consists of separating the short\nwaiting times -- out of scope for power-law distributions -- from the long\nones. The model is further enhanced by introducing a two-state Markovian\nprocess to incorporate memory.", "1509.04880": "An FPT 2-Approximation for Tree-Cut Decomposition,Kim, EunjungOum, Sang-ilPaul, ChristopheSau, IgnasiThilikos, Dimitrios M.,Computer Science - Data Structures and AlgorithmsComputer Science - Discrete Mathematics68R10, 05C85G.2.2F.2.2,The tree-cut width of a graph is a graph parameter defined by Wollan [J.\nComb. Theory, Ser. B, 110:47-66, 2015] with the help of tree-cut\ndecompositions. In certain cases, tree-cut width appears to be more adequate\nthan treewidth as an invariant that, when bounded, can accelerate the\nresolution of intractable problems. While designing algorithms for problems\nwith bounded tree-cut width, it is important to have a parametrically tractable\nway to compute the exact value of this parameter or, at least, some constant\napproximation of it. In this paper we give a parameterized 2-approximation\nalgorithm for the computation of tree-cut width; for an input $n$-vertex graph\n$G$ and an integer $w$, our algorithm either confirms that the tree-cut width\nof $G$ is more than $w$ or returns a tree-cut decomposition of $G$ certifying\nthat its tree-cut width is at most $2w$, in time $2^{O(w^2\\log w)} \\cdot n^2$.\nPrior to this work, no constructive parameterized algorithms, even approximated\nones, existed for computing the tree-cut width of a graph. As a consequence of\nthe Graph Minors series by Robertson and Seymour, only the existence of a\ndecision algorithm was known.Comment: 17 pages, 3 figures", "1509.05001": "Solving constrained quadratic binary problems via quantum adiabatic\n  evolution,Ronagh, PooyaWoods, BradIranmanesh, Ehsan,Mathematics - Optimization and ControlComputer Science - Emerging TechnologiesQuantum Physics,Quantum adiabatic evolution is perceived as useful for binary quadratic\nprogramming problems that are a priori unconstrained. For constrained problems,\nit is a common practice to relax linear equality constraints as penalty terms\nin the objective function. However, there has not yet been proposed a method\nfor efficiently dealing with inequality constraints using the quantum adiabatic\napproach. In this paper, we give a method for solving the Lagrangian dual of a\nbinary quadratic programming (BQP) problem in the presence of inequality\nconstraints and employ this procedure within a branch-and-bound framework for\nconstrained BQP (CBQP) problems.Comment: 20 pages, 2 figures", "1509.05498": "Supervisor Localization of Discrete-Event Systems under Partial\n  Observation,Zhang, RenyuanCai, KaiWonham, W. M.,Computer Science - Systems and Control,Recently we developed supervisor localization, a top-down approach to\ndistributed control of discrete-event systems. Its essence is the allocation of\nmonolithic (global) control action among the local control strategies of\nindividual agents. In this paper, we extend supervisor localization by\nconsidering partial observation; namely not all events are observable.\nSpecifically, we employ the recently proposed concept of relative observability\nto compute a partial-observation monolithic supervisor, and then design a\nsuitable localization procedure to decompose the supervisor into a set of local\ncontrollers. In the resulting local controllers, only observable events can\ncause state change. Further, to deal with large-scale systems, we combine the\npartial-observation supervisor localization with an efficient architectural\nsynthesis approach: first compute a heterarchical array of partial-observation\ndecentralized supervisors and coordinators, and then localize each of these\nsupervisors/coordinators into local controllers.", "1509.05572": "Randomised enumeration of small witnesses using a decision oracle,Meeks, Kitty,Computer Science - Data Structures and AlgorithmsComputer Science - Computational Complexity,Many combinatorial problems involve determining whether a universe of $n$\nelements contains a witness consisting of $k$ elements which have some\nspecified property. In this paper we investigate the relationship between the\ndecision and enumeration versions of such problems: efficient methods are known\nfor transforming a decision algorithm into a search procedure that finds a\nsingle witness, but even finding a second witness is not so straightforward in\ngeneral. We show that, if the decision version of the problem can be solved in\ntime $f(k) \\cdot poly(n)$, there is a randomised algorithm which enumerates all\nwitnesses in time $e^{k + o(k)} \\cdot f(k) \\cdot poly(n) \\cdot N$, where $N$ is\nthe total number of witnesses. If the decision version of the problem is solved\nby a randomised algorithm which may return false negatives, then the same\nmethod allows us to output a list of witnesses in which any given witness will\nbe included with high probability. The enumeration algorithm also gives rise to\nan efficient algorithm to count the total number of witnesses when this number\nis small.Comment: To appear in Algorithmica. Author final version, incorporating\n  reviewer comments. An extended abstract of part of this work appeared in proc\n  IPEC '16", "1509.05664": "Automated Synthesis of Distributed Self-Stabilizing Protocols,Faghih, FathiyehBonakdarpour, BorzooTixeuil, SebastienKulkarni, Sandeep,Computer Science - Software EngineeringComputer Science - Distributed, Parallel, and Cluster Computing,In this paper, we introduce an SMT-based method that automatically\nsynthesizes a distributed self-stabilizing protocol from a given high-level\nspecification and network topology. Unlike existing approaches, where synthesis\nalgorithms require the explicit description of the set of legitimate states,\nour technique only needs the temporal behavior of the protocol. We extend our\napproach to synthesize ideal-stabilizing protocols, where every state is\nlegitimate. We also extend our technique to synthesize monotonic-stabilizing\nprotocols, where during recovery, each process can execute an most once one\naction. Our proposed methods are fully implemented and we report successful\nsynthesis of well-known protocols such as Dijkstra's token ring, a\nself-stabilizing version of Raymond's mutual exclusion algorithm,\nideal-stabilizing leader election and local mutual exclusion, as well as\nmonotonic-stabilizing maximal independent set and distributed Grundy coloring.", "1509.05821": "New bounds on curve tangencies and orthogonalities,Ellenberg, Jordan S.Solymosi, JozsefZahl, Joshua,Mathematics - CombinatoricsComputer Science - Computational Geometry,We establish new bounds on the number of tangencies and orthogonal\nintersections determined by an arrangement of curves. First, given a set of $n$\nalgebraic plane curves, we show that there are $O(n^{3/2})$ points where two or\nmore curves are tangent. In particular, if no three curves are mutually tangent\nat a common point, then there are $O(n^{3/2})$ curve-curve tangencies. Second,\ngiven a family of algebraic plane curves and a set of $n$ curves from this\nfamily, we show that either there are $O(n^{3/2})$ points where two or more\ncurves are orthogonal, or the family of curves has certain special properties.\n  We obtain these bounds by transforming the arrangement of plane curves into\nan arrangement of space curves so that tangency (or orthogonality) of the\noriginal plane curves corresponds to intersection of space curves. We then\nbound the number of intersections of the corresponding space curves. For the\ncase of curve-curve tangency, we use a polynomial method technique that is\nreminiscent of Guth and Katz's proof of the joints theorem. For the case of\northogonal curve intersections, we employ a bound of Guth and the third author\nto control the number of two-rich points in space curve arrangements.Comment: 22 pages, 1 figure. v4: final version; to appear in Discrete Analysis", "1509.06191": "Product Space Models of Correlation: Between Noise Stability and\n  Additive Combinatorics,H\u0105z\u0142a, JanHolenstein, ThomasMossel, Elchanan,Computer Science - Discrete Mathematics,There is a common theme to some research questions in additive combinatorics\nand noise stability. Both study the following basic question: Let $\\mathcal{P}$\nbe a probability distribution over a space $\\Omega^\\ell$ with all $\\ell$\nmarginals equal. Let $\\underline{X}^{(1)}, \\ldots, \\underline{X}^{(\\ell)}$\nwhere $\\underline{X}^{(j)} = (X_1^{(j)}, \\ldots, X_n^{(j)})$ be random vectors\nsuch that for every coordinate $i \\in [n]$ the tuples $(X_i^{(1)}, \\ldots,\nX_i^{(\\ell)})$ are i.i.d. according to $\\mathcal{P}$.\n  A central question that is addressed in both areas is:\n  - Does there exist a function $c_{\\mathcal{P}}()$ independent of $n$ such\nthat for every $f: \\Omega^n \\to [0, 1]$ with $\\mathrm{E}[f(X^{(1)})] = \\mu >\n0$: \\begin{align*} \\mathrm{E} \\left[ \\prod_{j=1}^\\ell f(X^{(j)}) \\right]\n  \\ge c(\\mu) > 0 \\, ? \\end{align*}\n  Instances of this question include the finite field model version of Roth's\nand Szemer\\'edi's theorems as well as Borell's result about the optimality of\nnoise stability of half-spaces.\n  Our goal in this paper is to interpolate between the noise stability theory\nand the finite field additive combinatorics theory and address the question\nabove in further generality than considered before. In particular, we settle\nthe question for $\\ell = 2$ and when $\\ell > 2$ and $\\mathcal{P}$ has bounded\ncorrelation $\\rho(\\mathcal{P}) < 1$. Under the same conditions we also\ncharacterize the _obstructions_ for similar lower bounds in the case of $\\ell$\ndifferent functions. Part of the novelty in our proof is the combination of\nanalytic arguments from the theories of influences and hyper-contraction with\narguments from additive combinatorics.", "1509.06357": "Using Contracted Solution Graphs for Solving Reconfiguration Problems,Bonsma, PaulPaulusma, Daniel,Computer Science - Data Structures and AlgorithmsComputer Science - Computational Complexity,We introduce in a general setting a dynamic programming method for solving\nreconfiguration problems. Our method is based on contracted solution graphs,\nwhich are obtained from solution graphs by performing an appropriate series of\nedge contractions that decrease the graph size without losing any critical\ninformation needed to solve the reconfiguration problem under consideration.\nOur general framework captures the approach behind known reconfiguration\nresults of Bonsma (2012) and Hatanaka, Ito and Zhou (2014). As a third example,\nwe apply the method to the following problem: given two $k$-colorings $\\alpha$\nand $\\beta$ of a graph $G$, can $\\alpha$ be modified into $\\beta$ by recoloring\none vertex of $G$ at a time, while maintaining a $k$-coloring throughout? This\nproblem is known to be PSPACE-hard even for bipartite planar graphs and $k=4$.\nBy applying our method in combination with a thorough exploitation of the graph\nstructure we obtain a polynomial time algorithm for $(k-2)$-connected chordal\ngraphs.", "1509.06559": "Shape Aware Matching of Implicit Surfaces based on Thin Shell Energies,Iglesias, Jos\u00e9 A.Rumpf, MartinScherzer, Otmar,Mathematics - Optimization and ControlComputer Science - Computational Geometry65D18, 49J45, 74K25,A shape sensitive, variational approach for the matching of surfaces\nconsidered as thin elastic shells is investigated. The elasticity functional to\nbe minimized takes into account two different types of nonlinear energies: a\nmembrane energy measuring the rate of tangential distortion when deforming the\nreference shell into the template shell, and a bending energy measuring the\nbending under the deformation in terms of the change of the shape operators\nfrom the undeformed into the deformed configuration. The variational method\napplies to surfaces described as level sets. It is mathematically well-posed\nand an existence proof of an optimal matching deformation is given. The\nvariational model is implemented using a finite element discretization combined\nwith a narrow band approach on an efficient hierarchical grid structure. For\nthe optimization a regularized nonlinear conjugate gradient scheme and a\ncascadic multilevel strategy are used. The features of the proposed approach\nare studied for synthetic test cases and a collection of geometry processing\nexamples.Comment: 27 pages, 11 figures", "1509.07127": "Universal recovery maps and approximate sufficiency of quantum relative\n  entropy,Junge, MariusRenner, RenatoSutter, DavidWilde, Mark M.Winter, Andreas,Quantum PhysicsComputer Science - Information TheoryMathematical Physics,The data processing inequality states that the quantum relative entropy\nbetween two states $\\rho$ and $\\sigma$ can never increase by applying the same\nquantum channel $\\mathcal{N}$ to both states. This inequality can be\nstrengthened with a remainder term in the form of a distance between $\\rho$ and\nthe closest recovered state $(\\mathcal{R} \\circ \\mathcal{N})(\\rho)$, where\n$\\mathcal{R}$ is a recovery map with the property that $\\sigma = (\\mathcal{R}\n\\circ \\mathcal{N})(\\sigma)$. We show the existence of an explicit recovery map\nthat is universal in the sense that it depends only on $\\sigma$ and the quantum\nchannel $\\mathcal{N}$ to be reversed. This result gives an alternate,\ninformation-theoretic characterization of the conditions for approximate\nquantum error correction.Comment: v3: 24 pages, 1 figure, final version published in Annales Henri\n  Poincar\\'e", "1509.07314": "Adaptive-Robust Control of a Class of Uncertain Nonlinear Systems\n  Utilizing Time-Delayed Input and Position Feedback,Roy, SpandanKar, Indra Narayan,Computer Science - Systems and Control,In this paper, the tracking control problem of a class of Euler-Lagrange\nsystems subjected to unknown uncertainties is addressed and an adaptive-robust\ncontrol strategy, christened as Time-Delayed Adaptive Robust Control (TARC) is\npresented. The proposed control strategy approximates the unknown dynamics\nthrough time-delayed logic, and the switching logic provides robustness against\nthe approximation error. The novel adaptation law for the switching gain, in\ncontrast to the conventional adaptive-robust control methodologies, does not\nrequire either nominal modelling or predefined bounds of the uncertainties.\nAlso, the proposed adaptive law circumvents the overestimation-underestimation\nproblem of switching gain. The state derivatives in the proposed control law is\nestimated from past data of the state to alleviate the measurement error when\nstate derivatives are not available directly. Moreover, a new stability notion\nfor time-delayed control is proposed which in turn provides a selection\ncriterion for controller gain and sampling interval. Experimental result of the\nproposed methodology using a nonholonomic wheeled mobile robot (WMR) is\npresented and improved tracking accuracy of the proposed control law is noted\ncompared to time-delayed control and adaptive sliding mode control.Comment: 9 pages", "1509.07330": "Pricing Policies for Selling Indivisible Storable Goods to Strategic\n  Consumers,Berbeglia, GerardoRayaprolu, GautamVetta, Adrian,Computer Science - Computer Science and Game Theory,We study the dynamic pricing problem faced by a monopolistic retailer who\nsells a storable product to forward-looking consumers. In this framework, the\ntwo major pricing policies (or mechanisms) studied in the literature are the\npreannounced (commitment) pricing policy and the contingent (threat or history\ndependent) pricing policy. We analyse and compare these pricing policies in the\nsetting where the good can be purchased along a finite time horizon in\nindivisible atomic quantities. First, we show that, given linear storage costs,\nthe retailer can compute an optimal preannounced pricing policy in polynomial\ntime by solving a dynamic program. Moreover, under such a policy, we show that\nconsumers do not need to store units in order to anticipate price rises.\nSecond, under the contingent pricing policy rather than the preannounced\npricing mechanism, (i) prices could be lower, (ii) retailer revenues could be\nhigher, and (iii) consumer surplus could be higher. This result is surprising,\nin that these three facts are in complete contrast to the case of a retailer\nselling divisible storable goods Dudine et al. (2006). Third, we quantify\nexactly how much more profitable a contingent policy could be with respect to a\npreannounced policy. Specifically, for a market with $N$ consumers, a\ncontingent policy can produce a multiplicative factor of $\\Omega(\\log N)$ more\nrevenues than a preannounced policy, and this bound is tight.Comment: A 1-page abstract of an earlier version of this paper was published\n  in the proceedings of the 11th conference on Web and Internet Economics\n  (WINE), 2015", "1509.07417": "Deterministic Sparse Suffix Sorting in the Restore Model,Fischer, JohannesI, TomohiroK\u00f6ppl, Dominik,Computer Science - Data Structures and Algorithms,Given a text $T$ of length $n$, we propose a deterministic online algorithm\ncomputing the sparse suffix array and the sparse longest common prefix array of\n$T$ in $O(c \\sqrt{\\lg n} + m \\lg m \\lg n \\lg^* n)$ time with $O(m)$ words of\nspace under the premise that the space of $T$ is rewritable, where $m \\le n$ is\nthe number of suffixes to be sorted (provided online and arbitrarily), and $c$\nis the number of characters with $m \\le c \\le n$ that must be compared for\ndistinguishing the designated suffixes.", "1509.07552": "Formal Support for Standardizing Protocols with State,Guttman, Joshua D.Liskov, Moses D.Ramsdell, John D.Rowe, Paul D.,Computer Science - Cryptography and Security,Many cryptographic protocols are designed to achieve their goals using only\nmessages passed over an open network. Numerous tools, based on well-understood\nfoundations, exist for the design and analysis of protocols that rely purely on\nmessage passing. However, these tools encounter difficulties when faced with\nprotocols that rely on non-local, mutable state to coordinate several local\nsessions.\n  We adapt one of these tools, {\\cpsa}, to provide automated support for\nreasoning about state. We use Ryan's Envelope Protocol as an example to\ndemonstrate how the message-passing reasoning can be integrated with state\nreasoning to yield interesting and powerful results.\n  Keywords: protocol analysis tools, stateful protocols, TPM, PKCS#11.", "1509.07808": "A (1+epsilon)-Approximation for Makespan Scheduling with Precedence\n  Constraints using LP Hierarchies,Levey, ElaineRothvoss, Thomas,Computer Science - Data Structures and AlgorithmsComputer Science - Discrete Mathematics,In a classical problem in scheduling, one has $n$ unit size jobs with a\nprecedence order and the goal is to find a schedule of those jobs on $m$\nidentical machines as to minimize the makespan. It is one of the remaining four\nopen problems from the book of Garey & Johnson whether or not this problem is\n$\\mathbf{NP}$-hard for $m=3$.\n  We prove that for any fixed $\\varepsilon$ and $m$, an LP-hierarchy lift of\nthe time-indexed LP with a slightly super poly-logarithmic number of $r =\n(\\log(n))^{\\Theta(\\log \\log n)}$ rounds provides a $(1 +\n\\varepsilon)$-approximation. For example Sherali-Adams suffices as hierarchy.\nThis implies an algorithm that yields a $(1+\\varepsilon)$-approximation in time\n$n^{O(r)}$. The previously best approximation algorithms guarantee a $2 -\n\\frac{7}{3m+1}$-approximation in polynomial time for $m \\geq 4$ and\n$\\frac{4}{3}$ for $m=3$. Our algorithm is based on a recursive scheduling\napproach where in each step we reduce the correlation in form of long chains.\nOur method adds to the rather short list of examples where hierarchies are\nactually useful to obtain better approximation algorithms.", "1509.08102": "Discriminative Learning of the Prototype Set for Nearest Neighbor\n  Classification,Ando, Shin,Computer Science - Machine Learning,The nearest neighbor rule is a classic yet essential classification model,\nparticularly in problems where the supervising information is given by pairwise\ndissimilarities and the embedding function are not easily obtained. Prototype\nselection provides means of generalization and improving efficiency of the\nnearest neighbor model, but many existing methods assume and rely on the\nanalyses of the input vector space. In this paper, we explore a\ndissimilarity-based, parametrized model of the nearest neighbor rule. In the\nproposed model, the selection of the nearest prototypes is influenced by the\nparameters of the respective prototypes. It provides a formulation for\nminimizing the violation of the extended nearest neighbor rule over the\ntraining set in a tractable form to exploit numerical techniques. We show that\nthe minimization problem reduces to a large-margin principle learning and\ndemonstrate its advantage by empirical comparisons with other prototype\nselection methods.", "1509.08346": "UB-ANC Drone: A Flexible Airborne Networking and Communications Testbed,Modares, JalilMastronarde, Nicholas,Computer Science - Networking and Internet ArchitectureComputer Science - Robotics,We present the University at Buffalo's Airborne Networking and Communications\nTestbed (UB-ANC Drone). UB-ANC Drone is an open software/hardware platform that\naims to facilitate rapid testing and repeatable comparative evaluation of\nairborne networking and communications protocols at different layers of the\nprotocol stack. It combines quadcopters capable of autonomous flight with\nsophisticated command and control capabilities and embedded software-defined\nradios (SDRs), which enable flexible deployment of novel communications and\nnetworking protocols. This is in contrast to existing airborne network\ntestbeds, which rely on standard inflexible wireless technologies, e.g., Wi-Fi\nor Zigbee. UB-ANC Drone is designed with emphasis on modularity and\nextensibility, and is built around popular open-source projects and standards\ndeveloped by the research and hobby communities. This makes UB-ANC Drone highly\ncustomizable, while also simplifying its adoption. In this paper, we describe\nUB-ANC Drone's hardware and software architecture.", "1509.08690": "Kempe's Universality Theorem for Rational Space Curves,Li, ZijiaSchicho, JosefSchr\u00f6cker, Hans-Peter,Computer Science - Computational GeometryComputer Science - RoboticsComputer Science - Symbolic ComputationMathematics - Algebraic GeometryMathematics - Rings and Algebras70B05, 13F20, 65D17, 68U07,We prove that every bounded rational space curve of degree d and circularity\nc can be drawn by a linkage with 9/2 d - 6c + 1 revolute joints. Our proof is\nbased on two ingredients. The first one is the factorization theory of motion\npolynomials. The second one is the construction of a motion polynomial of\nminimum degree with given orbit. Our proof also gives the explicity\nconstruction of the linkage.Comment: The final publication is available at Springer via\n  http://dx.doi.org/10.1007/s10208-017-9348-x", "1509.08764": "On the Min-cost Traveling Salesman Problem with Drone,Ha, Quang MinhDeville, YvesPham, Quang DungH\u00e0, Minh Ho\u00e0ng,Computer Science - Artificial Intelligence,Over the past few years, unmanned aerial vehicles (UAV), also known as\ndrones, have been adopted as part of a new logistic method in the commercial\nsector called \"last-mile delivery\". In this novel approach, they are deployed\nalongside trucks to deliver goods to customers to improve the quality of\nservice and reduce the transportation cost. This approach gives rise to a new\nvariant of the traveling salesman problem (TSP), called TSP with drone (TSP-D).\nA variant of this problem that aims to minimize the time at which truck and\ndrone finish the service (or, in other words, to maximize the quality of\nservice) was studied in the work of Murray and Chu (2015). In contrast, this\npaper considers a new variant of TSP-D in which the objective is to minimize\noperational costs including total transportation cost and one created by waste\ntime a vehicle has to wait for the other. The problem is first formulated\nmathematically. Then, two algorithms are proposed for the solution. The first\nalgorithm (TSP-LS) was adapted from the approach proposed by Murray and Chu\n(2015), in which an optimal TSP solution is converted to a feasible TSP-D\nsolution by local searches. The second algorithm, a Greedy Randomized Adaptive\nSearch Procedure (GRASP), is based on a new split procedure that optimally\nsplits any TSP tour into a TSP-D solution. After a TSP-D solution has been\ngenerated, it is then improved through local search operators. Numerical\nresults obtained on various instances of both objective functions with\ndifferent sizes and characteristics are presented. The results show that GRASP\noutperforms TSP-LS in terms of solution quality under an acceptable running\ntime.Comment: 57 pages, technical report, latest work", "1509.08892": "A data-dependent weighted LASSO under Poisson noise,Jiang, XinReynaud-Bouret, PatriciaRivoirard, VincentSansonnet, LaureWillett, Rebecca,Mathematics - Statistics TheoryComputer Science - Information Theory,Sparse linear inverse problems appear in a variety of settings, but often the\nnoise contaminating observations cannot accurately be described as bounded by\nor arising from a Gaussian distribution. Poisson observations in particular are\na feature of several real-world applications. Previous work on sparse Poisson\ninverse problems encountered several limiting technical hurdles. This paper\ndescribes a novel alternative analysis approach for sparse Poisson inverse\nproblems that (a) sidesteps the technical challenges in previous work, (b)\nadmits estimators that can readily be computed using off-the-shelf LASSO\nalgorithms, and (c) hints at a general framework for broad classes of noise in\nsparse linear inverse problems. At the heart of this new approach lies a\nweighted LASSO estimator for which data-dependent weights are based on Poisson\nconcentration inequalities. Unlike previous analyses of the weighted LASSO, the\nproposed analysis depends on conditions which can be checked or shown to hold\nin general settings with high probability.Comment: 25 pages (48 pages with appendix), 3 figures", "1509.08979": "Fixpoint Node Selection Query Languages for Trees,Calvanese, DiegoDe Giacomo, GiuseppeLenzerini, MaurizioVardi, Moshe Y.,Computer Science - DatabasesComputer Science - Logic in Computer Science,The study of node selection query languages for (finite) trees has been a\nmajor topic in the recent research on query languages for Web documents. On one\nhand, there has been an extensive study of XPath and its various extensions. On\nthe other hand, query languages based on classical logics, such as first-order\nlogic (FO) or Monadic Second-Order Logic (MSO), have been considered. Results\nin this area typically relate an XPath-based language to a classical logic.\nWhat has yet to emerge is an XPath-related language that is as expressive as\nMSO, and at the same time enjoys the computational properties of XPath, which\nare linear time query evaluation and exponential time query-containment test.\nIn this paper we propose muXPath, which is the alternation-free fragment of\nXPath extended with fixpoint operators. Using two-way alternating automata, we\nshow that this language does combine desired expressiveness and computational\nproperties, placing it as an attractive candidate for the definite\nnode-selection query language for trees.", "1509.09121": "The \"handedness\" of language: Directional symmetry breaking of sign\n  usage in words,Ashraf, Md IzharSinha, Sitabhra,Computer Science - Computation and Language,Language, which allows complex ideas to be communicated through symbolic\nsequences, is a characteristic feature of our species and manifested in a\nmultitude of forms. Using large written corpora for many different languages\nand scripts, we show that the occurrence probability distributions of signs at\nthe left and right ends of words have a distinct heterogeneous nature.\nCharacterizing this asymmetry using quantitative inequality measures, viz.\ninformation entropy and the Gini index, we show that the beginning of a word is\nless restrictive in sign usage than the end. This property is not simply\nattributable to the use of common affixes as it is seen even when only word\nroots are considered. We use the existence of this asymmetry to infer the\ndirection of writing in undeciphered inscriptions that agrees with the\narchaeological evidence. Unlike traditional investigations of phonotactic\nconstraints which focus on language-specific patterns, our study reveals a\nproperty valid across languages and writing systems. As both language and\nwriting are unique aspects of our species, this universal signature may reflect\nan innate feature of the human cognitive phenomenon.Comment: 10 pages, 4 figures + Supplementary Information (15 pages, 8\n  figures), final corrected version", "1509.09188": "Approximate Spectral Clustering: Efficiency and Guarantees,Kolev, PavelMehlhorn, Kurt,Computer Science - Discrete Mathematics,Approximate Spectral Clustering (ASC) is a popular and successful heuristic\nfor partitioning the nodes of a graph $G$ into clusters for which the ratio of\noutside connections compared to the volume (sum of degrees) is small. ASC\nconsists of the following two subroutines: i) compute an approximate Spectral\nEmbedding via the Power method; and ii) partition the resulting vector set with\nan approximate $k$-means clustering algorithm. The resulting $k$-means\npartition naturally induces a $k$-way node partition of $G$.\n  We give a comprehensive analysis of ASC building on the work of Peng et\nal.~(SICOMP'17), Boutsidis et al.~(ICML'15) and Ostrovsky et al.~(JACM'13). We\nshow that ASC i) runs efficiently, and ii) yields a good approximation of an\noptimal $k$-way node partition of $G$. Moreover, we strengthen the quality\nguarantees of a structural result of Peng et al. by a factor of $k$, and\nsimultaneously weaken the eigenvalue gap assumption. Further, we show that ASC\nfinds a $k$-way node partition of $G$ with the strengthened quality guarantees.Comment: A preliminary version of this paper was presented at the 24th Annual\n  European Symposium on Algorithms (ESA 2016)", "1509.09236": "On the Complexity of Robust PCA and $\\ell_1$-norm Low-Rank Matrix\n  Approximation,Gillis, NicolasVavasis, Stephen A.,Computer Science - Machine LearningComputer Science - Computational ComplexityMathematics - Numerical AnalysisMathematics - Optimization and Control,The low-rank matrix approximation problem with respect to the component-wise\n$\\ell_1$-norm ($\\ell_1$-LRA), which is closely related to robust principal\ncomponent analysis (PCA), has become a very popular tool in data mining and\nmachine learning. Robust PCA aims at recovering a low-rank matrix that was\nperturbed with sparse noise, with applications for example in\nforeground-background video separation. Although $\\ell_1$-LRA is strongly\nbelieved to be NP-hard, there is, to the best of our knowledge, no formal proof\nof this fact. In this paper, we prove that $\\ell_1$-LRA is NP-hard, already in\nthe rank-one case, using a reduction from MAX CUT. Our derivations draw\ninteresting connections between $\\ell_1$-LRA and several other well-known\nproblems, namely, robust PCA, $\\ell_0$-LRA, binary matrix factorization, a\nparticular densest bipartite subgraph problem, the computation of the cut norm\nof $\\{-1,+1\\}$ matrices, and the discrete basis problem, which we all prove to\nbe NP-hard.Comment: 16 pages, some typos corrected", "1510.00215": "FPT Approximation Schemes for Maximizing Submodular Functions,Skowron, Piotr,Computer Science - Data Structures and Algorithms,We investigate the existence of approximation algorithms for maximization of\nsubmodular functions, that run in fixed parameter tractable (FPT) time. Given a\nnon-decreasing submodular set function $v: 2^X \\to \\mathbb{R}$ the goal is to\nselect a subset $S$ of $K$ elements from $X$ such that $v(S)$ is maximized. We\nidentify three properties of set functions, referred to as $p$-separability\nproperties, and we argue that many real-life problems can be expressed as\nmaximization of submodular, $p$-separable functions, with low values of the\nparameter $p$. We present FPT approximation schemes for the minimization and\nmaximization variants of the problem, for several parameters that depend on\ncharacteristics of the optimized set function, such as $p$ and $K$. We confirm\nthat our algorithms are applicable to a broad class of problems, in particular\nto problems from computational social choice, such as item selection or winner\ndetermination under several multiwinner election systems.", "1510.00347": "Coding Theorem and Converse for Abstract Channels with Time Structure\n  and Memory,Mittelbach, MartinJorswieck, Eduard A.,Computer Science - Information Theory,A coding theorem and converse are proved for a large class of abstract\nstationary channels with time structure including the result by Kadota and\nWyner (1972) on continuous-time real-valued channels as special cases. As main\ncontribution the coding theorem is proved for a significantly weaker condition\non the channel output memory - called total ergodicity w.r.t. finite alphabet\nblock-memoryless input sources - and under a crucial relaxation of the\nmeasurability requirement for the channel. These improvements are achieved by\nintroducing a suitable characterization of information rate capacity. It is\nshown that the $\\psi$-mixing output memory condition used by Kadota and Wyner\nis quite restrictive and excludes important channel models, in particular for\nthe class of Gaussian channels. In fact, it is proved that for Gaussian (e.g.,\nfading or additive noise) channels the $\\psi$-mixing condition is equivalent to\nfinite output memory. Further, it is demonstrated that the measurability\nrequirement of Kadota and Wyner is not satisfied for relevant continuous-time\nchannel models such as linear filters, whereas the condition used in this paper\nis satisfied for these models. Moreover, a weak converse is derived for all\nstationary channels with time structure. Intersymbol interference as well as\ninput constraints are taken into account in a general and flexible way,\nincluding amplitude and average power constraints as special case. Formulated\nin rigorous mathematical terms complete, explicit, and transparent proofs are\npresented. As a side product a gap in the proof of Kadota and Wyner -\nillustrated by a counterexample - is closed by providing a corrected proof of a\nlemma on the monotonicity of some sequence of normalized mutual information\nquantities. An abstract framework is established to treat discrete- and\ncontinuous-time channels with memory and arbitrary alphabets in a unified way.Comment: accepted for publication in IEEE Transactions on Information Theory", "1510.00549": "Bishellable drawings of $K_n$,\u00c1brego, Bernardo M.Aichholzer, OswinFern\u00e1ndez-Merchant, SilviaMcQuillan, DanMohar, BojanMutzel, PetraRamos, PedroRichter, R. BruceVogtenhuber, Birgit,Mathematics - CombinatoricsComputer Science - Computational Geometry05C10, 68R10,The Harary--Hill conjecture, still open after more than 50 years, asserts\nthat the crossing number of the complete graph $K_n$ is $ H(n) = \\frac 1 4\n\\left\\lfloor\\frac{\\mathstrut n}{\\mathstrut 2}\\right\\rfloor\n\\left\\lfloor\\frac{\\mathstrut n-1}{\\mathstrut 2}\\right\\rfloor\n\\left\\lfloor\\frac{\\mathstrut n-2}{\\mathstrut 2}\\right\\rfloor\n\\left\\lfloor\\frac{\\mathstrut n-3}{\\mathstrut 2}\\right \\rfloor$. \\'Abrego et al.\nintroduced the notion of shellability of a drawing $D$ of $K_n$. They proved\nthat if $D$ is $s$-shellable for some $s\\geq\\lfloor\\frac{n}{2}\\rfloor$, then\n$D$ has at least $H(n)$ crossings. This is the first combinatorial condition on\na drawing that guarantees at least $H(n)$ crossings. In this work, we\ngeneralize the concept of $s$-shellability to bishellability, where the former\nimplies the latter in the sense that every $s$-shellable drawing is, for any $b\n\\leq s-2$, also $b$-bishellable. Our main result is that $(\\lfloor \\frac{n}{2}\n\\rfloor\\!-\\!2)$-bishellability of a drawing $D$ of $K_n$ also guarantees, with\na simpler proof than for $s$-shellability, that $D$ has at least $H(n)$\ncrossings. We exhibit a drawing of $K_{11}$ that has $H(11)$ crossings, is\n3-bishellable, and is not $s$-shellable for any $s\\geq5$. This shows that we\nhave properly extended the class of drawings for which the Harary-Hill\nConjecture is proved. Moreover, we provide an infinite family of drawings of\n$K_n$ that are $(\\lfloor \\frac{n}{2} \\rfloor\\!-\\!2)$-bishellable, but not\n$s$-shellable for any $s\\geq\\lfloor\\frac{n}{2}\\rfloor$.Comment: 11 pages, 5 figures. updated, extended version", "1510.01072": "Routing in Unit Disk Graphs,Kaplan, HaimMulzer, WolfgangRoditty, LiamSeiferth, Paul,Computer Science - Computational GeometryComputer Science - Data Structures and Algorithms,Let $S \\subset \\mathbb{R}^2$ be a set of $n$ sites. The unit disk graph\n$\\text{UD}(S)$ on $S$ has vertex set $S$ and an edge between two distinct sites\n$s,t \\in S$ if and only if $s$ and $t$ have Euclidean distance $|st| \\leq 1$.\n  A routing scheme $R$ for $\\text{UD}(S)$ assigns to each site $s \\in S$ a\nlabel $\\ell(s)$ and a routing table $\\rho(s)$. For any two sites $s, t \\in S$,\nthe scheme $R$ must be able to route a packet from $s$ to $t$ in the following\nway: given a current site $r$ (initially, $r = s$), a header $h$ (initially\nempty), and the label $\\ell(t)$ of the target, the scheme $R$ consults the\nrouting table $\\rho(r)$ to compute a neighbor $r'$ of $r$, a new header $h'$,\nand the label $\\ell(t')$ of an intermediate target $t'$. (The label of the\noriginal target may be stored at the header $h'$.) The packet is then routed to\n$r'$, and the procedure is repeated until the packet reaches $t$. The resulting\nsequence of sites is called the routing path. The stretch of $R$ is the maximum\nratio of the (Euclidean) length of the routing path produced by $R$ and the\nshortest path in $\\text{UD}(S)$, over all pairs of distinct sites in $S$.\n  For any given $\\varepsilon > 0$, we show how to construct a routing scheme\nfor $\\text{UD}(S)$ with stretch $1+\\varepsilon$ using labels of $O(\\log n)$\nbits and routing tables of $O(\\varepsilon^{-5}\\log^2 n \\log^2 D)$ bits, where\n$D$ is the (Euclidean) diameter of $\\text{UD}(S)$. The header size is $O(\\log n\n\\log D)$ bits.Comment: 19 pages, 6 figures; a preliminary version appeared in LATIN 2016", "1510.01210": "Trading Networks with Bilateral Contracts,Fleiner, Tam\u00e1sJank\u00f3, ZsuzsannaTamura, AkihisaTeytelboym, Alexander,Computer Science - Computer Science and Game TheoryEconomics - General EconomicsJ.4G.2.1,We consider a model of matching in trading networks in which firms can enter\ninto bilateral contracts. In trading networks, stable outcomes, which are\nimmune to deviations of arbitrary sets of firms, may not exist. We define a new\nsolution concept called trail stability. Trail-stable outcomes are immune to\nconsecutive, pairwise deviations between linked firms. We show that any trading\nnetwork with bilateral contracts has a trail-stable outcome whenever firms'\nchoice functions satisfy the full substitutability condition. For trail-stable\noutcomes, we prove results on the lattice structure, the rural hospitals\ntheorem, strategy-proofness, and comparative statics of firm entry and exit. We\nalso introduce weak trail stability which is implied by trail stability under\nfull substitutability. We describe relationships between the solution concepts.", "1510.01429": "Distance-2 MDS codes and latin colorings in the Doob graphs,Krotov, DenisBespalov, Evgeny,Mathematics - CombinatoricsComputer Science - Discrete MathematicsComputer Science - Information Theory05B30,The maximum independent sets in the Doob graphs D(m,n) are analogs of the\ndistance-2 MDS codes in Hamming graphs and of the latin hypercubes. We prove\nthe characterization of these sets stating that every such set is semilinear or\nreducible. As related objects, we study vertex sets with maximum cut (edge\nboundary) in D(m,n) and prove some facts on their structure. We show that the\nconsidered two classes (the maximum independent sets and the maximum-cut sets)\ncan be defined as classes of completely regular sets with specified 2-by-2\nquotient matrices. It is notable that for a set from the considered classes,\nthe eigenvalues of the quotient matrix are the maximum and the minimum\neigenvalues of the graph. For D(m,0), we show the existence of a third,\nintermediate, class of completely regular sets with the same property.Comment: 18pp", "1510.01518": "DC Decomposition of Nonconvex Polynomials with Algebraic Techniques,Ahmadi, Amir AliHall, Georgina,Mathematics - Optimization and ControlComputer Science - Data Structures and AlgorithmsStatistics - Machine Learning,We consider the problem of decomposing a multivariate polynomial as the\ndifference of two convex polynomials. We introduce algebraic techniques which\nreduce this task to linear, second order cone, and semidefinite programming.\nThis allows us to optimize over subsets of valid difference of convex\ndecompositions (dcds) and find ones that speed up the convex-concave procedure\n(CCP). We prove, however, that optimizing over the entire set of dcds is\nNP-hard.", "1510.01591": "On the codes over the Z_3+vZ_3+v^2Z_3,Dertli, AbdullahCengellenmis, YaseinEren, Senol,Computer Science - Information TheoryQuantum Physics,In this paper, we study the structure of cyclic, quasi-cyclic, constacyclic\ncodes and their skew codes over the finite ring R=Z_3+vZ_3+v^2Z_3, v^3=v. The\nGray images of cyclic, quasi-cyclic, skew cyclic, skew quasi-cyclic and skew\nconstacyclic codes over R are obtained. A necessary and sufficient condition\nfor cyclic (negacyclic) codes over R that contains its dual has been given. The\nparameters of quantum error correcting codes are obtained from both cyclic and\nnegacyclic codes over R. It is given some examples. Firstly, quasi-constacyclic\nand skew quasi-constacyclic codes are introduced. By giving two product, it is\ninvestigated their duality. A sufficient condition for 1-generator skew\nquasi-constacyclic codes to be free is determined.", "1510.01671": "Cross-boundary Behavioural Reprogrammability Reveals Evidence of\n  Pervasive Universality,Riedel, J\u00fcrgenZenil, Hector,Computer Science - Formal Languages and Automata TheoryComputer Science - Computational ComplexityNonlinear Sciences - Cellular Automata and Lattice Gases,We exhaustively explore the reprogrammability capabilities and the intrinsic\nuniversality of the Cartesian product $P \\times C$ of the space $P$ of all\npossible computer programs of increasing size and the space $C$ of all possible\ncompilers of increasing length such that $p \\in P$ emulates $p^\\prime \\in P$\nwith $T|p^\\prime|=|p|$ under a coarse-graining transformation $T$. Our approach\nyields a novel perspective on the complexity, controllability, causality and\n(re)programmability discrete dynamical systems. We find evidence that the\ndensity of (qualitatively different) computer programs that can be reprogrammed\ngrows asymptotically as a function of program and compiler size. To illustrate\nthese findings we show a series of behavioural boundary crossing results,\nincluding emulations (for all initial conditions) of Wolfram class 2 Elementary\nCellular Automata (ECA) by Class 1 ECA, emulations of Classes 1, 2 and 3 ECA by\nClass 2 and 3 ECA, and of Classes 1, 2 and 3 by Class 3 ECA, along with results\nof even greater emulability for general CA (neighbourhood $r=3/2$), including\nClass 1 CA emulating Classes 2 and 3, and Classes 3 and 4 emulating all other\nclasses (1, 2, 3 and 4). The emulations occur with only a linear overhead and\ncan be considered computationally efficient. We also found that there is no\nhacking strategy to compress the search space based on compiler profiling in\nterms of e.g. similarity or complexity, suggesting that no strategy other than\nexhaustive search is viable. We also introduce emulation networks, derive a\ntopologically-based measure of complexity based upon out- and in-degree\nconnectivity, and establish bridges to fundamental ideas of complexity,\nuniversality, causality and dynamical systems.Comment: 22 pages, 51 pages including Supplemental, 10 figures, code available\n  online at URL in the paper", "1510.01819": "Balanced Islands in Two Colored Point Sets in the Plane,Aichholzer, OswinAtienza, NievesFabila-Monroy, RuyPerez-Lantero, PabloD\u0131az-B\u00e1\u00f1ez, Jose M.Flores-Pe\u00f1aloza, DavidVogtenhuber, BirgitUrrutia, Jorge,Computer Science - Computational Geometry,Let $S$ be a set of $n$ points in general position in the plane, $r$ of which\nare red and $b$ of which are blue. In this paper we prove that there exist: for\nevery $\\alpha \\in \\left [ 0,\\frac{1}{2} \\right ]$, a convex set containing\nexactly $\\lceil \\alpha r\\rceil$ red points and exactly $\\lceil \\alpha b \\rceil$\nblue points of $S$; a convex set containing exactly $\\left \\lceil\n\\frac{r+1}{2}\\right \\rceil$ red points and exactly $\\left \\lceil\n\\frac{b+1}{2}\\right \\rceil$ blue points of $S$. Furthermore, we present\npolynomial time algorithms to find these convex sets. In the first case we\nprovide an $O(n^4)$ time algorithm and an $O(n^2\\log n)$ time algorithm in the\nsecond case. Finally, if $\\lceil \\alpha r\\rceil+\\lceil \\alpha b\\rceil$ is\nsmall, that is, not much larger than $\\frac{1}{3}n$, we improve the running\ntime to $O(n \\log n)$.", "1510.01844": "Linear Bounds between Contraction Coefficients for $f$-Divergences,Makur, AnuranZheng, Lizhong,Computer Science - Information TheoryMathematics - ProbabilityMathematics - Statistics Theory,Data processing inequalities for $f$-divergences can be sharpened using\nconstants called \"contraction coefficients\" to produce strong data processing\ninequalities. For any discrete source-channel pair, the contraction\ncoefficients for $f$-divergences are lower bounded by the contraction\ncoefficient for $\\chi^2$-divergence. In this paper, we elucidate that this\nlower bound can be achieved by driving the input $f$-divergences of the\ncontraction coefficients to zero. Then, we establish a linear upper bound on\nthe contraction coefficients for a certain class of $f$-divergences using the\ncontraction coefficient for $\\chi^2$-divergence, and refine this upper bound\nfor the salient special case of Kullback-Leibler (KL) divergence. Furthermore,\nwe present an alternative proof of the fact that the contraction coefficients\nfor KL and $\\chi^2$-divergences are equal for a Gaussian source with an\nadditive Gaussian noise channel (where the former coefficient can be power\nconstrained). Finally, we generalize the well-known result that contraction\ncoefficients of channels (after extremizing over all possible sources) for all\n$f$-divergences with non-linear operator convex $f$ are equal. In particular,\nwe prove that the so called \"less noisy\" preorder over channels can be\nequivalently characterized by any non-linear operator convex $f$-divergence.Comment: Part of this work has been published in the 53rd Annual Allerton\n  Conference on Communication, Control, and Computing, 2015. This version\n  includes an overview of contraction coefficients as well as some new results", "1510.01913": "On the Uniform Computational Content of the Baire Category Theorem,Brattka, VascoHendtlass, MatthewKreuzer, Alexander P.,Mathematics - LogicComputer Science - Logic in Computer Science,We study the uniform computational content of different versions of the Baire\nCategory Theorem in the Weihrauch lattice. The Baire Category Theorem can be\nseen as a pigeonhole principle that states that a complete (i.e., \"large\")\nmetric space cannot be decomposed into countably many nowhere dense (i.e.,\n\"small\") pieces. The Baire Category Theorem is an illuminating example of a\ntheorem that can be used to demonstrate that one classical theorem can have\nseveral different computational interpretations. For one, we distinguish two\ndifferent logical versions of the theorem, where one can be seen as the\ncontrapositive form of the other one. The first version aims to find an\nuncovered point in the space, given a sequence of nowhere dense closed sets.\nThe second version aims to find the index of a closed set that is somewhere\ndense, given a sequence of closed sets that cover the space. Even though the\ntwo statements behind these versions are equivalent to each other in classical\nlogic, they are not equivalent in intuitionistic logic and likewise they\nexhibit different computational behavior in the Weihrauch lattice. Besides this\nlogical distinction, we also consider different ways how the sequence of closed\nsets is \"given\". Essentially, we can distinguish between positive and negative\ninformation on closed sets. We discuss all the four resulting versions of the\nBaire Category Theorem. Somewhat surprisingly it turns out that the difference\nin providing the input information can also be expressed with the jump\noperation. Finally, we also relate the Baire Category Theorem to notions of\ngenericity and computably comeager sets.Comment: 28 pages", "1510.02438": "Decomposing 1-Sperner hypergraphs,Boros, EndreGurvich, VladimirMilani\u010d, Martin,Mathematics - CombinatoricsComputer Science - Discrete Mathematics05C65, 94C10,A hypergraph is Sperner if no hyperedge contains another one. A Sperner\nhypergraph is equilizable (resp., threshold) if the characteristic vectors of\nits hyperedges are the (minimal) binary solutions to a linear equation (resp.,\ninequality) with positive coefficients. These combinatorial notions have many\napplications and are motivated by the theory of Boolean functions and integer\nprogramming. We introduce in this paper the class of $1$-Sperner hypergraphs,\ndefined by the property that for every two hyperedges the smallest of their two\nset differences is of size one. We characterize this class of Sperner\nhypergraphs by a decomposition theorem and derive several consequences from it.\nIn particular, we obtain bounds on the size of $1$-Sperner hypergraphs and\ntheir transversal hypergraphs, show that the characteristic vectors of the\nhyperedges are linearly independent over the reals, and prove that $1$-Sperner\nhypergraphs are both threshold and equilizable. The study of $1$-Sperner\nhypergraphs is motivated also by their applications in graph theory, which we\npresent in a companion paper.", "1510.02659": "Windrose Planarity: Embedding Graphs with Direction-Constrained Edges,Angelini, PatrizioDa Lozzo, GiordanoDi Battista, GiuseppeDi Donato, ValentinoKindermann, PhilippRote, G\u00fcnterRutter, Ignaz,Computer Science - Computational Geometry,Given a planar graph $G$ and a partition of the neighbors of each vertex $v$\nin four sets $UR(v)$, $UL(v)$, $DL(v)$, and $DR(v)$, the problem Windrose\nPlanarity asks to decide whether $G$ admits a windrose-planar drawing, that is,\na planar drawing in which (i) each neighbor $u \\in UR(v)$ is above and to the\nright of $v$, (ii) each neighbor $u \\in UL(v)$ is above and to the left of $v$,\n(iii) each neighbor $u \\in DL(v)$ is below and to the left of $v$, (iv) each\nneighbor $u \\in DR(v)$ is below and to the right of $v$, and (v) edges are\nrepresented by curves that are monotone with respect to each axis. By\nexploiting both the horizontal and the vertical relationship among vertices,\nwindrose-planar drawings allow to simultaneously visualize two partial orders\ndefined by means of the edges of the graph.\n  Although the problem is NP-hard in the general case, we give a\npolynomial-time algorithm for testing whether there exists a windrose-planar\ndrawing that respects a given combinatorial embedding. This algorithm is based\non a characterization of the plane triangulations admitting a windrose-planar\ndrawing. Furthermore, for any embedded graph with $n$ vertices that has a\nwindrose-planar drawing, we can construct one with at most one bend per edge\nand with at most $2n-5$ bends in total, which lies on the $3n \\times 3n$ grid.\nThe latter result contrasts with the fact that straight-line windrose-planar\ndrawings may require exponential area.Comment: Appeared in Proceedings of the 27th Annual ACM-SIAM Symposium on\n  Discrete Algorithms (SODA 2016)", "1510.02786": "Recovering a Hidden Community Beyond the Kesten-Stigum Threshold in\n  $O(|E| \\log^*|V|)$ Time,Hajek, BruceWu, YihongXu, Jiaming,Statistics - Machine LearningComputer Science - Computational ComplexityComputer Science - Social and Information NetworksMathematics - Probability,Community detection is considered for a stochastic block model graph of n\nvertices, with K vertices in the planted community, edge probability p for\npairs of vertices both in the community, and edge probability q for other pairs\nof vertices.\n  The main focus of the paper is on weak recovery of the community based on the\ngraph G, with o(K) misclassified vertices on average, in the sublinear regime\n$n^{1-o(1)} \\leq K \\leq o(n).$ A critical parameter is the effective\nsignal-to-noise ratio $\\lambda=K^2(p-q)^2/((n-K)q)$, with $\\lambda=1$\ncorresponding to the Kesten-Stigum threshold. We show that a belief propagation\nalgorithm achieves weak recovery if $\\lambda>1/e$, beyond the Kesten-Stigum\nthreshold by a factor of $1/e.$ The belief propagation algorithm only needs to\nrun for $\\log^\\ast n+O(1) $ iterations, with the total time complexity $O(|E|\n\\log^*n)$, where $\\log^*n$ is the iterated logarithm of $n.$ Conversely, if\n$\\lambda \\leq 1/e$, no local algorithm can asymptotically outperform trivial\nrandom guessing. Furthermore, a linear message-passing algorithm that\ncorresponds to applying power iteration to the non-backtracking matrix of the\ngraph is shown to attain weak recovery if and only if $\\lambda>1$. In addition,\nthe belief propagation algorithm can be combined with a linear-time voting\nprocedure to achieve the information limit of exact recovery (correctly\nclassify all vertices with high probability) for all $K \\ge \\frac{n}{\\log n}\n\\left( \\rho_{\\rm BP} +o(1) \\right),$ where $\\rho_{\\rm BP}$ is a function of\n$p/q$.Comment: New title replaces spectral limit by Kesten-Stigum threshold", "1510.02787": "The grounding for Continuum,Ambroszkiewicz, Stanislaw,Mathematics - LogicComputer Science - Logic in Computer Science03DF.4.1,It is a ubiquitous opinion among mathematicians that a real number is just a\npoint in the line. If this rough definition is not enough, then a mathematician\nmay provide a formal definition of the real numbers in the set theoretic and\naxiomatic fashion, i.e. via Cauchy sequences or Dedekind cuts, or as the\ncollection of axioms characterizing exactly (up to isomorphism) the set of real\nnumbers as the complete and totally ordered Archimedean field. Actually, the\nabove notions of the real numbers are abstract and do not have a constructive\ngrounding. Definition of Cauchy sequences, and equivalence classes of these\nsequences explicitly use the actual infinity. The same is for Dedekind cuts,\nwhere the set of rational numbers is used as actual infinity. Although there is\nno direct constructive grounding for these abstract notions, there are so\ncalled intuitions on which they are based. A rigorous approach to express these\nvery intuition in a constructive way is proposed. It is based on the concept of\nthe adjacency relation that seems to be a missing primitive concept in type\ntheory. The approach corresponds to the intuitionistic view of Continuum\nproposed by Brouwer. The famous and controversial Brouwer Continuity Theorem is\ndiscussed on the basis of different principle than the Axiom of Continuity. The\nreal numbers are the cornerstone of Calculus, Homotopy theory, Riemannian\ngeometry, and many others important subjects. The proposed grounding of\nContinuum is discussed in the context of these subjects.Comment: This is the second part of the general framework for a constructive\n  type theory presented in the paper Functionals and hardware arXiv:1501.03043.\n  In this version small errors were corrected", "1510.02807": "Avoiding fractional powers over the natural numbers,Pudwell, LaraRowland, Eric,Mathematics - CombinatoricsComputer Science - Discrete Mathematics,We study the lexicographically least infinite $a/b$-power-free word on the\nalphabet of non-negative integers. Frequently this word is a fixed point of a\nuniform morphism, or closely related to one. For example, the lexicographically\nleast $7/4$-power-free word is a fixed point of a $50847$-uniform morphism. We\nidentify the structure of the lexicographically least $a/b$-power-free word for\nthree infinite families of rationals $a/b$ as well many \"sporadic\" rationals\nthat do not seem to belong to general families. To accomplish this, we develop\nan automated procedure for proving $a/b$-power-freeness for morphisms of a\ncertain form, both for explicit and symbolic rational numbers $a/b$. Finally,\nwe establish a connection to words on a finite alphabet. Namely, the\nlexicographically least $27/23$-power-free word is in fact a word on the finite\nalphabet $\\{0, 1, 2\\}$, and its sequence of letters is $353$-automatic.Comment: 42 pages, 5 figures; publication version", "1510.02833": "On the Definiteness of Earth Mover's Distance and Its Relation to Set\n  Intersection,Gardner, AndrewDuncan, Christian A.Kanno, JinkoSelmic, Rastko R.,Computer Science - Machine LearningStatistics - Machine Learning,Positive definite kernels are an important tool in machine learning that\nenable efficient solutions to otherwise difficult or intractable problems by\nimplicitly linearizing the problem geometry. In this paper we develop a\nset-theoretic interpretation of the Earth Mover's Distance (EMD) and propose\nEarth Mover's Intersection (EMI), a positive definite analog to EMD for sets of\ndifferent sizes. We provide conditions under which EMD or certain\napproximations to EMD are negative definite. We also present a\npositive-definite-preserving transformation that can be applied to any kernel\nand can also be used to derive positive definite EMD-based kernels and show\nthat the Jaccard index is simply the result of this transformation. Finally, we\nevaluate kernels based on EMI and the proposed transformation versus EMD in\nvarious computer vision tasks and show that EMD is generally inferior even with\nindefinite kernel techniques.Comment: Major revision based on referee comments. Includes significant\n  reorganization of content, new title, new propositions, revised proofs of\n  previous propositions, and additional experiments with new data, kernels, and\n  indefinite kernel techniques", "1510.02923": "On 1-Laplacian Elliptic Equations Modeling Magnetic Resonance Image\n  Rician Denoising,Martin, AdrianSchiavi, Emanuelede Leon, Sergio Segura,Mathematics - Analysis of PDEsComputer Science - Computer Vision and Pattern RecognitionMathematics - Numerical Analysis,Modeling magnitude Magnetic Resonance Images (MRI) rician denoising in a\nBayesian or generalized Tikhonov framework using Total Variation (TV) leads\nnaturally to the consideration of nonlinear elliptic equations. These involve\nthe so called $1$-Laplacian operator and special care is needed to properly\nformulate the problem. The rician statistics of the data are introduced through\na singular equation with a reaction term defined in terms of modified first\norder Bessel functions. An existence theory is provided here together with\nother qualitative properties of the solutions. Remarkably, each positive global\nminimum of the associated functional is one of such solutions. Moreover, we\ndirectly solve this non--smooth non--convex minimization problem using a\nconvergent Proximal Point Algorithm. Numerical results based on synthetic and\nreal MRI demonstrate a better performance of the proposed method when compared\nto previous TV based models for rician denoising which regularize or convexify\nthe problem. Finally, an application on real Diffusion Tensor Images, a\nstrongly affected by rician noise MRI modality, is presented and discussed.", "1510.03170": "Fair and Square: Cake-Cutting in Two Dimensions,Segal-Halevi, ErelNitzan, ShmuelHassidim, AvinatanAumann, Yonatan,Computer Science - Computer Science and Game TheoryComputer Science - Computational Geometry,We consider the classic problem of fairly dividing a heterogeneous good\n(\"cake\") among several agents with different valuations. Classic cake-cutting\nprocedures either allocate each agent a collection of disconnected pieces, or\nassume that the cake is a one-dimensional interval. In practice, however, the\ntwo-dimensional shape of the allotted pieces is important. In particular, when\nbuilding a house or designing an advertisement in printed or electronic media,\nsquares are more usable than long and narrow rectangles. We thus introduce and\nstudy the problem of fair two-dimensional division wherein the allotted pieces\nmust be of some restricted two-dimensional geometric shape(s), particularly\nsquares and fat rectangles. Adding such geometric constraints re-opens most\nquestions and challenges related to cake-cutting. Indeed, even the most\nelementary fairness criterion --- proportionality --- can no longer be\nguaranteed. In this paper we thus examine the level of proportionality that can\nbe guaranteed, providing both impossibility results and constructive division\nprocedures.Comment: Journal version", "1510.03271": "A Core Model for Choreographic Programming,Cruz-Filipe, Lu\u00edsMontesi, Fabrizio,Computer Science - Programming Languages,Choreographic Programming is a programming paradigm for building concurrent\nprograms that are deadlock-free by construction, as a result of programming\ncommunications declaratively and then synthesising process implementations\nautomatically. Despite strong interest on choreographies, a foundational model\nthat explains which computations can be performed with the hallmark constructs\nof choreographies is still missing.\n  In this work, we introduce Core Choreographies (CC), a model that includes\nonly the core primitives of choreographic programming. Every computable\nfunction can be implemented as a choreography in CC, from which we can\nsynthesise a process implementation where independent computations run in\nparallel. We discuss the design of CC and argue that it constitutes a canonical\nmodel for choreographic programming.", "1510.03637": "Applied Choreographies,Giallorenzo, SaverioMontesi, FabrizioGabbrielli, Maurizio,Computer Science - Programming Languages,Choreographic Programming is a correct-by-construction paradigm for\ndistributed programming, where global declarative descriptions of\ncommunications (choreographies) are used to synthesise deadlock-free processes.\nChoreographies are global descriptions of communications in concurrent systems,\nwhich have been used in different methodologies for the verification or\nsynthesis of programs. However, there is no formalisation that provides a chain\nof correctness from choreographies to their implementations. This problem\noriginates from the gap between previous theoretical models, which abstract\ncommunications using channel names (\\`a la CCS/$\\pi$-calculus), and their\nimplementations, which use low-level mechanisms for message routing. As a\nsolution, we propose the framework of Applied Choreographies (AC). In AC,\nprogrammers write choreographies in a language that follows the standard syntax\nand semantics of previous works. Then, choreographies are compiled to a\nreal-world execution model for Service-Oriented Computing (SOC). To manage the\ncomplexity of this task, our compilation happens in three steps, respectively\ndealing with: implementing name-based communications using the concrete\nmechanism found in SOC, projecting a choreography to a set of processes, and\ntranslating processes to a distributed implementation in terms of services. For\neach step a suitable correspondence result guarantees that the behaviour is\npreserved, thus ensuring the correctness of the global compilation process.\nThis is the first correctness result of an end-to-end translation from standard\nchoreographies to programs based on a \"real-world\" communication mechanism.", "1510.03840": "Dynamic Spectrum Sensing Through Accelerated Particle Swarm Optimization,Paschos, Alexandros E.Kapinas, Vasileios M.Ntouni, Georgia D.Hadjileontiadis, Leontios J.Karagiannidis, George K.,Mathematics - Optimization and ControlComputer Science - Information TheoryStatistics - Applications,In this paper, a novel optimization algorithm, called the acceleration-aided\nparticle swarm optimization (AAPSO), is proposed for reliable dynamic spectrum\nsensing in cognitive radio networks. In A-APSO, the acceleration variable of\nthe particles in the swarm is also considered in the search space of the\noptimization problem. We show that the proposed A-APSO based spectrum sensing\ntechnique is more efficient in terms of performance than the corresponding one\nbased on the standard particle swarm optimization algorithm.Comment: 4 pages, 3 figures, 2 algorithms, 1 table", "1510.03895": "A faster subquadratic algorithm for finding outlier correlations,Karppa, MattiKaski, PetteriKohonen, Jukka,Computer Science - Data Structures and Algorithms65F30, 68W20, 62H20, 68T05, 68Q32F.2.1I.1.2G.3H.2.8H.3.3I.2.6,We study the problem of detecting outlier pairs of strongly correlated\nvariables among a collection of $n$ variables with otherwise weak pairwise\ncorrelations. After normalization, this task amounts to the geometric task\nwhere we are given as input a set of $n$ vectors with unit Euclidean norm and\ndimension $d$, and for some constants $0<\\tau<\\rho<1$, we are asked to find all\nthe outlier pairs of vectors whose inner product is at least $\\rho$ in absolute\nvalue, subject to the promise that all but at most $q$ pairs of vectors have\ninner product at most $\\tau$ in absolute value.\n  Improving on an algorithm of G. Valiant [FOCS 2012; J. ACM 2015], we present\na randomized algorithm that for Boolean inputs ($\\{-1,1\\}$-valued data\nnormalized to unit Euclidean length) runs in time \\[ \\tilde\nO\\bigl(n^{\\max\\,\\{1-\\gamma+M(\\Delta\\gamma,\\gamma),\\,M(1-\\gamma,2\\Delta\\gamma)\\}}+qdn^{2\\gamma}\\bigr)\\,,\n\\] where $0<\\gamma<1$ is a constant tradeoff parameter and $M(\\mu,\\nu)$ is the\nexponent to multiply an $\\lfloor n^\\mu\\rfloor\\times\\lfloor n^\\nu\\rfloor$ matrix\nwith an $\\lfloor n^\\nu\\rfloor\\times \\lfloor n^\\mu\\rfloor$ matrix and\n$\\Delta=1/(1-\\log_\\tau\\rho)$. As corollaries we obtain randomized algorithms\nthat run in time \\[ \\tilde\nO\\bigl(n^{\\frac{2\\omega}{3-\\log_\\tau\\rho}}+qdn^{\\frac{2(1-\\log_\\tau\\rho)}{3-\\log_\\tau\\rho}}\\bigr)\n\\] and in time \\[ \\tilde\nO\\bigl(n^{\\frac{4}{2+\\alpha(1-\\log_\\tau\\rho)}}+qdn^{\\frac{2\\alpha(1-\\log_\\tau\\rho)}{2+\\alpha(1-\\log_\\tau\\rho)}}\\bigr)\\,,\n\\] where $2\\leq\\omega<2.38$ is the exponent for square matrix multiplication\nand $0.3<\\alpha\\leq 1$ is the exponent for rectangular matrix multiplication.\nThe notation $\\tilde O(\\cdot)$ hides polylogarithmic factors in $n$ and $d$\nwhose degree may depend on $\\rho$ and $\\tau$. We present further corollaries\nfor the light bulb problem and for learning sparse Boolean functions.Comment: ACM TALG, to appear", "1510.03903": "Fair Cake-Cutting among Families,Segal-Halevi, ErelNitzan, Shmuel,Computer Science - Computer Science and Game Theory,We study the fair division of a continuous resource, such as a land-estate or\na time-interval, among pre-specified groups of agents, such as families. Each\nfamily is given a piece of the resource and this piece is used simultaneously\nby all family members, while different members may have different value\nfunctions. Three ways to assess the fairness of such a division are examined.\n(a) *Average fairness* means that each family's share is fair according to the\n\"family value function\", defined as the arithmetic mean of the value functions\nof the family members. (b) *Unanimous fairness* means that all members in all\nfamilies feel that their family received a fair share according to their\npersonal value function. (c) *Democratic fairness* means that in each family,\nat least half the members feel that their family's share is fair. We compare\nthese criteria based on the number of connected components in the resulting\ndivision, and based on their compatibility with Pareto-efficiency.Comment: Improved results for envy-freeness", "1510.03935": "Surface Approximation via Asymptotic Optimal Geometric Partition,Cai, YiqiGuo, XiaohuLiu, YangWang, WenpingMao, WeihuaZhong, Zichun,Computer Science - Graphics,In this paper, we present a surface remeshing method with high approximation\nquality based on Principal Component Analysis. Given a triangular mesh and a\nuser assigned polygon/vertex budget, traditional methods usually require the\nextra curvature metric field for the desired anisotropy to best approximate the\nsurface, even though the estimated curvature metric is known to be imperfect\nand already self-contained in the surface. In our approach, this anisotropic\ncontrol is achieved through the optimal geometry partition without this\nexplicit metric field. The minimization of our proposed partition energy has\nthe following properties: Firstly, on a C2 surface, it is theoretically\nguaranteed to have the optimal aspect ratio and cluster size as specified in\napproximation theory for L1 piecewise linear approximation. Secondly, it\ncaptures sharp features on practical models without any pre-tagging. We develop\nan effective merging-swapping framework to seek the optimal partition and\nconstruct polygonal/triangular mesh afterwards. The effectiveness and\nefficiency of our method are demonstrated through the comparison with other\nstate-of-the-art remeshing methods.Comment: 14 pages, 20 figures", "1510.04249": "Random Irregular Block-hierarchical Networks: Algorithms for Computation\n  of Main Properties,Avetisyan, SvetlanaSamvelyan, MikayelKarapetyan, Martun,Computer Science - Data Structures and Algorithms,In this paper, the class of random irregular block-hierarchical networks is\ndefined and algorithms for generation and calculation of network properties are\ndescribed. The algorithms presented for this class of networks are more\nefficient than known algorithms both in computation time and memory usage and\ncan be used to analyze topological properties of such networks. The algorithms\nare implemented in the system created by the authors for the study of\ntopological and statistical properties of random networks.Comment: The original is in Russian", "1510.04389": "Sketch-based Manga Retrieval using Manga109 Dataset,Matsui, YusukeIto, KotaAramaki, YujiYamasaki, ToshihikoAizawa, Kiyoharu,Computer Science - Computer Vision and Pattern RecognitionComputer Science - Information RetrievalComputer Science - Multimedia,Manga (Japanese comics) are popular worldwide. However, current e-manga\narchives offer very limited search support, including keyword-based search by\ntitle or author, or tag-based categorization. To make the manga search\nexperience more intuitive, efficient, and enjoyable, we propose a content-based\nmanga retrieval system. First, we propose a manga-specific image-describing\nframework. It consists of efficient margin labeling, edge orientation histogram\nfeature description, and approximate nearest-neighbor search using product\nquantization. Second, we propose a sketch-based interface as a natural way to\ninteract with manga content. The interface provides sketch-based querying,\nrelevance feedback, and query retouch. For evaluation, we built a novel dataset\nof manga images, Manga109, which consists of 109 comic books of 21,142 pages\ndrawn by professional manga artists. To the best of our knowledge, Manga109 is\ncurrently the biggest dataset of manga images available for research. We\nconducted a comparative study, a localization evaluation, and a large-scale\nqualitative study. From the experiments, we verified that: (1) the retrieval\naccuracy of the proposed method is higher than those of previous methods; (2)\nthe proposed method can localize an object instance with reasonable runtime and\naccuracy; and (3) sketch querying is useful for manga search.Comment: 13 pages", "1510.04390": "Dual Principal Component Pursuit,Tsakiris, Manolis C.Vidal, Rene,Computer Science - Computer Vision and Pattern RecognitionComputer Science - Machine Learning,We consider the problem of learning a linear subspace from data corrupted by\noutliers. Classical approaches are typically designed for the case in which the\nsubspace dimension is small relative to the ambient dimension. Our approach\nworks with a dual representation of the subspace and hence aims to find its\northogonal complement; as such, it is particularly suitable for subspaces whose\ndimension is close to the ambient dimension (subspaces of high relative\ndimension). We pose the problem of computing normal vectors to the inlier\nsubspace as a non-convex $\\ell_1$ minimization problem on the sphere, which we\ncall Dual Principal Component Pursuit (DPCP) problem. We provide theoretical\nguarantees under which every global solution to DPCP is a vector in the\northogonal complement of the inlier subspace. Moreover, we relax the non-convex\nDPCP problem to a recursion of linear programs whose solutions are shown to\nconverge in a finite number of steps to a vector orthogonal to the subspace. In\nparticular, when the inlier subspace is a hyperplane, the solutions to the\nrecursion of linear programs converge to the global minimum of the non-convex\nDPCP problem in a finite number of steps. We also propose algorithms based on\nalternating minimization and iteratively re-weighted least squares, which are\nsuitable for dealing with large-scale data. Experiments on synthetic data show\nthat the proposed methods are able to handle more outliers and higher relative\ndimensions than current state-of-the-art methods, while experiments in the\ncontext of the three-view geometry problem in computer vision suggest that the\nproposed methods can be a useful or even superior alternative to traditional\nRANSAC-based approaches for computer vision and other applications.", "1510.04524": "Old Bands, New Tracks---Revisiting the Band Model for Robust Hypothesis\n  Testing,Fau\u00df, MichaelZoubir, Abdelhak M.,Computer Science - Information Theory62C20,The density band model proposed by Kassam for robust hypothesis testing is\nrevisited in this paper. First, a novel criterion for the general\ncharacterization of least favorable distributions is proposed, which unifies\nexisting results. This criterion is then used to derive an implicit definition\nof the least favorable distributions under band uncertainties. In contrast to\nthe existing solution, it only requires two scalar values to be determined and\neliminates the need for case-by-case statements. Based on this definition, a\ngeneric fixed-point algorithm is proposed that iteratively calculates the least\nfavorable distributions for arbitrary band specifications. Finally, three\ndifferent types of robust tests that emerge from band models are discussed and\na numerical example is presented to illustrate their potential use in practice.Comment: 12 pages, 4 figures, published in the IEEE Transactions on Signal\n  Processing", "1510.04780": "A Graph Traversal Based Approach to Answer Non-Aggregation Questions\n  Over DBpedia,Zhu, ChenhaoRen, KanLiu, XuanWang, HaofenTian, YidingYu, Yong,Computer Science - Computation and LanguageComputer Science - Information Retrieval,We present a question answering system over DBpedia, filling the gap between\nuser information needs expressed in natural language and a structured query\ninterface expressed in SPARQL over the underlying knowledge base (KB). Given\nthe KB, our goal is to comprehend a natural language query and provide\ncorresponding accurate answers. Focusing on solving the non-aggregation\nquestions, in this paper, we construct a subgraph of the knowledge base from\nthe detected entities and propose a graph traversal method to solve both the\nsemantic item mapping problem and the disambiguation problem in a joint way.\nCompared with existing work, we simplify the process of query intention\nunderstanding and pay more attention to the answer path ranking. We evaluate\nour method on a non-aggregation question dataset and further on a complete\ndataset. Experimental results show that our method achieves best performance\ncompared with several state-of-the-art systems.Comment: In the proceedings of the 5th Joint International Semantic Technology\n  (JIST2015): https://link.springer.com/chapter/10.1007/978-3-319-31676-5_16", "1510.05071": "Distributed Robust Adaptive Frequency Control of Power Systems with\n  Dynamic Loads,Kim, HunminZhu, MinghuiLian, Jianming,Computer Science - Systems and Control,This paper investigates the frequency control of multi-machine power systems\nsubject to uncertain and dynamic net loads. We propose distributed internal\nmodel controllers which coordinate synchronous generators and demand response\nto tackle the unpredictable nature of net loads. Frequency stability is\nformally guaranteed via Lyapunov analysis. Numerical simulations on the IEEE\n68-bus test system as well as the Minni-WECC system demonstrate the\neffectiveness of the controllers and performance under a three-phase fault and\nload-switching during light/peak loads.Comment: Submitted to the IEEE Transaction on Automatic Control", "1510.05175": "Top-k Query Processing on Encrypted Databases with Strong Security\n  Guarantees,Meng, XianruiZhu, HaohanKollios, George,Computer Science - Cryptography and SecurityH.2.7K.4.4H.2.4,Privacy concerns in outsourced cloud databases have become more and more\nimportant recently and many efficient and scalable query processing methods\nover encrypted data have been proposed. However, there is very limited work on\nhow to securely process top-k ranking queries over encrypted databases in the\ncloud. In this paper, we focus exactly on this problem: secure and efficient\nprocessing of top-k queries over outsourced databases. In particular, we\npropose the first efficient and provable secure top-k query processing\nconstruction that achieves adaptively CQA security. We develop an encrypted\ndata structure called EHL and describe several secure sub-protocols under our\nsecurity model to answer top-k queries. Furthermore, we optimize our query\nalgorithms for both space and time efficiency. Finally, in the experiments, we\nempirically analyze our protocol using real world datasets and demonstrate that\nour construction is efficient and practical.", "1510.05229": "Monotonicity and Competitive Equilibrium in Cake-cutting,Segal-Halevi, ErelSziklai, Bal\u00e1zs,Computer Science - Computer Science and Game Theory,We study the monotonicity properties of solutions in the classic problem of\nfair cake-cutting --- dividing a heterogeneous resource among agents with\ndifferent preferences. Resource- and population-monotonicity relate to\nscenarios where the cake, or the number of participants who divide the cake,\nchanges. It is required that the utility of all participants change in the same\ndirection: either all of them are better-off (if there is more to share or\nfewer to share among) or all are worse-off (if there is less to share or more\nto share among).\n  We formally introduce these concepts to the cake-cutting problem and examine\nwhether they are satisfied by various common division rules. We prove that the\nNash-optimal rule, which maximizes the product of utilities, is\nresource-monotonic and population-monotonic, in addition to being\nPareto-optimal, envy-free and satisfying a strong competitive-equilibrium\ncondition. Moreover, we prove that it is the only rule among a natural family\nof welfare-maximizing rules that is both proportional and resource-monotonic.Comment: Revised version", "1510.05278": "A First Practical Fully Homomorphic Crypto-Processor Design: The Secret\n  Computer is Nearly Here,Breuer, PeterBowen, Jonathan,Computer Science - Cryptography and Security,Following a sequence of hardware designs for a fully homomorphic\ncrypto-processor - a general purpose processor that natively runs encrypted\nmachine code on encrypted data in registers and memory, resulting in encrypted\nmachine states - proposed by the authors in 2014, we discuss a working\nprototype of the first of those, a so-called `pseudo-homomorphic' design. This\nprocessor is in principle safe against physical or software-based attacks by\nthe owner/operator of the processor on user processes running in it. The\nprocessor is intended as a more secure option for those emerging computing\nparadigms that require trust to be placed in computations carried out in remote\nlocations or overseen by untrusted operators.\n  The prototype has a single-pipeline superscalar architecture that runs\nOpenRISC standard machine code in two distinct modes. The processor runs in the\nencrypted mode (the unprivileged, `user' mode, with a long pipeline) at 60-70%\nof the speed in the unencrypted mode (the privileged, `supervisor' mode, with a\nshort pipeline), emitting a completed encrypted instruction every 1.67-1.8\ncycles on average in real trials.Comment: 6 pages, draft", "1510.05461": "Confidence Sets for the Source of a Diffusion in Regular Trees,Khim, JustinLoh, Po-Ling,Mathematics - Statistics TheoryComputer Science - Discrete MathematicsComputer Science - Social and Information NetworksMathematics - ProbabilityStatistics - Machine Learning62M99,We study the problem of identifying the source of a diffusion spreading over\na regular tree. When the degree of each node is at least three, we show that it\nis possible to construct confidence sets for the diffusion source with size\nindependent of the number of infected nodes. Our estimators are motivated by\nanalogous results in the literature concerning identification of the root node\nin preferential attachment and uniform attachment trees. At the core of our\nproofs is a probabilistic analysis of P\\'{o}lya urns corresponding to the\nnumber of uninfected neighbors in specific subtrees of the infection tree. We\nalso provide an example illustrating the shortcomings of source estimation\ntechniques in settings where the underlying graph is asymmetric.Comment: 23 pages", "1510.05751": "Semi-Implicit Time Integration of Atmospheric Flows with\n  Characteristic-Based Flux Partitioning,Ghosh, DebojyotiConstantinescu, Emil M.,Computer Science - Computational Engineering, Finance, and ScienceMathematics - Numerical Analysis65M06, 86A10, 76N15,This paper presents a characteristic-based flux partitioning for the\nsemi-implicit time integration of atmospheric flows. Nonhydrostatic models\nrequire the solution of the compressible Euler equations. The acoustic\ntime-scale is significantly faster than the advective scale, yet it is\ntypically not relevant to atmospheric and weather phenomena. The acoustic and\nadvective components of the hyperbolic flux are separated in the characteristic\nspace. High-order, conservative additive Runge-Kutta methods are applied to the\npartitioned equations so that the acoustic component is integrated in time\nimplicitly with an unconditionally stable method, while the advective component\nis integrated explicitly. The time step of the overall algorithm is thus\ndetermined by the advective scale. Benchmark flow problems are used to\ndemonstrate the accuracy, stability, and convergence of the proposed algorithm.\nThe computational cost of the partitioned semi-implicit approach is compared\nwith that of explicit time integration.", "1510.06423": "Optimization as Estimation with Gaussian Processes in Bandit Settings,Wang, ZiZhou, BoleiJegelka, Stefanie,Statistics - Machine LearningComputer Science - Machine Learning,Recently, there has been rising interest in Bayesian optimization -- the\noptimization of an unknown function with assumptions usually expressed by a\nGaussian Process (GP) prior. We study an optimization strategy that directly\nuses an estimate of the argmax of the function. This strategy offers both\npractical and theoretical advantages: no tradeoff parameter needs to be\nselected, and, moreover, we establish close connections to the popular GP-UCB\nand GP-PI strategies. Our approach can be understood as automatically and\nadaptively trading off exploration and exploitation in GP-UCB and GP-PI. We\nillustrate the effects of this adaptive tuning via bounds on the regret as well\nas an extensive empirical evaluation on robotics and vision tasks,\ndemonstrating the robustness of this strategy for a range of performance\ncriteria.Comment: Proceedings of the 19th International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2016, Cadiz, Spain", "1510.06482": "Triangular Alignment (TAME): A Tensor-based Approach for Higher-order\n  Network Alignment,Mohammadi, ShahinGleich, DavidKolda, TamaraGrama, Ananth,Computer Science - Computational Engineering, Finance, and Science,Network alignment has extensive applications in comparative interactomics.\nTraditional approaches aim to simultaneously maximize the number of conserved\nedges and the underlying similarity of aligned entities. We propose a novel\nformulation of the network alignment problem that extends topological\nsimilarity to higher-order structures and provides a new objective function\nthat maximizes the number of aligned substructures. This objective function\ncorresponds to an integer programming problem, which is NP-hard. Consequently,\nwe identify a closely related surrogate function whose maximization results in\na tensor eigenvector problem. Based on this formulation, we present an\nalgorithm called Triangular AlignMEnt (TAME), which attempts to maximize the\nnumber of aligned triangles across networks. Using a case study on the\nNAPAbench dataset, we show that triangular alignment is capable of producing\nmappings with high node correctness. We further evaluate our method by aligning\nyeast and human interactomes. Our results indicate that TAME outperforms the\nstate-of-art alignment methods in terms of conserved triangles. In addition, we\nshow that the number of conserved triangles is more significantly correlated,\ncompared to the conserved edge, with node correctness and co-expression of\nedges. Our formulation and resulting algorithms can be easily extended to\narbitrary motifs.Comment: Submitted to the IEEE/ACM Transactions on Computational Biology and\n  Bioinformatics (TCBB) for review", "1510.06684": "Dual Free Adaptive Mini-batch SDCA for Empirical Risk Minimization,He, XiTak\u00e1\u010d, Martin,Mathematics - Optimization and ControlComputer Science - Machine Learning,In this paper we develop dual free mini-batch SDCA with adaptive\nprobabilities for regularized empirical risk minimization. This work is\nmotivated by recent work of Shai Shalev-Shwartz on dual free SDCA method,\nhowever, we allow a non-uniform selection of \"dual\" coordinates in SDCA.\nMoreover, the probability can change over time, making it more efficient than\nfix uniform or non-uniform selection. We also propose an efficient procedure to\ngenerate a random non-uniform mini-batch through iterative process. The work is\nconcluded with multiple numerical experiments to show the efficiency of\nproposed algorithms.", "1510.06750": "Quantum vs Classical Proofs and Subset Verification,Fefferman, BillKimmel, Shelby,Quantum PhysicsComputer Science - Computational Complexity,We study the ability of efficient quantum verifiers to decide properties of\nexponentially large subsets given either a classical or quantum witness. We\ndevelop a general framework that can be used to prove that QCMA machines, with\nonly classical witnesses, cannot verify certain properties of subsets given\nimplicitly via an oracle. We use this framework to prove an oracle separation\nbetween QCMA and QMA using an \"in-place\" permutation oracle, making the first\nprogress on this question since Aaronson and Kuperberg in 2007. We also use the\nframework to prove a particularly simple standard oracle separation between\nQCMA and AM.Comment: 23 pages, presentation and notation clarified, small errors fixed", "1510.07135": "Induced minors and well-quasi-ordering,B\u0142asiok, Jaros\u0142awKami\u0144ski, MarcinRaymond, Jean-FlorentTrunck, Th\u00e9ophile,Mathematics - CombinatoricsComputer Science - Discrete Mathematics05C, 06A07G.2.2,A graph $H$ is an induced minor of a graph $G$ if it can be obtained from an\ninduced subgraph of $G$ by contracting edges. Otherwise, $G$ is said to be\n$H$-induced minor-free. Robin Thomas showed that $K_4$-induced minor-free\ngraphs are well-quasi-ordered by induced minors [Graphs without $K_4$ and\nwell-quasi-ordering, Journal of Combinatorial Theory, Series B, 38(3):240 --\n247, 1985].\n  We provide a dichotomy theorem for $H$-induced minor-free graphs and show\nthat the class of $H$-induced minor-free graphs is well-quasi-ordered by the\ninduced minor relation if and only if $H$ is an induced minor of the gem (the\npath on 4 vertices plus a dominating vertex) or of the graph obtained by adding\na vertex of degree 2 to the complete graph on 4 vertices. To this end we proved\ntwo decomposition theorems which are of independent interest.\n  Similar dichotomy results were previously given for subgraphs by Guoli Ding\nin [Subgraphs and well-quasi-ordering, Journal of Graph Theory, 16(5):489--502,\n1992] and for induced subgraphs by Peter Damaschke in [Induced subgraphs and\nwell-quasi-ordering, Journal of Graph Theory, 14(4):427--435, 1990].", "1510.07357": "Distributed Bare-Bones Communication in Wireless Networks,Chlebus, Bogdan S.Kowalski, Dariusz R.Vaya, Shailesh,Computer Science - Distributed, Parallel, and Cluster Computing,We consider wireless networks with the SINR model of interference when nodes\nhave very limited individual knowledge and capabilities. In particular, nodes\ndo not know their geographic coordinates and their neighborhoods, nor even the\nsize $n$ of the network, nor can they sense collisions. Each node is equipped\nonly with a unique integer name, where $N$ is an upper bound on their range. We\nstudy distributed algorithms for communication problems in the following three\nsettings. In the single-node-start case, when one node starts an execution and\nthe other nodes are awoken by receiving messages from already awoken nodes, we\npresent a randomized broadcast algorithm which wakes up all the nodes in $O(n\n\\log^2 N)$ rounds with high probability. Let $\\Delta$ denote the maximum number\nof nodes that successfully receive a message transmitted by a node when no\nother nodes transmit. For the synchronized-start case, when all the nodes start\nan execution simultaneously, we give a randomized algorithm that computes a\nbackbone of the network in $O(\\Delta\\log^{7} N)$ rounds with high probability.\nFinally, in the partly-coordinated-start case, when a number of nodes start an\nexecution together and other nodes are awoken by receiving messages from the\nalready awoken nodes, we develop an algorithm that creates a backbone network\nin time $O(n\\log^2 N +\\Delta\\log^{7} N)$ with high probability.", "1510.07380": "SLAP: Simultaneous Localization and Planning Under Uncertainty for\n  Physical Mobile Robots via Dynamic Replanning in Belief Space: Extended\n  version,Agha-mohammadi, Ali-akbarAgarwal, SauravKim, Sung-KyunChakravorty, SumanAmato, Nancy M.,Computer Science - RoboticsComputer Science - Systems and Control,Simultaneous localization and Planning (SLAP) is a crucial ability for an\nautonomous robot operating under uncertainty. In its most general form, SLAP\ninduces a continuous POMDP (partially-observable Markov decision process),\nwhich needs to be repeatedly solved online. This paper addresses this problem\nand proposes a dynamic replanning scheme in belief space. The underlying POMDP,\nwhich is continuous in state, action, and observation space, is approximated\noffline via sampling-based methods, but operates in a replanning loop online to\nadmit local improvements to the coarse offline policy. This construct enables\nthe proposed method to combat changing environments and large localization\nerrors, even when the change alters the homotopy class of the optimal\ntrajectory. It further outperforms the state-of-the-art FIRM (Feedback-based\nInformation RoadMap) method by eliminating unnecessary stabilization steps.\nApplying belief space planning to physical systems brings with it a plethora of\nchallenges. A key focus of this paper is to implement the proposed planner on a\nphysical robot and show the SLAP solution performance under uncertainty, in\nchanging environments and in the presence of large disturbances, such as a\nkidnapped robot situation.Comment: 20 pages, updated figures, extended theory and simulation results", "1510.07391": "Vehicle Color Recognition using Convolutional Neural Network,Rachmadi, Reza FuadPurnama, I Ketut Eddy,Computer Science - Computer Vision and Pattern Recognition,Vehicle color information is one of the important elements in ITS\n(Intelligent Traffic System). In this paper, we present a vehicle color\nrecognition method using convolutional neural network (CNN). Naturally, CNN is\ndesigned to learn classification method based on shape information, but we\nproved that CNN can also learn classification based on color distribution. In\nour method, we convert the input image to two different color spaces, HSV and\nCIE Lab, and run it to some CNN architecture. The training process follow\nprocedure introduce by Krizhevsky, that learning rate is decreasing by factor\nof 10 after some iterations. To test our method, we use publicly vehicle color\nrecognition dataset provided by Chen. The results, our model outperform the\noriginal system provide by Chen with 2% higher overall accuracy.", "1510.07424": "The Impossibility of Extending Random Dictatorship to Weak Preferences,Brandl, FlorianBrandt, FelixSuksompong, Warut,Computer Science - Multiagent SystemsComputer Science - Computer Science and Game TheoryC.6D.7D.8,Random dictatorship has been characterized as the only social decision scheme\nthat satisfies efficiency and strategyproofness when individual preferences are\nstrict. We show that no extension of random dictatorship to weak preferences\nsatisfies these properties, even when significantly weakening the required\ndegree of strategyproofness.", "1510.08183": "Raptor Codes in the Low SNR Regime,Shirvanimoghaddam, MahyarJohnson, Sarah J.,Computer Science - Information Theory,In this paper, we revisit the design of Raptor codes for binary input\nadditive white Gaussian noise (BIAWGN) channels, where we are interested in\nvery low signal to noise ratios (SNRs). A linear programming degree\ndistribution optimization problem is defined for Raptor codes in the low SNR\nregime through several approximations. We also provide an exact expression for\nthe polynomial representation of the degree distribution with infinite maximum\ndegree in the low SNR regime, which enables us to calculate the exact value of\nthe fractions of output nodes of small degrees. A more practical degree\ndistribution design is also proposed for Raptor codes in the low SNR regime,\nwhere we include the rate efficiency and the decoding complexity in the\noptimization problem, and an upper bound on the maximum rate efficiency is\nderived for given design parameters. Simulation results show that the Raptor\ncode with the designed degree distributions can approach rate efficiencies\nlarger than 0.95 in the low SNR regime.Comment: Submitted to the IEEE Transactions on Communications. arXiv admin\n  note: text overlap with arXiv:1510.07728", "1510.08202": "Oblivious Fronthaul-Constrained Relay for a Gaussian Channel,Homri, AdiPeleg, MichaelShamai, Shlomo,Computer Science - Information Theory,We consider systems in which the transmitter conveys messages to the receiver\nthrough a capacity-limited relay station. The channel between the transmitter\nand the relay-station is assumed to be a frequency selective additive Gaussian\nnoise channel. It is assumed that the transmitter can shape the spectrum and\nadapt the coding technique so as to optimize performance. The relay operation\nis oblivious (nomadic transmitters), that is, the specific codebooks used are\nunknown. We find the reliable information rate that can be achieved with\nGaussian signaling in this setting, and to that end, employ Gaussian bottleneck\nresults combined with Shannon's incremental frequency approach. We also prove\nthat, unlike classical water-pouring, the allocated spectrum (power and\nbit-rate) of the optimal solution could frequently be discontinuous. These\nresults can be applied to a MIMO transmission scheme. We also investigate the\ncase of an entropy limited relay. We present lower and upper bounds on the\noptimal performance (in terms of mutual information), and derive an analytical\napproximation.", "1510.08368": "Switching control for incremental stabilization of nonlinear systems via\n  contraction theory,di Bernardo, MarioFiore, Davide,Computer Science - Systems and Control,In this paper we present a switching control strategy to incrementally\nstabilize a class of nonlinear dynamical systems. Exploiting recent results on\ncontraction analysis of switched Filippov systems derived using regularization,\nsufficient conditions are presented to prove incremental stability of the\nclosed-loop system. Furthermore, based on these sufficient conditions, a design\nprocedure is proposed to design a switched control action that is active only\nwhere the open-loop system is not sufficiently incrementally stable in order to\nreduce the required control effort. The design procedure to either locally or\nglobally incrementally stabilize a dynamical system is then illustrated by\nmeans of a representative example.Comment: Accepted to ECC 2016", "1510.08417": "Monotone Projection Lower Bounds from Extended Formulation Lower Bounds,Grochow, Joshua A.,Computer Science - Computational Complexity68Q15, 68Q17, 90C05, 15A15, 05C70F.1.3F.2.1G.1.6,In this short note, we reduce lower bounds on monotone projections of\npolynomials to lower bounds on extended formulations of polytopes. Applying our\nreduction to the seminal extended formulation lower bounds of Fiorini, Massar,\nPokutta, Tiwari, & de Wolf (STOC 2012; J. ACM, 2015) and Rothvoss (STOC 2014;\nJ. ACM, 2017), we obtain the following interesting consequences.\n  1. The Hamiltonian Cycle polynomial is not a monotone subexponential-size\nprojection of the permanent; this both rules out a natural attempt at a\nmonotone lower bound on the Boolean permanent, and shows that the permanent is\nnot complete for non-negative polynomials in VNP$_{{\\mathbb R}}$ under monotone\np-projections.\n  2. The cut polynomials and the perfect matching polynomial (or \"unsigned\nPfaffian\") are not monotone p-projections of the permanent. The latter, over\nthe Boolean and-or semi-ring, rules out monotone reductions in one of the\nnatural approaches to reducing perfect matchings in general graphs to perfect\nmatchings in bipartite graphs.\n  As the permanent is universal for monotone formulas, these results also imply\nexponential lower bounds on the monotone formula size and monotone circuit size\nof these polynomials.Comment: Published in Theory of Computing, Volume 13 (2017), Article 18;\n  Received: November 10, 2015, Revised: July 27, 2016, Published: December 22,\n  2017", "1510.08578": "My Reflections on the First Man vs. Machine No-Limit Texas Hold 'em\n  Competition,Ganzfried, Sam,Computer Science - Computer Science and Game TheoryComputer Science - Artificial IntelligenceComputer Science - Multiagent SystemsEconomics - Theoretical Economics,The first ever human vs. computer no-limit Texas hold 'em competition took\nplace from April 24-May 8, 2015 at River's Casino in Pittsburgh, PA. In this\narticle I present my thoughts on the competition design, agent architecture,\nand lessons learned.", "1510.08779": "Effect of Gromov-hyperbolicity Parameter on Cuts and Expansions in\n  Graphs and Some Algorithmic Implications,DasGupta, BhaskarKarpinski, MarekMobasheri, NasimYahyanejad, Farzaneh,Computer Science - Computational ComplexityComputer Science - Discrete MathematicsMathematics - Combinatorics68Q25, 68W25, 68W40, 05C85F.2.2G.2.2I.1.2,$\\delta$-hyperbolic graphs, originally conceived by Gromov in 1987, occur\noften in many network applications; for fixed $\\delta$, such graphs are simply\ncalled hyperbolic graphs and include non-trivial interesting classes of\n\"non-expander\" graphs. The main motivation of this paper is to investigate the\neffect of the hyperbolicity measure $\\delta$ on expansion and cut-size bounds\non graphs (here $\\delta$ need not be a constant), and the asymptotic ranges of\n$\\delta$ for which these results may provide improved approximation algorithms\nfor related combinatorial problems. To this effect, we provide constructive\nbounds on node expansions for $\\delta$-hyperbolic graphs as a function of\n$\\delta$, and show that many witnesses (subsets of nodes) for such expansions\ncan be computed efficiently even if the witnesses are required to be nested or\nsufficiently distinct from each other. To the best of our knowledge, these are\nthe first such constructive bounds proven. We also show how to find a large\nfamily of s-t cuts with relatively small number of cut-edges when s and t are\nsufficiently far apart. We then provide algorithmic consequences of these\nbounds and their related proof techniques for two problems for\n$\\delta$-hyperbolic graphs (where $\\delta$ is a function $f$ of the number of\nnodes, the exact nature of growth of $f$ being dependent on the particular\nproblem considered).Comment: Final corrected author version, to appear in the journal Algorithmica", "1510.08797": "Convexity in Tree Spaces,Lin, BoSturmfels, BerndTang, XiaoxianYoshida, Ruriko,Mathematics - Metric GeometryComputer Science - Computational GeometryMathematics - CombinatoricsQuantitative Biology - Populations and Evolution,We study the geometry of metrics and convexity structures on the space of\nphylogenetic trees, which is here realized as the tropical linear space of all\n\\ ultrametrics. The ${\\rm CAT}(0)$-metric of Billera-Holmes-Vogtman arises from\nthe theory of orthant spaces. While its geodesics can be computed by the\nOwen-Provan algorithm, geodesic triangles are complicated. We show that the\ndimension of such a triangle can be arbitrarily high. Tropical convexity and\nthe tropical metric behave better. They exhibit properties desirable for\ngeometric statistics, such as geodesics of small depth.Comment: 21 pages, 5 figures; Theorem 13 is now proved in all dimensions", "1510.08887": "Phase Retrieval Using Unitary 2-Designs,Kimmel, ShelbyLiu, Yi-Kai,Quantum PhysicsComputer Science - Information TheoryMathematics - Statistics Theory,We consider a variant of the phase retrieval problem, where vectors are\nreplaced by unitary matrices, i.e., the unknown signal is a unitary matrix U,\nand the measurements consist of squared inner products |Tr(C*U)|^2 with unitary\nmatrices C that are chosen by the observer. This problem has applications to\nquantum process tomography, when the unknown process is a unitary operation.\n  We show that PhaseLift, a convex programming algorithm for phase retrieval,\ncan be adapted to this matrix setting, using measurements that are sampled from\nunitary 4- and 2-designs. In the case of unitary 4-design measurements, we show\nthat PhaseLift can reconstruct all unitary matrices, using a near-optimal\nnumber of measurements. This extends previous work on PhaseLift using spherical\n4-designs.\n  In the case of unitary 2-design measurements, we show that PhaseLift still\nworks pretty well on average: it recovers almost all signals, up to a constant\nadditive error, using a near-optimal number of measurements. These 2-design\nmeasurements are convenient for quantum process tomography, as they can be\nimplemented via randomized benchmarking techniques. This is the first positive\nresult on PhaseLift using 2-designs.Comment: 21 pages; v3: minor revisions, to appear at SampTA 2017; v2:\n  rewritten to focus on phase retrieval, with new title, improved error bounds,\n  and numerics; v1: original version, titled \"Quantum Compressed Sensing Using\n  2-Designs\"", "1510.08983": "Highway Long Short-Term Memory RNNs for Distant Speech Recognition,Zhang, YuChen, GuoguoYu, DongYao, KaishengKhudanpur, SanjeevGlass, James,Computer Science - Neural and Evolutionary ComputingComputer Science - Artificial IntelligenceComputer Science - Computation and LanguageComputer Science - Machine LearningElectrical Engineering and Systems Science - Audio and Speech Processing,In this paper, we extend the deep long short-term memory (DLSTM) recurrent\nneural networks by introducing gated direct connections between memory cells in\nadjacent layers. These direct links, called highway connections, enable\nunimpeded information flow across different layers and thus alleviate the\ngradient vanishing problem when building deeper LSTMs. We further introduce the\nlatency-controlled bidirectional LSTMs (BLSTMs) which can exploit the whole\nhistory while keeping the latency under control. Efficient algorithms are\nproposed to train these novel networks using both frame and sequence\ndiscriminative criteria. Experiments on the AMI distant speech recognition\n(DSR) task indicate that we can train deeper LSTMs and achieve better\nimprovement from sequence training with highway LSTMs (HLSTMs). Our novel model\nobtains $43.9/47.7\\%$ WER on AMI (SDM) dev and eval sets, outperforming all\nprevious works. It beats the strong DNN and DLSTM baselines with $15.7\\%$ and\n$5.3\\%$ relative improvement respectively.", "1510.08985": "Prediction-Adaptation-Correction Recurrent Neural Networks for\n  Low-Resource Language Speech Recognition,Zhang, YuChuangsuwanich, EkapolGlass, JamesYu, Dong,Computer Science - Computation and LanguageComputer Science - Machine LearningComputer Science - Neural and Evolutionary ComputingElectrical Engineering and Systems Science - Audio and Speech Processing,In this paper, we investigate the use of prediction-adaptation-correction\nrecurrent neural networks (PAC-RNNs) for low-resource speech recognition. A\nPAC-RNN is comprised of a pair of neural networks in which a {\\it correction}\nnetwork uses auxiliary information given by a {\\it prediction} network to help\nestimate the state probability. The information from the correction network is\nalso used by the prediction network in a recurrent loop. Our model outperforms\nother state-of-the-art neural networks (DNNs, LSTMs) on IARPA-Babel tasks.\nMoreover, transfer learning from a language that is similar to the target\nlanguage can help improve performance further.", "1510.09102": "Trace Refinement in Labelled Markov Decision Processes,Fijalkow, Nathana\u00eblKiefer, StefanShirmohammadi, Mahsa,Computer Science - Logic in Computer Science,Given two labelled Markov decision processes (MDPs), the trace-refinement\nproblem asks whether for all strategies of the first MDP there exists a\nstrategy of the second MDP such that the induced labelled Markov chains are\ntrace-equivalent. We show that this problem is decidable in polynomial time if\nthe second MDP is a Markov chain. The algorithm is based on new results on a\nparticular notion of bisimulation between distributions over the states.\nHowever, we show that the general trace-refinement problem is undecidable, even\nif the first MDP is a Markov chain. Decidability of those problems was stated\nas open in 2008. We further study the decidability and complexity of the\ntrace-refinement problem provided that the strategies are restricted to be\nmemoryless.", "1511.00158": "Prediction of Dynamical time Series Using Kernel Based Regression and\n  Smooth Splines,Navarrete, RaymundoViswanath, Divakar,Statistics - Machine LearningComputer Science - Machine Learning,Prediction of dynamical time series with additive noise using support vector\nmachines or kernel based regression has been proved to be consistent for\ncertain classes of discrete dynamical systems. Consistency implies that these\nmethods are effective at computing the expected value of a point at a future\ntime given the present coordinates. However, the present coordinates themselves\nare noisy, and therefore, these methods are not necessarily effective at\nremoving noise. In this article, we consider denoising and prediction as\nseparate problems for flows, as opposed to discrete time dynamical systems, and\nshow that the use of smooth splines is more effective at removing noise.\nCombination of smooth splines and kernel based regression yields predictors\nthat are more accurate on benchmarks typically by a factor of 2 or more. We\nprove that kernel based regression in combination with smooth splines converges\nto the exact predictor for time series extracted from any compact invariant set\nof any sufficiently smooth flow. As a consequence of convergence, one can find\nexamples where the combination of kernel based regression with smooth splines\nis superior by even a factor of $100$. The predictors that we compute operate\non delay coordinate data and not the full state vector, which is typically not\nobservable.Comment: minor changes", "1511.00452": "Stable Matching Mechanisms are Not Obviously Strategy-Proof,Ashlagi, ItaiGonczarowski, Yannai A.,Computer Science - Computer Science and Game Theory,Many two-sided matching markets, from labor markets to school choice\nprograms, use a clearinghouse based on the applicant-proposing deferred\nacceptance algorithm, which is well known to be strategy-proof for the\napplicants. Nonetheless, a growing amount of empirical evidence reveals that\napplicants misrepresent their preferences when this mechanism is used. This\npaper shows that no mechanism that implements a stable matching is \"obviously\nstrategy-proof\" for any side of the market, a stronger incentive property than\nstrategy-proofness that was introduced by Li (2017). A stable mechanism that is\nobviously strategy-proof for applicants is introduced for the case in which\nagents on the other side have acyclical preferences.", "1511.00493": "Uniqueness, Spatial Mixing, and Approximation for Ferromagnetic 2-Spin\n  Systems,Guo, HengLu, Pinyan,Computer Science - Data Structures and AlgorithmsComputer Science - Discrete Mathematics,We give fully polynomial-time approximation schemes (FPTAS) for the partition\nfunction of ferromagnetic 2-spin systems in certain parameter regimes. The\nthreshold we obtain is almost tight up to an integrality gap. Our technique is\nbased on the correlation decay framework. The main technical contribution is a\nnew potential function, with which we establish a new kind of spatial mixing.Comment: to appear in ACM TOCT", "1511.00523": "Minimizing Regret in Discounted-Sum Games,Hunter, PaulP\u00e9rez, Guillermo A.Raskin, Jean-Fran\u00e7ois,Computer Science - Computer Science and Game TheoryComputer Science - Formal Languages and Automata TheoryComputer Science - Logic in Computer ScienceF.1.1D.2.4,In this paper, we study the problem of minimizing regret in discounted-sum\ngames played on weighted game graphs. We give algorithms for the general\nproblem of computing the minimal regret of the controller (Eve) as well as\nseveral variants depending on which strategies the environment (Adam) is\npermitted to use. We also consider the problem of synthesizing regret-free\nstrategies for Eve in each of these scenarios.Comment: arXiv admin note: text overlap with arXiv:1504.01708; some typos have\n  been removed in the proof of simple strategies being sufficient to minimize\n  regret against any adversary", "1511.00546": "An Impossibility Result for Reconstruction in a Degree-Corrected\n  Planted-Partition Model,Gulikers, LennartLelarge, MarcMassouli\u00e9, Laurent,Mathematics - ProbabilityComputer Science - Machine LearningComputer Science - Social and Information NetworksStatistics - Machine Learning,We consider the Degree-Corrected Stochastic Block Model (DC-SBM): a random\ngraph on $n$ nodes, having i.i.d. weights $(\\phi_u)_{u=1}^n$ (possibly\nheavy-tailed), partitioned into $q \\geq 2$ asymptotically equal-sized clusters.\nThe model parameters are two constants $a,b > 0$ and the finite second moment\nof the weights $\\Phi^{(2)}$. Vertices $u$ and $v$ are connected by an edge with\nprobability $\\frac{\\phi_u \\phi_v}{n}a$ when they are in the same class and with\nprobability $\\frac{\\phi_u \\phi_v}{n}b$ otherwise.\n  We prove that it is information-theoretically impossible to estimate the\nclusters in a way positively correlated with the true community structure when\n$(a-b)^2 \\Phi^{(2)} \\leq q(a+b)$.\n  As by-products of our proof we obtain $(1)$ a precise coupling result for\nlocal neighbourhoods in DC-SBM's, that we use in a follow up paper [Gulikers et\nal., 2017] to establish a law of large numbers for local-functionals and $(2)$\nthat long-range interactions are weak in (power-law) DC-SBM's.Comment: Appeared in Annals of Applied Probability", "1511.00725": "Toward an Efficient Multi-class Classification in an Open Universe,Dhifli, WajdiDiallo, Abdoulaye Banir\u00e9,Computer Science - Machine LearningComputer Science - Artificial IntelligenceComputer Science - DatabasesComputer Science - Information Retrieval,Classification is a fundamental task in machine learning and data mining.\nExisting classification methods are designed to classify unknown instances\nwithin a set of previously known training classes. Such a classification takes\nthe form of a prediction within a closed-set of classes. However, a more\nrealistic scenario that fits real-world applications is to consider the\npossibility of encountering instances that do not belong to any of the training\nclasses, $i.e.$, an open-set classification. In such situation, existing\nclosed-set classifiers will assign a training label to these instances\nresulting in a misclassification. In this paper, we introduce Galaxy-X, a novel\nmulti-class classification approach for open-set recognition problems. For each\nclass of the training set, Galaxy-X creates a minimum bounding hyper-sphere\nthat encompasses the distribution of the class by enclosing all of its\ninstances. In such manner, our method is able to distinguish instances\nresembling previously seen classes from those that are of unknown ones. To\nadequately evaluate open-set classification, we introduce a novel evaluation\nprocedure. Experimental results on benchmark datasets show the efficiency of\nour approach in classifying novel instances from known as well as unknown\nclasses.", "1511.00736": "ProtNN: Fast and Accurate Nearest Neighbor Protein Function Prediction\n  based on Graph Embedding in Structural and Topological Space,Dhifli, WajdiDiallo, Abdoulaye Banir\u00e9,Computer Science - Machine LearningComputer Science - Social and Information Networks,Studying the function of proteins is important for understanding the\nmolecular mechanisms of life. The number of publicly available protein\nstructures has increasingly become extremely large. Still, the determination of\nthe function of a protein structure remains a difficult, costly, and time\nconsuming task. The difficulties are often due to the essential role of spatial\nand topological structures in the determination of protein functions in living\ncells. In this paper, we propose ProtNN, a novel approach for protein function\nprediction. Given an unannotated protein structure and a set of annotated\nproteins, ProtNN finds the nearest neighbor annotated structures based on\nprotein-graph pairwise similarities. Given a query protein, ProtNN finds the\nnearest neighbor reference proteins based on a graph representation model and a\npairwise similarity between vector embedding of both query and reference\nprotein-graphs in structural and topological spaces. ProtNN assigns to the\nquery protein the function with the highest number of votes across the set of k\nnearest neighbor reference proteins, where k is a user-defined parameter.\nExperimental evaluation demonstrates that ProtNN is able to accurately classify\nseveral datasets in an extremely fast runtime compared to state-of-the-art\napproaches. We further show that ProtNN is able to scale up to a whole PDB\ndataset in a single-process mode with no parallelization, with a gain of\nthousands order of magnitude of runtime compared to state-of-the-art\napproaches.", "1511.00867": "Dynamic Gossip,van Ditmarsch, Hansvan Eijck, JanPardo, PereRamezanian, RahimSchwarzentruber, Fran\u00e7ois,Computer Science - Discrete Mathematics,A gossip protocol is a procedure for spreading secrets among a group of\nagents, using a connection graph. The goal is for all agents to get to know all\nsecrets, in which case we call the execution of the protocol successful. We\nconsider distributed and dynamic gossip protocols. In distributed gossip the\nagents themselves instead of a global scheduler determine whom to call. In\ndynamic gossip not only secrets are exchanged but also telephone numbers (agent\nidentities). This results in increased graph connectivity. We define six such\ndistributed dynamic gossip protocols, and we characterize them in terms of the\ntopology of the graphs on which they are successful, wherein we distinguish\nstrong success (the protocol always terminates, possibly assuming fair\nscheduling) from weak success (the protocol sometimes terminates). For five of\nthese protocols strong (fair) and weak success are characterized by weakly\nconnected graphs. This result is surprising because the protocols are fairly\ndifferent. In the sixth protocol an agent may only call another agent if it\ndoes not know the other agent's secret. Strong success for this protocol is\ncharacterized by graphs for which the set of non-terminal nodes is strongly\nconnected. Weak success for this protocol is characterized by weakly connected\ngraphs satisfying further topological constraints that we define in the paper.\nOne direction of this characterization is surprisingly harder to prove than the\nother results in this contribution.", "1511.00876": "Beating the Harmonic lower bound for online bin packing,Heydrich, Sandyvan Stee, Rob,Computer Science - Data Structures and Algorithms,In the online bin packing problem, items of sizes in (0,1] arrive online to\nbe packed into bins of size 1. The goal is to minimize the number of used bins.\nIn this paper, we present an online bin packing algorithm with asymptotic\ncompetitive ratio of 1.5813. This is the first improvement in fifteen years and\nreduces the gap to the lower bound by 15%. Within the well-known SuperHarmonic\nframework, no competitive ratio below 1.58333 can be achieved.\n  We make two crucial changes to that framework. First, some of our algorithm's\ndecisions depend on exact sizes of items, instead of only their types. In\nparticular, for each item with size in (1/3,1/2], we use its exact size to\ndetermine if it can be packed together with an item of size greater than 1/2.\nSecond, we add constraints to the linear programs considered by Seiden, in\norder to better lower bound the optimal solution. These extra constraints are\nbased on marks that we give to items based on how they are packed by our\nalgorithm. We show that for each input, a single weighting function can be\nconstructed to upper bound the competitive ratio on it.\n  We use this idea to simplify the analysis of SuperHarmonic, and show that the\nalgorithm Harmonic++ is in fact 1.58880-competitive (Seiden proved 1.58889),\nand that 1.5884 can be achieved within the SuperHarmonic framework. Finally, we\ngive a lower bound of 1.5762 for our new framework.Comment: Added reference and clarified some sentences", "1511.00925": "Do Prices Coordinate Markets?,Hsu, JustinMorgenstern, JamieRogers, RyanRoth, AaronVohra, Rakesh,Computer Science - Computer Science and Game TheoryComputer Science - Machine Learning,Walrasian equilibrium prices can be said to coordinate markets: They support\na welfare optimal allocation in which each buyer is buying bundle of goods that\nis individually most preferred. However, this clean story has two caveats.\nFirst, the prices alone are not sufficient to coordinate the market, and buyers\nmay need to select among their most preferred bundles in a coordinated way to\nfind a feasible allocation. Second, we don't in practice expect to encounter\nexact equilibrium prices tailored to the market, but instead only approximate\nprices, somehow encoding \"distributional\" information about the market. How\nwell do prices work to coordinate markets when tie-breaking is not coordinated,\nand they encode only distributional information?\n  We answer this question. First, we provide a genericity condition such that\nfor buyers with Matroid Based Valuations, overdemand with respect to\nequilibrium prices is at most 1, independent of the supply of goods, even when\ntie-breaking is done in an uncoordinated fashion. Second, we provide\nlearning-theoretic results that show that such prices are robust to changing\nthe buyers in the market, so long as all buyers are sampled from the same\n(unknown) distribution.", "1511.01238": "The wisdom of networks: A general adaptation and learning mechanism of\n  complex systems: The network core triggers fast responses to known stimuli;\n  innovations require the slow network periphery and are encoded by\n  core-remodeling,Csermely, Peter,Quantitative Biology - Molecular NetworksCondensed Matter - Disordered Systems and Neural NetworksComputer Science - Social and Information NetworksNonlinear Sciences - Adaptation and Self-Organizing SystemsPhysics - Biological Physics,I hypothesize that re-occurring prior experience of complex systems mobilizes\na fast response, whose attractor is encoded by their strongly connected network\ncore. In contrast, responses to novel stimuli are often slow and require the\nweakly connected network periphery. Upon repeated stimulus, peripheral network\nnodes remodel the network core that encodes the attractor of the new response.\nThis \"core-periphery learning\" theory reviews and generalizes the heretofore\nfragmented knowledge on attractor formation by neural networks,\nperiphery-driven innovation and a number of recent reports on the adaptation of\nprotein, neuronal and social networks. The coreperiphery learning theory may\nincrease our understanding of signaling, memory formation, information encoding\nand decision-making processes. Moreover, the power of network periphery-related\n'wisdom of crowds' inventing creative, novel responses indicates that\ndeliberative democracy is a slow yet efficient learning strategy developed as\nthe success of a billion-year evolution.Comment: The 2015 preliminary version can be downloaded as an earlier version\n  of the final paper here. Please find illustrative videos here:\n  http://networkdecisions.linkgroup.hu and a video abstract here:\n  https://youtu.be/IIjP7zWGjVE", "1511.01249": "Privacy by Design: On the Formal Design and Conformance Check of\n  Personal Data Protection Policies and Architectures,Ta, Vinh Thong,Computer Science - Cryptography and Security,The new General Data Protection Regulation (GDPR) will take effect in May\n2018, and hence, designing compliant data protection policies and system\narchitectures became crucial for organizations to avoid penalties.\nUnfortunately, the regulations given in a textual format can be easily\nmisinterpreted by the policy and system designers, which also making the\nconformance check error-prone for auditors. In this paper, we apply formal\napproach to facilitate systematic design of policies and architectures in an\nunambiguous way, and provide a framework for mathematically sound conformance\nchecks against the current data protection regulations. We propose a\n(semi-)formal approach for specifying and reasoning about data protection\npolicies and architectures as well as defining conformance relations between\narchitectures and policies. The usability of our proposed approach is\ndemonstrated on a smart metering service case study.Comment: 41 pages, 2 figures", "1511.01258": "Learn on Source, Refine on Target:A Model Transfer Learning Framework\n  with Random Forests,Segev, NoamHarel, MaayanMannor, ShieCrammer, KobyEl-Yaniv, Ran,Computer Science - Machine Learning,We propose novel model transfer-learning methods that refine a decision\nforest model M learned within a \"source\" domain using a training set sampled\nfrom a \"target\" domain, assumed to be a variation of the source. We present two\nrandom forest transfer algorithms. The first algorithm searches greedily for\nlocally optimal modifications of each tree structure by trying to locally\nexpand or reduce the tree around individual nodes. The second algorithm does\nnot modify structure, but only the parameter (thresholds) associated with\ndecision nodes. We also propose to combine both methods by considering an\nensemble that contains the union of the two forests. The proposed methods\nexhibit impressive experimental results over a range of problems.Comment: 2 columns, 14 pages, TPAMI submitted", "1511.01807": "The height of piecewise-testable languages and the complexity of the\n  logic of subwords,Karandikar, PrateekSchnoebelen, Philippe,Computer Science - Logic in Computer ScienceComputer Science - Formal Languages and Automata TheoryF.4.1F.4.3F.3.1,The height of a piecewise-testable language $L$ is the maximum length of the\nwords needed to define $L$ by excluding and requiring given subwords. The\nheight of $L$ is an important descriptive complexity measure that has not yet\nbeen investigated in a systematic way. This paper develops a series of new\ntechniques for bounding the height of finite languages and of languages\nobtained by taking closures by subwords, superwords and related operations.\n  As an application of these results, we show that\n$\\text{FO}^2(A^*,\\sqsubseteq)$, the two-variable fragment of the first-order\nlogic of sequences with the subword ordering, can only express\npiecewise-testable properties and has elementary complexity.Comment: This article is a full version of \"The height of piecewise-testable\n  languages with applications in logical complexity\", in Proc. CSL 2016, LIPiCS\n  62:37", "1511.02166": "Evaluation of the Intel Xeon Phi 7120 and NVIDIA K80 as accelerators for\n  two-dimensional panel codes,Einkemmer, Lukas,Computer Science - Distributed, Parallel, and Cluster ComputingComputer Science - Mathematical SoftwarePhysics - Computational Physics,To optimize the geometry of airfoils for a specific application is an\nimportant engineering problem. In this context genetic algorithms have enjoyed\nsome success as they are able to explore the search space without getting stuck\nin local optima. However, these algorithms require the computation of\naerodynamic properties for a significant number of airfoil geometries.\nConsequently, for low-speed aerodynamics, panel methods are most often used as\nthe inner solver.\n  In this paper we evaluate the performance of such an optimization algorithm\non modern accelerators (more specifically, the Intel Xeon Phi 7120 and the\nNVIDIA K80). For that purpose, we have implemented an optimized version of the\nalgorithm on the CPU and Xeon Phi (based on OpenMP, vectorization, and the\nIntel MKL library) and on the GPU (based on CUDA and the MAGMA library). We\npresent timing results for all codes and discuss the similarities and\ndifferences between the three implementations. Overall, we observe a speedup of\napproximately $2.5$ for adding an Intel Xeon Phi 7120 to a dual socket\nworkstation and a speedup between $3.4$ and $3.8$ for adding a NVIDIA K80 to a\ndual socket workstation.", "1511.02475": "On Sylvester Colorings of Cubic Graphs,Hakobyan, AnushMkrtchyan, Vahan,Mathematics - CombinatoricsComputer Science - Discrete Mathematics,If $G$ and $H$ are two cubic graphs, then an $H$-coloring of $G$ is a proper\nedge-coloring $f$ with edges of $H$, such that for each vertex $x$ of $G$,\nthere is a vertex $y$ of $H$ with $f(\\partial_G(x))=\\partial_H(y)$. If $G$\nadmits an $H$-coloring, then we will write $H\\prec G$. The Petersen coloring\nconjecture of Jaeger states that for any bridgeless cubic graph $G$, one has:\n$P\\prec G$. The second author has recently introduced the Sylvester coloring\nconjecture, which states that for any cubic graph $G$ one has: $S\\prec G$. Here\n$S$ is the Sylvester graph on $10$ vertices. In this paper, we prove the\nanalogue of Sylvester coloring conjecture for cubic pseudo-graphs. Moreover, we\nshow that if $G$ is any connected simple cubic graph $G$ with $G\\prec P$, then\n$G = P$. This implies that the Petersen graph does not admit an\n$S_{16}$-coloring, where $S_{16}$ is the smallest connected simple cubic graph\nwithout a perfect matching. $S_{16}$ has $16$ vertices. %We conjecture that\nthere are infinitely many connected cubic simple graphs which do not admit an\n%$S_{16}$-coloring. Finally, we obtain $2$ results towards the Sylvester\ncoloring conjecture. The first result states that any cubic graph $G$ has a\ncoloring with edges of Sylvester graph $S$ such that at least $\\frac45$ of\nvertices of $G$ meet the conditions of Sylvester coloring conjecture. The\nsecond result states that any claw-free cubic graph graph admits an\n$S$-coloring. This results is an application of our result on cubic\npseudo-graphs.Comment: 18 pages, 14 figures", "1511.02476": "Statistical physics of inference: Thresholds and algorithms,Zdeborov\u00e1, LenkaKrzakala, Florent,Condensed Matter - Statistical MechanicsComputer Science - Data Structures and AlgorithmsStatistics - Machine Learning,Many questions of fundamental interest in todays science can be formulated as\ninference problems: Some partial, or noisy, observations are performed over a\nset of variables and the goal is to recover, or infer, the values of the\nvariables based on the indirect information contained in the measurements. For\nsuch problems, the central scientific questions are: Under what conditions is\nthe information contained in the measurements sufficient for a satisfactory\ninference to be possible? What are the most efficient algorithms for this task?\nA growing body of work has shown that often we can understand and locate these\nfundamental barriers by thinking of them as phase transitions in the sense of\nstatistical physics. Moreover, it turned out that we can use the gained\nphysical insight to develop new promising algorithms. Connection between\ninference and statistical physics is currently witnessing an impressive\nrenaissance and we review here the current state-of-the-art, with a pedagogical\nfocus on the Ising model which formulated as an inference problem we call the\nplanted spin glass. In terms of applications we review two classes of problems:\n(i) inference of clusters on graphs and networks, with community detection as a\nspecial case and (ii) estimating a signal from its noisy linear measurements,\nwith compressed sensing as a case of sparse estimation. Our goal is to provide\na pedagogical review for researchers in physics and other fields interested in\nthis fascinating topic.Comment: 86 pages, 16 Figures. Review article based on HDR thesis of the first\n  author and lecture notes of the second", "1511.02599": "Waste Makes Haste: Bounded Time Protocols for Envy-Free Cake Cutting\n  with Free Disposal,Segal-Halevi, ErelHassidim, AvinatanAumann, Yonatan,Computer Science - Data Structures and AlgorithmsComputer Science - Computer Science and Game TheoryF.2.2,We consider the classic problem of envy-free division of a heterogeneous good\n(\"cake\") among several agents. It is known that, when the allotted pieces must\nbe connected, the problem cannot be solved by a finite algorithm for 3 or more\nagents. The impossibility result, however, assumes that the entire cake must be\nallocated. In this paper we replace the entire-allocation requirement with a\nweaker \\emph{partial-proportionality} requirement: the piece given to each\nagent must be worth for it at least a certain positive fraction of the entire\ncake value. We prove that this version of the problem is solvable in bounded\ntime even when the pieces must be connected. We present simple, bounded-time\nenvy-free cake-cutting algorithms for: (1) giving each of $n$ agents a\nconnected piece with a positive value; (2) giving each of 3 agents a connected\npiece worth at least 1/3; (3) giving each of 4 agents a connected piece worth\nat least 1/7; (4) giving each of 4 agents a disconnected piece worth at least\n1/4; (5) giving each of $n$ agents a disconnected piece worth at least\n$(1-\\epsilon)/n$ for any positive $\\epsilon$.Comment: The first version was presented at AAMAS 2015:\n  http://dl.acm.org/citation.cfm?id=2773268 . The current version is\n  substantially revised and extended", "1511.02683": "A Light CNN for Deep Face Representation with Noisy Labels,Wu, XiangHe, RanSun, ZhenanTan, Tieniu,Computer Science - Computer Vision and Pattern Recognition,The volume of convolutional neural network (CNN) models proposed for face\nrecognition has been continuously growing larger to better fit large amount of\ntraining data. When training data are obtained from internet, the labels are\nlikely to be ambiguous and inaccurate. This paper presents a Light CNN\nframework to learn a compact embedding on the large-scale face data with\nmassive noisy labels. First, we introduce a variation of maxout activation,\ncalled Max-Feature-Map (MFM), into each convolutional layer of CNN. Different\nfrom maxout activation that uses many feature maps to linearly approximate an\narbitrary convex activation function, MFM does so via a competitive\nrelationship. MFM can not only separate noisy and informative signals but also\nplay the role of feature selection between two feature maps. Second, three\nnetworks are carefully designed to obtain better performance meanwhile reducing\nthe number of parameters and computational costs. Lastly, a semantic\nbootstrapping method is proposed to make the prediction of the networks more\nconsistent with noisy labels. Experimental results show that the proposed\nframework can utilize large-scale noisy data to learn a Light model that is\nefficient in computational costs and storage spaces. The learned single network\nwith a 256-D representation achieves state-of-the-art results on various face\nbenchmarks without fine-tuning. The code is released on\nhttps://github.com/AlfredXiangWu/LightCNN.Comment: arXiv admin note: text overlap with arXiv:1507.04844. The models are\n  released on https://github.com/AlfredXiangWu/LightCNN, IEEE Transactions on\n  Information Forensics and Security, 2018", "1511.02899": "On the Combinatorial Version of the Slepian-Wolf Problem,Chumbalov, DaniyarRomashchenko, Andrei,Computer Science - Information TheoryComputer Science - Discrete Mathematics,We study the following combinatorial version of the Slepian-Wolf coding\nscheme. Two isolated Senders are given binary strings $X$ and $Y$ respectively;\nthe length of each string is equal to $n$, and the Hamming distance between the\nstrings is at most $\\alpha n$. The Senders compress their strings and\ncommunicate the results to the Receiver. Then the Receiver must reconstruct\nboth strings $X$ and $Y$. The aim is to minimise the lengths of the transmitted\nmessages.\n  For an asymmetric variant of this problem (where one of the Senders transmits\nthe input string to the Receiver without compression) with deterministic\nencoding a nontrivial lower bound was found by A.Orlitsky and K.Viswanathany.\nIn our paper we prove a new lower bound for the schemes with syndrome coding,\nwhere at least one of the Senders uses linear encoding of the input string.\n  For the combinatorial Slepian-Wolf problem with randomized encoding the\ntheoretical optimum of communication complexity was recently found by the first\nauthor, though effective protocols with optimal lengths of messages remained\nunknown. We close this gap and present a polynomial time randomized protocol\nthat achieves the optimal communication complexity.Comment: 20 pages, 14 figures. Accepted to IEEE Transactions on Information\n  Theory (June 2018)", "1511.03005": "ELDA: Towards Efficient and Lightweight Detection of Cache Pollution\n  Attacks in NDN,Xu, ZhiweiChen, BoWang, NinghanZhang, YujunLi, Zhongcheng,Computer Science - Cryptography and SecurityComputer Science - Networking and Internet ArchitectureComputer Science - PerformanceB.2.4C.4,As a promising architectural design for future Internet, named data\nnetworking (NDN) relies on in-network caching to efficiently deliver name-based\ncontent. However, the in-network caching is vulnerable to cache pollution\nattacks (CPA), which can reduce cache hits by violating cache locality and\nsignificantly degrade the overall performance of NDN. To defend against CPA\nattacks, the most effective way is to first detect the attacks and then\nthrottle them. Since the CPA attack itself has already imposed a huge burden on\nvictims, to avoid exhausting the remaining resources on the victims for\ndetection purpose, we expect a lightweight detection solution. We thus propose\nELDA, an Efficient and Lightweight Detection scheme against cache pollution\nAttacks, in which we design a Lightweight Flajolet-Martin (LFM) sketch to\nmonitor the interest traffic. Our analysis and simulations demonstrate that, by\nconsuming a few computation and memory resources, ELDA can effectively and\nefficiently detect CPA attacks.Comment: A regular paper published in LCN 2015,9 pages,which includes a novel\n  lightweight FM sketch for estimating the number of distinct items in data\n  streams", "1511.03234": "A general framework for Noetherian well ordered polynomial reductions,Ceria, MichelaMora, TeoRoggero, Margherita,Mathematics - Commutative AlgebraComputer Science - Symbolic Computation14C05, 14Q20, 13P10,Polynomial reduction is one of the main tools in computational algebra with\ninnumerable applications in many areas, both pure and applied. Since many years\nboth the theory and an efficient design of the related algorithm have been\nsolidly established.\n  This paper presents a general definition of polynomial reduction structure,\nstudies its features and highlights the aspects needed in order to grant and to\nefficiently test the main properties (noetherianity, confluence, ideal\nmembership).\n  The most significant aspect of this analysis is a negative reappraisal of the\nrole of the notion of term order which is usually considered a central and\ncrucial tool in the theory. In fact, as it was already established in the\ncomputer science context in relation with termination of algorithms, most of\nthe properties can be obtained simply considering a well-founded ordering,\nwhile the classical requirement that it be preserved by multiplication is\nirrelevant.\n  The last part of the paper shows how the polynomial basis concepts present in\nliterature are interpreted in our language and their properties are\nconsequences of the general results established in the first part of the paper.Comment: 36 pages. New title and substantial improvements to the presentation\n  according to the comments of the reviewers", "1511.03407": "Reorganizing topologies of Steiner trees to accelerate their elimination,Grodet, AymericTsuchiya, Takuya,Computer Science - Data Structures and Algorithms90C35, 05C05, 90C57,We describe a technique to reorganize topologies of Steiner trees by\nexchanging neighbors of adjacent Steiner points. We explain how to use the\nsystematic way of building trees, and therefore topologies, to find the correct\ntopology after nodes have been exchanged. Topology reorganizations can be\ninserted into the enumeration scheme commonly used by exact algorithms for the\nEuclidean Steiner tree problem in $d$-space, providing a method of improvement\ndifferent than the usual approaches. As an example, we show how topology\nreorganizations can be used to dynamically change the exploration of the usual\nbranch-and-bound tree when two Steiner points collide during the optimization\nprocess. We also turn our attention to the erroneous use of a pre-optimization\nlower bound in the original algorithm and give an example to confirm its usage\nis incorrect. In order to provide numerical results on correct solutions, we\nuse planar equilateral points to quickly compute this lower bound, even in\ndimensions higher than two. Finally, we describe planar twin trees, identical\ntrees yielded by different topologies, whose generalization to higher\ndimensions could open a new way of building Steiner trees.", "1511.03501": "Eliminating Higher-Multiplicity Intersections, III. Codimension 2,Avvakumov, S.Mabillard, I.Skopenkov, A.Wagner, U.,Mathematics - Geometric TopologyComputer Science - Computational GeometryMathematics - Combinatorics57Q35, 55S91, 52A35,We study conditions under which a finite simplicial complex $K$ can be mapped\nto $\\mathbb R^d$ without higher-multiplicity intersections. An almost\n$r$-embedding is a map $f: K\\to \\mathbb R^d$ such that the images of any $r$\npairwise disjoint simplices of $K$ do not have a common point. We show that if\n$r$ is not a prime power and $d\\geq 2r+1$, then there is a counterexample to\nthe topological Tverberg conjecture, i.e., there is an almost $r$-embedding of\nthe $(d+1)(r-1)$-simplex in $\\mathbb R^d$. This improves on previous\nconstructions of counterexamples (for $d\\geq 3r$) based on a series of papers\nby M. \\\"Ozaydin, M. Gromov, P. Blagojevi\\'c, F. Frick, G. Ziegler, and the\nsecond and fourth present authors.\n  The counterexamples are obtained by proving the following algebraic criterion\nin codimension 2: If $r\\ge3$ and if $K$ is a finite $2(r-1)$-complex then there\nexists an almost $r$-embedding $K\\to \\mathbb R^{2r}$ if and only if there\nexists a general position PL map $f:K\\to \\mathbb R^{2r}$ such that the\nalgebraic intersection number of the $f$-images of any $r$ pairwise disjoint\nsimplices of $K$ is zero. This result can be restated in terms of cohomological\nobstructions or equivariant maps, and extends an analogous codimension 3\ncriterion by the second and fourth authors. As another application we classify\nornaments $f:S^3 \\sqcup S^3\\sqcup S^3\\to \\mathbb R^5$ up to ornament\nconcordance.\n  It follows from work of M. Freedman, V. Krushkal and P. Teichner that the\nanalogous criterion for $r=2$ is false. We prove a lemma on singular\nhigher-dimensional Borromean rings, yielding an elementary proof of the\ncounterexample.Comment: 24 pages, 4 figures, exposition improved", "1511.03518": "Diffusion-like recommendation with enhanced similarity of objects,An, Ya-HuiDong, QiangSun, Chong-JingNie, Da-ChengFu, Yan,Computer Science - Information RetrievalComputer Science - Social and Information Networks,In last decades, diversity and accuracy have been regarded as two important\nmeasures in evaluating a recommendation model. However, a clear concern is that\na model focusing excessively on one measure will put the other one at risk,\nthus it is not easy to greatly improve diversity and accuracy simultaneously.\nIn this paper, we propose to enhance the Resource-Allocation (RA) similarity in\nresource transfer equations of diffusion-like models, by giving a tunable\nexponent to the RA similarity, and traversing the value of the exponent to\nachieve the optimal recommendation results. In this way, we can increase the\nrecommendation scores (allocated resource) of many unpopular objects.\nExperiments on three benchmark data sets, MovieLens, Netflix, and RateYourMusic\nshow that the modified models can yield remarkable performance improvement\ncompared with the original ones.", "1511.03693": "Game characterizations and lower cones in the Weihrauch degrees,Nobrega, HugoPauly, Arno,Mathematics - LogicComputer Science - Logic in Computer Science03E15, 54H05, 03D60, 03F15,We introduce a parametrized version of the Wadge game for functions and show\nthat each lower cone in the Weihrauch degrees is characterized by such a game.\nThese parametrized Wadge games subsume the original Wadge game, the eraser and\nbacktrack games as well as Semmes's tree games. In particular, we propose that\nthe lower cones in the Weihrauch degrees are the answer to Andretta's question\non which classes of functions admit game characterizations. We then discuss\nsome applications of such parametrized Wadge games. Using machinery from\nWeihrauch reducibility theory, we introduce games characterizing every\n(transfinite) level of the Baire hierarchy via an iteration of a pruning\nderivative on countably branching trees.", "1511.03894": "The Game of Phishing,Kilcullen, Joseph,Computer Science - Cryptography and Security,The current implementation of TLS involves your browser displaying a padlock,\nand a green bar, after successfully verifying the digital signature on the TLS\ncertificate. Proposed is a solution where your browser's response to successful\nverification of a TLS certificate is to display a login window. That login\nwindow displays the identity credentials from the TLS certificate, to allow the\nuser to authenticate Bob. It also displays a 'user-browser' shared secret i.e.\na specific picture from your hard disk. This is not SiteKey, the image is\nshared between the computer user and their browser. It is never transmitted\nover the internet. Since sandboxed websites cannot access your hard disk this\nimage cannot be counterfeited by phishing websites. Basically if you view the\ninstalled software component of your browser as an actor in the cryptography\nprotocol, then the solution to phishing attacks is classic cryptography, as\ndocumented in any cryptography textbook.Comment: Published in International Journal on Cryptography and Information\n  Security (IJCIS)", "1511.04731": "Hardness of RNA Folding Problem with Four Symbols,Chang, Yi-Jun,Computer Science - Computational ComplexityComputer Science - Data Structures and Algorithms,An RNA sequence is a string composed of four types of nucleotides, $A, C, G$,\nand $U$. The goal of the RNA folding problem is to find a maximum cardinality\nset of crossing-free pairs of the form $\\{A,U\\}$ or $\\{C,G\\}$ in a given RNA\nsequence. The problem is central in bioinformatics and has received much\nattention over the years. Abboud, Backurs, and Williams (FOCS 2015)\ndemonstrated a conditional lower bound for a generalized version of the RNA\nfolding problem based on a conjectured hardness of the $k$-clique problem.\nTheir lower bound requires the RNA sequence to have at least 36 types of\nsymbols, making the result not applicable to the RNA folding problem in real\nlife (i.e., alphabet size 4). In this paper, we present an improved lower bound\nthat works for the alphabet size 4 case.\n  We also investigate the Dyck edit distance problem, which is a string problem\nclosely related to RNA folding. We demonstrate a reduction from RNA folding to\nDyck edit distance with alphabet size 10. This leads to a much simpler proof of\nthe conditional lower bound for Dyck edit distance problem given by Abboud,\nBackurs, and Williams (FOCS 2015), and lowers the alphabet size requirement.", "1511.04798": "Heterogeneous Knowledge Transfer in Video Emotion Recognition,\n  Attribution and Summarization,Xu, BaohanFu, YanweiJiang, Yu-GangLi, BoyangSigal, Leonid,Computer Science - Computer Vision and Pattern RecognitionComputer Science - Artificial IntelligenceComputer Science - Multimedia,Emotion is a key element in user-generated videos. However, it is difficult\nto understand emotions conveyed in such videos due to the complex and\nunstructured nature of user-generated content and the sparsity of video frames\nexpressing emotion. In this paper, for the first time, we study the problem of\ntransferring knowledge from heterogeneous external sources, including image and\ntextual data, to facilitate three related tasks in understanding video emotion:\nemotion recognition, emotion attribution and emotion-oriented summarization.\nSpecifically, our framework (1) learns a video encoding from an auxiliary\nemotional image dataset in order to improve supervised video emotion\nrecognition, and (2) transfers knowledge from an auxiliary textual corpora for\nzero-shot recognition of emotion classes unseen during training. The proposed\ntechnique for knowledge transfer facilitates novel applications of emotion\nattribution and emotion-oriented summarization. A comprehensive set of\nexperiments on multiple datasets demonstrate the effectiveness of our\nframework.Comment: 13 pages, 11 figures. Published at the IEEE Transactions on Affective\n  Computing", "1511.04855": "Deep learning is a good steganalysis tool when embedding key is reused\n  for different images, even if there is a cover source-mismatch,Pibre, LionelJ\u00e9r\u00f4me, PasquetIenco, DinoChaumont, Marc,Computer Science - MultimediaComputer Science - Computer Vision and Pattern RecognitionComputer Science - Machine LearningComputer Science - Neural and Evolutionary Computing,Since the BOSS competition, in 2010, most steganalysis approaches use a\nlearning methodology involving two steps: feature extraction, such as the Rich\nModels (RM), for the image representation, and use of the Ensemble Classifier\n(EC) for the learning step. In 2015, Qian et al. have shown that the use of a\ndeep learning approach that jointly learns and computes the features, is very\npromising for the steganalysis. In this paper, we follow-up the study of Qian\net al., and show that, due to intrinsic joint minimization, the results\nobtained from a Convolutional Neural Network (CNN) or a Fully Connected Neural\nNetwork (FNN), if well parameterized, surpass the conventional use of a RM with\nan EC. First, numerous experiments were conducted in order to find the best \"\nshape \" of the CNN. Second, experiments were carried out in the clairvoyant\nscenario in order to compare the CNN and FNN to an RM with an EC. The results\nshow more than 16% reduction in the classification error with our CNN or FNN.\nThird, experiments were also performed in a cover-source mismatch setting. The\nresults show that the CNN and FNN are naturally robust to the mismatch problem.\nIn Addition to the experiments, we provide discussions on the internal\nmechanisms of a CNN, and weave links with some previously stated ideas, in\norder to understand the impressive results we obtained.Comment: IS&T. Media Watermarking, Security, and Forensics, Part of IS&T\n  International Symposium on Electronic Imaging, EI'2016, Feb 2015, San\n  Fransisco, United States", "1511.04944": "NASCUP: Nucleic Acid Sequence Classification by Universal Probability,Kwon, SunyoungKim, GyuwanLee, ByunghanChun, JongsikYoon, SungrohKim, Young-Han,Quantitative Biology - GenomicsComputer Science - Information Theory,Motivated by the need for fast and accurate classification of unlabeled\nnucleotide sequences on a large scale, we developed NASCUP, a new\nclassification method that captures statistical structures of nucleotide\nsequences by compact context-tree models and universal probability from\ninformation theory. NASCUP achieved BLAST-like classification accuracy\nconsistently for several large-scale databases in orders-of-magnitude reduced\nruntime, and was applied to other bioinformatics tasks such as outlier\ndetection and synthetic sequence generation.", "1511.05174": "Cross-scale predictive dictionaries,Saragadam, VishwanathLi, XinSankaranarayanan, Aswin,Computer Science - Computer Vision and Pattern RecognitionStatistics - Machine Learning,Sparse representations using data dictionaries provide an efficient model\nparticularly for signals that do not enjoy alternate analytic sparsifying\ntransformations. However, solving inverse problems with sparsifying\ndictionaries can be computationally expensive, especially when the dictionary\nunder consideration has a large number of atoms. In this paper, we incorporate\nadditional structure on to dictionary-based sparse representations for visual\nsignals to enable speedups when solving sparse approximation problems. The\nspecific structure that we endow onto sparse models is that of a multi-scale\nmodeling where the sparse representation at each scale is constrained by the\nsparse representation at coarser scales. We show that this cross-scale\npredictive model delivers significant speedups, often in the range of\n10-60$\\times$, with little loss in accuracy for linear inverse problems\nassociated with images, videos, and light fields.Comment: 12 pages", "1511.05432": "Understanding Adversarial Training: Increasing Local Stability of Neural\n  Nets through Robust Optimization,Shaham, UriYamada, YutaroNegahban, Sahand,Statistics - Machine LearningComputer Science - Machine LearningComputer Science - Neural and Evolutionary Computing,We propose a general framework for increasing local stability of Artificial\nNeural Nets (ANNs) using Robust Optimization (RO). We achieve this through an\nalternating minimization-maximization procedure, in which the loss of the\nnetwork is minimized over perturbed examples that are generated at each\nparameter update. We show that adversarial training of ANNs is in fact\nrobustification of the network optimization, and that our proposed framework\ngeneralizes previous approaches for increasing local stability of ANNs.\nExperimental results reveal that our approach increases the robustness of the\nnetwork to existing adversarial examples, while making it harder to generate\nnew ones. Furthermore, our algorithm improves the accuracy of the network also\non the original test data.", "1511.05546": "Complexity and Approximability of Parameterized MAX-CSPs,Dell, HolgerKim, Eun JungLampis, MichaelMitsou, ValiaM\u00f6mke, Tobias,Computer Science - Computational ComplexityComputer Science - Data Structures and Algorithms,We study the optimization version of constraint satisfaction problems\n(Max-CSPs) in the framework of parameterized complexity; the goal is to compute\nthe maximum fraction of constraints that can be satisfied simultaneously. In\nstandard CSPs, we want to decide whether this fraction equals one. The\nparameters we investigate are structural measures, such as the treewidth or the\nclique-width of the variable-constraint incidence graph of the CSP instance.\n  We consider Max-CSPs with the constraint types AND, OR, PARITY, and MAJORITY,\nand with various parameters k, and we attempt to fully classify them into the\nfollowing three cases: 1. The exact optimum can be computed in FPT time. 2. It\nis W[1]-hard to compute the exact optimum, but there is a randomized FPT\napproximation scheme (FPTAS), which computes a $(1-\\epsilon)$-approximation in\ntime $f(k,\\epsilon)\\cdot poly(n)$. 3. There is no FPTAS unless FPT=W[1].\n  For the corresponding standard CSPs, we establish FPT vs. W[1]-hardness\nresults.Comment: Appeared in IPEC 2015", "1511.05635": "Competitive Multi-scale Convolution,Liao, ZhibinCarneiro, Gustavo,Computer Science - Computer Vision and Pattern RecognitionComputer Science - Machine LearningComputer Science - Neural and Evolutionary Computing,In this paper, we introduce a new deep convolutional neural network (ConvNet)\nmodule that promotes competition among a set of multi-scale convolutional\nfilters. This new module is inspired by the inception module, where we replace\nthe original collaborative pooling stage (consisting of a concatenation of the\nmulti-scale filter outputs) by a competitive pooling represented by a maxout\nactivation unit. This extension has the following two objectives: 1) the\nselection of the maximum response among the multi-scale filters prevents filter\nco-adaptation and allows the formation of multiple sub-networks within the same\nmodel, which has been shown to facilitate the training of complex learning\nproblems; and 2) the maxout unit reduces the dimensionality of the outputs from\nthe multi-scale filters. We show that the use of our proposed module in typical\ndeep ConvNets produces classification results that are either better than or\ncomparable to the state of the art on the following benchmark datasets: MNIST,\nCIFAR-10, CIFAR-100 and SVHN.", "1511.05646": "The Invisible Hand of Dynamic Market Pricing,Cohen-Addad, VincentEden, AlonFeldman, MichalFiat, Amos,Computer Science - Computer Science and Game TheoryComputer Science - Data Structures and Algorithms,Walrasian prices, if they exist, have the property that one can assign every\nbuyer some bundle in her demand set, such that the resulting assignment will\nmaximize social welfare. Unfortunately, this assumes carefully breaking ties\namongst different bundles in the buyer demand set. Presumably, the shopkeeper\ncleverly convinces the buyer to break ties in a manner consistent with\nmaximizing social welfare. Lacking such a shopkeeper, if buyers arrive\nsequentially and simply choose some arbitrary bundle in their demand set, the\nsocial welfare may be arbitrarily bad. In the context of matching markets, we\nshow how to compute dynamic prices, based upon the current inventory, that\nguarantee that social welfare is maximized. Such prices are set without knowing\nthe identity of the next buyer to arrive. We also show that this is impossible\nin general (e.g., for coverage valuations), but consider other scenarios where\nthis can be done. We further extend our results to Bayesian and bounded\nrationality models.", "1511.05710": "Complex-Valued Gaussian Processes for Regression,Boloix-Tortosa, RafaelArias-de-Reyna, EvaPayan-Somet, F. JavierMurillo-Fuentes, Juan J.,Computer Science - Machine Learning,In this paper we propose a novel Bayesian solution for nonlinear regression\nin complex fields. Previous solutions for kernels methods usually assume a\ncomplexification approach, where the real-valued kernel is replaced by a\ncomplex-valued one. This approach is limited. Based on results in\ncomplex-valued linear theory and Gaussian random processes we show that a\npseudo-kernel must be included. This is the starting point to develop the new\ncomplex-valued formulation for Gaussian process for regression (CGPR). We face\nthe design of the covariance and pseudo-covariance based on a convolution\napproach and for several scenarios. Just in the particular case where the\noutputs are proper, the pseudo-kernel cancels. Also, the hyperparameters of the\ncovariance {can be learnt} maximizing the marginal likelihood using Wirtinger's\ncalculus and patterned complex-valued matrix derivatives. In the experiments\nincluded, we show how CGPR successfully solve systems where real and imaginary\nparts are correlated. Besides, we successfully solve the nonlinear channel\nequalization problem by developing a recursive solution with basis removal. We\nreport remarkable improvements compared to previous solutions: a 2-4 dB\nreduction of the MSE with {just a quarter} of the training samples used by\nprevious approaches.Comment: 13 pages, 18 figures", "1511.06030": "BIRDNEST: Bayesian Inference for Ratings-Fraud Detection,Hooi, BryanShah, NeilBeutel, AlexGunnemann, StephanAkoglu, LemanKumar, MohitMakhija, DishaFaloutsos, Christos,Computer Science - Artificial IntelligenceComputer Science - Social and Information Networks,Review fraud is a pervasive problem in online commerce, in which fraudulent\nsellers write or purchase fake reviews to manipulate perception of their\nproducts and services. Fake reviews are often detected based on several signs,\nincluding 1) they occur in short bursts of time; 2) fraudulent user accounts\nhave skewed rating distributions. However, these may both be true in any given\ndataset. Hence, in this paper, we propose an approach for detecting fraudulent\nreviews which combines these 2 approaches in a principled manner, allowing\nsuccessful detection even when one of these signs is not present. To combine\nthese 2 approaches, we formulate our Bayesian Inference for Rating Data (BIRD)\nmodel, a flexible Bayesian model of user rating behavior. Based on our model we\nformulate a likelihood-based suspiciousness metric, Normalized Expected\nSurprise Total (NEST). We propose a linear-time algorithm for performing\nBayesian inference using our model and computing the metric. Experiments on\nreal data show that BIRDNEST successfully spots review fraud in large,\nreal-world graphs: the 50 most suspicious users of the Flipkart platform\nflagged by our algorithm were investigated and all identified as fraudulent by\ndomain experts at Flipkart.Comment: 9 pages; v2: minor typos corrected", "1511.06033": "EigenRec: Generalizing PureSVD for Effective and Efficient Top-N\n  Recommendations,Nikolakopoulos, Athanasios N.Kalantzis, VassilisGallopoulos, EfstratiosGarofalakis, John D.,Computer Science - Information RetrievalComputer Science - DatabasesComputer Science - Distributed, Parallel, and Cluster ComputingComputer Science - Numerical AnalysisComputer Science - Social and Information NetworksH.3.3H.2.8G.1.3,We introduce EigenRec; a versatile and efficient Latent-Factor framework for\nTop-N Recommendations that includes the well-known PureSVD algorithm as a\nspecial case. EigenRec builds a low dimensional model of an inter-item\nproximity matrix that combines a similarity component, with a scaling operator,\ndesigned to control the influence of the prior item popularity on the final\nmodel. Seeing PureSVD within our framework provides intuition about its inner\nworkings, exposes its inherent limitations, and also, paves the path towards\npainlessly improving its recommendation performance. A comprehensive set of\nexperiments on the MovieLens and the Yahoo datasets based on widely applied\nperformance metrics, indicate that EigenRec outperforms several\nstate-of-the-art algorithms, in terms of Standard and Long-Tail recommendation\naccuracy, exhibiting low susceptibility to sparsity, even in its most extreme\nmanifestations -- the Cold-Start problems. At the same time EigenRec has an\nattractive computational profile and it can apply readily in large-scale\nrecommendation settings.Comment: 23 pages. Journal version of the conference paper \"Factored Proximity\n  Models for Top-N Recommendation\"", "1511.06324": "Global Convergence of ADMM in Nonconvex Nonsmooth Optimization,Wang, YuYin, WotaoZeng, Jinshan,Mathematics - Optimization and ControlComputer Science - Numerical AnalysisMathematics - Numerical Analysis,In this paper, we analyze the convergence of the alternating direction method\nof multipliers (ADMM) for minimizing a nonconvex and possibly nonsmooth\nobjective function, $\\phi(x_0,\\ldots,x_p,y)$, subject to coupled linear\nequality constraints. Our ADMM updates each of the primal variables\n$x_0,\\ldots,x_p,y$, followed by updating the dual variable. We separate the\nvariable $y$ from $x_i$'s as it has a special role in our analysis.\n  The developed convergence guarantee covers a variety of nonconvex functions\nsuch as piecewise linear functions, $\\ell_q$ quasi-norm, Schatten-$q$\nquasi-norm ($0<q<1$), minimax concave penalty (MCP), and smoothly clipped\nabsolute deviation (SCAD) penalty. It also allows nonconvex constraints such as\ncompact manifolds (e.g., spherical, Stiefel, and Grassman manifolds) and linear\ncomplementarity constraints. Also, the $x_0$-block can be almost any lower\nsemi-continuous function.\n  By applying our analysis, we show, for the first time, that several ADMM\nalgorithms applied to solve nonconvex models in statistical learning,\noptimization on manifold, and matrix decomposition are guaranteed to converge.\n  Our results provide sufficient conditions for ADMM to converge on (convex or\nnonconvex) monotropic programs with three or more blocks, as they are special\ncases of our model.\n  ADMM has been regarded as a variant to the augmented Lagrangian method (ALM).\nWe present a simple example to illustrate how ADMM converges but ALM diverges\nwith bounded penalty parameter $\\beta$. Indicated by this example and other\nanalysis in this paper, ADMM might be a better choice than ALM for some\nnonconvex \\emph{nonsmooth} problems, because ADMM is not only easier to\nimplement, it is also more likely to converge for the concerned scenarios.Comment: 33 pages, 1 figure, Accepted by Journal of Scientific Computing", "1511.06382": "Iterative Refinement of the Approximate Posterior for Directed Belief\n  Networks,Hjelm, R DevonCho, KyunghyunChung, JunyoungSalakhutdinov, RussCalhoun, VinceJojic, Nebojsa,Computer Science - Machine LearningStatistics - Machine Learning,Variational methods that rely on a recognition network to approximate the\nposterior of directed graphical models offer better inference and learning than\nprevious methods. Recent advances that exploit the capacity and flexibility in\nthis approach have expanded what kinds of models can be trained. However, as a\nproposal for the posterior, the capacity of the recognition network is limited,\nwhich can constrain the representational power of the generative model and\nincrease the variance of Monte Carlo estimates. To address these issues, we\nintroduce an iterative refinement procedure for improving the approximate\nposterior of the recognition network and show that training with the refined\nposterior is competitive with state-of-the-art methods. The advantages of\nrefinement are further evident in an increased effective sample size, which\nimplies a lower variance of gradient estimates.", "1511.06436": "On the robust hardness of Gr\\\"obner basis computation,Spencer, GwenRolnick, David,Computer Science - Symbolic Computation,The computation of Gr\\\"obner bases is an established hard problem. By\ncontrast with many other problems, however, there has been little investigation\nof whether this hardness is robust. In this paper, we frame and present results\non the problem of approximate computation of Gr\\\"obner bases. We show that it\nis NP-hard to construct a Gr\\\"obner basis of the ideal generated by a set of\npolynomials, even when the algorithm is allowed to discard a $(1 - \\epsilon)$\nfraction of the generators, and likewise when the algorithm is allowed to\ndiscard variables (and the generators containing them). Our results shows that\ncomputation of Gr\\\"obner bases is robustly hard even for simple polynomial\nsystems (e.g. maximum degree 2, with at most 3 variables per generator). We\nconclude by greatly strengthening results for the Strong $c$-Partial Gr\\\"obner\nproblem posed by De Loera et al. Our proofs also establish interesting\nconnections between the robust hardness of Gr\\\"obner bases and that of SAT\nvariants and graph-coloring.Comment: 19 pages", "1511.06444": "Universal halting times in optimization and machine learning,Sagun, LeventTrogdon, ThomasLeCun, Yann,Computer Science - Machine LearningMathematics - Numerical AnalysisMathematics - Probability65K10, 82D30, 37E20,The authors present empirical distributions for the halting time (measured by\nthe number of iterations to reach a given accuracy) of optimization algorithms\napplied to two random systems: spin glasses and deep learning. Given an\nalgorithm, which we take to be both the optimization routine and the form of\nthe random landscape, the fluctuations of the halting time follow a\ndistribution that, after centering and scaling, remains unchanged even when the\ndistribution on the landscape is changed. We observe two qualitative classes: A\nGumbel-like distribution that appears in Google searches, human decision times,\nthe QR eigenvalue algorithm and spin glasses, and a Gaussian-like distribution\nthat appears in conjugate gradient method, deep network with MNIST input data\nand deep network with random input data. This empirical evidence suggests\npresence of a class of distributions for which the halting time is independent\nof the underlying distribution under some conditions.", "1511.06489": "A Simple Hierarchical Pooling Data Structure for Loop Closure,Fei, XiaohanTsotsos, KonstantineSoatto, Stefano,Computer Science - Computer Vision and Pattern RecognitionComputer Science - Robotics,We propose a data structure obtained by hierarchically averaging bag-of-word\ndescriptors during a sequence of views that achieves average speedups in\nlarge-scale loop closure applications ranging from 4 to 20 times on benchmark\ndatasets. Although simple, the method works as well as sophisticated\nagglomerative schemes at a fraction of the cost with minimal loss of\nperformance.", "1511.06653": "Recurrent Semi-supervised Classification and Constrained Adversarial\n  Generation with Motion Capture Data,Harvey, F\u00e9lix G.Roy, JulienKanaa, DavidPal, Christopher,Computer Science - Computer Vision and Pattern RecognitionComputer Science - Machine Learning,We explore recurrent encoder multi-decoder neural network architectures for\nsemi-supervised sequence classification and reconstruction. We find that the\nuse of multiple reconstruction modules helps models generalize in a\nclassification task when only a small amount of labeled data is available,\nwhich is often the case in practice. Such models provide useful high-level\nrepresentations of motions allowing clustering, searching and faster labeling\nof new sequences. We also propose a new, realistic partitioning of a\nwell-known, high quality motion-capture dataset for better evaluations. We\nfurther explore a novel formulation for future-predicting decoders based on\nconditional recurrent generative adversarial networks, for which we propose\nboth soft and hard constraints for transition generation derived from desired\nphysical properties of synthesized future movements and desired animation\ngoals. We find that using such constraints allow to stabilize the training of\nrecurrent adversarial architectures for animation generation.Comment: IVC Journal Submission", "1511.06860": "Convex Sparse Spectral Clustering: Single-view to Multi-view,Lu, CanyiYan, ShuichengLin, Zhouchen,Computer Science - Computer Vision and Pattern Recognition,Spectral Clustering (SC) is one of the most widely used methods for data\nclustering. It first finds a low-dimensonal embedding $U$ of data by computing\nthe eigenvectors of the normalized Laplacian matrix, and then performs k-means\non $U^\\top$ to get the final clustering result. In this work, we observe that,\nin the ideal case, $UU^\\top$ should be block diagonal and thus sparse.\nTherefore we propose the Sparse Spectral Clustering (SSC) method which extends\nSC with sparse regularization on $UU^\\top$. To address the computational issue\nof the nonconvex SSC model, we propose a novel convex relaxation of SSC based\non the convex hull of the fixed rank projection matrices. Then the convex SSC\nmodel can be efficiently solved by the Alternating Direction Method of\n\\canyi{Multipliers} (ADMM). Furthermore, we propose the Pairwise Sparse\nSpectral Clustering (PSSC) which extends SSC to boost the clustering\nperformance by using the multi-view information of data. Experimental\ncomparisons with several baselines on real-world datasets testify to the\nefficacy of our proposed methods.", "1511.06971": "A General Framework for the Design and Analysis of Sparse FIR Linear\n  Equalizers,Al-Abbasi, Abubakr O.Hamila, RidhaBajwa, Waheed U.Al-Dhahir, Naofal,Computer Science - Information Theory,Complexity of linear finite-impulse-response (FIR) equalizers is proportional\nto the square of the number of nonzero taps in the filter. This makes\nequalization of channels with long impulse responses using either zero-forcing\nor minimum mean square error (MMSE) filters computationally expensive. Sparse\nequalization is a widely-used technique to solve this problem. In this paper, a\ngeneral framework is provided that transforms the problem of sparse linear\nequalizers (LEs) design into the problem of sparsest-approximation of a vector\nin different dictionaries. In addition, some possible choices of sparsifying\ndictionaries in this framework are discussed. Furthermore, the worst-case\ncoherence of some of these dictionaries, which determines their sparsifying\nstrength, are analytically and/or numerically evaluated. Finally, the\nusefulness of the proposed framework for the design of sparse FIR LEs is\nvalidated through numerical experiments.Comment: 7 pages, 4 figures, IEEE GlobalSIP'15 Conference", "1511.07174": "Developing a High Performance Software Library with MPI and CUDA for\n  Matrix Computations,Oancea, BogdanAndrei, Tudorel,Computer Science - Distributed, Parallel, and Cluster ComputingComputer Science - Mathematical Software,Nowadays, the paradigm of parallel computing is changing. CUDA is now a\npopular programming model for general purpose computations on GPUs and a great\nnumber of applications were ported to CUDA obtaining speedups of orders of\nmagnitude comparing to optimized CPU implementations. Hybrid approaches that\ncombine the message passing model with the shared memory model for parallel\ncomputing are a solution for very large applications. We considered a\nheterogeneous cluster that combines the CPU and GPU computations using MPI and\nCUDA for developing a high performance linear algebra library. Our library\ndeals with large linear systems solvers because they are a common problem in\nthe fields of science and engineering. Direct methods for computing the\nsolution of such systems can be very expensive due to high memory requirements\nand computational cost. An efficient alternative are iterative methods which\ncomputes only an approximation of the solution. In this paper we present an\nimplementation of a library that uses a hybrid model of computation using MPI\nand CUDA implementing both direct and iterative linear systems solvers. Our\nlibrary implements LU and Cholesky factorization based solvers and some of the\nnon-stationary iterative methods using the MPI/CUDA combination. We compared\nthe performance of our MPI/CUDA implementation with classic programs written to\nbe run on a single CPU.Comment: in Computational Methods for Social Sciences, VOL. I, ISSUE 2/2013", "1511.07212": "Face Alignment Across Large Poses: A 3D Solution,Zhu, XiangyuLei, ZhenLiu, XiaomingShi, HailinLi, Stan Z.,Computer Science - Computer Vision and Pattern Recognition,Face alignment, which fits a face model to an image and extracts the semantic\nmeanings of facial pixels, has been an important topic in CV community.\nHowever, most algorithms are designed for faces in small to medium poses (below\n45 degree), lacking the ability to align faces in large poses up to 90 degree.\nThe challenges are three-fold: Firstly, the commonly used landmark-based face\nmodel assumes that all the landmarks are visible and is therefore not suitable\nfor profile views. Secondly, the face appearance varies more dramatically\nacross large poses, ranging from frontal view to profile view. Thirdly,\nlabelling landmarks in large poses is extremely challenging since the invisible\nlandmarks have to be guessed. In this paper, we propose a solution to the three\nproblems in an new alignment framework, called 3D Dense Face Alignment (3DDFA),\nin which a dense 3D face model is fitted to the image via convolutional neutral\nnetwork (CNN). We also propose a method to synthesize large-scale training\nsamples in profile views to solve the third problem of data labelling.\nExperiments on the challenging AFLW database show that our approach achieves\nsignificant improvements over state-of-the-art methods.Comment: 11 pages, 10 figures", "1511.07860": "Super-Linear Gate and Super-Quadratic Wire Lower Bounds for Depth-Two\n  and Depth-Three Threshold Circuits,Kane, Daniel M.Williams, Ryan,Computer Science - Computational ComplexityComputer Science - Neural and Evolutionary Computing68Q17C.1.3F.1.3,In order to formally understand the power of neural computing, we first need\nto crack the frontier of threshold circuits with two and three layers, a regime\nthat has been surprisingly intractable to analyze. We prove the first\nsuper-linear gate lower bounds and the first super-quadratic wire lower bounds\nfor depth-two linear threshold circuits with arbitrary weights, and depth-three\nmajority circuits computing an explicit function.\n  $\\bullet$ We prove that for all $\\epsilon\\gg \\sqrt{\\log(n)/n}$, the\nlinear-time computable Andreev's function cannot be computed on a\n$(1/2+\\epsilon)$-fraction of $n$-bit inputs by depth-two linear threshold\ncircuits of $o(\\epsilon^3 n^{3/2}/\\log^3 n)$ gates, nor can it be computed with\n$o(\\epsilon^{3} n^{5/2}/\\log^{7/2} n)$ wires. This establishes an average-case\n``size hierarchy'' for threshold circuits, as Andreev's function is computable\nby uniform depth-two circuits of $o(n^3)$ linear threshold gates, and by\nuniform depth-three circuits of $O(n)$ majority gates.\n  $\\bullet$ We present a new function in $P$ based on small-biased sets, which\nwe prove cannot be computed by a majority vote of depth-two linear threshold\ncircuits with $o(n^{3/2}/\\log^3 n)$ gates, nor with $o(n^{5/2}/\\log^{7/2}n)$\nwires.\n  $\\bullet$ We give tight average-case (gate and wire) complexity results for\ncomputing PARITY with depth-two threshold circuits; the answer turns out to be\nthe same as for depth-two majority circuits.\n  The key is a new random restriction lemma for linear threshold functions. Our\nmain analytical tool is the Littlewood-Offord Lemma from additive\ncombinatorics.", "1511.08152": "Max-Cut under Graph Constraints,Lee, JonNagarajan, ViswanathShen, Xiangkun,Computer Science - Data Structures and Algorithms,An instance of the graph-constrained max-cut (GCMC) problem consists of (i)\nan undirected graph G and (ii) edge-weights on a complete undirected graph on\nthe same vertex set. The objective is to find a subset of vertices satisfying\nsome graph-based constraint in G that maximizes the total weight of edges in\nthe cut. The types of graph constraints we can handle include independent set,\nvertex cover, dominating set and connectivity. Our main results are for the\ncase when G is a graph with bounded treewidth, where we obtain a\n0.5-approximation algorithm. Our algorithm uses an LP relaxation based on the\nSherali-Adams hierarchy. It can handle any graph constraint for which there is\na (certain type of) dynamic program that exactly optimizes linear objectives.\nUsing known decomposition results, these imply essentially the same\napproximation ratio for GCMC under constraints such as independent set,\ndominating set and connectivity on a planar graph G (more generally for\nbounded-genus or excluded-minor graphs).", "1511.08189": "Graph Isomorphism and Circuit Size,Allender, EricGrochow, Joshua A.van Melkebeek, DieterMoore, CristopherMorgan, Andrew,Computer Science - Computational Complexity,It is well-known [KST93] that the complexity of the Graph Automorphism\nproblem is characterized by a special case of Graph Isomorphism, where the\ninput graphs satisfy the \"promise\" of being rigid (that is, having no\nnontrivial automorphisms). In this brief note, we observe that the reduction of\nGraph Automorphism to the Rigid Graph Ismorphism problem can be accomplished\neven using Grollman and Selman's notion of a \"smart reduction\".Comment: 6 pages", "1511.08280": "Welfare of Sequential Allocation Mechanisms for Indivisible Goods,Aziz, HarisKalinowski, ThomasWalsh, TobyXia, Lirong,Computer Science - Artificial IntelligenceComputer Science - Computer Science and Game Theory,Sequential allocation is a simple and attractive mechanism for the allocation\nof indivisible goods. Agents take turns, according to a policy, to pick items.\nSequential allocation is guaranteed to return an allocation which is efficient\nbut may not have an optimal social welfare. We consider therefore the relation\nbetween welfare and efficiency. We study the (computational) questions of what\nwelfare is possible or necessary depending on the choice of policy. We also\nconsider a novel control problem in which the chair chooses a policy to improve\nsocial welfare.", "1511.08416": "Who Can Win a Single-Elimination Tournament?,Kim, Michael P.Suksompong, WarutWilliams, Virginia Vassilevska,Computer Science - Computer Science and Game Theory,A single-elimination (SE) tournament is a popular way to select a winner in\nboth sports competitions and in elections. A natural and well-studied question\nis the tournament fixing problem (TFP): given the set of all pairwise match\noutcomes, can a tournament organizer rig an SE tournament by adjusting the\ninitial seeding so that their favorite player wins? We prove new sufficient\nconditions on the pairwise match outcome information and the favorite player,\nunder which there is guaranteed to be a seeding where the player wins the\ntournament. Our results greatly generalize previous results. We also\ninvestigate the relationship between the set of players that can win an SE\ntournament under some seeding (so called SE winners) and other traditional\ntournament solutions. In addition, we generalize and strengthen prior work on\nprobabilistic models for generating tournaments. For instance, we show that\n\\emph{every} player in an $n$ player tournament generated by the Condorcet\nRandom Model will be an SE winner even when the noise is as small as possible,\n$p=\\Theta(\\ln n/n)$; prior work only had such results for $p\\geq\n\\Omega(\\sqrt{\\ln n/n})$. We also establish new results for significantly more\ngeneral generative models.Comment: A preliminary version appeared in Proceedings of the 30th AAAI\n  Conference on Artificial Intelligence (AAAI), 2016", "1511.08575": "A Modified Multiple OLS (m$^2$OLS) Algorithm for Signal Recovery in\n  Compressive Sensing,Mukhopadhyay, SamratSatpathi, SiddharthaChakraborty, Mrityunjoy,Computer Science - Information TheoryStatistics - Methodology,Orthogonal least square (OLS) is an important sparse signal recovery\nalgorithm for compressive sensing, which enjoys superior probability of success\nover other well-known recovery algorithms under conditions of correlated\nmeasurement matrices. Multiple OLS (mOLS) is a recently proposed improved\nversion of OLS which selects multiple candidates per iteration by generalizing\nthe greedy selection principle used in OLS and enjoys faster convergence than\nOLS. In this paper, we present a refined version of the mOLS algorithm where at\neach step of the iteration, we first preselect a submatrix of the measurement\nmatrix suitably and then apply the mOLS computations to the chosen submatrix.\nSince mOLS now works only on a submatrix and not on the overall matrix,\ncomputations reduce drastically. Convergence of the algorithm, however,\nrequires ensuring passage of true candidates through the two stages of\npreselection and mOLS based selection successively. This paper presents\nconvergence conditions for both noisy and noise free signal models. The\nproposed algorithm enjoys faster convergence properties similar to mOLS, at a\nmuch reduced computational complexity.Comment: 15 pages, 7 figures, journal, added new material, changed few\n  figures, changed title, some minor changes in writing", "1511.08585": "Real-Time Residential-Side Joint Energy Storage Management and Load\n  Scheduling with Renewable Integration,Li, TianyiDong, Min,Computer Science - Systems and Control,We consider joint energy storage management and load scheduling at a\nresidential site with integrated renewable generation. Assuming unknown\narbitrary dynamics of renewable source, loads, and electricity price, we aim at\noptimizing the load scheduling and energy storage control simultaneously in\norder to minimize the overall system cost within a finite time period. Besides\nincorporating battery operational constraints and costs, we model each\nindividual load task by its requested power intensity and service durations, as\nwell as the maximum and average delay requirements. To tackle this finite time\nhorizon stochastic problem, we propose a real-time scheduling and storage\ncontrol solution by applying a sequence of modification and transformation to\nemploy Lyapunov optimization that otherwise is not directly applicable. With\nour proposed algorithm, we show that the joint load scheduling and energy\nstorage control can in fact be separated and sequentially determined.\nFurthermore, both scheduling and energy control decisions have closed-form\nsolutions for simple implementation. Through analysis, we show that our\nproposed real-time algorithm has a bounded performance guarantee from the\noptimal T-slot look-ahead solution and is asymptotically equivalent to it as\nthe battery capacity and time period goes to infinity. The effectiveness of\njoint load scheduling and energy storage control by our proposed algorithm is\ndemonstrated through simulation as compared with alternative algorithms.Comment: to appear in IEEE Transactions on Smart Grid", "1511.08861": "Loss Functions for Neural Networks for Image Processing,Zhao, HangGallo, OrazioFrosio, IuriKautz, Jan,Computer Science - Computer Vision and Pattern Recognition,Neural networks are becoming central in several areas of computer vision and\nimage processing and different architectures have been proposed to solve\nspecific problems. The impact of the loss layer of neural networks, however,\nhas not received much attention in the context of image processing: the default\nand virtually only choice is L2. In this paper, we bring attention to\nalternative choices for image restoration. In particular, we show the\nimportance of perceptually-motivated losses when the resulting image is to be\nevaluated by a human observer. We compare the performance of several losses,\nand propose a novel, differentiable error function. We show that the quality of\nthe results improves significantly with better loss functions, even when the\nnetwork architecture is left unchanged.Comment: This paper was published in IEEE Transactions on Computational\n  Imaging on December 23, 2016", "1511.08887": "On the Degrees of Freedom of the Symmetric Multi-Relay MIMO Y Channel,Ding, TianYuan, XiaojunLiew, Soung Chang,Computer Science - Information Theory,In this paper, we study the degrees of freedom (DoF) of the symmetric\nmulti-relay multiple-input multiple-output (MIMO) Y channel, where three user\nnodes, each with M antennas, communicate via K geographically separated relay\nnodes, each with N antennas. For this model, we establish a general DoF\nachievability framework based on linear precoding and post-processing methods.\nThe framework poses a nonlinear problem with respect to user precoders and\npost-processors, as well as relay precoders. To solve this problem, we adopt an\nuplink-downlink asymmetric strategy, where the user precoders are designed for\nsignal alignment and the user post-processors are used for interference\nneutralization. With the user precoder and post-processor designs fixed as\nsuch, the original problem then reduces to a problem of relay precoder design.\nTo address the solvability of the system, we propose a general method for\nsolving matrix equations. This method is also useful to the DoF analysis of\nmany other multiway relay networks. Together with the techniques of antenna\ndisablement and symbol extension, an achievable DoF of the symmetric\nmulti-relay MIMO Y channel is derived for an arbitrary setup of (K, M, N). We\nshow that, for K >= 2, the optimal DoF is achieved for M/N in [0,\nmax{sqrt(3K)/3,1}) and [(3K+sqrt(9K^2-12K))/6,infinity). We also show that the\nuplink-downlink asymmetric design proposed in this paper considerably\noutperforms the conventional approach based on uplink-downlink symmetry.Comment: 30 pages, 5 figures, submitted to IEEE Trans. Wireless Communication", "1511.09156": "Constant-approximation algorithms for highly connected multi-dominating\n  sets in unit disk graphs,Fukunaga, Takuro,Computer Science - Data Structures and Algorithms,Given an undirected graph on a node set $V$ and positive integers $k$ and\n$m$, a $k$-connected $m$-dominating set ($(k,m)$-CDS) is defined as a subset\n$S$ of $V$ such that each node in $V \\setminus S$ has at least $m$ neighbors in\n$S$, and a $k$-connected subgraph is induced by $S$. The weighted $(k,m)$-CDS\nproblem is to find a minimum weight $(k,m)$-CDS in a given node-weighted graph.\nThe problem is called the unweighted $(k,m)$-CDS problem if the objective is to\nminimize the cardinality of a $(k,m)$-CDS. These problems have been actively\nstudied for unit disk graphs, motivated by the application of constructing a\nvirtual backbone in a wireless ad hoc network. However, constant-approximation\nalgorithms are known only for $k \\leq 3$ in the unweighted $(k,m)$-CDS problem,\nand for $(k,m)=(1,1)$ in the weighted $(k,m)$-CDS problem. In this paper, we\nconsider the case in which $m \\geq k$, and we present a simple $O(5^k\nk!)$-approximation algorithm for the unweighted $(k,m)$-CDS problem, and a\nprimal-dual $O(k^2 \\log k)$-approximation algorithm for the weighted\n$(k,m)$-CDS problem. Both algorithms achieve constant approximation factors\nwhen $k$ is a fixed constant.", "1511.09259": "The Alternating Stock Size Problem and the Gasoline Puzzle,Newman, AlanthaR\u00f6glin, HeikoSeif, Johanna,Computer Science - Data Structures and Algorithms,Given a set S of integers whose sum is zero, consider the problem of finding\na permutation of these integers such that: (i) all prefix sums of the ordering\nare nonnegative, and (ii) the maximum value of a prefix sum is minimized.\nKellerer et al. referred to this problem as the \"Stock Size Problem\" and showed\nthat it can be approximated to within 3/2. They also showed that an\napproximation ratio of 2 can be achieved via several simple algorithms.\n  We consider a related problem, which we call the \"Alternating Stock Size\nProblem\", where the number of positive and negative integers in the input set S\nare equal. The problem is the same as above, but we are additionally required\nto alternate the positive and negative numbers in the output ordering. This\nproblem also has several simple 2-approximations. We show that it can be\napproximated to within 1.79.\n  Then we show that this problem is closely related to an optimization version\nof the gasoline puzzle due to Lov\\'asz, in which we want to minimize the size\nof the gas tank necessary to go around the track. We present a 2-approximation\nfor this problem, using a natural linear programming relaxation whose feasible\nsolutions are doubly stochastic matrices. Our novel rounding algorithm is based\non a transformation that yields another doubly stochastic matrix with special\nproperties, from which we can extract a suitable permutation.", "1511.09324": "Isomorphisms considered as equalities: Projecting functions and\n  enhancing partial application through and implementation of lambda+,D\u00edaz-Caro, AlejandroL\u00f3pez, Pablo E. Mart\u00ednez,Computer Science - Logic in Computer ScienceF.4.1,We propose an implementation of lambda+, a recently introduced simply typed\nlambda-calculus with pairs where isomorphic types are made equal. The rewrite\nsystem of lambda+ is a rewrite system modulo an equivalence relation, which\nmakes its implementation non-trivial. We also extend lambda+ with natural\nnumbers and general recursion and use Beki\\'c's theorem to split mutual\nrecursions. This splitting, together with the features of lambda+, allows for a\nnovel way of program transformation by reduction, by projecting a function\nbefore it is applied in order to simplify it. Also, currying together with the\nassociativity and commutativity of pairs gives an enhanced form of partial\napplication.Comment: A prototype writen in Haskell can be found at\n  http://diaz-caro.web.unq.edu.ar/IsoAsEq-v1.0.tar.gz", "1512.00135": "Entropies of weighted sums in cyclic groups and an application to polar\n  codes,Abbe, EmmanuelLi, JiangeMadiman, Mokshay,Computer Science - Information Theory,In this note, the following basic question is explored: in a cyclic group,\nhow are the Shannon entropies of the sum and difference of i.i.d. random\nvariables related to each other? For the integer group, we show that they can\ndiffer by any real number additively, but not too much multiplicatively; on the\nother hand, for $\\mathbb{Z}/3\\mathbb{Z}$, the entropy of the difference is\nalways at least as large as that of the sum. These results are closely related\nto the study of more-sum-than-difference (i.e. MSTD) sets in additive\ncombinatorics. We also investigate polar codes for $q$-ary input channels using\nnon-canonical kernels to construct the generator matrix, and present\napplications of our results to constructing polar codes with significantly\nimproved error probability compared to the canonical construction.", "1512.00327": "Technical Privacy Metrics: a Systematic Survey,Wagner, IsabelEckhoff, David,Computer Science - Cryptography and SecurityComputer Science - Information TheoryComputer Science - Performance,The goal of privacy metrics is to measure the degree of privacy enjoyed by\nusers in a system and the amount of protection offered by privacy-enhancing\ntechnologies. In this way, privacy metrics contribute to improving user privacy\nin the digital world. The diversity and complexity of privacy metrics in the\nliterature makes an informed choice of metrics challenging. As a result,\ninstead of using existing metrics, new metrics are proposed frequently, and\nprivacy studies are often incomparable. In this survey we alleviate these\nproblems by structuring the landscape of privacy metrics. To this end, we\nexplain and discuss a selection of over eighty privacy metrics and introduce\ncategorizations based on the aspect of privacy they measure, their required\ninputs, and the type of data that needs protection. In addition, we present a\nmethod on how to choose privacy metrics based on nine questions that help\nidentify the right privacy metrics for a given scenario, and highlight topics\nwhere additional work on privacy metrics is needed. Our survey spans multiple\nprivacy domains and can be understood as a general framework for privacy\nmeasurement."}